begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertFalse
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Supplier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsClientConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsClientConfigKeys
operator|.
name|BlockWrite
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|BlockUCState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DataNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DataNodeFaultInjector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DataNodeTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|ReplicaInPipeline
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|LeaseExpiredException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamenodeProtocols
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|tools
operator|.
name|DFSAdmin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|GenericTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|mockito
operator|.
name|Mockito
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * This tests pipeline recovery related client protocol works correct or not.  */
end_comment

begin_class
DECL|class|TestClientProtocolForPipelineRecovery
specifier|public
class|class
name|TestClientProtocolForPipelineRecovery
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TestClientProtocolForPipelineRecovery
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|method|testGetNewStamp ()
annotation|@
name|Test
specifier|public
name|void
name|testGetNewStamp
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|numDataNodes
init|=
literal|1
decl_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|MiniDFSCluster
name|cluster
init|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|numDataNodes
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
try|try
block|{
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|NamenodeProtocols
name|namenode
init|=
name|cluster
operator|.
name|getNameNodeRpc
argument_list|()
decl_stmt|;
comment|/* Test writing to finalized replicas */
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"dataprotocol.dat"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|1L
argument_list|,
operator|(
name|short
operator|)
name|numDataNodes
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
comment|// get the first blockid for the file
name|ExtendedBlock
name|firstBlock
init|=
name|DFSTestUtil
operator|.
name|getFirstBlock
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|)
decl_stmt|;
comment|// test getNewStampAndToken on a finalized block
try|try
block|{
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|firstBlock
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|fail
argument_list|(
literal|"Can not get a new GS from a finalized block"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
literal|"not "
operator|+
name|BlockUCState
operator|.
name|UNDER_CONSTRUCTION
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// test getNewStampAndToken on a non-existent block
try|try
block|{
name|long
name|newBlockId
init|=
name|firstBlock
operator|.
name|getBlockId
argument_list|()
operator|+
literal|1
decl_stmt|;
name|ExtendedBlock
name|newBlock
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|firstBlock
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|newBlockId
argument_list|,
literal|0
argument_list|,
name|firstBlock
operator|.
name|getGenerationStamp
argument_list|()
argument_list|)
decl_stmt|;
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|newBlock
argument_list|,
literal|""
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|fail
argument_list|(
literal|"Cannot get a new GS from a non-existent block"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
literal|"does not exist"
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/* Test RBW replicas */
comment|// change first block to a RBW
name|DFSOutputStream
name|out
init|=
literal|null
decl_stmt|;
try|try
block|{
name|out
operator|=
call|(
name|DFSOutputStream
call|)
argument_list|(
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|FSDataInputStream
name|in
init|=
literal|null
decl_stmt|;
try|try
block|{
name|in
operator|=
name|fileSys
operator|.
name|open
argument_list|(
name|file
argument_list|)
expr_stmt|;
name|firstBlock
operator|=
name|DFSTestUtil
operator|.
name|getAllBlocks
argument_list|(
name|in
argument_list|)
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getBlock
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
comment|// test non-lease holder
name|DFSClient
name|dfs
init|=
operator|(
operator|(
name|DistributedFileSystem
operator|)
name|fileSys
operator|)
operator|.
name|dfs
decl_stmt|;
try|try
block|{
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|firstBlock
argument_list|,
literal|"test"
operator|+
name|dfs
operator|.
name|clientName
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|fail
argument_list|(
literal|"Cannot get a new GS for a non lease holder"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LeaseExpiredException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"Lease mismatch"
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// test null lease holder
try|try
block|{
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|firstBlock
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|fail
argument_list|(
literal|"Cannot get a new GS for a null lease holder"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LeaseExpiredException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"Lease mismatch"
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// test getNewStampAndToken on a rbw block
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|firstBlock
argument_list|,
name|dfs
operator|.
name|clientName
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** Test whether corrupt replicas are detected correctly during pipeline    * recoveries.    */
annotation|@
name|Test
DECL|method|testPipelineRecoveryForLastBlock ()
specifier|public
name|void
name|testPipelineRecoveryForLastBlock
parameter_list|()
throws|throws
name|IOException
block|{
name|DFSClientFaultInjector
name|faultInjector
init|=
name|Mockito
operator|.
name|mock
argument_list|(
name|DFSClientFaultInjector
operator|.
name|class
argument_list|)
decl_stmt|;
name|DFSClientFaultInjector
name|oldInjector
init|=
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
decl_stmt|;
name|DFSClientFaultInjector
operator|.
name|set
argument_list|(
name|faultInjector
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|BlockWrite
operator|.
name|LOCATEFOLLOWINGBLOCK_RETRIES_KEY
argument_list|,
literal|3
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|numDataNodes
init|=
literal|3
decl_stmt|;
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|numDataNodes
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"dataprotocol1.dat"
argument_list|)
decl_stmt|;
name|Mockito
operator|.
name|when
argument_list|(
name|faultInjector
operator|.
name|failPacket
argument_list|()
argument_list|)
operator|.
name|thenReturn
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|68000000L
argument_list|,
operator|(
name|short
operator|)
name|numDataNodes
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
comment|// At this point, NN should have accepted only valid replicas.
comment|// Read should succeed.
name|FSDataInputStream
name|in
init|=
name|fileSys
operator|.
name|open
argument_list|(
name|file
argument_list|)
decl_stmt|;
try|try
block|{
name|in
operator|.
name|read
argument_list|()
expr_stmt|;
comment|// Test will fail with BlockMissingException if NN does not update the
comment|// replica state based on the latest report.
block|}
catch|catch
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|BlockMissingException
name|bme
parameter_list|)
block|{
name|Assert
operator|.
name|fail
argument_list|(
literal|"Block is missing because the file was closed with"
operator|+
literal|" corrupt replicas."
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|DFSClientFaultInjector
operator|.
name|set
argument_list|(
name|oldInjector
argument_list|)
expr_stmt|;
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Test
DECL|method|testPacketTransmissionDelay ()
specifier|public
name|void
name|testPacketTransmissionDelay
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Make the first datanode to not relay heartbeat packet.
name|DataNodeFaultInjector
name|dnFaultInjector
init|=
operator|new
name|DataNodeFaultInjector
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|dropHeartbeatPacket
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
block|}
decl_stmt|;
name|DataNodeFaultInjector
name|oldDnInjector
init|=
name|DataNodeFaultInjector
operator|.
name|get
argument_list|()
decl_stmt|;
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
name|dnFaultInjector
argument_list|)
expr_stmt|;
comment|// Setting the timeout to be 3 seconds. Normally heartbeat packet
comment|// would be sent every 1.5 seconds if there is no data traffic.
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_SOCKET_TIMEOUT_KEY
argument_list|,
literal|"3000"
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|numDataNodes
init|=
literal|2
decl_stmt|;
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|numDataNodes
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fs
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
literal|"noheartbeat.dat"
argument_list|)
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|0x31
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|DFSOutputStream
name|dfsOut
init|=
operator|(
name|DFSOutputStream
operator|)
name|out
operator|.
name|getWrappedStream
argument_list|()
decl_stmt|;
comment|// original pipeline
name|DatanodeInfo
index|[]
name|orgNodes
init|=
name|dfsOut
operator|.
name|getPipeline
argument_list|()
decl_stmt|;
comment|// Cause the second datanode to timeout on reading packet
name|Thread
operator|.
name|sleep
argument_list|(
literal|3500
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|0x32
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
comment|// new pipeline
name|DatanodeInfo
index|[]
name|newNodes
init|=
name|dfsOut
operator|.
name|getPipeline
argument_list|()
decl_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
name|boolean
name|contains
init|=
literal|false
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|newNodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|orgNodes
index|[
literal|0
index|]
operator|.
name|getXferAddr
argument_list|()
operator|.
name|equals
argument_list|(
name|newNodes
index|[
name|i
index|]
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The first datanode should have been replaced."
argument_list|)
throw|;
block|}
if|if
condition|(
name|orgNodes
index|[
literal|1
index|]
operator|.
name|getXferAddr
argument_list|()
operator|.
name|equals
argument_list|(
name|newNodes
index|[
name|i
index|]
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
name|contains
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|Assert
operator|.
name|assertTrue
argument_list|(
name|contains
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
name|oldDnInjector
argument_list|)
expr_stmt|;
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Test recovery on restart OOB message. It also tests the delivery of     * OOB ack originating from the primary datanode. Since there is only    * one node in the cluster, failure of restart-recovery will fail the    * test.    */
annotation|@
name|Test
DECL|method|testPipelineRecoveryOnOOB ()
specifier|public
name|void
name|testPipelineRecoveryOnOOB
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_DATANODE_RESTART_TIMEOUT_KEY
argument_list|,
literal|"15"
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|numDataNodes
init|=
literal|1
decl_stmt|;
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|numDataNodes
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"dataprotocol2.dat"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|10240L
argument_list|,
operator|(
name|short
operator|)
literal|1
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
name|DFSOutputStream
name|out
init|=
call|(
name|DFSOutputStream
call|)
argument_list|(
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|DFSAdmin
name|dfsadmin
init|=
operator|new
name|DFSAdmin
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|DataNode
name|dn
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|String
name|dnAddr
init|=
name|dn
operator|.
name|getDatanodeId
argument_list|()
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// issue shutdown to the datanode.
specifier|final
name|String
index|[]
name|args1
init|=
block|{
literal|"-shutdownDatanode"
block|,
name|dnAddr
block|,
literal|"upgrade"
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|dfsadmin
operator|.
name|run
argument_list|(
name|args1
argument_list|)
argument_list|)
expr_stmt|;
comment|// Wait long enough to receive an OOB ack before closing the file.
name|GenericTestUtils
operator|.
name|waitForThreadTermination
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
comment|// Retart the datanode
name|cluster
operator|.
name|restartDataNode
argument_list|(
literal|0
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// The following forces a data packet and end of block packets to be sent.
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Test that the writer is kicked out of a node.    */
annotation|@
name|Test
DECL|method|testEvictWriter ()
specifier|public
name|void
name|testEvictWriter
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
operator|(
name|int
operator|)
literal|3
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fs
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"testEvictWriter.dat"
argument_list|)
decl_stmt|;
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
name|file
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|0x31
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
comment|// get nodes in the pipeline
name|DFSOutputStream
name|dfsOut
init|=
operator|(
name|DFSOutputStream
operator|)
name|out
operator|.
name|getWrappedStream
argument_list|()
decl_stmt|;
name|DatanodeInfo
index|[]
name|nodes
init|=
name|dfsOut
operator|.
name|getPipeline
argument_list|()
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|2
argument_list|,
name|nodes
operator|.
name|length
argument_list|)
expr_stmt|;
name|String
name|dnAddr
init|=
name|nodes
index|[
literal|1
index|]
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// evict the writer from the second datanode and wait until
comment|// the pipeline is rebuilt.
name|DFSAdmin
name|dfsadmin
init|=
operator|new
name|DFSAdmin
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|String
index|[]
name|args1
init|=
block|{
literal|"-evictWriters"
block|,
name|dnAddr
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|dfsadmin
operator|.
name|run
argument_list|(
name|args1
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|0x31
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
comment|// get the new pipline and check the node is not in there.
name|nodes
operator|=
name|dfsOut
operator|.
name|getPipeline
argument_list|()
expr_stmt|;
try|try
block|{
name|Assert
operator|.
name|assertTrue
argument_list|(
name|nodes
operator|.
name|length
operator|>
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Assert
operator|.
name|assertFalse
argument_list|(
name|dnAddr
operator|.
name|equals
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/** Test restart timeout */
annotation|@
name|Test
DECL|method|testPipelineRecoveryOnRestartFailure ()
specifier|public
name|void
name|testPipelineRecoveryOnRestartFailure
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_DATANODE_RESTART_TIMEOUT_KEY
argument_list|,
literal|"5"
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|numDataNodes
init|=
literal|2
decl_stmt|;
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|numDataNodes
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"dataprotocol3.dat"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|10240L
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
name|DFSOutputStream
name|out
init|=
call|(
name|DFSOutputStream
call|)
argument_list|(
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|DFSAdmin
name|dfsadmin
init|=
operator|new
name|DFSAdmin
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|DataNode
name|dn
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|String
name|dnAddr1
init|=
name|dn
operator|.
name|getDatanodeId
argument_list|()
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// issue shutdown to the datanode.
specifier|final
name|String
index|[]
name|args1
init|=
block|{
literal|"-shutdownDatanode"
block|,
name|dnAddr1
block|,
literal|"upgrade"
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|dfsadmin
operator|.
name|run
argument_list|(
name|args1
argument_list|)
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitForThreadTermination
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
comment|// This should succeed without restarting the node. The restart will
comment|// expire and regular pipeline recovery will kick in.
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// At this point there is only one node in the cluster.
name|out
operator|=
call|(
name|DFSOutputStream
call|)
argument_list|(
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|dn
operator|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|1
argument_list|)
expr_stmt|;
specifier|final
name|String
name|dnAddr2
init|=
name|dn
operator|.
name|getDatanodeId
argument_list|()
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// issue shutdown to the datanode.
specifier|final
name|String
index|[]
name|args2
init|=
block|{
literal|"-shutdownDatanode"
block|,
name|dnAddr2
block|,
literal|"upgrade"
block|}
decl_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|dfsadmin
operator|.
name|run
argument_list|(
name|args2
argument_list|)
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitForThreadTermination
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
try|try
block|{
comment|// close should fail
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
assert|assert
literal|false
assert|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{ }
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    *  HDFS-9752. The client keeps sending heartbeat packets during datanode    *  rolling upgrades. The client should be able to retry pipeline recovery    *  more times than the default.    *  (in a row for the same packet, including the heartbeat packet)    *  (See{@link DataStreamer#pipelineRecoveryCount})    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|60000
argument_list|)
DECL|method|testPipelineRecoveryOnDatanodeUpgrade ()
specifier|public
name|void
name|testPipelineRecoveryOnDatanodeUpgrade
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
literal|2
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"/testPipelineRecoveryOnDatanodeUpgrade"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|10240L
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
specifier|final
name|DFSOutputStream
name|out
init|=
call|(
name|DFSOutputStream
call|)
argument_list|(
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
specifier|final
name|long
name|oldGs
init|=
name|out
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
decl_stmt|;
name|MiniDFSCluster
operator|.
name|DataNodeProperties
name|dnProps
init|=
name|cluster
operator|.
name|stopDataNodeForUpgrade
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|GenericTestUtils
operator|.
name|waitForThreadTermination
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|restartDataNode
argument_list|(
name|dnProps
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
comment|// wait pipeline to be recovered
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
operator|new
name|Supplier
argument_list|<
name|Boolean
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Boolean
name|get
parameter_list|()
block|{
return|return
name|out
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
operator|>
name|oldGs
return|;
block|}
block|}
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"The pipeline recovery count shouldn't increase"
argument_list|,
literal|0
argument_list|,
name|out
operator|.
name|getStreamer
argument_list|()
operator|.
name|getPipelineRecoveryCount
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Test
DECL|method|testPipelineRecoveryOnRemoteDatanodeUpgrade ()
specifier|public
name|void
name|testPipelineRecoveryOnRemoteDatanodeUpgrade
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|BlockWrite
operator|.
name|ReplaceDatanodeOnFailure
operator|.
name|BEST_EFFORT_KEY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
name|DFSClientFaultInjector
name|old
init|=
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
decl_stmt|;
try|try
block|{
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
literal|3
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fileSys
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
literal|"/testPipelineRecoveryOnDatanodeUpgrade"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|10240L
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
comment|// treat all restarting nodes as remote for test.
name|DFSClientFaultInjector
operator|.
name|set
argument_list|(
operator|new
name|DFSClientFaultInjector
argument_list|()
block|{
specifier|public
name|boolean
name|skipRollingRestartWait
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
block|}
argument_list|)
expr_stmt|;
specifier|final
name|DFSOutputStream
name|out
init|=
operator|(
name|DFSOutputStream
operator|)
name|fileSys
operator|.
name|append
argument_list|(
name|file
argument_list|)
operator|.
name|getWrappedStream
argument_list|()
decl_stmt|;
specifier|final
name|AtomicBoolean
name|running
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|failed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|Thread
name|t
init|=
operator|new
name|Thread
argument_list|()
block|{
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|running
operator|.
name|get
argument_list|()
condition|)
block|{
try|try
block|{
name|out
operator|.
name|write
argument_list|(
literal|"test"
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
comment|// Keep writing data every one second
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception during write"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|failed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|running
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
decl_stmt|;
name|t
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// Let write start
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
name|DatanodeInfo
index|[]
name|pipeline
init|=
name|out
operator|.
name|getPipeline
argument_list|()
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|node
range|:
name|pipeline
control|)
block|{
name|assertFalse
argument_list|(
literal|"Write should be going on"
argument_list|,
name|failed
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|ArrayList
argument_list|<
name|DataNode
argument_list|>
name|dataNodes
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
decl_stmt|;
name|int
name|indexToShutdown
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|dataNodes
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|dataNodes
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getIpcPort
argument_list|()
operator|==
name|node
operator|.
name|getIpcPort
argument_list|()
condition|)
block|{
name|indexToShutdown
operator|=
name|i
expr_stmt|;
break|break;
block|}
block|}
comment|// Note old genstamp to findout pipeline recovery
specifier|final
name|long
name|oldGs
init|=
name|out
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
decl_stmt|;
name|MiniDFSCluster
operator|.
name|DataNodeProperties
name|dnProps
init|=
name|cluster
operator|.
name|stopDataNodeForUpgrade
argument_list|(
name|indexToShutdown
argument_list|)
decl_stmt|;
name|GenericTestUtils
operator|.
name|waitForThreadTermination
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|restartDataNode
argument_list|(
name|dnProps
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
comment|// wait pipeline to be recovered
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
operator|new
name|Supplier
argument_list|<
name|Boolean
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Boolean
name|get
parameter_list|()
block|{
return|return
name|out
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
operator|>
name|oldGs
return|;
block|}
block|}
argument_list|,
literal|100
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|assertEquals
argument_list|(
literal|"The pipeline recovery count shouldn't increase"
argument_list|,
literal|0
argument_list|,
name|out
operator|.
name|getStreamer
argument_list|()
operator|.
name|getPipelineRecoveryCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|assertFalse
argument_list|(
literal|"Write should be going on"
argument_list|,
name|failed
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|running
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|t
operator|.
name|join
argument_list|()
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|"testagain"
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"There should be atleast 2 nodes in pipeline still"
argument_list|,
name|out
operator|.
name|getPipeline
argument_list|()
operator|.
name|length
operator|>=
literal|2
argument_list|)
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|DFSClientFaultInjector
operator|.
name|set
argument_list|(
name|old
argument_list|)
expr_stmt|;
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Test to make sure the checksum is set correctly after pipeline    * recovery transfers 0 byte partial block. If fails the test case    * will say "java.io.IOException: Failed to replace a bad datanode    * on the existing pipeline due to no more good datanodes being    * available to try."  This indicates there was a real failure    * after the staged failure.    */
annotation|@
name|Test
DECL|method|testZeroByteBlockRecovery ()
specifier|public
name|void
name|testZeroByteBlockRecovery
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Make the first datanode fail once. With 3 nodes and a block being
comment|// created with 2 replicas, anything more than this planned failure
comment|// will cause a test failure.
name|DataNodeFaultInjector
name|dnFaultInjector
init|=
operator|new
name|DataNodeFaultInjector
argument_list|()
block|{
name|int
name|tries
init|=
literal|1
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|stopSendingPacketDownstream
parameter_list|(
specifier|final
name|String
name|mirrAddr
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|tries
operator|>
literal|0
condition|)
block|{
name|tries
operator|--
expr_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|60000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted while sleeping. Bailing out."
argument_list|)
throw|;
block|}
block|}
block|}
block|}
decl_stmt|;
name|DataNodeFaultInjector
name|oldDnInjector
init|=
name|DataNodeFaultInjector
operator|.
name|get
argument_list|()
decl_stmt|;
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
name|dnFaultInjector
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_SOCKET_TIMEOUT_KEY
argument_list|,
literal|"1000"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|BlockWrite
operator|.
name|ReplaceDatanodeOnFailure
operator|.
name|POLICY_KEY
argument_list|,
literal|"ALWAYS"
argument_list|)
expr_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
literal|3
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|FileSystem
name|fs
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
literal|"noheartbeat.dat"
argument_list|)
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|0x31
argument_list|)
expr_stmt|;
name|out
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
name|oldDnInjector
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Test to verify that blocks are no longer corrupted after HDFS-4660.
comment|// Revert HDFS-4660 and the other related ones (HDFS-9220, HDFS-8722), this
comment|// test would fail.
comment|// Scenario: Prior to the fix, block get corrupted when the transferBlock
comment|// happens during pipeline recovery with extra bytes to make up the end of
comment|// chunk.
comment|// For verification, Need to fail the pipeline for last datanode when the
comment|// second datanode have more bytes on disk than already acked bytes.
comment|// This will enable to transfer extra bytes to the newNode to makeup
comment|// end-of-chunk during pipeline recovery. This is achieved by the customized
comment|// DataNodeFaultInjector class in this test.
comment|// For detailed info, please refer to HDFS-4660 and HDFS-10587. HDFS-9220
comment|// fixes an issue in HDFS-4660 patch, and HDFS-8722 is an optimization.
annotation|@
name|Test
DECL|method|testPipelineRecoveryWithTransferBlock ()
specifier|public
name|void
name|testPipelineRecoveryWithTransferBlock
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|int
name|chunkSize
init|=
literal|512
decl_stmt|;
specifier|final
name|int
name|oneWriteSize
init|=
literal|5000
decl_stmt|;
specifier|final
name|int
name|totalSize
init|=
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|final
name|int
name|errorInjectionPos
init|=
literal|512
decl_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
comment|// Need 4 datanodes to verify the replaceDatanode during pipeline recovery
specifier|final
name|MiniDFSCluster
name|cluster
init|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
literal|4
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|DataNodeFaultInjector
name|old
init|=
name|DataNodeFaultInjector
operator|.
name|get
argument_list|()
decl_stmt|;
try|try
block|{
name|DistributedFileSystem
name|fs
init|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|Path
name|fileName
init|=
operator|new
name|Path
argument_list|(
literal|"/f"
argument_list|)
decl_stmt|;
name|FSDataOutputStream
name|o
init|=
name|fs
operator|.
name|create
argument_list|(
name|fileName
argument_list|)
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
comment|// Flush to get the pipeline created.
name|o
operator|.
name|writeBytes
argument_list|(
literal|"hello"
argument_list|)
expr_stmt|;
name|o
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|DFSOutputStream
name|dfsO
init|=
operator|(
name|DFSOutputStream
operator|)
name|o
operator|.
name|getWrappedStream
argument_list|()
decl_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|pipeline
init|=
name|dfsO
operator|.
name|getStreamer
argument_list|()
operator|.
name|getNodes
argument_list|()
decl_stmt|;
specifier|final
name|String
name|lastDn
init|=
name|pipeline
index|[
literal|2
index|]
operator|.
name|getXferAddr
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|failed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
operator|new
name|DataNodeFaultInjector
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|failPipeline
parameter_list|(
name|ReplicaInPipeline
name|replicaInfo
parameter_list|,
name|String
name|mirror
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|lastDn
operator|.
name|equals
argument_list|(
name|mirror
argument_list|)
condition|)
block|{
comment|// Only fail for second DN
return|return;
block|}
if|if
condition|(
operator|!
name|failed
operator|.
name|get
argument_list|()
operator|&&
operator|(
name|replicaInfo
operator|.
name|getBytesAcked
argument_list|()
operator|>
name|errorInjectionPos
operator|)
operator|&&
operator|(
name|replicaInfo
operator|.
name|getBytesAcked
argument_list|()
operator|%
name|chunkSize
operator|!=
literal|0
operator|)
condition|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|count
operator|<
literal|10
condition|)
block|{
comment|// Fail the pipeline (Throw exception) when:
comment|//   1. bytsAcked is not at chunk boundary (checked in the if
comment|//      statement above)
comment|//   2. bytesOnDisk is bigger than bytesAcked and at least
comment|//      reaches (or go beyond) the end of the chunk that
comment|//      bytesAcked is in (checked in the if statement below).
comment|// At this condition, transferBlock that happens during
comment|// pipeline recovery would transfer extra bytes to make up to the
comment|// end of the chunk. And this is when the block corruption
comment|// described in HDFS-4660 would occur.
if|if
condition|(
operator|(
name|replicaInfo
operator|.
name|getBytesOnDisk
argument_list|()
operator|/
name|chunkSize
operator|)
operator|-
operator|(
name|replicaInfo
operator|.
name|getBytesAcked
argument_list|()
operator|/
name|chunkSize
operator|)
operator|>=
literal|1
condition|)
block|{
name|failed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failing Pipeline "
operator|+
name|replicaInfo
operator|.
name|getBytesAcked
argument_list|()
operator|+
literal|" : "
operator|+
name|replicaInfo
operator|.
name|getBytesOnDisk
argument_list|()
argument_list|)
throw|;
block|}
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|200
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{               }
name|count
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|Random
name|r
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|oneWriteSize
index|]
decl_stmt|;
while|while
condition|(
name|count
operator|<
name|totalSize
condition|)
block|{
name|r
operator|.
name|nextBytes
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|o
operator|.
name|write
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|count
operator|+=
name|oneWriteSize
expr_stmt|;
name|o
operator|.
name|hflush
argument_list|()
expr_stmt|;
block|}
name|assertTrue
argument_list|(
literal|"Expected a failure in the pipeline"
argument_list|,
name|failed
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|DatanodeInfo
index|[]
name|newNodes
init|=
name|dfsO
operator|.
name|getStreamer
argument_list|()
operator|.
name|getNodes
argument_list|()
decl_stmt|;
name|o
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Trigger block report to NN
for|for
control|(
name|DataNode
name|d
range|:
name|cluster
operator|.
name|getDataNodes
argument_list|()
control|)
block|{
name|DataNodeTestUtils
operator|.
name|triggerBlockReport
argument_list|(
name|d
argument_list|)
expr_stmt|;
block|}
comment|// Read from the replaced datanode to verify the corruption. So shutdown
comment|// all other nodes in the pipeline.
name|List
argument_list|<
name|DatanodeInfo
argument_list|>
name|pipelineList
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|pipeline
argument_list|)
decl_stmt|;
name|DatanodeInfo
name|newNode
init|=
literal|null
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|node
range|:
name|newNodes
control|)
block|{
if|if
condition|(
operator|!
name|pipelineList
operator|.
name|contains
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|newNode
operator|=
name|node
expr_stmt|;
break|break;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of nodes in pipeline: {} newNode {}"
argument_list|,
name|newNodes
operator|.
name|length
argument_list|,
name|newNode
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|// shutdown old 2 nodes
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|newNodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|newNodes
index|[
name|i
index|]
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|newNode
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"shutdown {}"
argument_list|,
name|newNodes
index|[
name|i
index|]
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|stopDataNode
argument_list|(
name|newNodes
index|[
name|i
index|]
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Read should be successfull from only the newNode. There should not be
comment|// any corruption reported.
name|DFSTestUtil
operator|.
name|readFile
argument_list|(
name|fs
argument_list|,
name|fileName
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|DataNodeFaultInjector
operator|.
name|set
argument_list|(
name|old
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

