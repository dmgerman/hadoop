begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.datanode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|PlatformAssumptions
operator|.
name|assumeNotWindows
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|hamcrest
operator|.
name|core
operator|.
name|Is
operator|.
name|is
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertFalse
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertNotNull
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertThat
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|fail
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|filefilter
operator|.
name|TrueFileFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|ArrayUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|BlockReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|ClientContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSTestUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtilClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|RemotePeerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|impl
operator|.
name|BlockReaderFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|impl
operator|.
name|DfsClientConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|net
operator|.
name|Peer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|Block
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|BlockManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|BlockManagerTestUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|FsDatasetSpi
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|FsVolumeSpi
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|impl
operator|.
name|AddBlockPoolException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|impl
operator|.
name|FsDatasetTestUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|FSNamesystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamenodeProtocols
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|VolumeFailureSummary
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|GenericTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|rules
operator|.
name|Timeout
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Supplier
import|;
end_import

begin_comment
comment|/**  * Fine-grain testing of block files and locations after volume failure.  */
end_comment

begin_class
DECL|class|TestDataNodeVolumeFailure
specifier|public
class|class
name|TestDataNodeVolumeFailure
block|{
DECL|field|LOG
specifier|private
specifier|final
specifier|static
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TestDataNodeVolumeFailure
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|block_size
specifier|final
specifier|private
name|int
name|block_size
init|=
literal|512
decl_stmt|;
DECL|field|cluster
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
DECL|field|conf
specifier|private
name|Configuration
name|conf
decl_stmt|;
DECL|field|dn_num
specifier|final
name|int
name|dn_num
init|=
literal|2
decl_stmt|;
DECL|field|blocks_num
specifier|final
name|int
name|blocks_num
init|=
literal|30
decl_stmt|;
DECL|field|repl
specifier|final
name|short
name|repl
init|=
literal|2
decl_stmt|;
DECL|field|dataDir
name|File
name|dataDir
init|=
literal|null
decl_stmt|;
DECL|field|data_fail
name|File
name|data_fail
init|=
literal|null
decl_stmt|;
DECL|field|failedDir
name|File
name|failedDir
init|=
literal|null
decl_stmt|;
DECL|field|fs
specifier|private
name|FileSystem
name|fs
decl_stmt|;
comment|// mapping blocks to Meta files(physical files) and locs(NameNode locations)
DECL|class|BlockLocs
specifier|private
class|class
name|BlockLocs
block|{
DECL|field|num_files
specifier|public
name|int
name|num_files
init|=
literal|0
decl_stmt|;
DECL|field|num_locs
specifier|public
name|int
name|num_locs
init|=
literal|0
decl_stmt|;
block|}
comment|// block id to BlockLocs
DECL|field|block_map
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|BlockLocs
argument_list|>
name|block_map
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|BlockLocs
argument_list|>
argument_list|()
decl_stmt|;
comment|// specific the timeout for entire test class
annotation|@
name|Rule
DECL|field|timeout
specifier|public
name|Timeout
name|timeout
init|=
operator|new
name|Timeout
argument_list|(
literal|120
operator|*
literal|1000
argument_list|)
decl_stmt|;
annotation|@
name|Before
DECL|method|setUp ()
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
comment|// bring up a cluster of 2
name|conf
operator|=
operator|new
name|HdfsConfiguration
argument_list|()
expr_stmt|;
name|conf
operator|.
name|setLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_SIZE_KEY
argument_list|,
name|block_size
argument_list|)
expr_stmt|;
comment|// Allow a single volume failure (there are two volumes)
name|conf
operator|.
name|setInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_KEY
argument_list|,
literal|30
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setTimeDuration
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DISK_CHECK_MIN_GAP_KEY
argument_list|,
literal|0
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|dn_num
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|fs
operator|=
name|cluster
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
name|dataDir
operator|=
operator|new
name|File
argument_list|(
name|cluster
operator|.
name|getDataDirectory
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|After
DECL|method|tearDown ()
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|data_fail
operator|!=
literal|null
condition|)
block|{
name|FileUtil
operator|.
name|setWritable
argument_list|(
name|data_fail
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|data_fail
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|failedDir
operator|!=
literal|null
condition|)
block|{
name|FileUtil
operator|.
name|setWritable
argument_list|(
name|failedDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|failedDir
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|cluster
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/*    * Verify the number of blocks and files are correct after volume failure,    * and that we can replicate to both datanodes even after a single volume    * failure if the configuration parameter allows this.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
DECL|method|testVolumeFailure ()
specifier|public
name|void
name|testVolumeFailure
parameter_list|()
throws|throws
name|Exception
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Data dir: is "
operator|+
name|dataDir
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
comment|// Data dir structure is dataDir/data[1-4]/[current,tmp...]
comment|// data1,2 is for datanode 1, data2,3 - datanode2
name|String
name|filename
init|=
literal|"/test.txt"
decl_stmt|;
name|Path
name|filePath
init|=
operator|new
name|Path
argument_list|(
name|filename
argument_list|)
decl_stmt|;
comment|// we use only small number of blocks to avoid creating subdirs in the data dir..
name|int
name|filesize
init|=
name|block_size
operator|*
name|blocks_num
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|filePath
argument_list|,
name|filesize
argument_list|,
name|repl
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|filePath
argument_list|,
name|repl
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"file "
operator|+
name|filename
operator|+
literal|"(size "
operator|+
name|filesize
operator|+
literal|") is created and replicated"
argument_list|)
expr_stmt|;
comment|// fail the volume
comment|// delete/make non-writable one of the directories (failed volume)
name|data_fail
operator|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|1
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|failedDir
operator|=
name|MiniDFSCluster
operator|.
name|getFinalizedDir
argument_list|(
name|data_fail
argument_list|,
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|failedDir
operator|.
name|exists
argument_list|()
operator|&&
comment|//!FileUtil.fullyDelete(failedDir)
operator|!
name|deteteBlocks
argument_list|(
name|failedDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not delete hdfs directory '"
operator|+
name|failedDir
operator|+
literal|"'"
argument_list|)
throw|;
block|}
name|data_fail
operator|.
name|setReadOnly
argument_list|()
expr_stmt|;
name|failedDir
operator|.
name|setReadOnly
argument_list|()
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Deleteing "
operator|+
name|failedDir
operator|.
name|getPath
argument_list|()
operator|+
literal|"; exist="
operator|+
name|failedDir
operator|.
name|exists
argument_list|()
argument_list|)
expr_stmt|;
comment|// access all the blocks on the "failed" DataNode,
comment|// we need to make sure that the "failed" volume is being accessed -
comment|// and that will cause failure, blocks removal, "emergency" block report
name|triggerFailure
argument_list|(
name|filename
argument_list|,
name|filesize
argument_list|)
expr_stmt|;
comment|// DN eventually have latest volume failure information for next heartbeat
specifier|final
name|DataNode
name|dn
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
operator|new
name|Supplier
argument_list|<
name|Boolean
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Boolean
name|get
parameter_list|()
block|{
specifier|final
name|VolumeFailureSummary
name|summary
init|=
name|dn
operator|.
name|getFSDataset
argument_list|()
operator|.
name|getVolumeFailureSummary
argument_list|()
decl_stmt|;
return|return
name|summary
operator|!=
literal|null
operator|&&
name|summary
operator|.
name|getFailedStorageLocations
argument_list|()
operator|!=
literal|null
operator|&&
name|summary
operator|.
name|getFailedStorageLocations
argument_list|()
operator|.
name|length
operator|==
literal|1
return|;
block|}
block|}
argument_list|,
literal|10
argument_list|,
literal|30
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|// trigger DN to send heartbeat
name|DataNodeTestUtils
operator|.
name|triggerHeartbeat
argument_list|(
name|dn
argument_list|)
expr_stmt|;
specifier|final
name|BlockManager
name|bm
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockManager
argument_list|()
decl_stmt|;
comment|// trigger NN handel heartbeat
name|BlockManagerTestUtil
operator|.
name|checkHeartbeat
argument_list|(
name|bm
argument_list|)
expr_stmt|;
comment|// NN now should have latest volume failure
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getVolumeFailuresTotal
argument_list|()
argument_list|)
expr_stmt|;
comment|// verify number of blocks and files...
name|verify
argument_list|(
name|filename
argument_list|,
name|filesize
argument_list|)
expr_stmt|;
comment|// create another file (with one volume failed).
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"creating file test1.txt"
argument_list|)
expr_stmt|;
name|Path
name|fileName1
init|=
operator|new
name|Path
argument_list|(
literal|"/test1.txt"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|fileName1
argument_list|,
name|filesize
argument_list|,
name|repl
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
comment|// should be able to replicate to both nodes (2 DN, repl=2)
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|fileName1
argument_list|,
name|repl
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"file "
operator|+
name|fileName1
operator|.
name|getName
argument_list|()
operator|+
literal|" is created and replicated"
argument_list|)
expr_stmt|;
block|}
comment|/*    * If one of the sub-folders under the finalized directory is unreadable,    * either due to permissions or a filesystem corruption, the DN will fail    * to read it when scanning it for blocks to load into the replica map. This    * test ensures the DN does not exit and reports the failed volume to the    * NN (HDFS-14333). This is done by using a simulated FsDataset that throws    * an exception for a failed volume when the block pool is initialized.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|15000
argument_list|)
DECL|method|testDnStartsAfterDiskErrorScanningBlockPool ()
specifier|public
name|void
name|testDnStartsAfterDiskErrorScanningBlockPool
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Don't use the cluster configured in the setup() method for this test.
name|cluster
operator|.
name|shutdown
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|close
argument_list|()
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_FSDATASET_FACTORY_KEY
argument_list|,
name|BadDiskFSDataset
operator|.
name|Factory
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
specifier|final
name|MiniDFSCluster
name|localCluster
init|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|numDataNodes
argument_list|(
literal|1
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
try|try
block|{
name|localCluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|DataNode
name|dn
init|=
name|localCluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
try|try
block|{
name|localCluster
operator|.
name|waitDatanodeFullyStarted
argument_list|(
name|dn
argument_list|,
literal|3000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|e
parameter_list|)
block|{
name|fail
argument_list|(
literal|"Datanode did not get fully started"
argument_list|)
expr_stmt|;
block|}
name|assertTrue
argument_list|(
name|dn
operator|.
name|isDatanodeUp
argument_list|()
argument_list|)
expr_stmt|;
comment|// trigger DN to send heartbeat
name|DataNodeTestUtils
operator|.
name|triggerHeartbeat
argument_list|(
name|dn
argument_list|)
expr_stmt|;
specifier|final
name|BlockManager
name|bm
init|=
name|localCluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockManager
argument_list|()
decl_stmt|;
comment|// trigger NN handle heartbeat
name|BlockManagerTestUtil
operator|.
name|checkHeartbeat
argument_list|(
name|bm
argument_list|)
expr_stmt|;
comment|// NN now should have the failed volume
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|localCluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getVolumeFailuresTotal
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|localCluster
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Test that DataStorage and BlockPoolSliceStorage remove the failed volume    * after failure.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|150000
argument_list|)
DECL|method|testFailedVolumeBeingRemovedFromDataNode ()
specifier|public
name|void
name|testFailedVolumeBeingRemovedFromDataNode
parameter_list|()
throws|throws
name|Exception
block|{
comment|// The test uses DataNodeTestUtils#injectDataDirFailure() to simulate
comment|// volume failures which is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
name|Path
name|file1
init|=
operator|new
name|Path
argument_list|(
literal|"/test1"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|file1
argument_list|,
literal|1024
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|file1
argument_list|,
operator|(
name|short
operator|)
literal|2
argument_list|)
expr_stmt|;
name|File
name|dn0Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol1
argument_list|)
expr_stmt|;
name|DataNode
name|dn0
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol1
argument_list|)
argument_list|)
expr_stmt|;
comment|// Verify dn0Vol1 has been completely removed from DN0.
comment|// 1. dn0Vol1 is removed from DataStorage.
name|DataStorage
name|storage
init|=
name|dn0
operator|.
name|getStorage
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|storage
operator|.
name|getNumStorageDirs
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|storage
operator|.
name|getNumStorageDirs
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Storage
operator|.
name|StorageDirectory
name|sd
init|=
name|storage
operator|.
name|getStorageDir
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|assertFalse
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getAbsolutePath
argument_list|()
operator|.
name|startsWith
argument_list|(
name|dn0Vol1
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|final
name|String
name|bpid
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockPoolId
argument_list|()
decl_stmt|;
name|BlockPoolSliceStorage
name|bpsStorage
init|=
name|storage
operator|.
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|bpsStorage
operator|.
name|getNumStorageDirs
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bpsStorage
operator|.
name|getNumStorageDirs
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Storage
operator|.
name|StorageDirectory
name|sd
init|=
name|bpsStorage
operator|.
name|getStorageDir
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|assertFalse
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getAbsolutePath
argument_list|()
operator|.
name|startsWith
argument_list|(
name|dn0Vol1
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// 2. dn0Vol1 is removed from FsDataset
name|FsDatasetSpi
argument_list|<
name|?
extends|extends
name|FsVolumeSpi
argument_list|>
name|data
init|=
name|dn0
operator|.
name|getFSDataset
argument_list|()
decl_stmt|;
try|try
init|(
name|FsDatasetSpi
operator|.
name|FsVolumeReferences
name|vols
init|=
name|data
operator|.
name|getFsVolumeReferences
argument_list|()
init|)
block|{
for|for
control|(
name|FsVolumeSpi
name|volume
range|:
name|vols
control|)
block|{
name|assertFalse
argument_list|(
operator|new
name|File
argument_list|(
name|volume
operator|.
name|getStorageLocation
argument_list|()
operator|.
name|getUri
argument_list|()
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
operator|.
name|startsWith
argument_list|(
name|dn0Vol1
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// 3. all blocks on dn0Vol1 have been removed.
for|for
control|(
name|ReplicaInfo
name|replica
range|:
name|FsDatasetTestUtil
operator|.
name|getReplicas
argument_list|(
name|data
argument_list|,
name|bpid
argument_list|)
control|)
block|{
name|assertNotNull
argument_list|(
name|replica
operator|.
name|getVolume
argument_list|()
argument_list|)
expr_stmt|;
name|assertFalse
argument_list|(
operator|new
name|File
argument_list|(
name|replica
operator|.
name|getVolume
argument_list|()
operator|.
name|getStorageLocation
argument_list|()
operator|.
name|getUri
argument_list|()
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
operator|.
name|startsWith
argument_list|(
name|dn0Vol1
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// 4. dn0Vol1 is not in DN0's configuration and dataDirs anymore.
name|String
index|[]
name|dataDirStrs
init|=
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|dataDirStrs
operator|.
name|length
argument_list|)
expr_stmt|;
name|assertFalse
argument_list|(
name|dataDirStrs
index|[
literal|0
index|]
operator|.
name|contains
argument_list|(
name|dn0Vol1
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test DataNode stops when the number of failed volumes exceeds    * dfs.datanode.failed.volumes.tolerated .    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|10000
argument_list|)
DECL|method|testDataNodeShutdownAfterNumFailedVolumeExceedsTolerated ()
specifier|public
name|void
name|testDataNodeShutdownAfterNumFailedVolumeExceedsTolerated
parameter_list|()
throws|throws
name|Exception
block|{
comment|// The test uses DataNodeTestUtils#injectDataDirFailure() to simulate
comment|// volume failures which is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
comment|// make both data directories to fail on dn0
specifier|final
name|File
name|dn0Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|File
name|dn0Vol2
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol1
argument_list|,
name|dn0Vol2
argument_list|)
expr_stmt|;
name|DataNode
name|dn0
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol1
argument_list|)
argument_list|)
expr_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol2
argument_list|)
argument_list|)
expr_stmt|;
comment|// DN0 should stop after the number of failure disks exceed tolerated
comment|// value (1).
name|dn0
operator|.
name|checkDiskError
argument_list|()
expr_stmt|;
name|assertFalse
argument_list|(
name|dn0
operator|.
name|shouldRun
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test that DN does not shutdown, as long as failure volumes being hot swapped.    */
annotation|@
name|Test
DECL|method|testVolumeFailureRecoveredByHotSwappingVolume ()
specifier|public
name|void
name|testVolumeFailureRecoveredByHotSwappingVolume
parameter_list|()
throws|throws
name|Exception
block|{
comment|// The test uses DataNodeTestUtils#injectDataDirFailure() to simulate
comment|// volume failures which is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
specifier|final
name|File
name|dn0Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|File
name|dn0Vol2
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|1
argument_list|)
decl_stmt|;
specifier|final
name|DataNode
name|dn0
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|String
name|oldDataDirs
init|=
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
decl_stmt|;
comment|// Fail dn0Vol1 first.
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol1
argument_list|)
expr_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol1
argument_list|)
argument_list|)
expr_stmt|;
comment|// Hot swap out the failure volume.
name|String
name|dataDirs
init|=
name|dn0Vol2
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|assertThat
argument_list|(
name|dn0
operator|.
name|reconfigurePropertyImpl
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|dataDirs
argument_list|)
argument_list|,
name|is
argument_list|(
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|// Fix failure volume dn0Vol1 and remount it back.
name|DataNodeTestUtils
operator|.
name|restoreDataDirFromFailure
argument_list|(
name|dn0Vol1
argument_list|)
expr_stmt|;
name|assertThat
argument_list|(
name|dn0
operator|.
name|reconfigurePropertyImpl
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|oldDataDirs
argument_list|)
argument_list|,
name|is
argument_list|(
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|// Fail dn0Vol2. Now since dn0Vol1 has been fixed, DN0 has sufficient
comment|// resources, thus it should keep running.
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol2
argument_list|)
expr_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol2
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|dn0
operator|.
name|shouldRun
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test changing the number of volumes does not impact the disk failure    * tolerance.    */
annotation|@
name|Test
DECL|method|testTolerateVolumeFailuresAfterAddingMoreVolumes ()
specifier|public
name|void
name|testTolerateVolumeFailuresAfterAddingMoreVolumes
parameter_list|()
throws|throws
name|Exception
block|{
comment|// The test uses DataNodeTestUtils#injectDataDirFailure() to simulate
comment|// volume failures which is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
specifier|final
name|File
name|dn0Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|File
name|dn0Vol2
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|1
argument_list|)
decl_stmt|;
specifier|final
name|File
name|dn0VolNew
init|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"data_new"
argument_list|)
decl_stmt|;
specifier|final
name|DataNode
name|dn0
init|=
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|String
name|oldDataDirs
init|=
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
decl_stmt|;
comment|// Add a new volume to DN0
name|assertThat
argument_list|(
name|dn0
operator|.
name|reconfigurePropertyImpl
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|oldDataDirs
operator|+
literal|","
operator|+
name|dn0VolNew
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
argument_list|,
name|is
argument_list|(
name|dn0
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|// Fail dn0Vol1 first and hot swap it.
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol1
argument_list|)
expr_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol1
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|dn0
operator|.
name|shouldRun
argument_list|()
argument_list|)
expr_stmt|;
comment|// Fail dn0Vol2, now dn0 should stop, because we only tolerate 1 disk failure.
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn0Vol2
argument_list|)
expr_stmt|;
name|DataNodeTestUtils
operator|.
name|waitForDiskError
argument_list|(
name|dn0
argument_list|,
name|DataNodeTestUtils
operator|.
name|getVolume
argument_list|(
name|dn0
argument_list|,
name|dn0Vol2
argument_list|)
argument_list|)
expr_stmt|;
name|dn0
operator|.
name|checkDiskError
argument_list|()
expr_stmt|;
name|assertFalse
argument_list|(
name|dn0
operator|.
name|shouldRun
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test that there are under replication blocks after vol failures    */
annotation|@
name|Test
DECL|method|testUnderReplicationAfterVolFailure ()
specifier|public
name|void
name|testUnderReplicationAfterVolFailure
parameter_list|()
throws|throws
name|Exception
block|{
comment|// The test uses DataNodeTestUtils#injectDataDirFailure() to simulate
comment|// volume failures which is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
comment|// Bring up one more datanode
name|cluster
operator|.
name|startDataNodes
argument_list|(
name|conf
argument_list|,
literal|1
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
specifier|final
name|BlockManager
name|bm
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockManager
argument_list|()
decl_stmt|;
name|Path
name|file1
init|=
operator|new
name|Path
argument_list|(
literal|"/test1"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|file1
argument_list|,
literal|1024
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|file1
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|)
expr_stmt|;
comment|// Fail the first volume on both datanodes
name|File
name|dn1Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|File
name|dn2Vol1
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
literal|1
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|DataNodeTestUtils
operator|.
name|injectDataDirFailure
argument_list|(
name|dn1Vol1
argument_list|,
name|dn2Vol1
argument_list|)
expr_stmt|;
name|Path
name|file2
init|=
operator|new
name|Path
argument_list|(
literal|"/test2"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|file2
argument_list|,
literal|1024
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|file2
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
operator|new
name|Supplier
argument_list|<
name|Boolean
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Boolean
name|get
parameter_list|()
block|{
comment|// underReplicatedBlocks are due to failed volumes
name|long
name|underReplicatedBlocks
init|=
name|bm
operator|.
name|getLowRedundancyBlocksCount
argument_list|()
operator|+
name|bm
operator|.
name|getPendingReconstructionBlocksCount
argument_list|()
decl_stmt|;
if|if
condition|(
name|underReplicatedBlocks
operator|>
literal|0
condition|)
block|{
return|return
literal|true
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"There is no under replicated block after volume failure."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
argument_list|,
literal|500
argument_list|,
literal|60000
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test if there is volume failure, the DataNode will fail to start.    *    * We fail a volume by setting the parent directory non-writable.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
DECL|method|testDataNodeFailToStartWithVolumeFailure ()
specifier|public
name|void
name|testDataNodeFailToStartWithVolumeFailure
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Method to simulate volume failures is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
name|failedDir
operator|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"failedDir"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to fail a volume by setting it non-writable"
argument_list|,
name|failedDir
operator|.
name|mkdir
argument_list|()
operator|&&
name|failedDir
operator|.
name|setReadOnly
argument_list|()
argument_list|)
expr_stmt|;
name|startNewDataNodeWithDiskFailure
argument_list|(
operator|new
name|File
argument_list|(
name|failedDir
argument_list|,
literal|"newDir1"
argument_list|)
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * DataNode will start and tolerate one failing disk according to config.    *    * We fail a volume by setting the parent directory non-writable.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
DECL|method|testDNStartAndTolerateOneVolumeFailure ()
specifier|public
name|void
name|testDNStartAndTolerateOneVolumeFailure
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Method to simulate volume failures is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
name|failedDir
operator|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"failedDir"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to fail a volume by setting it non-writable"
argument_list|,
name|failedDir
operator|.
name|mkdir
argument_list|()
operator|&&
name|failedDir
operator|.
name|setReadOnly
argument_list|()
argument_list|)
expr_stmt|;
name|startNewDataNodeWithDiskFailure
argument_list|(
operator|new
name|File
argument_list|(
name|failedDir
argument_list|,
literal|"newDir1"
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test if data directory is not readable/writable, DataNode won't start.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
DECL|method|testDNFailToStartWithDataDirNonWritable ()
specifier|public
name|void
name|testDNFailToStartWithDataDirNonWritable
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Method to simulate volume failures is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
specifier|final
name|File
name|readOnlyDir
init|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"nonWritable"
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Set the data dir permission non-writable"
argument_list|,
name|readOnlyDir
operator|.
name|mkdir
argument_list|()
operator|&&
name|readOnlyDir
operator|.
name|setReadOnly
argument_list|()
argument_list|)
expr_stmt|;
name|startNewDataNodeWithDiskFailure
argument_list|(
operator|new
name|File
argument_list|(
name|readOnlyDir
argument_list|,
literal|"newDir1"
argument_list|)
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * DataNode will start and tolerate one non-writable data directory    * according to config.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
DECL|method|testDNStartAndTolerateOneDataDirNonWritable ()
specifier|public
name|void
name|testDNStartAndTolerateOneDataDirNonWritable
parameter_list|()
throws|throws
name|Exception
block|{
comment|// Method to simulate volume failures is currently not supported on Windows.
name|assumeNotWindows
argument_list|()
expr_stmt|;
specifier|final
name|File
name|readOnlyDir
init|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"nonWritable"
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Set the data dir permission non-writable"
argument_list|,
name|readOnlyDir
operator|.
name|mkdir
argument_list|()
operator|&&
name|readOnlyDir
operator|.
name|setReadOnly
argument_list|()
argument_list|)
expr_stmt|;
name|startNewDataNodeWithDiskFailure
argument_list|(
operator|new
name|File
argument_list|(
name|readOnlyDir
argument_list|,
literal|"newDir1"
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param badDataDir bad data dir, either disk failure or non-writable    * @param tolerated true if one volume failure is allowed else false    */
DECL|method|startNewDataNodeWithDiskFailure (File badDataDir, boolean tolerated)
specifier|private
name|void
name|startNewDataNodeWithDiskFailure
parameter_list|(
name|File
name|badDataDir
parameter_list|,
name|boolean
name|tolerated
parameter_list|)
throws|throws
name|Exception
block|{
specifier|final
name|File
name|data5
init|=
operator|new
name|File
argument_list|(
name|dataDir
argument_list|,
literal|"data5"
argument_list|)
decl_stmt|;
specifier|final
name|String
name|newDirs
init|=
name|badDataDir
operator|.
name|toString
argument_list|()
operator|+
literal|","
operator|+
name|data5
operator|.
name|toString
argument_list|()
decl_stmt|;
specifier|final
name|Configuration
name|newConf
init|=
operator|new
name|Configuration
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|newConf
operator|.
name|set
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|newDirs
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting dfs.datanode.data.dir for new DataNode as {}"
argument_list|,
name|newDirs
argument_list|)
expr_stmt|;
name|newConf
operator|.
name|setInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_FAILED_VOLUMES_TOLERATED_KEY
argument_list|,
name|tolerated
condition|?
literal|1
else|:
literal|0
argument_list|)
expr_stmt|;
comment|// bring up one more DataNode
name|assertEquals
argument_list|(
name|repl
argument_list|,
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|cluster
operator|.
name|startDataNodes
argument_list|(
name|newConf
argument_list|,
literal|1
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to get expected IOException"
argument_list|,
name|tolerated
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|assertFalse
argument_list|(
literal|"Unexpected IOException "
operator|+
name|ioe
argument_list|,
name|tolerated
argument_list|)
expr_stmt|;
return|return;
block|}
name|assertEquals
argument_list|(
name|repl
operator|+
literal|1
argument_list|,
name|cluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// create new file and it should be able to replicate to 3 nodes
specifier|final
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
literal|"/test1.txt"
argument_list|)
decl_stmt|;
name|DFSTestUtil
operator|.
name|createFile
argument_list|(
name|fs
argument_list|,
name|p
argument_list|,
name|block_size
operator|*
name|blocks_num
argument_list|,
operator|(
name|short
operator|)
literal|3
argument_list|,
literal|1L
argument_list|)
expr_stmt|;
name|DFSTestUtil
operator|.
name|waitReplication
argument_list|(
name|fs
argument_list|,
name|p
argument_list|,
call|(
name|short
call|)
argument_list|(
name|repl
operator|+
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * verifies two things:    *  1. number of locations of each block in the name node    *   matches number of actual files    *  2. block files + pending block equals to total number of blocks that a file has     *     including the replication (HDFS file has 30 blocks, repl=2 - total 60    * @param fn - file name    * @param fs - file size    * @throws IOException    */
DECL|method|verify (String fn, int fs)
specifier|private
name|void
name|verify
parameter_list|(
name|String
name|fn
parameter_list|,
name|int
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|// now count how many physical blocks are there
name|int
name|totalReal
init|=
name|countRealBlocks
argument_list|(
name|block_map
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"countRealBlocks counted "
operator|+
name|totalReal
operator|+
literal|" blocks"
argument_list|)
expr_stmt|;
comment|// count how many blocks store in NN structures.
name|int
name|totalNN
init|=
name|countNNBlocks
argument_list|(
name|block_map
argument_list|,
name|fn
argument_list|,
name|fs
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"countNNBlocks counted "
operator|+
name|totalNN
operator|+
literal|" blocks"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|bid
range|:
name|block_map
operator|.
name|keySet
argument_list|()
control|)
block|{
name|BlockLocs
name|bl
init|=
name|block_map
operator|.
name|get
argument_list|(
name|bid
argument_list|)
decl_stmt|;
comment|// System.out.println(bid + "->" + bl.num_files + "vs." + bl.num_locs);
comment|// number of physical files (1 or 2) should be same as number of datanodes
comment|// in the list of the block locations
name|assertEquals
argument_list|(
literal|"Num files should match num locations"
argument_list|,
name|bl
operator|.
name|num_files
argument_list|,
name|bl
operator|.
name|num_locs
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"Num physical blocks should match num stored in the NN"
argument_list|,
name|totalReal
argument_list|,
name|totalNN
argument_list|)
expr_stmt|;
comment|// now check the number of under-replicated blocks
name|FSNamesystem
name|fsn
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
decl_stmt|;
comment|// force update of all the metric counts by calling computeDatanodeWork
name|BlockManagerTestUtil
operator|.
name|getComputedDatanodeWork
argument_list|(
name|fsn
operator|.
name|getBlockManager
argument_list|()
argument_list|)
expr_stmt|;
comment|// get all the counts
name|long
name|underRepl
init|=
name|fsn
operator|.
name|getUnderReplicatedBlocks
argument_list|()
decl_stmt|;
name|long
name|pendRepl
init|=
name|fsn
operator|.
name|getPendingReplicationBlocks
argument_list|()
decl_stmt|;
name|long
name|totalRepl
init|=
name|underRepl
operator|+
name|pendRepl
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"underreplicated after = "
operator|+
name|underRepl
operator|+
literal|" and pending repl ="
operator|+
name|pendRepl
operator|+
literal|"; total underRepl = "
operator|+
name|totalRepl
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"total blocks (real and replicating):"
operator|+
operator|(
name|totalReal
operator|+
name|totalRepl
operator|)
operator|+
literal|" vs. all files blocks "
operator|+
name|blocks_num
operator|*
literal|2
argument_list|)
expr_stmt|;
comment|// together all the blocks should be equal to all real + all underreplicated
name|assertEquals
argument_list|(
literal|"Incorrect total block count"
argument_list|,
name|totalReal
operator|+
name|totalRepl
argument_list|,
name|blocks_num
operator|*
name|repl
argument_list|)
expr_stmt|;
block|}
comment|/**    * go to each block on the 2nd DataNode until it fails...    * @param path    * @param size    * @throws IOException    */
DECL|method|triggerFailure (String path, long size)
specifier|private
name|void
name|triggerFailure
parameter_list|(
name|String
name|path
parameter_list|,
name|long
name|size
parameter_list|)
throws|throws
name|IOException
block|{
name|NamenodeProtocols
name|nn
init|=
name|cluster
operator|.
name|getNameNodeRpc
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|locatedBlocks
init|=
name|nn
operator|.
name|getBlockLocations
argument_list|(
name|path
argument_list|,
literal|0
argument_list|,
name|size
argument_list|)
operator|.
name|getLocatedBlocks
argument_list|()
decl_stmt|;
for|for
control|(
name|LocatedBlock
name|lb
range|:
name|locatedBlocks
control|)
block|{
name|DatanodeInfo
name|dinfo
init|=
name|lb
operator|.
name|getLocations
argument_list|()
index|[
literal|1
index|]
decl_stmt|;
name|ExtendedBlock
name|b
init|=
name|lb
operator|.
name|getBlock
argument_list|()
decl_stmt|;
try|try
block|{
name|accessBlock
argument_list|(
name|dinfo
argument_list|,
name|lb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Failure triggered, on block: "
operator|+
name|b
operator|.
name|getBlockId
argument_list|()
operator|+
literal|"; corresponding volume should be removed by now"
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
comment|/**    * simulate failure delete all the block files    * @param dir    * @throws IOException    */
DECL|method|deteteBlocks (File dir)
specifier|private
name|boolean
name|deteteBlocks
parameter_list|(
name|File
name|dir
parameter_list|)
block|{
name|Collection
argument_list|<
name|File
argument_list|>
name|fileList
init|=
name|FileUtils
operator|.
name|listFiles
argument_list|(
name|dir
argument_list|,
name|TrueFileFilter
operator|.
name|INSTANCE
argument_list|,
name|TrueFileFilter
operator|.
name|INSTANCE
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|f
range|:
name|fileList
control|)
block|{
if|if
condition|(
name|f
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|Block
operator|.
name|BLOCK_FILE_PREFIX
argument_list|)
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Deleting file "
operator|+
name|f
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|f
operator|.
name|delete
argument_list|()
condition|)
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * try to access a block on a data node. If fails - throws exception    * @param datanode    * @param lblock    * @throws IOException    */
DECL|method|accessBlock (DatanodeInfo datanode, LocatedBlock lblock)
specifier|private
name|void
name|accessBlock
parameter_list|(
name|DatanodeInfo
name|datanode
parameter_list|,
name|LocatedBlock
name|lblock
parameter_list|)
throws|throws
name|IOException
block|{
name|InetSocketAddress
name|targetAddr
init|=
literal|null
decl_stmt|;
name|ExtendedBlock
name|block
init|=
name|lblock
operator|.
name|getBlock
argument_list|()
decl_stmt|;
name|targetAddr
operator|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|datanode
operator|.
name|getXferAddr
argument_list|()
argument_list|)
expr_stmt|;
name|BlockReader
name|blockReader
init|=
operator|new
name|BlockReaderFactory
argument_list|(
operator|new
name|DfsClientConf
argument_list|(
name|conf
argument_list|)
argument_list|)
operator|.
name|setInetSocketAddress
argument_list|(
name|targetAddr
argument_list|)
operator|.
name|setBlock
argument_list|(
name|block
argument_list|)
operator|.
name|setFileName
argument_list|(
name|BlockReaderFactory
operator|.
name|getFileName
argument_list|(
name|targetAddr
argument_list|,
literal|"test-blockpoolid"
argument_list|,
name|block
operator|.
name|getBlockId
argument_list|()
argument_list|)
argument_list|)
operator|.
name|setBlockToken
argument_list|(
name|lblock
operator|.
name|getBlockToken
argument_list|()
argument_list|)
operator|.
name|setStartOffset
argument_list|(
literal|0
argument_list|)
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
operator|.
name|setVerifyChecksum
argument_list|(
literal|true
argument_list|)
operator|.
name|setClientName
argument_list|(
literal|"TestDataNodeVolumeFailure"
argument_list|)
operator|.
name|setDatanodeInfo
argument_list|(
name|datanode
argument_list|)
operator|.
name|setCachingStrategy
argument_list|(
name|CachingStrategy
operator|.
name|newDefaultStrategy
argument_list|()
argument_list|)
operator|.
name|setClientCacheContext
argument_list|(
name|ClientContext
operator|.
name|getFromConf
argument_list|(
name|conf
argument_list|)
argument_list|)
operator|.
name|setConfiguration
argument_list|(
name|conf
argument_list|)
operator|.
name|setRemotePeerFactory
argument_list|(
operator|new
name|RemotePeerFactory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Peer
name|newConnectedPeer
parameter_list|(
name|InetSocketAddress
name|addr
parameter_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|,
name|DatanodeID
name|datanodeId
parameter_list|)
throws|throws
name|IOException
block|{
name|Peer
name|peer
init|=
literal|null
decl_stmt|;
name|Socket
name|sock
init|=
name|NetUtils
operator|.
name|getDefaultSocketFactory
argument_list|(
name|conf
argument_list|)
operator|.
name|createSocket
argument_list|()
decl_stmt|;
try|try
block|{
name|sock
operator|.
name|connect
argument_list|(
name|addr
argument_list|,
name|HdfsConstants
operator|.
name|READ_TIMEOUT
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|HdfsConstants
operator|.
name|READ_TIMEOUT
argument_list|)
expr_stmt|;
name|peer
operator|=
name|DFSUtilClient
operator|.
name|peerFromSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|peer
operator|==
literal|null
condition|)
block|{
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|peer
return|;
block|}
block|}
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|blockReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Count datanodes that have copies of the blocks for a file    * put it into the map    * @param map    * @param path    * @param size    * @return    * @throws IOException    */
DECL|method|countNNBlocks (Map<String, BlockLocs> map, String path, long size)
specifier|private
name|int
name|countNNBlocks
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|BlockLocs
argument_list|>
name|map
parameter_list|,
name|String
name|path
parameter_list|,
name|long
name|size
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|total
init|=
literal|0
decl_stmt|;
name|NamenodeProtocols
name|nn
init|=
name|cluster
operator|.
name|getNameNodeRpc
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|locatedBlocks
init|=
name|nn
operator|.
name|getBlockLocations
argument_list|(
name|path
argument_list|,
literal|0
argument_list|,
name|size
argument_list|)
operator|.
name|getLocatedBlocks
argument_list|()
decl_stmt|;
comment|//System.out.println("Number of blocks: " + locatedBlocks.size());
for|for
control|(
name|LocatedBlock
name|lb
range|:
name|locatedBlocks
control|)
block|{
name|String
name|blockId
init|=
literal|""
operator|+
name|lb
operator|.
name|getBlock
argument_list|()
operator|.
name|getBlockId
argument_list|()
decl_stmt|;
comment|//System.out.print(blockId + ": ");
name|DatanodeInfo
index|[]
name|dn_locs
init|=
name|lb
operator|.
name|getLocations
argument_list|()
decl_stmt|;
name|BlockLocs
name|bl
init|=
name|map
operator|.
name|get
argument_list|(
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|bl
operator|==
literal|null
condition|)
block|{
name|bl
operator|=
operator|new
name|BlockLocs
argument_list|()
expr_stmt|;
block|}
comment|//System.out.print(dn_info.name+",");
name|total
operator|+=
name|dn_locs
operator|.
name|length
expr_stmt|;
name|bl
operator|.
name|num_locs
operator|+=
name|dn_locs
operator|.
name|length
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|blockId
argument_list|,
name|bl
argument_list|)
expr_stmt|;
comment|//System.out.println();
block|}
return|return
name|total
return|;
block|}
comment|/**    *  look for real blocks    *  by counting *.meta files in all the storage dirs     * @param map    * @return    */
DECL|method|countRealBlocks (Map<String, BlockLocs> map)
specifier|private
name|int
name|countRealBlocks
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|BlockLocs
argument_list|>
name|map
parameter_list|)
block|{
name|int
name|total
init|=
literal|0
decl_stmt|;
specifier|final
name|String
name|bpid
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
operator|.
name|getBlockPoolId
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|dn_num
condition|;
name|i
operator|++
control|)
block|{
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<=
literal|1
condition|;
name|j
operator|++
control|)
block|{
name|File
name|storageDir
init|=
name|cluster
operator|.
name|getInstanceStorageDir
argument_list|(
name|i
argument_list|,
name|j
argument_list|)
decl_stmt|;
name|File
name|dir
init|=
name|MiniDFSCluster
operator|.
name|getFinalizedDir
argument_list|(
name|storageDir
argument_list|,
name|bpid
argument_list|)
decl_stmt|;
if|if
condition|(
name|dir
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"dir is null for dn="
operator|+
name|i
operator|+
literal|" and data_dir="
operator|+
name|j
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|List
argument_list|<
name|File
argument_list|>
name|res
init|=
name|MiniDFSCluster
operator|.
name|getAllBlockMetadataFiles
argument_list|(
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|res
operator|==
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"res is null for dir = "
operator|+
name|dir
operator|+
literal|" i="
operator|+
name|i
operator|+
literal|" and j="
operator|+
name|j
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|//System.out.println("for dn" + i + "." + j + ": " + dir + "=" + res.length+ " files");
comment|//int ii = 0;
for|for
control|(
name|File
name|f
range|:
name|res
control|)
block|{
name|String
name|s
init|=
name|f
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// cut off "blk_-" at the beginning and ".meta" at the end
name|assertNotNull
argument_list|(
literal|"Block file name should not be null"
argument_list|,
name|s
argument_list|)
expr_stmt|;
name|String
name|bid
init|=
name|s
operator|.
name|substring
argument_list|(
name|s
operator|.
name|indexOf
argument_list|(
literal|"_"
argument_list|)
operator|+
literal|1
argument_list|,
name|s
operator|.
name|lastIndexOf
argument_list|(
literal|"_"
argument_list|)
argument_list|)
decl_stmt|;
comment|//System.out.println(ii++ + ". block " + s + "; id=" + bid);
name|BlockLocs
name|val
init|=
name|map
operator|.
name|get
argument_list|(
name|bid
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
condition|)
block|{
name|val
operator|=
operator|new
name|BlockLocs
argument_list|()
expr_stmt|;
block|}
name|val
operator|.
name|num_files
operator|++
expr_stmt|;
comment|// one more file for the block
name|map
operator|.
name|put
argument_list|(
name|bid
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
comment|//System.out.println("dir1="+dir.getPath() + "blocks=" + res.length);
comment|//System.out.println("dir2="+dir2.getPath() + "blocks=" + res2.length);
name|total
operator|+=
name|res
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|total
return|;
block|}
DECL|class|BadDiskFSDataset
specifier|private
specifier|static
class|class
name|BadDiskFSDataset
extends|extends
name|SimulatedFSDataset
block|{
DECL|method|BadDiskFSDataset (DataStorage storage, Configuration conf)
name|BadDiskFSDataset
parameter_list|(
name|DataStorage
name|storage
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|storage
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
DECL|field|failedStorageLocations
specifier|private
name|String
index|[]
name|failedStorageLocations
init|=
literal|null
decl_stmt|;
annotation|@
name|Override
DECL|method|addBlockPool (String bpid, Configuration conf)
specifier|public
name|void
name|addBlockPool
parameter_list|(
name|String
name|bpid
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|super
operator|.
name|addBlockPool
argument_list|(
name|bpid
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|FsVolumeSpi
argument_list|,
name|IOException
argument_list|>
name|unhealthyDataDirs
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|unhealthyDataDirs
operator|.
name|put
argument_list|(
name|this
operator|.
name|getStorages
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getVolume
argument_list|()
argument_list|,
operator|new
name|IOException
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|AddBlockPoolException
argument_list|(
name|unhealthyDataDirs
argument_list|)
throw|;
block|}
annotation|@
name|Override
DECL|method|removeVolumes (Collection<StorageLocation> volumes, boolean clearFailure)
specifier|public
specifier|synchronized
name|void
name|removeVolumes
parameter_list|(
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|volumes
parameter_list|,
name|boolean
name|clearFailure
parameter_list|)
block|{
name|Iterator
argument_list|<
name|StorageLocation
argument_list|>
name|itr
init|=
name|volumes
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|String
index|[]
name|failedLocations
init|=
operator|new
name|String
index|[
name|volumes
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|index
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|itr
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|StorageLocation
name|s
init|=
name|itr
operator|.
name|next
argument_list|()
decl_stmt|;
name|failedLocations
index|[
name|index
index|]
operator|=
name|s
operator|.
name|getUri
argument_list|()
operator|.
name|getPath
argument_list|()
expr_stmt|;
name|index
operator|+=
literal|1
expr_stmt|;
block|}
name|failedStorageLocations
operator|=
name|failedLocations
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|handleVolumeFailures (Set<FsVolumeSpi> failedVolumes)
specifier|public
name|void
name|handleVolumeFailures
parameter_list|(
name|Set
argument_list|<
name|FsVolumeSpi
argument_list|>
name|failedVolumes
parameter_list|)
block|{
comment|// do nothing
block|}
annotation|@
name|Override
DECL|method|getVolumeFailureSummary ()
specifier|public
name|VolumeFailureSummary
name|getVolumeFailureSummary
parameter_list|()
block|{
if|if
condition|(
name|failedStorageLocations
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|VolumeFailureSummary
argument_list|(
name|failedStorageLocations
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|VolumeFailureSummary
argument_list|(
name|ArrayUtils
operator|.
name|EMPTY_STRING_ARRAY
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
block|}
block|}
DECL|class|Factory
specifier|static
class|class
name|Factory
extends|extends
name|FsDatasetSpi
operator|.
name|Factory
argument_list|<
name|BadDiskFSDataset
argument_list|>
block|{
annotation|@
name|Override
DECL|method|newInstance (DataNode datanode, DataStorage storage, Configuration conf)
specifier|public
name|BadDiskFSDataset
name|newInstance
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|DataStorage
name|storage
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|BadDiskFSDataset
argument_list|(
name|storage
argument_list|,
name|conf
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|isSimulated ()
specifier|public
name|boolean
name|isSimulated
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
end_class

end_unit

