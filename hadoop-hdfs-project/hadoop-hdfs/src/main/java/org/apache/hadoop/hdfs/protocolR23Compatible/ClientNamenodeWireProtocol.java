begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.protocolR23Compatible
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolR23Compatible
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|avro
operator|.
name|reflect
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Options
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ParentNotDirectoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|UnresolvedLinkException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|AlreadyBeingCreatedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
operator|.
name|UpgradeAction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NotReplicatedYetException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|SafeModeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|EnumSetWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|VersionedProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|AccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|KerberosInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|NSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|ProtocolInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|delegation
operator|.
name|DelegationTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|delegation
operator|.
name|DelegationTokenSelector
import|;
end_import

begin_comment
comment|/**********************************************************************  * This class defines the actual protocol used to communicate with the  * NN via RPC using writable types.  * The parameters in the methods which are specified in the  * package are separate from those used internally in the NN and DFSClient  * and hence need to be converted using {@link ClientNamenodeProtocolTranslatorR23}  * and {@link ClientNamenodeProtocolServerSideTranslatorR23}.  *  **********************************************************************/
end_comment

begin_interface
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Stable
annotation|@
name|KerberosInfo
argument_list|(
name|serverPrincipal
operator|=
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_USER_NAME_KEY
argument_list|)
annotation|@
name|TokenInfo
argument_list|(
name|DelegationTokenSelector
operator|.
name|class
argument_list|)
annotation|@
name|ProtocolInfo
argument_list|(
name|protocolName
operator|=
name|HdfsConstants
operator|.
name|CLIENT_NAMENODE_PROTOCOL_NAME
argument_list|)
DECL|interface|ClientNamenodeWireProtocol
specifier|public
interface|interface
name|ClientNamenodeWireProtocol
extends|extends
name|VersionedProtocol
block|{
comment|/**    * Changes to the protocol:    *     * Do NOT change a method's signature (ie name, parameters, parameter types    * or exceptions thrown). If you need to make changes then ADD new methods and    * new data types.    * Hence if you maintain compatibility you will NOT have to change    * the version number below. The version number is changed ONLY    * if you break compatibility (which is a big deal).    * Hence the version number is really a Major Version Number.    *    * The log of historical changes prior to 69 can be retrieved from the svn.    * ALL changes since version 69L are recorded.    * Version number is changed ONLY for Incompatible changes.    *  (note previously we used to change version number for both    *  compatible and incompatible changes).    * 69: Eliminate overloaded method names. (Compatible)    * 70: Separation of Datatypes - the client namenode protocol is implemented    *     in this class instead of in     *           {@link org.apache.hadoop.hdfs.protocol.ClientProtocol}    *     as was done prior to version 70.    */
DECL|field|versionID
specifier|public
specifier|static
specifier|final
name|long
name|versionID
init|=
literal|70L
decl_stmt|;
comment|///////////////////////////////////////
comment|// File contents
comment|///////////////////////////////////////
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getBlockLocations}    */
annotation|@
name|Nullable
DECL|method|getBlockLocations (String src, long offset, long length)
specifier|public
name|LocatedBlocksWritable
name|getBlockLocations
parameter_list|(
name|String
name|src
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getServerDefaults()}    */
DECL|method|getServerDefaults ()
specifier|public
name|FsServerDefaultsWritable
name|getServerDefaults
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#create(String,     * org.apache.hadoop.fs.permission.FsPermission, String,     * EnumSetWritable, boolean, short, long)}    */
DECL|method|create (String src, FsPermissionWritable masked, String clientName, EnumSetWritable<CreateFlag> flag, boolean createParent, short replication, long blockSize)
specifier|public
name|void
name|create
parameter_list|(
name|String
name|src
parameter_list|,
name|FsPermissionWritable
name|masked
parameter_list|,
name|String
name|clientName
parameter_list|,
name|EnumSetWritable
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|boolean
name|createParent
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|AlreadyBeingCreatedException
throws|,
name|DSQuotaExceededException
throws|,
name|FileAlreadyExistsException
throws|,
name|FileNotFoundException
throws|,
name|NSQuotaExceededException
throws|,
name|ParentNotDirectoryException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#append(String, String)}    */
DECL|method|append (String src, String clientName)
specifier|public
name|LocatedBlockWritable
name|append
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|clientName
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|DSQuotaExceededException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setReplication(String, short)}    */
DECL|method|setReplication (String src, short replication)
specifier|public
name|boolean
name|setReplication
parameter_list|(
name|String
name|src
parameter_list|,
name|short
name|replication
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|DSQuotaExceededException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setPermission(String,    * org.apache.hadoop.fs.permission.FsPermission)}    */
DECL|method|setPermission (String src, FsPermissionWritable permission)
specifier|public
name|void
name|setPermission
parameter_list|(
name|String
name|src
parameter_list|,
name|FsPermissionWritable
name|permission
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setOwner(String, String, String)}    */
DECL|method|setOwner (String src, String username, String groupname)
specifier|public
name|void
name|setOwner
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|username
parameter_list|,
name|String
name|groupname
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#abandonBlock(    * org.apache.hadoop.hdfs.protocol.ExtendedBlock, String, String)}    */
DECL|method|abandonBlock (ExtendedBlockWritable b, String src, String holder)
specifier|public
name|void
name|abandonBlock
parameter_list|(
name|ExtendedBlockWritable
name|b
parameter_list|,
name|String
name|src
parameter_list|,
name|String
name|holder
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#addBlock(String,     * String, org.apache.hadoop.hdfs.protocol.ExtendedBlock,     * org.apache.hadoop.hdfs.protocol.DatanodeInfo[])}    */
DECL|method|addBlock (String src, String clientName, @Nullable ExtendedBlockWritable previous, @Nullable DatanodeInfoWritable[] excludeNodes)
specifier|public
name|LocatedBlockWritable
name|addBlock
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|clientName
parameter_list|,
annotation|@
name|Nullable
name|ExtendedBlockWritable
name|previous
parameter_list|,
annotation|@
name|Nullable
name|DatanodeInfoWritable
index|[]
name|excludeNodes
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|NotReplicatedYetException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getAdditionalDatanode}    */
DECL|method|getAdditionalDatanode ( final String src, final ExtendedBlockWritable blk, final DatanodeInfoWritable[] existings, final DatanodeInfoWritable[] excludes, final int numAdditionalNodes, final String clientName )
specifier|public
name|LocatedBlockWritable
name|getAdditionalDatanode
parameter_list|(
specifier|final
name|String
name|src
parameter_list|,
specifier|final
name|ExtendedBlockWritable
name|blk
parameter_list|,
specifier|final
name|DatanodeInfoWritable
index|[]
name|existings
parameter_list|,
specifier|final
name|DatanodeInfoWritable
index|[]
name|excludes
parameter_list|,
specifier|final
name|int
name|numAdditionalNodes
parameter_list|,
specifier|final
name|String
name|clientName
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#complete}    */
DECL|method|complete ( String src, String clientName, ExtendedBlockWritable last)
specifier|public
name|boolean
name|complete
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|clientName
parameter_list|,
name|ExtendedBlockWritable
name|last
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#reportBadBlocks}    */
DECL|method|reportBadBlocks (LocatedBlockWritable[] blocks)
specifier|public
name|void
name|reportBadBlocks
parameter_list|(
name|LocatedBlockWritable
index|[]
name|blocks
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|///////////////////////////////////////
comment|// Namespace management
comment|///////////////////////////////////////
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#rename(String, String)}    */
DECL|method|rename (String src, String dst)
specifier|public
name|boolean
name|rename
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|dst
parameter_list|)
throws|throws
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#concat(String, String[])}    */
DECL|method|concat (String trg, String[] srcs)
specifier|public
name|void
name|concat
parameter_list|(
name|String
name|trg
parameter_list|,
name|String
index|[]
name|srcs
parameter_list|)
throws|throws
name|IOException
throws|,
name|UnresolvedLinkException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#rename2}    */
DECL|method|rename2 (String src, String dst, Options.Rename... options)
specifier|public
name|void
name|rename2
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|dst
parameter_list|,
name|Options
operator|.
name|Rename
modifier|...
name|options
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|DSQuotaExceededException
throws|,
name|FileAlreadyExistsException
throws|,
name|FileNotFoundException
throws|,
name|NSQuotaExceededException
throws|,
name|ParentNotDirectoryException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#delete(String, boolean)}    */
DECL|method|delete (String src, boolean recursive)
specifier|public
name|boolean
name|delete
parameter_list|(
name|String
name|src
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#mkdirs}    */
DECL|method|mkdirs ( String src, FsPermissionWritable masked, boolean createParent)
specifier|public
name|boolean
name|mkdirs
parameter_list|(
name|String
name|src
parameter_list|,
name|FsPermissionWritable
name|masked
parameter_list|,
name|boolean
name|createParent
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileAlreadyExistsException
throws|,
name|FileNotFoundException
throws|,
name|NSQuotaExceededException
throws|,
name|ParentNotDirectoryException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getListing}    */
DECL|method|getListing (String src, byte[] startAfter, boolean needLocation)
specifier|public
name|DirectoryListingWritable
name|getListing
parameter_list|(
name|String
name|src
parameter_list|,
name|byte
index|[]
name|startAfter
parameter_list|,
name|boolean
name|needLocation
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|///////////////////////////////////////
comment|// System issues and management
comment|///////////////////////////////////////
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#renewLease(String)}    */
DECL|method|renewLease (String clientName)
specifier|public
name|void
name|renewLease
parameter_list|(
name|String
name|clientName
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#recoverLease(String, String)}    */
DECL|method|recoverLease (String src, String clientName)
specifier|public
name|boolean
name|recoverLease
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|clientName
parameter_list|)
throws|throws
name|IOException
function_decl|;
DECL|field|GET_STATS_CAPACITY_IDX
specifier|public
name|int
name|GET_STATS_CAPACITY_IDX
init|=
literal|0
decl_stmt|;
DECL|field|GET_STATS_USED_IDX
specifier|public
name|int
name|GET_STATS_USED_IDX
init|=
literal|1
decl_stmt|;
DECL|field|GET_STATS_REMAINING_IDX
specifier|public
name|int
name|GET_STATS_REMAINING_IDX
init|=
literal|2
decl_stmt|;
DECL|field|GET_STATS_UNDER_REPLICATED_IDX
specifier|public
name|int
name|GET_STATS_UNDER_REPLICATED_IDX
init|=
literal|3
decl_stmt|;
DECL|field|GET_STATS_CORRUPT_BLOCKS_IDX
specifier|public
name|int
name|GET_STATS_CORRUPT_BLOCKS_IDX
init|=
literal|4
decl_stmt|;
DECL|field|GET_STATS_MISSING_BLOCKS_IDX
specifier|public
name|int
name|GET_STATS_MISSING_BLOCKS_IDX
init|=
literal|5
decl_stmt|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getStats()}    */
DECL|method|getStats ()
specifier|public
name|long
index|[]
name|getStats
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getDatanodeReport}    */
DECL|method|getDatanodeReport ( HdfsConstants.DatanodeReportType type)
specifier|public
name|DatanodeInfoWritable
index|[]
name|getDatanodeReport
parameter_list|(
name|HdfsConstants
operator|.
name|DatanodeReportType
name|type
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getPreferredBlockSize}    */
DECL|method|getPreferredBlockSize (String filename)
specifier|public
name|long
name|getPreferredBlockSize
parameter_list|(
name|String
name|filename
parameter_list|)
throws|throws
name|IOException
throws|,
name|UnresolvedLinkException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setSafeMode(org.apache.hadoop.hdfs.protocol.HdfsConstants.SafeModeAction)}    */
DECL|method|setSafeMode (HdfsConstants.SafeModeAction action)
specifier|public
name|boolean
name|setSafeMode
parameter_list|(
name|HdfsConstants
operator|.
name|SafeModeAction
name|action
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#saveNamespace()}    */
DECL|method|saveNamespace ()
specifier|public
name|void
name|saveNamespace
parameter_list|()
throws|throws
name|AccessControlException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#restoreFailedStorage(String)}    */
DECL|method|restoreFailedStorage (String arg)
specifier|public
name|boolean
name|restoreFailedStorage
parameter_list|(
name|String
name|arg
parameter_list|)
throws|throws
name|AccessControlException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#refreshNodes()}    */
DECL|method|refreshNodes ()
specifier|public
name|void
name|refreshNodes
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#finalizeUpgrade()}    */
DECL|method|finalizeUpgrade ()
specifier|public
name|void
name|finalizeUpgrade
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#distributedUpgradeProgress}    */
annotation|@
name|Nullable
DECL|method|distributedUpgradeProgress ( UpgradeAction action)
specifier|public
name|UpgradeStatusReportWritable
name|distributedUpgradeProgress
parameter_list|(
name|UpgradeAction
name|action
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#listCorruptFileBlocks(String, String)}    */
specifier|public
name|CorruptFileBlocksWritable
DECL|method|listCorruptFileBlocks (String path, String cookie)
name|listCorruptFileBlocks
parameter_list|(
name|String
name|path
parameter_list|,
name|String
name|cookie
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#metaSave(String)}    */
DECL|method|metaSave (String filename)
specifier|public
name|void
name|metaSave
parameter_list|(
name|String
name|filename
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setBalancerBandwidth(long)}    */
DECL|method|setBalancerBandwidth (long bandwidth)
specifier|public
name|void
name|setBalancerBandwidth
parameter_list|(
name|long
name|bandwidth
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getFileInfo(String)}    */
annotation|@
name|Nullable
DECL|method|getFileInfo (String src)
specifier|public
name|HdfsFileStatusWritable
name|getFileInfo
parameter_list|(
name|String
name|src
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getFileLinkInfo(String)}    */
DECL|method|getFileLinkInfo (String src)
specifier|public
name|HdfsFileStatusWritable
name|getFileLinkInfo
parameter_list|(
name|String
name|src
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getContentSummary(String)}    */
DECL|method|getContentSummary (String path)
specifier|public
name|ContentSummaryWritable
name|getContentSummary
parameter_list|(
name|String
name|path
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setQuota(String, long, long)}    */
DECL|method|setQuota (String path, long namespaceQuota, long diskspaceQuota)
specifier|public
name|void
name|setQuota
parameter_list|(
name|String
name|path
parameter_list|,
name|long
name|namespaceQuota
parameter_list|,
name|long
name|diskspaceQuota
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#fsync(String, String)}    */
DECL|method|fsync (String src, String client)
specifier|public
name|void
name|fsync
parameter_list|(
name|String
name|src
parameter_list|,
name|String
name|client
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#setTimes(String, long, long)}    */
DECL|method|setTimes (String src, long mtime, long atime)
specifier|public
name|void
name|setTimes
parameter_list|(
name|String
name|src
parameter_list|,
name|long
name|mtime
parameter_list|,
name|long
name|atime
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#createSymlink}    */
DECL|method|createSymlink ( String target, String link, FsPermissionWritable dirPerm, boolean createParent)
specifier|public
name|void
name|createSymlink
parameter_list|(
name|String
name|target
parameter_list|,
name|String
name|link
parameter_list|,
name|FsPermissionWritable
name|dirPerm
parameter_list|,
name|boolean
name|createParent
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileAlreadyExistsException
throws|,
name|FileNotFoundException
throws|,
name|ParentNotDirectoryException
throws|,
name|SafeModeException
throws|,
name|UnresolvedLinkException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getLinkTarget(String)}    */
DECL|method|getLinkTarget (String path)
specifier|public
name|String
name|getLinkTarget
parameter_list|(
name|String
name|path
parameter_list|)
throws|throws
name|AccessControlException
throws|,
name|FileNotFoundException
throws|,
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#updateBlockForPipeline}    */
DECL|method|updateBlockForPipeline ( ExtendedBlockWritable block, String clientName)
specifier|public
name|LocatedBlockWritable
name|updateBlockForPipeline
parameter_list|(
name|ExtendedBlockWritable
name|block
parameter_list|,
name|String
name|clientName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#updatePipeline}    */
DECL|method|updatePipeline (String clientName, ExtendedBlockWritable oldBlock, ExtendedBlockWritable newBlock, DatanodeIDWritable[] newNodes)
specifier|public
name|void
name|updatePipeline
parameter_list|(
name|String
name|clientName
parameter_list|,
name|ExtendedBlockWritable
name|oldBlock
parameter_list|,
name|ExtendedBlockWritable
name|newBlock
parameter_list|,
name|DatanodeIDWritable
index|[]
name|newNodes
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#getDelegationToken(Text)}    */
DECL|method|getDelegationToken (Text renewer)
specifier|public
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|getDelegationToken
parameter_list|(
name|Text
name|renewer
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#renewDelegationToken(Token)}    */
DECL|method|renewDelegationToken (Token<DelegationTokenIdentifier> token)
specifier|public
name|long
name|renewDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * The specification of this method matches that of    * {@link org.apache.hadoop.hdfs.protocol.ClientProtocol#cancelDelegationToken(Token)}    */
DECL|method|cancelDelegationToken (Token<DelegationTokenIdentifier> token)
specifier|public
name|void
name|cancelDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This method is defined to get the protocol signature using     * the R23 protocol - hence we have added the suffix of 2 the method name    * to avoid conflict.    */
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolR23Compatible
operator|.
name|ProtocolSignatureWritable
DECL|method|getProtocolSignature2 (String protocol, long clientVersion, int clientMethodsHash)
name|getProtocolSignature2
parameter_list|(
name|String
name|protocol
parameter_list|,
name|long
name|clientVersion
parameter_list|,
name|int
name|clientMethodsHash
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
end_interface

end_unit

