begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.datanode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_ADDRESS_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_ADDRESS_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DNS_INTERFACE_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DNS_NAMESERVER_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HANDLER_COUNT_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HANDLER_COUNT_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HOST_NAME_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_ADDRESS_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_ADDRESS_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_IPC_ADDRESS_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_KERBEROS_PRINCIPAL_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_KEYTAB_FILE_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_MAX_LOCKED_MEMORY_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_OOB_TIMEOUT_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_OOB_TIMEOUT_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_PLUGINS_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_STARTUP_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_MAX_NUM_BLOCKS_TO_LOG_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_MAX_NUM_BLOCKS_TO_LOG_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_METRICS_LOGGER_PERIOD_SECONDS_DEFAULT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_METRICS_LOGGER_PERIOD_SECONDS_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ExitUtil
operator|.
name|terminate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeysPublic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|ReconfigurationProtocolProtos
operator|.
name|ReconfigurationProtocolService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|ManagementFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|UnknownHostException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|ServerSocketChannel
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|SocketChannel
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadLocalRandom
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|management
operator|.
name|ObjectName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|ReconfigurableBase
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|ReconfigurationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|ReconfigurationTaskStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StorageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtilClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HDFSPolicyProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|BlockReportOptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsClientConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|net
operator|.
name|DomainPeerServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|net
operator|.
name|TcpPeerServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|Block
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|BlockLocalPathInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ClientDatanodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeLocalInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ReconfigurationProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|BlockConstructionStage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|IOStreamPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PipelineAck
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|Sender
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|sasl
operator|.
name|DataEncryptionKeyFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|sasl
operator|.
name|SaslDataTransferClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|sasl
operator|.
name|SaslDataTransferServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|ClientDatanodeProtocolProtos
operator|.
name|ClientDatanodeProtocolService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|DNTransferAckProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|InterDatanodeProtocolProtos
operator|.
name|InterDatanodeProtocolService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|ClientDatanodeProtocolPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|ClientDatanodeProtocolServerSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|DatanodeLifelineProtocolClientSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|DatanodeProtocolClientSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|InterDatanodeProtocolPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|InterDatanodeProtocolServerSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|InterDatanodeProtocolTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|PBHelperClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|ReconfigurationProtocolPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|ReconfigurationProtocolServerSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockPoolTokenSecretManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
operator|.
name|AccessMode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenSecretManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|DataEncryptionKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|ExportedBlockKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|InvalidBlockTokenException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|NodeType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|ReplicaState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|StartupOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|MetricsLoggerTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|StorageInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|SecureDataNodeStarter
operator|.
name|SecureResources
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|erasurecode
operator|.
name|ErasureCodingWorker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|FsDatasetSpi
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|FsVolumeSpi
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|metrics
operator|.
name|DataNodeMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|web
operator|.
name|DatanodeHttpServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|BlockRecoveryCommand
operator|.
name|RecoveringBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeRegistration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|InterDatanodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamespaceInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|ReplicaRecoveryInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|http
operator|.
name|HttpConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|ReadaheadPool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|nativeio
operator|.
name|NativeIO
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|ProtobufRpcEngine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RPC
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|lib
operator|.
name|DefaultMetricsSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|util
operator|.
name|MBeans
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|DNS
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|unix
operator|.
name|DomainSocket
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|AccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SaslPropertiesResolver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
operator|.
name|AuthenticationMethod
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|SpanReceiverInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TraceAdminPB
operator|.
name|TraceAdminService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TraceAdminProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TraceAdminProtocolPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TraceAdminProtocolServerSideTranslatorPB
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TraceUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tracing
operator|.
name|TracerConfigurationManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
operator|.
name|DiskErrorException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|GenericOptionsParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|JvmPauseMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ServicePlugin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|VersionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|Tracer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|mortbay
operator|.
name|util
operator|.
name|ajax
operator|.
name|JSON
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|LoadingCache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|BlockingService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**********************************************************  * DataNode is a class (and program) that stores a set of  * blocks for a DFS deployment.  A single deployment can  * have one or many DataNodes.  Each DataNode communicates  * regularly with a single NameNode.  It also communicates  * with client code and other DataNodes from time to time.  *  * DataNodes store a series of named blocks.  The DataNode  * allows client code to read these blocks, or to write new  * block data.  The DataNode may also, in response to instructions  * from its NameNode, delete blocks or copy blocks to/from other  * DataNodes.  *  * The DataNode maintains just one critical table:  *   block-> stream of bytes (of BLOCK_SIZE or less)  *  * This info is stored on a local disk.  The DataNode  * reports the table's contents to the NameNode upon startup  * and every so often afterwards.  *  * DataNodes spend their lives in an endless loop of asking  * the NameNode for something to do.  A NameNode cannot connect  * to a DataNode directly; a NameNode simply returns values from  * functions invoked by a DataNode.  *  * DataNodes maintain an open server socket so that client code   * or other DataNodes can read/write data.  The host/port for  * this server is reported to the NameNode, which then sends that  * information to clients or other DataNodes that might be interested.  *  **********************************************************/
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DataNode
specifier|public
class|class
name|DataNode
extends|extends
name|ReconfigurableBase
implements|implements
name|InterDatanodeProtocol
implements|,
name|ClientDatanodeProtocol
implements|,
name|TraceAdminProtocol
implements|,
name|DataNodeMXBean
implements|,
name|ReconfigurationProtocol
block|{
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DataNode
operator|.
name|class
argument_list|)
decl_stmt|;
static|static
block|{
name|HdfsConfiguration
operator|.
name|init
argument_list|()
expr_stmt|;
block|}
DECL|field|DN_CLIENTTRACE_FORMAT
specifier|public
specifier|static
specifier|final
name|String
name|DN_CLIENTTRACE_FORMAT
init|=
literal|"src: %s"
operator|+
comment|// src IP
literal|", dest: %s"
operator|+
comment|// dst IP
literal|", bytes: %s"
operator|+
comment|// byte count
literal|", op: %s"
operator|+
comment|// operation
literal|", cliID: %s"
operator|+
comment|// DFSClient id
literal|", offset: %s"
operator|+
comment|// offset
literal|", srvID: %s"
operator|+
comment|// DatanodeRegistration
literal|", blockid: %s"
operator|+
comment|// block id
literal|", duration: %s"
decl_stmt|;
comment|// duration time
DECL|field|ClientTraceLog
specifier|static
specifier|final
name|Log
name|ClientTraceLog
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|DataNode
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|".clienttrace"
argument_list|)
decl_stmt|;
DECL|field|USAGE
specifier|private
specifier|static
specifier|final
name|String
name|USAGE
init|=
literal|"Usage: hdfs datanode [-regular | -rollback | -rollingupgrade rollback"
operator|+
literal|" ]\n"
operator|+
literal|"    -regular                 : Normal DataNode startup (default).\n"
operator|+
literal|"    -rollback                : Rollback a standard or rolling upgrade.\n"
operator|+
literal|"    -rollingupgrade rollback : Rollback a rolling upgrade operation.\n"
operator|+
literal|"  Refer to HDFS documentation for the difference between standard\n"
operator|+
literal|"  and rolling upgrades."
decl_stmt|;
DECL|field|CURRENT_BLOCK_FORMAT_VERSION
specifier|static
specifier|final
name|int
name|CURRENT_BLOCK_FORMAT_VERSION
init|=
literal|1
decl_stmt|;
comment|/** A list of property that are reconfigurable at runtime. */
DECL|field|RECONFIGURABLE_PROPERTIES
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|RECONFIGURABLE_PROPERTIES
init|=
name|Collections
operator|.
name|unmodifiableList
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_KEY
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|METRICS_LOG
specifier|public
specifier|static
specifier|final
name|Log
name|METRICS_LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
literal|"DataNodeMetricsLog"
argument_list|)
decl_stmt|;
DECL|field|DATANODE_HTRACE_PREFIX
specifier|private
specifier|static
specifier|final
name|String
name|DATANODE_HTRACE_PREFIX
init|=
literal|"datanode.htrace."
decl_stmt|;
comment|/**    * Use {@link NetUtils#createSocketAddr(String)} instead.    */
annotation|@
name|Deprecated
DECL|method|createSocketAddr (String target)
specifier|public
specifier|static
name|InetSocketAddress
name|createSocketAddr
parameter_list|(
name|String
name|target
parameter_list|)
block|{
return|return
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|target
argument_list|)
return|;
block|}
DECL|field|shouldRun
specifier|volatile
name|boolean
name|shouldRun
init|=
literal|true
decl_stmt|;
DECL|field|shutdownForUpgrade
specifier|volatile
name|boolean
name|shutdownForUpgrade
init|=
literal|false
decl_stmt|;
DECL|field|shutdownInProgress
specifier|private
name|boolean
name|shutdownInProgress
init|=
literal|false
decl_stmt|;
DECL|field|blockPoolManager
specifier|private
name|BlockPoolManager
name|blockPoolManager
decl_stmt|;
DECL|field|data
specifier|volatile
name|FsDatasetSpi
argument_list|<
name|?
extends|extends
name|FsVolumeSpi
argument_list|>
name|data
init|=
literal|null
decl_stmt|;
DECL|field|clusterId
specifier|private
name|String
name|clusterId
init|=
literal|null
decl_stmt|;
DECL|field|xmitsInProgress
specifier|final
name|AtomicInteger
name|xmitsInProgress
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
DECL|field|dataXceiverServer
name|Daemon
name|dataXceiverServer
init|=
literal|null
decl_stmt|;
DECL|field|xserver
name|DataXceiverServer
name|xserver
init|=
literal|null
decl_stmt|;
DECL|field|localDataXceiverServer
name|Daemon
name|localDataXceiverServer
init|=
literal|null
decl_stmt|;
DECL|field|shortCircuitRegistry
name|ShortCircuitRegistry
name|shortCircuitRegistry
init|=
literal|null
decl_stmt|;
DECL|field|threadGroup
name|ThreadGroup
name|threadGroup
init|=
literal|null
decl_stmt|;
DECL|field|dnConf
specifier|private
name|DNConf
name|dnConf
decl_stmt|;
DECL|field|heartbeatsDisabledForTests
specifier|private
specifier|volatile
name|boolean
name|heartbeatsDisabledForTests
init|=
literal|false
decl_stmt|;
DECL|field|cacheReportsDisabledForTests
specifier|private
specifier|volatile
name|boolean
name|cacheReportsDisabledForTests
init|=
literal|false
decl_stmt|;
DECL|field|storage
specifier|private
name|DataStorage
name|storage
init|=
literal|null
decl_stmt|;
DECL|field|httpServer
specifier|private
name|DatanodeHttpServer
name|httpServer
init|=
literal|null
decl_stmt|;
DECL|field|infoPort
specifier|private
name|int
name|infoPort
decl_stmt|;
DECL|field|infoSecurePort
specifier|private
name|int
name|infoSecurePort
decl_stmt|;
DECL|field|metrics
name|DataNodeMetrics
name|metrics
decl_stmt|;
DECL|field|streamingAddr
specifier|private
name|InetSocketAddress
name|streamingAddr
decl_stmt|;
comment|// See the note below in incrDatanodeNetworkErrors re: concurrency.
DECL|field|datanodeNetworkCounts
specifier|private
name|LoadingCache
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|>
name|datanodeNetworkCounts
decl_stmt|;
DECL|field|hostName
specifier|private
name|String
name|hostName
decl_stmt|;
DECL|field|id
specifier|private
name|DatanodeID
name|id
decl_stmt|;
DECL|field|fileDescriptorPassingDisabledReason
specifier|final
specifier|private
name|String
name|fileDescriptorPassingDisabledReason
decl_stmt|;
DECL|field|isBlockTokenEnabled
name|boolean
name|isBlockTokenEnabled
decl_stmt|;
DECL|field|blockPoolTokenSecretManager
name|BlockPoolTokenSecretManager
name|blockPoolTokenSecretManager
decl_stmt|;
DECL|field|hasAnyBlockPoolRegistered
specifier|private
name|boolean
name|hasAnyBlockPoolRegistered
init|=
literal|false
decl_stmt|;
DECL|field|blockScanner
specifier|private
specifier|final
name|BlockScanner
name|blockScanner
decl_stmt|;
DECL|field|directoryScanner
specifier|private
name|DirectoryScanner
name|directoryScanner
init|=
literal|null
decl_stmt|;
comment|/** Activated plug-ins. */
DECL|field|plugins
specifier|private
name|List
argument_list|<
name|ServicePlugin
argument_list|>
name|plugins
decl_stmt|;
comment|// For InterDataNodeProtocol
DECL|field|ipcServer
specifier|public
name|RPC
operator|.
name|Server
name|ipcServer
decl_stmt|;
DECL|field|pauseMonitor
specifier|private
name|JvmPauseMonitor
name|pauseMonitor
decl_stmt|;
DECL|field|secureResources
specifier|private
name|SecureResources
name|secureResources
init|=
literal|null
decl_stmt|;
comment|// dataDirs must be accessed while holding the DataNode lock.
DECL|field|dataDirs
specifier|private
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
decl_stmt|;
DECL|field|conf
specifier|private
name|Configuration
name|conf
decl_stmt|;
DECL|field|confVersion
specifier|private
specifier|final
name|String
name|confVersion
decl_stmt|;
DECL|field|maxNumberOfBlocksToLog
specifier|private
specifier|final
name|long
name|maxNumberOfBlocksToLog
decl_stmt|;
DECL|field|pipelineSupportECN
specifier|private
specifier|final
name|boolean
name|pipelineSupportECN
decl_stmt|;
DECL|field|usersWithLocalPathAccess
specifier|private
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|usersWithLocalPathAccess
decl_stmt|;
DECL|field|connectToDnViaHostname
specifier|private
specifier|final
name|boolean
name|connectToDnViaHostname
decl_stmt|;
DECL|field|readaheadPool
name|ReadaheadPool
name|readaheadPool
decl_stmt|;
DECL|field|saslClient
name|SaslDataTransferClient
name|saslClient
decl_stmt|;
DECL|field|saslServer
name|SaslDataTransferServer
name|saslServer
decl_stmt|;
DECL|field|dataNodeInfoBeanName
specifier|private
name|ObjectName
name|dataNodeInfoBeanName
decl_stmt|;
DECL|field|checkDiskErrorThread
specifier|private
name|Thread
name|checkDiskErrorThread
init|=
literal|null
decl_stmt|;
DECL|field|checkDiskErrorInterval
specifier|protected
specifier|final
name|int
name|checkDiskErrorInterval
decl_stmt|;
DECL|field|checkDiskErrorFlag
specifier|private
name|boolean
name|checkDiskErrorFlag
init|=
literal|false
decl_stmt|;
DECL|field|checkDiskErrorMutex
specifier|private
name|Object
name|checkDiskErrorMutex
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
DECL|field|lastDiskErrorCheck
specifier|private
name|long
name|lastDiskErrorCheck
decl_stmt|;
DECL|field|supergroup
specifier|private
name|String
name|supergroup
decl_stmt|;
DECL|field|isPermissionEnabled
specifier|private
name|boolean
name|isPermissionEnabled
decl_stmt|;
DECL|field|dnUserName
specifier|private
name|String
name|dnUserName
init|=
literal|null
decl_stmt|;
DECL|field|blockRecoveryWorker
specifier|private
name|BlockRecoveryWorker
name|blockRecoveryWorker
decl_stmt|;
DECL|field|ecWorker
specifier|private
name|ErasureCodingWorker
name|ecWorker
decl_stmt|;
DECL|field|tracer
specifier|private
specifier|final
name|Tracer
name|tracer
decl_stmt|;
DECL|field|tracerConfigurationManager
specifier|private
specifier|final
name|TracerConfigurationManager
name|tracerConfigurationManager
decl_stmt|;
DECL|field|NUM_CORES
specifier|private
specifier|static
specifier|final
name|int
name|NUM_CORES
init|=
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|availableProcessors
argument_list|()
decl_stmt|;
DECL|field|CONGESTION_RATIO
specifier|private
specifier|static
specifier|final
name|double
name|CONGESTION_RATIO
init|=
literal|1.5
decl_stmt|;
DECL|method|createTracer (Configuration conf)
specifier|private
specifier|static
name|Tracer
name|createTracer
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
operator|new
name|Tracer
operator|.
name|Builder
argument_list|(
literal|"DataNode"
argument_list|)
operator|.
name|conf
argument_list|(
name|TraceUtils
operator|.
name|wrapHadoopConf
argument_list|(
name|DATANODE_HTRACE_PREFIX
argument_list|,
name|conf
argument_list|)
argument_list|)
operator|.
name|build
argument_list|()
return|;
block|}
DECL|field|oobTimeouts
specifier|private
name|long
index|[]
name|oobTimeouts
decl_stmt|;
comment|/** timeout value of each OOB type */
DECL|field|metricsLoggerTimer
specifier|private
name|ScheduledThreadPoolExecutor
name|metricsLoggerTimer
decl_stmt|;
comment|/**    * Creates a dummy DataNode for testing purpose.    */
annotation|@
name|VisibleForTesting
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
literal|"HDFS"
argument_list|)
DECL|method|DataNode (final Configuration conf)
name|DataNode
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|tracer
operator|=
name|createTracer
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|tracerConfigurationManager
operator|=
operator|new
name|TracerConfigurationManager
argument_list|(
name|DATANODE_HTRACE_PREFIX
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|fileDescriptorPassingDisabledReason
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|maxNumberOfBlocksToLog
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|confVersion
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|usersWithLocalPathAccess
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|connectToDnViaHostname
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|blockScanner
operator|=
operator|new
name|BlockScanner
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|pipelineSupportECN
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|checkDiskErrorInterval
operator|=
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextInt
argument_list|(
literal|5000
argument_list|,
call|(
name|int
call|)
argument_list|(
literal|5000
operator|*
literal|1.25
argument_list|)
argument_list|)
expr_stmt|;
name|initOOBTimeout
argument_list|()
expr_stmt|;
block|}
comment|/**    * Create the DataNode given a configuration, an array of dataDirs,    * and a namenode proxy.    */
DECL|method|DataNode (final Configuration conf, final List<StorageLocation> dataDirs, final SecureResources resources)
name|DataNode
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
specifier|final
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|tracer
operator|=
name|createTracer
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|tracerConfigurationManager
operator|=
operator|new
name|TracerConfigurationManager
argument_list|(
name|DATANODE_HTRACE_PREFIX
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|blockScanner
operator|=
operator|new
name|BlockScanner
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastDiskErrorCheck
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|maxNumberOfBlocksToLog
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFS_MAX_NUM_BLOCKS_TO_LOG_KEY
argument_list|,
name|DFS_MAX_NUM_BLOCKS_TO_LOG_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|usersWithLocalPathAccess
operator|=
name|Arrays
operator|.
name|asList
argument_list|(
name|conf
operator|.
name|getTrimmedStrings
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_LOCAL_PATH_ACCESS_USER_KEY
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|connectToDnViaHostname
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_USE_DN_HOSTNAME
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_USE_DN_HOSTNAME_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|supergroup
operator|=
name|conf
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_PERMISSIONS_SUPERUSERGROUP_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_PERMISSIONS_SUPERUSERGROUP_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|isPermissionEnabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_PERMISSIONS_ENABLED_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_PERMISSIONS_ENABLED_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|pipelineSupportECN
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_PIPELINE_ECN_ENABLED
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_PIPELINE_ECN_ENABLED_DEFAULT
argument_list|)
expr_stmt|;
name|confVersion
operator|=
literal|"core-"
operator|+
name|conf
operator|.
name|get
argument_list|(
literal|"hadoop.common.configuration.version"
argument_list|,
literal|"UNSPECIFIED"
argument_list|)
operator|+
literal|",hdfs-"
operator|+
name|conf
operator|.
name|get
argument_list|(
literal|"hadoop.hdfs.configuration.version"
argument_list|,
literal|"UNSPECIFIED"
argument_list|)
expr_stmt|;
name|this
operator|.
name|checkDiskErrorInterval
operator|=
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextInt
argument_list|(
literal|5000
argument_list|,
call|(
name|int
call|)
argument_list|(
literal|5000
operator|*
literal|1.25
argument_list|)
argument_list|)
expr_stmt|;
comment|// Determine whether we should try to pass file descriptors to clients.
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|KEY
argument_list|,
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|DEFAULT
argument_list|)
condition|)
block|{
name|String
name|reason
init|=
name|DomainSocket
operator|.
name|getLoadingFailureReason
argument_list|()
decl_stmt|;
if|if
condition|(
name|reason
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"File descriptor passing is disabled because "
operator|+
name|reason
argument_list|)
expr_stmt|;
name|this
operator|.
name|fileDescriptorPassingDisabledReason
operator|=
name|reason
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"File descriptor passing is enabled."
argument_list|)
expr_stmt|;
name|this
operator|.
name|fileDescriptorPassingDisabledReason
operator|=
literal|null
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|fileDescriptorPassingDisabledReason
operator|=
literal|"File descriptor passing was not configured."
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|this
operator|.
name|fileDescriptorPassingDisabledReason
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|hostName
operator|=
name|getHostName
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Configured hostname is "
operator|+
name|hostName
argument_list|)
expr_stmt|;
name|startDataNode
argument_list|(
name|conf
argument_list|,
name|dataDirs
argument_list|,
name|resources
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|shutdown
argument_list|()
expr_stmt|;
throw|throw
name|ie
throw|;
block|}
specifier|final
name|int
name|dncCacheMaxSize
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_KEY
argument_list|,
name|DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_DEFAULT
argument_list|)
decl_stmt|;
name|datanodeNetworkCounts
operator|=
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|maximumSize
argument_list|(
name|dncCacheMaxSize
argument_list|)
operator|.
name|build
argument_list|(
operator|new
name|CacheLoader
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|load
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|Exception
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|ret
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
name|ret
operator|.
name|put
argument_list|(
literal|"networkErrors"
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|initOOBTimeout
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ReconfigurableBase
DECL|method|getNewConf ()
specifier|protected
name|Configuration
name|getNewConf
parameter_list|()
block|{
return|return
operator|new
name|HdfsConfiguration
argument_list|()
return|;
block|}
comment|/**    * {@inheritdoc}.    */
annotation|@
name|Override
DECL|method|reconfigurePropertyImpl (String property, String newVal)
specifier|public
name|String
name|reconfigurePropertyImpl
parameter_list|(
name|String
name|property
parameter_list|,
name|String
name|newVal
parameter_list|)
throws|throws
name|ReconfigurationException
block|{
switch|switch
condition|(
name|property
condition|)
block|{
case|case
name|DFS_DATANODE_DATA_DIR_KEY
case|:
block|{
name|IOException
name|rootException
init|=
literal|null
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Reconfiguring "
operator|+
name|property
operator|+
literal|" to "
operator|+
name|newVal
argument_list|)
expr_stmt|;
name|this
operator|.
name|refreshVolumes
argument_list|(
name|newVal
argument_list|)
expr_stmt|;
return|return
name|conf
operator|.
name|get
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|rootException
operator|=
name|e
expr_stmt|;
block|}
finally|finally
block|{
comment|// Send a full block report to let NN acknowledge the volume changes.
try|try
block|{
name|triggerBlockReport
argument_list|(
operator|new
name|BlockReportOptions
operator|.
name|Factory
argument_list|()
operator|.
name|setIncremental
argument_list|(
literal|false
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception while sending the block report after refreshing"
operator|+
literal|" volumes "
operator|+
name|property
operator|+
literal|" to "
operator|+
name|newVal
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|rootException
operator|==
literal|null
condition|)
block|{
name|rootException
operator|=
name|e
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|rootException
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|ReconfigurationException
argument_list|(
name|property
argument_list|,
name|newVal
argument_list|,
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|property
argument_list|)
argument_list|,
name|rootException
argument_list|)
throw|;
block|}
block|}
block|}
break|break;
block|}
case|case
name|DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_KEY
case|:
block|{
name|ReconfigurationException
name|rootException
init|=
literal|null
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Reconfiguring "
operator|+
name|property
operator|+
literal|" to "
operator|+
name|newVal
argument_list|)
expr_stmt|;
name|int
name|movers
decl_stmt|;
if|if
condition|(
name|newVal
operator|==
literal|null
condition|)
block|{
comment|// set to default
name|movers
operator|=
name|DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_DEFAULT
expr_stmt|;
block|}
else|else
block|{
name|movers
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|newVal
argument_list|)
expr_stmt|;
if|if
condition|(
name|movers
operator|<=
literal|0
condition|)
block|{
name|rootException
operator|=
operator|new
name|ReconfigurationException
argument_list|(
name|property
argument_list|,
name|newVal
argument_list|,
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|property
argument_list|)
argument_list|,
operator|new
name|IllegalArgumentException
argument_list|(
literal|"balancer max concurrent movers must be larger than 0"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|xserver
operator|.
name|updateBalancerMaxConcurrentMovers
argument_list|(
name|movers
argument_list|)
expr_stmt|;
return|return
name|Integer
operator|.
name|toString
argument_list|(
name|movers
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|nfe
parameter_list|)
block|{
name|rootException
operator|=
operator|new
name|ReconfigurationException
argument_list|(
name|property
argument_list|,
name|newVal
argument_list|,
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|property
argument_list|)
argument_list|,
name|nfe
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|rootException
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Exception in updating balancer max concurrent movers %s to %s"
argument_list|,
name|property
argument_list|,
name|newVal
argument_list|)
argument_list|,
name|rootException
argument_list|)
expr_stmt|;
throw|throw
name|rootException
throw|;
block|}
block|}
break|break;
block|}
default|default:
break|break;
block|}
throw|throw
operator|new
name|ReconfigurationException
argument_list|(
name|property
argument_list|,
name|newVal
argument_list|,
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|property
argument_list|)
argument_list|)
throw|;
block|}
comment|/**    * Get a list of the keys of the re-configurable properties in configuration.    */
annotation|@
name|Override
comment|// Reconfigurable
DECL|method|getReconfigurableProperties ()
specifier|public
name|Collection
argument_list|<
name|String
argument_list|>
name|getReconfigurableProperties
parameter_list|()
block|{
return|return
name|RECONFIGURABLE_PROPERTIES
return|;
block|}
comment|/**    * The ECN bit for the DataNode. The DataNode should return:    *<ul>    *<li>ECN.DISABLED when ECN is disabled.</li>    *<li>ECN.SUPPORTED when ECN is enabled but the DN still has capacity.</li>    *<li>ECN.CONGESTED when ECN is enabled and the DN is congested.</li>    *</ul>    */
DECL|method|getECN ()
specifier|public
name|PipelineAck
operator|.
name|ECN
name|getECN
parameter_list|()
block|{
if|if
condition|(
operator|!
name|pipelineSupportECN
condition|)
block|{
return|return
name|PipelineAck
operator|.
name|ECN
operator|.
name|DISABLED
return|;
block|}
name|double
name|load
init|=
name|ManagementFactory
operator|.
name|getOperatingSystemMXBean
argument_list|()
operator|.
name|getSystemLoadAverage
argument_list|()
decl_stmt|;
return|return
name|load
operator|>
name|NUM_CORES
operator|*
name|CONGESTION_RATIO
condition|?
name|PipelineAck
operator|.
name|ECN
operator|.
name|CONGESTED
else|:
name|PipelineAck
operator|.
name|ECN
operator|.
name|SUPPORTED
return|;
block|}
comment|/**    * Contains the StorageLocations for changed data volumes.    */
annotation|@
name|VisibleForTesting
DECL|class|ChangedVolumes
specifier|static
class|class
name|ChangedVolumes
block|{
comment|/** The storage locations of the newly added volumes. */
DECL|field|newLocations
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|newLocations
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|/** The storage locations of the volumes that are removed. */
DECL|field|deactivateLocations
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|deactivateLocations
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|/** The unchanged locations that existed in the old configuration. */
DECL|field|unchangedLocations
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|unchangedLocations
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
block|}
comment|/**    * Parse the new DFS_DATANODE_DATA_DIR value in the configuration to detect    * changed volumes.    * @param newVolumes a comma separated string that specifies the data volumes.    * @return changed volumes.    * @throws IOException if none of the directories are specified in the    * configuration.    */
annotation|@
name|VisibleForTesting
DECL|method|parseChangedVolumes (String newVolumes)
name|ChangedVolumes
name|parseChangedVolumes
parameter_list|(
name|String
name|newVolumes
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|newVolumes
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|locations
init|=
name|getStorageLocations
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|locations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No directory is specified."
argument_list|)
throw|;
block|}
name|ChangedVolumes
name|results
init|=
operator|new
name|ChangedVolumes
argument_list|()
decl_stmt|;
name|results
operator|.
name|newLocations
operator|.
name|addAll
argument_list|(
name|locations
argument_list|)
expr_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Storage
operator|.
name|StorageDirectory
argument_list|>
name|it
init|=
name|storage
operator|.
name|dirIterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|Storage
operator|.
name|StorageDirectory
name|dir
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|boolean
name|found
init|=
literal|false
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|StorageLocation
argument_list|>
name|sl
init|=
name|results
operator|.
name|newLocations
operator|.
name|iterator
argument_list|()
init|;
name|sl
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageLocation
name|location
init|=
name|sl
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|location
operator|.
name|getFile
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
operator|.
name|equals
argument_list|(
name|dir
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
argument_list|)
condition|)
block|{
name|sl
operator|.
name|remove
argument_list|()
expr_stmt|;
name|results
operator|.
name|unchangedLocations
operator|.
name|add
argument_list|(
name|location
argument_list|)
expr_stmt|;
name|found
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|found
condition|)
block|{
name|results
operator|.
name|deactivateLocations
operator|.
name|add
argument_list|(
name|StorageLocation
operator|.
name|parse
argument_list|(
name|dir
operator|.
name|getRoot
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
return|;
block|}
comment|/**    * Attempts to reload data volumes with new configuration.    * @param newVolumes a comma separated string that specifies the data volumes.    * @throws IOException on error. If an IOException is thrown, some new volumes    * may have been successfully added and removed.    */
DECL|method|refreshVolumes (String newVolumes)
specifier|private
specifier|synchronized
name|void
name|refreshVolumes
parameter_list|(
name|String
name|newVolumes
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|newVolumes
argument_list|)
expr_stmt|;
name|ExecutorService
name|service
init|=
literal|null
decl_stmt|;
name|int
name|numOldDataDirs
init|=
name|dataDirs
operator|.
name|size
argument_list|()
decl_stmt|;
name|ChangedVolumes
name|changedVolumes
init|=
name|parseChangedVolumes
argument_list|(
name|newVolumes
argument_list|)
decl_stmt|;
name|StringBuilder
name|errorMessageBuilder
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|effectiveVolumes
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|StorageLocation
name|sl
range|:
name|changedVolumes
operator|.
name|unchangedLocations
control|)
block|{
name|effectiveVolumes
operator|.
name|add
argument_list|(
name|sl
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|numOldDataDirs
operator|+
name|changedVolumes
operator|.
name|newLocations
operator|.
name|size
argument_list|()
operator|-
name|changedVolumes
operator|.
name|deactivateLocations
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Attempt to remove all volumes."
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|changedVolumes
operator|.
name|newLocations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Adding new volumes: "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|changedVolumes
operator|.
name|newLocations
argument_list|)
argument_list|)
expr_stmt|;
comment|// Add volumes for each Namespace
specifier|final
name|List
argument_list|<
name|NamespaceInfo
argument_list|>
name|nsInfos
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
name|nsInfos
operator|.
name|add
argument_list|(
name|bpos
operator|.
name|getNamespaceInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|service
operator|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|changedVolumes
operator|.
name|newLocations
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|IOException
argument_list|>
argument_list|>
name|exceptions
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
specifier|final
name|StorageLocation
name|location
range|:
name|changedVolumes
operator|.
name|newLocations
control|)
block|{
name|exceptions
operator|.
name|add
argument_list|(
name|service
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|IOException
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|IOException
name|call
parameter_list|()
block|{
try|try
block|{
name|data
operator|.
name|addVolume
argument_list|(
name|location
argument_list|,
name|nsInfos
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
return|return
name|e
return|;
block|}
return|return
literal|null
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|changedVolumes
operator|.
name|newLocations
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|StorageLocation
name|volume
init|=
name|changedVolumes
operator|.
name|newLocations
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Future
argument_list|<
name|IOException
argument_list|>
name|ioExceptionFuture
init|=
name|exceptions
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
try|try
block|{
name|IOException
name|ioe
init|=
name|ioExceptionFuture
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
block|{
name|errorMessageBuilder
operator|.
name|append
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"FAILED TO ADD: %s: %s%n"
argument_list|,
name|volume
argument_list|,
name|ioe
operator|.
name|getMessage
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to add volume: "
operator|+
name|volume
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|effectiveVolumes
operator|.
name|add
argument_list|(
name|volume
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully added volume: "
operator|+
name|volume
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|errorMessageBuilder
operator|.
name|append
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"FAILED to ADD: %s: %s%n"
argument_list|,
name|volume
argument_list|,
name|e
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to add volume: "
operator|+
name|volume
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
try|try
block|{
name|removeVolumes
argument_list|(
name|changedVolumes
operator|.
name|deactivateLocations
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|errorMessageBuilder
operator|.
name|append
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to remove volume: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|errorMessageBuilder
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|errorMessageBuilder
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|service
operator|!=
literal|null
condition|)
block|{
name|service
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|effectiveVolumes
argument_list|)
argument_list|)
expr_stmt|;
name|dataDirs
operator|=
name|getStorageLocations
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Remove volumes from DataNode.    * See {@link #removeVolumes(Set, boolean)} for details.    *    * @param locations the StorageLocations of the volumes to be removed.    * @throws IOException    */
DECL|method|removeVolumes (final Collection<StorageLocation> locations)
specifier|private
name|void
name|removeVolumes
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|locations
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|locations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|Set
argument_list|<
name|File
argument_list|>
name|volumesToRemove
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|StorageLocation
name|loc
range|:
name|locations
control|)
block|{
name|volumesToRemove
operator|.
name|add
argument_list|(
name|loc
operator|.
name|getFile
argument_list|()
operator|.
name|getAbsoluteFile
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|removeVolumes
argument_list|(
name|volumesToRemove
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove volumes from DataNode.    *    * It does three things:    *<li>    *<ul>Remove volumes and block info from FsDataset.</ul>    *<ul>Remove volumes from DataStorage.</ul>    *<ul>Reset configuration DATA_DIR and {@link #dataDirs} to represent    *   active volumes.</ul>    *</li>    * @param absoluteVolumePaths the absolute path of volumes.    * @param clearFailure if true, clears the failure information related to the    *                     volumes.    * @throws IOException    */
DECL|method|removeVolumes ( final Set<File> absoluteVolumePaths, boolean clearFailure)
specifier|private
specifier|synchronized
name|void
name|removeVolumes
parameter_list|(
specifier|final
name|Set
argument_list|<
name|File
argument_list|>
name|absoluteVolumePaths
parameter_list|,
name|boolean
name|clearFailure
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|File
name|vol
range|:
name|absoluteVolumePaths
control|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|vol
operator|.
name|isAbsolute
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|absoluteVolumePaths
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Deactivating volumes (clear failure=%b): %s"
argument_list|,
name|clearFailure
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|absoluteVolumePaths
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
comment|// Remove volumes and block infos from FsDataset.
name|data
operator|.
name|removeVolumes
argument_list|(
name|absoluteVolumePaths
argument_list|,
name|clearFailure
argument_list|)
expr_stmt|;
comment|// Remove volumes from DataStorage.
try|try
block|{
name|storage
operator|.
name|removeVolumes
argument_list|(
name|absoluteVolumePaths
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|ioe
operator|=
name|e
expr_stmt|;
block|}
comment|// Set configuration and dataDirs to reflect volume changes.
for|for
control|(
name|Iterator
argument_list|<
name|StorageLocation
argument_list|>
name|it
init|=
name|dataDirs
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageLocation
name|loc
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|absoluteVolumePaths
operator|.
name|contains
argument_list|(
name|loc
operator|.
name|getFile
argument_list|()
operator|.
name|getAbsoluteFile
argument_list|()
argument_list|)
condition|)
block|{
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
name|conf
operator|.
name|set
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|,
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|dataDirs
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
block|{
throw|throw
name|ioe
throw|;
block|}
block|}
DECL|method|setClusterId (final String nsCid, final String bpid )
specifier|private
specifier|synchronized
name|void
name|setClusterId
parameter_list|(
specifier|final
name|String
name|nsCid
parameter_list|,
specifier|final
name|String
name|bpid
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|clusterId
operator|!=
literal|null
operator|&&
operator|!
name|clusterId
operator|.
name|equals
argument_list|(
name|nsCid
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cluster IDs not matched: dn cid="
operator|+
name|clusterId
operator|+
literal|" but ns cid="
operator|+
name|nsCid
operator|+
literal|"; bpid="
operator|+
name|bpid
argument_list|)
throw|;
block|}
comment|// else
name|clusterId
operator|=
name|nsCid
expr_stmt|;
block|}
comment|/**    * Returns the hostname for this datanode. If the hostname is not    * explicitly configured in the given config, then it is determined    * via the DNS class.    *    * @param config configuration    * @return the hostname (NB: may not be a FQDN)    * @throws UnknownHostException if the dfs.datanode.dns.interface    *    option is used and the hostname can not be determined    */
DECL|method|getHostName (Configuration config)
specifier|private
specifier|static
name|String
name|getHostName
parameter_list|(
name|Configuration
name|config
parameter_list|)
throws|throws
name|UnknownHostException
block|{
name|String
name|name
init|=
name|config
operator|.
name|get
argument_list|(
name|DFS_DATANODE_HOST_NAME_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|name
operator|==
literal|null
condition|)
block|{
name|String
name|dnsInterface
init|=
name|config
operator|.
name|get
argument_list|(
name|CommonConfigurationKeys
operator|.
name|HADOOP_SECURITY_DNS_INTERFACE_KEY
argument_list|)
decl_stmt|;
name|String
name|nameServer
init|=
name|config
operator|.
name|get
argument_list|(
name|CommonConfigurationKeys
operator|.
name|HADOOP_SECURITY_DNS_NAMESERVER_KEY
argument_list|)
decl_stmt|;
name|boolean
name|fallbackToHosts
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|dnsInterface
operator|==
literal|null
condition|)
block|{
comment|// Try the legacy configuration keys.
name|dnsInterface
operator|=
name|config
operator|.
name|get
argument_list|(
name|DFS_DATANODE_DNS_INTERFACE_KEY
argument_list|)
expr_stmt|;
name|nameServer
operator|=
name|config
operator|.
name|get
argument_list|(
name|DFS_DATANODE_DNS_NAMESERVER_KEY
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// If HADOOP_SECURITY_DNS_* is set then also attempt hosts file
comment|// resolution if DNS fails. We will not use hosts file resolution
comment|// by default to avoid breaking existing clusters.
name|fallbackToHosts
operator|=
literal|true
expr_stmt|;
block|}
name|name
operator|=
name|DNS
operator|.
name|getDefaultHost
argument_list|(
name|dnsInterface
argument_list|,
name|nameServer
argument_list|,
name|fallbackToHosts
argument_list|)
expr_stmt|;
block|}
return|return
name|name
return|;
block|}
comment|/**    * @see DFSUtil#getHttpPolicy(org.apache.hadoop.conf.Configuration)    * for information related to the different configuration options and    * Http Policy is decided.    */
DECL|method|startInfoServer (Configuration conf)
specifier|private
name|void
name|startInfoServer
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// SecureDataNodeStarter will bind the privileged port to the channel if
comment|// the DN is started by JSVC, pass it along.
name|ServerSocketChannel
name|httpServerChannel
init|=
name|secureResources
operator|!=
literal|null
condition|?
name|secureResources
operator|.
name|getHttpServerChannel
argument_list|()
else|:
literal|null
decl_stmt|;
name|this
operator|.
name|httpServer
operator|=
operator|new
name|DatanodeHttpServer
argument_list|(
name|conf
argument_list|,
name|this
argument_list|,
name|httpServerChannel
argument_list|)
expr_stmt|;
name|httpServer
operator|.
name|start
argument_list|()
expr_stmt|;
if|if
condition|(
name|httpServer
operator|.
name|getHttpAddress
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|infoPort
operator|=
name|httpServer
operator|.
name|getHttpAddress
argument_list|()
operator|.
name|getPort
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|httpServer
operator|.
name|getHttpsAddress
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|infoSecurePort
operator|=
name|httpServer
operator|.
name|getHttpsAddress
argument_list|()
operator|.
name|getPort
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|startPlugins (Configuration conf)
specifier|private
name|void
name|startPlugins
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|plugins
operator|=
name|conf
operator|.
name|getInstances
argument_list|(
name|DFS_DATANODE_PLUGINS_KEY
argument_list|,
name|ServicePlugin
operator|.
name|class
argument_list|)
expr_stmt|;
for|for
control|(
name|ServicePlugin
name|p
range|:
name|plugins
control|)
block|{
try|try
block|{
name|p
operator|.
name|start
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Started plug-in "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"ServicePlugin "
operator|+
name|p
operator|+
literal|" could not be started"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|initIpcServer (Configuration conf)
specifier|private
name|void
name|initIpcServer
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|InetSocketAddress
name|ipcAddr
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFS_DATANODE_IPC_ADDRESS_KEY
argument_list|)
argument_list|)
decl_stmt|;
comment|// Add all the RPC protocols that the Datanode implements
name|RPC
operator|.
name|setProtocolEngine
argument_list|(
name|conf
argument_list|,
name|ClientDatanodeProtocolPB
operator|.
name|class
argument_list|,
name|ProtobufRpcEngine
operator|.
name|class
argument_list|)
expr_stmt|;
name|ClientDatanodeProtocolServerSideTranslatorPB
name|clientDatanodeProtocolXlator
init|=
operator|new
name|ClientDatanodeProtocolServerSideTranslatorPB
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|BlockingService
name|service
init|=
name|ClientDatanodeProtocolService
operator|.
name|newReflectiveBlockingService
argument_list|(
name|clientDatanodeProtocolXlator
argument_list|)
decl_stmt|;
name|ipcServer
operator|=
operator|new
name|RPC
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|setProtocol
argument_list|(
name|ClientDatanodeProtocolPB
operator|.
name|class
argument_list|)
operator|.
name|setInstance
argument_list|(
name|service
argument_list|)
operator|.
name|setBindAddress
argument_list|(
name|ipcAddr
operator|.
name|getHostName
argument_list|()
argument_list|)
operator|.
name|setPort
argument_list|(
name|ipcAddr
operator|.
name|getPort
argument_list|()
argument_list|)
operator|.
name|setNumHandlers
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|DFS_DATANODE_HANDLER_COUNT_KEY
argument_list|,
name|DFS_DATANODE_HANDLER_COUNT_DEFAULT
argument_list|)
argument_list|)
operator|.
name|setVerbose
argument_list|(
literal|false
argument_list|)
operator|.
name|setSecretManager
argument_list|(
name|blockPoolTokenSecretManager
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|ReconfigurationProtocolServerSideTranslatorPB
name|reconfigurationProtocolXlator
init|=
operator|new
name|ReconfigurationProtocolServerSideTranslatorPB
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|service
operator|=
name|ReconfigurationProtocolService
operator|.
name|newReflectiveBlockingService
argument_list|(
name|reconfigurationProtocolXlator
argument_list|)
expr_stmt|;
name|DFSUtil
operator|.
name|addPBProtocol
argument_list|(
name|conf
argument_list|,
name|ReconfigurationProtocolPB
operator|.
name|class
argument_list|,
name|service
argument_list|,
name|ipcServer
argument_list|)
expr_stmt|;
name|InterDatanodeProtocolServerSideTranslatorPB
name|interDatanodeProtocolXlator
init|=
operator|new
name|InterDatanodeProtocolServerSideTranslatorPB
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|service
operator|=
name|InterDatanodeProtocolService
operator|.
name|newReflectiveBlockingService
argument_list|(
name|interDatanodeProtocolXlator
argument_list|)
expr_stmt|;
name|DFSUtil
operator|.
name|addPBProtocol
argument_list|(
name|conf
argument_list|,
name|InterDatanodeProtocolPB
operator|.
name|class
argument_list|,
name|service
argument_list|,
name|ipcServer
argument_list|)
expr_stmt|;
name|TraceAdminProtocolServerSideTranslatorPB
name|traceAdminXlator
init|=
operator|new
name|TraceAdminProtocolServerSideTranslatorPB
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|BlockingService
name|traceAdminService
init|=
name|TraceAdminService
operator|.
name|newReflectiveBlockingService
argument_list|(
name|traceAdminXlator
argument_list|)
decl_stmt|;
name|DFSUtil
operator|.
name|addPBProtocol
argument_list|(
name|conf
argument_list|,
name|TraceAdminProtocolPB
operator|.
name|class
argument_list|,
name|traceAdminService
argument_list|,
name|ipcServer
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Opened IPC server at "
operator|+
name|ipcServer
operator|.
name|getListenerAddress
argument_list|()
argument_list|)
expr_stmt|;
comment|// set service-level authorization security policy
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|CommonConfigurationKeys
operator|.
name|HADOOP_SECURITY_AUTHORIZATION
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|ipcServer
operator|.
name|refreshServiceAcl
argument_list|(
name|conf
argument_list|,
operator|new
name|HDFSPolicyProvider
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Check whether the current user is in the superuser group. */
DECL|method|checkSuperuserPrivilege ()
specifier|private
name|void
name|checkSuperuserPrivilege
parameter_list|()
throws|throws
name|IOException
throws|,
name|AccessControlException
block|{
if|if
condition|(
operator|!
name|isPermissionEnabled
condition|)
block|{
return|return;
block|}
comment|// Try to get the ugi in the RPC call.
name|UserGroupInformation
name|callerUgi
init|=
name|ipcServer
operator|.
name|getRemoteUser
argument_list|()
decl_stmt|;
if|if
condition|(
name|callerUgi
operator|==
literal|null
condition|)
block|{
comment|// This is not from RPC.
name|callerUgi
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
expr_stmt|;
block|}
comment|// Is this by the DN user itself?
assert|assert
name|dnUserName
operator|!=
literal|null
assert|;
if|if
condition|(
name|callerUgi
operator|.
name|getShortUserName
argument_list|()
operator|.
name|equals
argument_list|(
name|dnUserName
argument_list|)
condition|)
block|{
return|return;
block|}
comment|// Is the user a member of the super group?
name|List
argument_list|<
name|String
argument_list|>
name|groups
init|=
name|Arrays
operator|.
name|asList
argument_list|(
name|callerUgi
operator|.
name|getGroupNames
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|groups
operator|.
name|contains
argument_list|(
name|supergroup
argument_list|)
condition|)
block|{
return|return;
block|}
comment|// Not a superuser.
throw|throw
operator|new
name|AccessControlException
argument_list|()
throw|;
block|}
DECL|method|shutdownPeriodicScanners ()
specifier|private
name|void
name|shutdownPeriodicScanners
parameter_list|()
block|{
name|shutdownDirectoryScanner
argument_list|()
expr_stmt|;
name|blockScanner
operator|.
name|removeAllVolumeScanners
argument_list|()
expr_stmt|;
block|}
comment|/**    * See {@link DirectoryScanner}    */
DECL|method|initDirectoryScanner (Configuration conf)
specifier|private
specifier|synchronized
name|void
name|initDirectoryScanner
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|directoryScanner
operator|!=
literal|null
condition|)
block|{
return|return;
block|}
name|String
name|reason
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getInt
argument_list|(
name|DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY
argument_list|,
name|DFS_DATANODE_DIRECTORYSCAN_INTERVAL_DEFAULT
argument_list|)
operator|<
literal|0
condition|)
block|{
name|reason
operator|=
literal|"verification is turned off by configuration"
expr_stmt|;
block|}
elseif|else
if|if
condition|(
literal|"SimulatedFSDataset"
operator|.
name|equals
argument_list|(
name|data
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
condition|)
block|{
name|reason
operator|=
literal|"verifcation is not supported by SimulatedFSDataset"
expr_stmt|;
block|}
if|if
condition|(
name|reason
operator|==
literal|null
condition|)
block|{
name|directoryScanner
operator|=
operator|new
name|DirectoryScanner
argument_list|(
name|this
argument_list|,
name|data
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|directoryScanner
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Periodic Directory Tree Verification scan is disabled because "
operator|+
name|reason
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|shutdownDirectoryScanner ()
specifier|private
specifier|synchronized
name|void
name|shutdownDirectoryScanner
parameter_list|()
block|{
if|if
condition|(
name|directoryScanner
operator|!=
literal|null
condition|)
block|{
name|directoryScanner
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|initDataXceiver (Configuration conf)
specifier|private
name|void
name|initDataXceiver
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// find free port or use privileged port provided
name|TcpPeerServer
name|tcpPeerServer
decl_stmt|;
if|if
condition|(
name|secureResources
operator|!=
literal|null
condition|)
block|{
name|tcpPeerServer
operator|=
operator|new
name|TcpPeerServer
argument_list|(
name|secureResources
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|int
name|backlogLength
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|CommonConfigurationKeysPublic
operator|.
name|IPC_SERVER_LISTEN_QUEUE_SIZE_KEY
argument_list|,
name|CommonConfigurationKeysPublic
operator|.
name|IPC_SERVER_LISTEN_QUEUE_SIZE_DEFAULT
argument_list|)
decl_stmt|;
name|tcpPeerServer
operator|=
operator|new
name|TcpPeerServer
argument_list|(
name|dnConf
operator|.
name|socketWriteTimeout
argument_list|,
name|DataNode
operator|.
name|getStreamingAddr
argument_list|(
name|conf
argument_list|)
argument_list|,
name|backlogLength
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dnConf
operator|.
name|getTransferSocketRecvBufferSize
argument_list|()
operator|>
literal|0
condition|)
block|{
name|tcpPeerServer
operator|.
name|setReceiveBufferSize
argument_list|(
name|dnConf
operator|.
name|getTransferSocketRecvBufferSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|streamingAddr
operator|=
name|tcpPeerServer
operator|.
name|getStreamingAddr
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Opened streaming server at "
operator|+
name|streamingAddr
argument_list|)
expr_stmt|;
name|this
operator|.
name|threadGroup
operator|=
operator|new
name|ThreadGroup
argument_list|(
literal|"dataXceiverServer"
argument_list|)
expr_stmt|;
name|xserver
operator|=
operator|new
name|DataXceiverServer
argument_list|(
name|tcpPeerServer
argument_list|,
name|conf
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|dataXceiverServer
operator|=
operator|new
name|Daemon
argument_list|(
name|threadGroup
argument_list|,
name|xserver
argument_list|)
expr_stmt|;
name|this
operator|.
name|threadGroup
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// auto destroy when empty
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|KEY
argument_list|,
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|DEFAULT
argument_list|)
operator|||
name|conf
operator|.
name|getBoolean
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_DOMAIN_SOCKET_DATA_TRAFFIC
argument_list|,
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_DOMAIN_SOCKET_DATA_TRAFFIC_DEFAULT
argument_list|)
condition|)
block|{
name|DomainPeerServer
name|domainPeerServer
init|=
name|getDomainPeerServer
argument_list|(
name|conf
argument_list|,
name|streamingAddr
operator|.
name|getPort
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|domainPeerServer
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|localDataXceiverServer
operator|=
operator|new
name|Daemon
argument_list|(
name|threadGroup
argument_list|,
operator|new
name|DataXceiverServer
argument_list|(
name|domainPeerServer
argument_list|,
name|conf
argument_list|,
name|this
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Listening on UNIX domain socket: "
operator|+
name|domainPeerServer
operator|.
name|getBindPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|shortCircuitRegistry
operator|=
operator|new
name|ShortCircuitRegistry
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
DECL|method|getDomainPeerServer (Configuration conf, int port)
specifier|private
specifier|static
name|DomainPeerServer
name|getDomainPeerServer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|int
name|port
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|domainSocketPath
init|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DOMAIN_SOCKET_PATH_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DOMAIN_SOCKET_PATH_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|domainSocketPath
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|KEY
argument_list|,
name|HdfsClientConfigKeys
operator|.
name|Read
operator|.
name|ShortCircuit
operator|.
name|DEFAULT
argument_list|)
operator|&&
operator|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_USE_LEGACY_BLOCKREADERLOCAL
argument_list|,
name|HdfsClientConfigKeys
operator|.
name|DFS_CLIENT_USE_LEGACY_BLOCKREADERLOCAL_DEFAULT
argument_list|)
operator|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Although short-circuit local reads are configured, "
operator|+
literal|"they are disabled because you didn't configure "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_DOMAIN_SOCKET_PATH_KEY
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
if|if
condition|(
name|DomainSocket
operator|.
name|getLoadingFailureReason
argument_list|()
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Although a UNIX domain socket "
operator|+
literal|"path is configured as "
operator|+
name|domainSocketPath
operator|+
literal|", we cannot "
operator|+
literal|"start a localDataXceiverServer because "
operator|+
name|DomainSocket
operator|.
name|getLoadingFailureReason
argument_list|()
argument_list|)
throw|;
block|}
name|DomainPeerServer
name|domainPeerServer
init|=
operator|new
name|DomainPeerServer
argument_list|(
name|domainSocketPath
argument_list|,
name|port
argument_list|)
decl_stmt|;
name|int
name|recvBufferSize
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_TRANSFER_SOCKET_RECV_BUFFER_SIZE_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_TRANSFER_SOCKET_RECV_BUFFER_SIZE_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|recvBufferSize
operator|>
literal|0
condition|)
block|{
name|domainPeerServer
operator|.
name|setReceiveBufferSize
argument_list|(
name|recvBufferSize
argument_list|)
expr_stmt|;
block|}
return|return
name|domainPeerServer
return|;
block|}
comment|// calls specific to BP
DECL|method|notifyNamenodeReceivedBlock (ExtendedBlock block, String delHint, String storageUuid, boolean isOnTransientStorage)
specifier|public
name|void
name|notifyNamenodeReceivedBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|String
name|delHint
parameter_list|,
name|String
name|storageUuid
parameter_list|,
name|boolean
name|isOnTransientStorage
parameter_list|)
block|{
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|!=
literal|null
condition|)
block|{
name|bpos
operator|.
name|notifyNamenodeReceivedBlock
argument_list|(
name|block
argument_list|,
name|delHint
argument_list|,
name|storageUuid
argument_list|,
name|isOnTransientStorage
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot find BPOfferService for reporting block received for bpid="
operator|+
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// calls specific to BP
DECL|method|notifyNamenodeReceivingBlock ( ExtendedBlock block, String storageUuid)
specifier|protected
name|void
name|notifyNamenodeReceivingBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|String
name|storageUuid
parameter_list|)
block|{
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|!=
literal|null
condition|)
block|{
name|bpos
operator|.
name|notifyNamenodeReceivingBlock
argument_list|(
name|block
argument_list|,
name|storageUuid
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot find BPOfferService for reporting block receiving for bpid="
operator|+
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Notify the corresponding namenode to delete the block. */
DECL|method|notifyNamenodeDeletedBlock (ExtendedBlock block, String storageUuid)
specifier|public
name|void
name|notifyNamenodeDeletedBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|String
name|storageUuid
parameter_list|)
block|{
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|!=
literal|null
condition|)
block|{
name|bpos
operator|.
name|notifyNamenodeDeletedBlock
argument_list|(
name|block
argument_list|,
name|storageUuid
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot find BPOfferService for reporting block deleted for bpid="
operator|+
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Report a bad block which is hosted on the local DN.    */
DECL|method|reportBadBlocks (ExtendedBlock block)
specifier|public
name|void
name|reportBadBlocks
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
name|BPOfferService
name|bpos
init|=
name|getBPOSForBlock
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|FsVolumeSpi
name|volume
init|=
name|getFSDataset
argument_list|()
operator|.
name|getVolume
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|bpos
operator|.
name|reportBadBlocks
argument_list|(
name|block
argument_list|,
name|volume
operator|.
name|getStorageID
argument_list|()
argument_list|,
name|volume
operator|.
name|getStorageType
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Report a bad block on another DN (eg if we received a corrupt replica    * from a remote host).    * @param srcDataNode the DN hosting the bad block    * @param block the block itself    */
DECL|method|reportRemoteBadBlock (DatanodeInfo srcDataNode, ExtendedBlock block)
specifier|public
name|void
name|reportRemoteBadBlock
parameter_list|(
name|DatanodeInfo
name|srcDataNode
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
name|BPOfferService
name|bpos
init|=
name|getBPOSForBlock
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|bpos
operator|.
name|reportRemoteBadBlock
argument_list|(
name|srcDataNode
argument_list|,
name|block
argument_list|)
expr_stmt|;
block|}
DECL|method|reportCorruptedBlocks ( DFSUtilClient.CorruptedBlocks corruptedBlocks)
specifier|public
name|void
name|reportCorruptedBlocks
parameter_list|(
name|DFSUtilClient
operator|.
name|CorruptedBlocks
name|corruptedBlocks
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptionMap
init|=
name|corruptedBlocks
operator|.
name|getCorruptionMap
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|corruptionMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|entry
range|:
name|corruptionMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
for|for
control|(
name|DatanodeInfo
name|dnInfo
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|reportRemoteBadBlock
argument_list|(
name|dnInfo
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Try to send an error report to the NNs associated with the given    * block pool.    * @param bpid the block pool ID    * @param errCode error code to send    * @param errMsg textual message to send    */
DECL|method|trySendErrorReport (String bpid, int errCode, String errMsg)
name|void
name|trySendErrorReport
parameter_list|(
name|String
name|bpid
parameter_list|,
name|int
name|errCode
parameter_list|,
name|String
name|errMsg
parameter_list|)
block|{
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Bad block pool: "
operator|+
name|bpid
argument_list|)
throw|;
block|}
name|bpos
operator|.
name|trySendErrorReport
argument_list|(
name|errCode
argument_list|,
name|errMsg
argument_list|)
expr_stmt|;
block|}
comment|/**    * Return the BPOfferService instance corresponding to the given block.    * @return the BPOS    * @throws IOException if no such BPOS can be found    */
DECL|method|getBPOSForBlock (ExtendedBlock block)
specifier|private
name|BPOfferService
name|getBPOSForBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|block
argument_list|)
expr_stmt|;
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"cannot locate OfferService thread for bp="
operator|+
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|bpos
return|;
block|}
comment|// used only for testing
annotation|@
name|VisibleForTesting
DECL|method|setHeartbeatsDisabledForTests ( boolean heartbeatsDisabledForTests)
name|void
name|setHeartbeatsDisabledForTests
parameter_list|(
name|boolean
name|heartbeatsDisabledForTests
parameter_list|)
block|{
name|this
operator|.
name|heartbeatsDisabledForTests
operator|=
name|heartbeatsDisabledForTests
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|areHeartbeatsDisabledForTests ()
name|boolean
name|areHeartbeatsDisabledForTests
parameter_list|()
block|{
return|return
name|this
operator|.
name|heartbeatsDisabledForTests
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setCacheReportsDisabledForTest (boolean disabled)
name|void
name|setCacheReportsDisabledForTest
parameter_list|(
name|boolean
name|disabled
parameter_list|)
block|{
name|this
operator|.
name|cacheReportsDisabledForTests
operator|=
name|disabled
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|areCacheReportsDisabledForTests ()
name|boolean
name|areCacheReportsDisabledForTests
parameter_list|()
block|{
return|return
name|this
operator|.
name|cacheReportsDisabledForTests
return|;
block|}
comment|/**    * This method starts the data node with the specified conf.    *     * @param conf - the configuration    *  if conf's CONFIG_PROPERTY_SIMULATED property is set    *  then a simulated storage based data node is created.    *     * @param dataDirs - only for a non-simulated storage data node    * @throws IOException    */
DECL|method|startDataNode (Configuration conf, List<StorageLocation> dataDirs, SecureResources resources )
name|void
name|startDataNode
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|IOException
block|{
comment|// settings global for all BPs in the Data Node
name|this
operator|.
name|secureResources
operator|=
name|resources
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|this
operator|.
name|dataDirs
operator|=
name|dataDirs
expr_stmt|;
block|}
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|dnConf
operator|=
operator|new
name|DNConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|checkSecureConfig
argument_list|(
name|dnConf
argument_list|,
name|conf
argument_list|,
name|resources
argument_list|)
expr_stmt|;
if|if
condition|(
name|dnConf
operator|.
name|maxLockedMemory
operator|>
literal|0
condition|)
block|{
if|if
condition|(
operator|!
name|NativeIO
operator|.
name|POSIX
operator|.
name|getCacheManipulator
argument_list|()
operator|.
name|verifyCanMlock
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Cannot start datanode because the configured max locked memory"
operator|+
literal|" size (%s) is greater than zero and native code is not available."
argument_list|,
name|DFS_DATANODE_MAX_LOCKED_MEMORY_KEY
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|Path
operator|.
name|WINDOWS
condition|)
block|{
name|NativeIO
operator|.
name|Windows
operator|.
name|extendWorkingSetSize
argument_list|(
name|dnConf
operator|.
name|maxLockedMemory
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|long
name|ulimit
init|=
name|NativeIO
operator|.
name|POSIX
operator|.
name|getCacheManipulator
argument_list|()
operator|.
name|getMemlockLimit
argument_list|()
decl_stmt|;
if|if
condition|(
name|dnConf
operator|.
name|maxLockedMemory
operator|>
name|ulimit
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Cannot start datanode because the configured max locked memory"
operator|+
literal|" size (%s) of %d bytes is more than the datanode's available"
operator|+
literal|" RLIMIT_MEMLOCK ulimit of %d bytes."
argument_list|,
name|DFS_DATANODE_MAX_LOCKED_MEMORY_KEY
argument_list|,
name|dnConf
operator|.
name|maxLockedMemory
argument_list|,
name|ulimit
argument_list|)
argument_list|)
throw|;
block|}
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting DataNode with maxLockedMemory = "
operator|+
name|dnConf
operator|.
name|maxLockedMemory
argument_list|)
expr_stmt|;
name|int
name|volFailuresTolerated
init|=
name|dnConf
operator|.
name|getVolFailuresTolerated
argument_list|()
decl_stmt|;
name|int
name|volsConfigured
init|=
name|dnConf
operator|.
name|getVolsConfigured
argument_list|()
decl_stmt|;
if|if
condition|(
name|volFailuresTolerated
operator|<
literal|0
operator|||
name|volFailuresTolerated
operator|>=
name|volsConfigured
condition|)
block|{
throw|throw
operator|new
name|DiskErrorException
argument_list|(
literal|"Invalid value configured for "
operator|+
literal|"dfs.datanode.failed.volumes.tolerated - "
operator|+
name|volFailuresTolerated
operator|+
literal|". Value configured is either less than 0 or>= "
operator|+
literal|"to the number of configured volumes ("
operator|+
name|volsConfigured
operator|+
literal|")."
argument_list|)
throw|;
block|}
name|storage
operator|=
operator|new
name|DataStorage
argument_list|()
expr_stmt|;
comment|// global DN settings
name|registerMXBean
argument_list|()
expr_stmt|;
name|initDataXceiver
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|startInfoServer
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|pauseMonitor
operator|=
operator|new
name|JvmPauseMonitor
argument_list|()
expr_stmt|;
name|pauseMonitor
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|pauseMonitor
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// BlockPoolTokenSecretManager is required to create ipc server.
name|this
operator|.
name|blockPoolTokenSecretManager
operator|=
operator|new
name|BlockPoolTokenSecretManager
argument_list|()
expr_stmt|;
comment|// Login is done by now. Set the DN user name.
name|dnUserName
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"dnUserName = "
operator|+
name|dnUserName
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"supergroup = "
operator|+
name|supergroup
argument_list|)
expr_stmt|;
name|initIpcServer
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|metrics
operator|=
name|DataNodeMetrics
operator|.
name|create
argument_list|(
name|conf
argument_list|,
name|getDisplayName
argument_list|()
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|getJvmMetrics
argument_list|()
operator|.
name|setPauseMonitor
argument_list|(
name|pauseMonitor
argument_list|)
expr_stmt|;
name|ecWorker
operator|=
operator|new
name|ErasureCodingWorker
argument_list|(
name|conf
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|blockRecoveryWorker
operator|=
operator|new
name|BlockRecoveryWorker
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|blockPoolManager
operator|=
operator|new
name|BlockPoolManager
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|blockPoolManager
operator|.
name|refreshNamenodes
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Create the ReadaheadPool from the DataNode context so we can
comment|// exit without having to explicitly shutdown its thread pool.
name|readaheadPool
operator|=
name|ReadaheadPool
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|saslClient
operator|=
operator|new
name|SaslDataTransferClient
argument_list|(
name|dnConf
operator|.
name|conf
argument_list|,
name|dnConf
operator|.
name|saslPropsResolver
argument_list|,
name|dnConf
operator|.
name|trustedChannelResolver
argument_list|)
expr_stmt|;
name|saslServer
operator|=
operator|new
name|SaslDataTransferServer
argument_list|(
name|dnConf
argument_list|,
name|blockPoolTokenSecretManager
argument_list|)
expr_stmt|;
name|startMetricsLogger
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Checks if the DataNode has a secure configuration if security is enabled.    * There are 2 possible configurations that are considered secure:    * 1. The server has bound to privileged ports for RPC and HTTP via    *   SecureDataNodeStarter.    * 2. The configuration enables SASL on DataTransferProtocol and HTTPS (no    *   plain HTTP) for the HTTP server.  The SASL handshake guarantees    *   authentication of the RPC server before a client transmits a secret, such    *   as a block access token.  Similarly, SSL guarantees authentication of the    *   HTTP server before a client transmits a secret, such as a delegation    *   token.    * It is not possible to run with both privileged ports and SASL on    * DataTransferProtocol.  For backwards-compatibility, the connection logic    * must check if the target port is a privileged port, and if so, skip the    * SASL handshake.    *    * @param dnConf DNConf to check    * @param conf Configuration to check    * @param resources SecuredResources obtained for DataNode    * @throws RuntimeException if security enabled, but configuration is insecure    */
DECL|method|checkSecureConfig (DNConf dnConf, Configuration conf, SecureResources resources)
specifier|private
specifier|static
name|void
name|checkSecureConfig
parameter_list|(
name|DNConf
name|dnConf
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|RuntimeException
block|{
if|if
condition|(
operator|!
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// Abort out of inconsistent state if Kerberos is enabled
comment|// but block access tokens are not enabled.
name|boolean
name|isEnabled
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_ACCESS_TOKEN_ENABLE_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|isEnabled
condition|)
block|{
name|String
name|errMessage
init|=
literal|"Security is enabled but block access tokens "
operator|+
literal|"(via "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY
operator|+
literal|") "
operator|+
literal|"aren't enabled. This may cause issues "
operator|+
literal|"when clients attempt to connect to a DataNode. Aborting DataNode"
decl_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|errMessage
argument_list|)
throw|;
block|}
name|SaslPropertiesResolver
name|saslPropsResolver
init|=
name|dnConf
operator|.
name|getSaslPropsResolver
argument_list|()
decl_stmt|;
if|if
condition|(
name|resources
operator|!=
literal|null
operator|&&
name|saslPropsResolver
operator|==
literal|null
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|dnConf
operator|.
name|getIgnoreSecurePortsForTesting
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|saslPropsResolver
operator|!=
literal|null
operator|&&
name|DFSUtil
operator|.
name|getHttpPolicy
argument_list|(
name|conf
argument_list|)
operator|==
name|HttpConfig
operator|.
name|Policy
operator|.
name|HTTPS_ONLY
operator|&&
name|resources
operator|==
literal|null
condition|)
block|{
return|return;
block|}
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cannot start secure DataNode without "
operator|+
literal|"configuring either privileged resources or SASL RPC data transfer "
operator|+
literal|"protection and SSL for HTTP.  Using privileged resources in "
operator|+
literal|"combination with SASL RPC data transfer protection is not supported."
argument_list|)
throw|;
block|}
DECL|method|generateUuid ()
specifier|public
specifier|static
name|String
name|generateUuid
parameter_list|()
block|{
return|return
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|getSaslClient ()
specifier|public
name|SaslDataTransferClient
name|getSaslClient
parameter_list|()
block|{
return|return
name|saslClient
return|;
block|}
comment|/**    * Verify that the DatanodeUuid has been initialized. If this is a new    * datanode then we generate a new Datanode Uuid and persist it to disk.    *    * @throws IOException    */
DECL|method|checkDatanodeUuid ()
specifier|synchronized
name|void
name|checkDatanodeUuid
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
name|storage
operator|.
name|setDatanodeUuid
argument_list|(
name|generateUuid
argument_list|()
argument_list|)
expr_stmt|;
name|storage
operator|.
name|writeAll
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Generated and persisted new Datanode UUID "
operator|+
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a DatanodeRegistration for a specific block pool.    * @param nsInfo the namespace info from the first part of the NN handshake    */
DECL|method|createBPRegistration (NamespaceInfo nsInfo)
name|DatanodeRegistration
name|createBPRegistration
parameter_list|(
name|NamespaceInfo
name|nsInfo
parameter_list|)
block|{
name|StorageInfo
name|storageInfo
init|=
name|storage
operator|.
name|getBPStorage
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|storageInfo
operator|==
literal|null
condition|)
block|{
comment|// it's null in the case of SimulatedDataSet
name|storageInfo
operator|=
operator|new
name|StorageInfo
argument_list|(
name|DataNodeLayoutVersion
operator|.
name|CURRENT_LAYOUT_VERSION
argument_list|,
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|clusterID
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|NodeType
operator|.
name|DATA_NODE
argument_list|)
expr_stmt|;
block|}
name|DatanodeID
name|dnId
init|=
operator|new
name|DatanodeID
argument_list|(
name|streamingAddr
operator|.
name|getAddress
argument_list|()
operator|.
name|getHostAddress
argument_list|()
argument_list|,
name|hostName
argument_list|,
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|,
name|getXferPort
argument_list|()
argument_list|,
name|getInfoPort
argument_list|()
argument_list|,
name|infoSecurePort
argument_list|,
name|getIpcPort
argument_list|()
argument_list|)
decl_stmt|;
return|return
operator|new
name|DatanodeRegistration
argument_list|(
name|dnId
argument_list|,
name|storageInfo
argument_list|,
operator|new
name|ExportedBlockKeys
argument_list|()
argument_list|,
name|VersionInfo
operator|.
name|getVersion
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Check that the registration returned from a NameNode is consistent    * with the information in the storage. If the storage is fresh/unformatted,    * sets the storage ID based on this registration.    * Also updates the block pool's state in the secret manager.    */
DECL|method|bpRegistrationSucceeded (DatanodeRegistration bpRegistration, String blockPoolId)
specifier|synchronized
name|void
name|bpRegistrationSucceeded
parameter_list|(
name|DatanodeRegistration
name|bpRegistration
parameter_list|,
name|String
name|blockPoolId
parameter_list|)
throws|throws
name|IOException
block|{
name|id
operator|=
name|bpRegistration
expr_stmt|;
if|if
condition|(
operator|!
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
operator|.
name|equals
argument_list|(
name|bpRegistration
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Inconsistent Datanode IDs. Name-node returned "
operator|+
name|bpRegistration
operator|.
name|getDatanodeUuid
argument_list|()
operator|+
literal|". Expecting "
operator|+
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
throw|;
block|}
name|registerBlockPoolWithSecretManager
argument_list|(
name|bpRegistration
argument_list|,
name|blockPoolId
argument_list|)
expr_stmt|;
block|}
comment|/**    * After the block pool has contacted the NN, registers that block pool    * with the secret manager, updating it with the secrets provided by the NN.    * @throws IOException on error    */
DECL|method|registerBlockPoolWithSecretManager ( DatanodeRegistration bpRegistration, String blockPoolId)
specifier|private
specifier|synchronized
name|void
name|registerBlockPoolWithSecretManager
parameter_list|(
name|DatanodeRegistration
name|bpRegistration
parameter_list|,
name|String
name|blockPoolId
parameter_list|)
throws|throws
name|IOException
block|{
name|ExportedBlockKeys
name|keys
init|=
name|bpRegistration
operator|.
name|getExportedKeys
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|hasAnyBlockPoolRegistered
condition|)
block|{
name|hasAnyBlockPoolRegistered
operator|=
literal|true
expr_stmt|;
name|isBlockTokenEnabled
operator|=
name|keys
operator|.
name|isBlockTokenEnabled
argument_list|()
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|isBlockTokenEnabled
operator|!=
name|keys
operator|.
name|isBlockTokenEnabled
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Inconsistent configuration of block access"
operator|+
literal|" tokens. Either all block pools must be configured to use block"
operator|+
literal|" tokens, or none may be."
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|isBlockTokenEnabled
condition|)
return|return;
if|if
condition|(
operator|!
name|blockPoolTokenSecretManager
operator|.
name|isBlockPoolRegistered
argument_list|(
name|blockPoolId
argument_list|)
condition|)
block|{
name|long
name|blockKeyUpdateInterval
init|=
name|keys
operator|.
name|getKeyUpdateInterval
argument_list|()
decl_stmt|;
name|long
name|blockTokenLifetime
init|=
name|keys
operator|.
name|getTokenLifetime
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Block token params received from NN: for block pool "
operator|+
name|blockPoolId
operator|+
literal|" keyUpdateInterval="
operator|+
name|blockKeyUpdateInterval
operator|/
operator|(
literal|60
operator|*
literal|1000
operator|)
operator|+
literal|" min(s), tokenLifetime="
operator|+
name|blockTokenLifetime
operator|/
operator|(
literal|60
operator|*
literal|1000
operator|)
operator|+
literal|" min(s)"
argument_list|)
expr_stmt|;
specifier|final
name|BlockTokenSecretManager
name|secretMgr
init|=
operator|new
name|BlockTokenSecretManager
argument_list|(
literal|0
argument_list|,
name|blockTokenLifetime
argument_list|,
name|blockPoolId
argument_list|,
name|dnConf
operator|.
name|encryptionAlgorithm
argument_list|)
decl_stmt|;
name|blockPoolTokenSecretManager
operator|.
name|addBlockPool
argument_list|(
name|blockPoolId
argument_list|,
name|secretMgr
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Remove the given block pool from the block scanner, dataset, and storage.    */
DECL|method|shutdownBlockPool (BPOfferService bpos)
name|void
name|shutdownBlockPool
parameter_list|(
name|BPOfferService
name|bpos
parameter_list|)
block|{
name|blockPoolManager
operator|.
name|remove
argument_list|(
name|bpos
argument_list|)
expr_stmt|;
if|if
condition|(
name|bpos
operator|.
name|hasBlockPoolId
argument_list|()
condition|)
block|{
comment|// Possible that this is shutting down before successfully
comment|// registering anywhere. If that's the case, we wouldn't have
comment|// a block pool id
name|String
name|bpId
init|=
name|bpos
operator|.
name|getBlockPoolId
argument_list|()
decl_stmt|;
name|blockScanner
operator|.
name|disableBlockPoolId
argument_list|(
name|bpId
argument_list|)
expr_stmt|;
if|if
condition|(
name|data
operator|!=
literal|null
condition|)
block|{
name|data
operator|.
name|shutdownBlockPool
argument_list|(
name|bpId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|storage
operator|!=
literal|null
condition|)
block|{
name|storage
operator|.
name|removeBlockPoolStorage
argument_list|(
name|bpId
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * One of the Block Pools has successfully connected to its NN.    * This initializes the local storage for that block pool,    * checks consistency of the NN's cluster ID, etc.    *     * If this is the first block pool to register, this also initializes    * the datanode-scoped storage.    *     * @param bpos Block pool offer service    * @throws IOException if the NN is inconsistent with the local storage.    */
DECL|method|initBlockPool (BPOfferService bpos)
name|void
name|initBlockPool
parameter_list|(
name|BPOfferService
name|bpos
parameter_list|)
throws|throws
name|IOException
block|{
name|NamespaceInfo
name|nsInfo
init|=
name|bpos
operator|.
name|getNamespaceInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|nsInfo
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"NamespaceInfo not found: Block pool "
operator|+
name|bpos
operator|+
literal|" should have retrieved namespace info before initBlockPool."
argument_list|)
throw|;
block|}
name|setClusterId
argument_list|(
name|nsInfo
operator|.
name|clusterID
argument_list|,
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|)
expr_stmt|;
comment|// Register the new block pool with the BP manager.
name|blockPoolManager
operator|.
name|addBlockPool
argument_list|(
name|bpos
argument_list|)
expr_stmt|;
comment|// In the case that this is the first block pool to connect, initialize
comment|// the dataset, block scanners, etc.
name|initStorage
argument_list|(
name|nsInfo
argument_list|)
expr_stmt|;
comment|// Exclude failed disks before initializing the block pools to avoid startup
comment|// failures.
name|checkDiskError
argument_list|()
expr_stmt|;
name|data
operator|.
name|addBlockPool
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|blockScanner
operator|.
name|enableBlockPoolId
argument_list|(
name|bpos
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
name|initDirectoryScanner
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
DECL|method|getAllBpOs ()
name|List
argument_list|<
name|BPOfferService
argument_list|>
name|getAllBpOs
parameter_list|()
block|{
return|return
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
return|;
block|}
DECL|method|getBPOfferService (String bpid)
name|BPOfferService
name|getBPOfferService
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
return|return
name|blockPoolManager
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
return|;
block|}
DECL|method|getBpOsCount ()
name|int
name|getBpOsCount
parameter_list|()
block|{
return|return
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * Initializes the {@link #data}. The initialization is done only once, when    * handshake with the the first namenode is completed.    */
DECL|method|initStorage (final NamespaceInfo nsInfo)
specifier|private
name|void
name|initStorage
parameter_list|(
specifier|final
name|NamespaceInfo
name|nsInfo
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|FsDatasetSpi
operator|.
name|Factory
argument_list|<
name|?
extends|extends
name|FsDatasetSpi
argument_list|<
name|?
argument_list|>
argument_list|>
name|factory
init|=
name|FsDatasetSpi
operator|.
name|Factory
operator|.
name|getFactory
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|factory
operator|.
name|isSimulated
argument_list|()
condition|)
block|{
specifier|final
name|StartupOption
name|startOpt
init|=
name|getStartupOption
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|startOpt
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Startup option not set."
argument_list|)
throw|;
block|}
specifier|final
name|String
name|bpid
init|=
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
decl_stmt|;
comment|//read storage info, lock data dirs and transition fs state if necessary
synchronized|synchronized
init|(
name|this
init|)
block|{
name|storage
operator|.
name|recoverTransitionRead
argument_list|(
name|this
argument_list|,
name|nsInfo
argument_list|,
name|dataDirs
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
block|}
specifier|final
name|StorageInfo
name|bpStorage
init|=
name|storage
operator|.
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting up storage: nsid="
operator|+
name|bpStorage
operator|.
name|getNamespaceID
argument_list|()
operator|+
literal|";bpid="
operator|+
name|bpid
operator|+
literal|";lv="
operator|+
name|storage
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|";nsInfo="
operator|+
name|nsInfo
operator|+
literal|";dnuuid="
operator|+
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// If this is a newly formatted DataNode then assign a new DatanodeUuid.
name|checkDatanodeUuid
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|data
operator|==
literal|null
condition|)
block|{
name|data
operator|=
name|factory
operator|.
name|newInstance
argument_list|(
name|this
argument_list|,
name|storage
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Determine the http server's effective addr    */
DECL|method|getInfoAddr (Configuration conf)
specifier|public
specifier|static
name|InetSocketAddress
name|getInfoAddr
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFS_DATANODE_HTTP_ADDRESS_KEY
argument_list|,
name|DFS_DATANODE_HTTP_ADDRESS_DEFAULT
argument_list|)
argument_list|)
return|;
block|}
DECL|method|registerMXBean ()
specifier|private
name|void
name|registerMXBean
parameter_list|()
block|{
name|dataNodeInfoBeanName
operator|=
name|MBeans
operator|.
name|register
argument_list|(
literal|"DataNode"
argument_list|,
literal|"DataNodeInfo"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getXferServer ()
specifier|public
name|DataXceiverServer
name|getXferServer
parameter_list|()
block|{
return|return
name|xserver
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getXferPort ()
specifier|public
name|int
name|getXferPort
parameter_list|()
block|{
return|return
name|streamingAddr
operator|.
name|getPort
argument_list|()
return|;
block|}
comment|/**    * @return name useful for logging    */
DECL|method|getDisplayName ()
specifier|public
name|String
name|getDisplayName
parameter_list|()
block|{
comment|// NB: our DatanodeID may not be set yet
return|return
name|hostName
operator|+
literal|":"
operator|+
name|getXferPort
argument_list|()
return|;
block|}
comment|/**    * NB: The datanode can perform data transfer on the streaming    * address however clients are given the IPC IP address for data    * transfer, and that may be a different address.    *     * @return socket address for data transfer    */
DECL|method|getXferAddress ()
specifier|public
name|InetSocketAddress
name|getXferAddress
parameter_list|()
block|{
return|return
name|streamingAddr
return|;
block|}
comment|/**    * @return the datanode's IPC port    */
DECL|method|getIpcPort ()
specifier|public
name|int
name|getIpcPort
parameter_list|()
block|{
return|return
name|ipcServer
operator|.
name|getListenerAddress
argument_list|()
operator|.
name|getPort
argument_list|()
return|;
block|}
comment|/**    * get BP registration by blockPool id    * @return BP registration object    * @throws IOException on error    */
annotation|@
name|VisibleForTesting
DECL|method|getDNRegistrationForBP (String bpid)
specifier|public
name|DatanodeRegistration
name|getDNRegistrationForBP
parameter_list|(
name|String
name|bpid
parameter_list|)
throws|throws
name|IOException
block|{
name|DataNodeFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|noRegistration
argument_list|()
expr_stmt|;
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpos
operator|==
literal|null
operator|||
name|bpos
operator|.
name|bpRegistration
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"cannot find BPOfferService for bpid="
operator|+
name|bpid
argument_list|)
throw|;
block|}
return|return
name|bpos
operator|.
name|bpRegistration
return|;
block|}
comment|/**    * Creates either NIO or regular depending on socketWriteTimeout.    */
DECL|method|newSocket ()
specifier|public
name|Socket
name|newSocket
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|(
name|dnConf
operator|.
name|socketWriteTimeout
operator|>
literal|0
operator|)
condition|?
name|SocketChannel
operator|.
name|open
argument_list|()
operator|.
name|socket
argument_list|()
else|:
operator|new
name|Socket
argument_list|()
return|;
block|}
comment|/**    * Connect to the NN. This is separated out for easier testing.    */
DECL|method|connectToNN ( InetSocketAddress nnAddr)
name|DatanodeProtocolClientSideTranslatorPB
name|connectToNN
parameter_list|(
name|InetSocketAddress
name|nnAddr
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|DatanodeProtocolClientSideTranslatorPB
argument_list|(
name|nnAddr
argument_list|,
name|conf
argument_list|)
return|;
block|}
comment|/**    * Connect to the NN for the lifeline protocol. This is separated out for    * easier testing.    *    * @param lifelineNnAddr address of lifeline RPC server    * @return lifeline RPC proxy    */
DECL|method|connectToLifelineNN ( InetSocketAddress lifelineNnAddr)
name|DatanodeLifelineProtocolClientSideTranslatorPB
name|connectToLifelineNN
parameter_list|(
name|InetSocketAddress
name|lifelineNnAddr
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|DatanodeLifelineProtocolClientSideTranslatorPB
argument_list|(
name|lifelineNnAddr
argument_list|,
name|conf
argument_list|)
return|;
block|}
DECL|method|createInterDataNodeProtocolProxy ( DatanodeID datanodeid, final Configuration conf, final int socketTimeout, final boolean connectToDnViaHostname)
specifier|public
specifier|static
name|InterDatanodeProtocol
name|createInterDataNodeProtocolProxy
parameter_list|(
name|DatanodeID
name|datanodeid
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|int
name|socketTimeout
parameter_list|,
specifier|final
name|boolean
name|connectToDnViaHostname
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|dnAddr
init|=
name|datanodeid
operator|.
name|getIpcAddr
argument_list|(
name|connectToDnViaHostname
argument_list|)
decl_stmt|;
specifier|final
name|InetSocketAddress
name|addr
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connecting to datanode "
operator|+
name|dnAddr
operator|+
literal|" addr="
operator|+
name|addr
argument_list|)
expr_stmt|;
block|}
specifier|final
name|UserGroupInformation
name|loginUgi
init|=
name|UserGroupInformation
operator|.
name|getLoginUser
argument_list|()
decl_stmt|;
try|try
block|{
return|return
name|loginUgi
operator|.
name|doAs
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|InterDatanodeProtocol
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|InterDatanodeProtocol
name|run
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|new
name|InterDatanodeProtocolTranslatorPB
argument_list|(
name|addr
argument_list|,
name|loginUgi
argument_list|,
name|conf
argument_list|,
name|NetUtils
operator|.
name|getDefaultSocketFactory
argument_list|(
name|conf
argument_list|)
argument_list|,
name|socketTimeout
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
block|}
DECL|method|getMetrics ()
specifier|public
name|DataNodeMetrics
name|getMetrics
parameter_list|()
block|{
return|return
name|metrics
return|;
block|}
comment|/** Ensure the authentication method is kerberos */
DECL|method|checkKerberosAuthMethod (String msg)
specifier|private
name|void
name|checkKerberosAuthMethod
parameter_list|(
name|String
name|msg
parameter_list|)
throws|throws
name|IOException
block|{
comment|// User invoking the call must be same as the datanode user
if|if
condition|(
operator|!
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getAuthenticationMethod
argument_list|()
operator|!=
name|AuthenticationMethod
operator|.
name|KERBEROS
condition|)
block|{
throw|throw
operator|new
name|AccessControlException
argument_list|(
literal|"Error in "
operator|+
name|msg
operator|+
literal|"Only kerberos based authentication is allowed."
argument_list|)
throw|;
block|}
block|}
DECL|method|checkBlockLocalPathAccess ()
specifier|private
name|void
name|checkBlockLocalPathAccess
parameter_list|()
throws|throws
name|IOException
block|{
name|checkKerberosAuthMethod
argument_list|(
literal|"getBlockLocalPathInfo()"
argument_list|)
expr_stmt|;
name|String
name|currentUser
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|usersWithLocalPathAccess
operator|.
name|contains
argument_list|(
name|currentUser
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|AccessControlException
argument_list|(
literal|"Can't continue with getBlockLocalPathInfo() "
operator|+
literal|"authorization. The user "
operator|+
name|currentUser
operator|+
literal|" is not configured in "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_LOCAL_PATH_ACCESS_USER_KEY
argument_list|)
throw|;
block|}
block|}
DECL|method|getMaxNumberOfBlocksToLog ()
specifier|public
name|long
name|getMaxNumberOfBlocksToLog
parameter_list|()
block|{
return|return
name|maxNumberOfBlocksToLog
return|;
block|}
annotation|@
name|Override
DECL|method|getBlockLocalPathInfo (ExtendedBlock block, Token<BlockTokenIdentifier> token)
specifier|public
name|BlockLocalPathInfo
name|getBlockLocalPathInfo
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|IOException
block|{
name|checkBlockLocalPathAccess
argument_list|()
expr_stmt|;
name|checkBlockToken
argument_list|(
name|block
argument_list|,
name|token
argument_list|,
name|BlockTokenIdentifier
operator|.
name|AccessMode
operator|.
name|READ
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|data
argument_list|,
literal|"Storage not yet initialized"
argument_list|)
expr_stmt|;
name|BlockLocalPathInfo
name|info
init|=
name|data
operator|.
name|getBlockLocalPathInfo
argument_list|(
name|block
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|info
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"getBlockLocalPathInfo successful block="
operator|+
name|block
operator|+
literal|" blockfile "
operator|+
name|info
operator|.
name|getBlockPath
argument_list|()
operator|+
literal|" metafile "
operator|+
name|info
operator|.
name|getMetaPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"getBlockLocalPathInfo for block="
operator|+
name|block
operator|+
literal|" returning null"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|metrics
operator|.
name|incrBlocksGetLocalPathInfo
argument_list|()
expr_stmt|;
return|return
name|info
return|;
block|}
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
literal|"HDFS"
argument_list|)
DECL|class|ShortCircuitFdsUnsupportedException
specifier|static
specifier|public
class|class
name|ShortCircuitFdsUnsupportedException
extends|extends
name|IOException
block|{
DECL|field|serialVersionUID
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
DECL|method|ShortCircuitFdsUnsupportedException (String msg)
specifier|public
name|ShortCircuitFdsUnsupportedException
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
name|super
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
literal|"HDFS"
argument_list|)
DECL|class|ShortCircuitFdsVersionException
specifier|static
specifier|public
class|class
name|ShortCircuitFdsVersionException
extends|extends
name|IOException
block|{
DECL|field|serialVersionUID
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
DECL|method|ShortCircuitFdsVersionException (String msg)
specifier|public
name|ShortCircuitFdsVersionException
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
name|super
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|requestShortCircuitFdsForRead (final ExtendedBlock blk, final Token<BlockTokenIdentifier> token, int maxVersion)
name|FileInputStream
index|[]
name|requestShortCircuitFdsForRead
parameter_list|(
specifier|final
name|ExtendedBlock
name|blk
parameter_list|,
specifier|final
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|token
parameter_list|,
name|int
name|maxVersion
parameter_list|)
throws|throws
name|ShortCircuitFdsUnsupportedException
throws|,
name|ShortCircuitFdsVersionException
throws|,
name|IOException
block|{
if|if
condition|(
name|fileDescriptorPassingDisabledReason
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|ShortCircuitFdsUnsupportedException
argument_list|(
name|fileDescriptorPassingDisabledReason
argument_list|)
throw|;
block|}
name|int
name|blkVersion
init|=
name|CURRENT_BLOCK_FORMAT_VERSION
decl_stmt|;
if|if
condition|(
name|maxVersion
operator|<
name|blkVersion
condition|)
block|{
throw|throw
operator|new
name|ShortCircuitFdsVersionException
argument_list|(
literal|"Your client is too old "
operator|+
literal|"to read this block!  Its format version is "
operator|+
name|blkVersion
operator|+
literal|", but the highest format version you can read is "
operator|+
name|maxVersion
argument_list|)
throw|;
block|}
name|metrics
operator|.
name|incrBlocksGetLocalPathInfo
argument_list|()
expr_stmt|;
name|FileInputStream
name|fis
index|[]
init|=
operator|new
name|FileInputStream
index|[
literal|2
index|]
decl_stmt|;
try|try
block|{
name|fis
index|[
literal|0
index|]
operator|=
operator|(
name|FileInputStream
operator|)
name|data
operator|.
name|getBlockInputStream
argument_list|(
name|blk
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|fis
index|[
literal|1
index|]
operator|=
name|DatanodeUtil
operator|.
name|getMetaDataInputStream
argument_list|(
name|blk
argument_list|,
name|data
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassCastException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"requestShortCircuitFdsForRead failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ShortCircuitFdsUnsupportedException
argument_list|(
literal|"This DataNode's "
operator|+
literal|"FsDatasetSpi does not support short-circuit local reads"
argument_list|)
throw|;
block|}
return|return
name|fis
return|;
block|}
DECL|method|checkBlockToken (ExtendedBlock block, Token<BlockTokenIdentifier> token, AccessMode accessMode)
specifier|private
name|void
name|checkBlockToken
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|token
parameter_list|,
name|AccessMode
name|accessMode
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isBlockTokenEnabled
condition|)
block|{
name|BlockTokenIdentifier
name|id
init|=
operator|new
name|BlockTokenIdentifier
argument_list|()
decl_stmt|;
name|ByteArrayInputStream
name|buf
init|=
operator|new
name|ByteArrayInputStream
argument_list|(
name|token
operator|.
name|getIdentifier
argument_list|()
argument_list|)
decl_stmt|;
name|DataInputStream
name|in
init|=
operator|new
name|DataInputStream
argument_list|(
name|buf
argument_list|)
decl_stmt|;
name|id
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got: "
operator|+
name|id
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|blockPoolTokenSecretManager
operator|.
name|checkAccess
argument_list|(
name|id
argument_list|,
literal|null
argument_list|,
name|block
argument_list|,
name|accessMode
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Shut down this instance of the datanode.    * Returns only after shutdown is complete.    * This method can only be called by the offerService thread.    * Otherwise, deadlock might occur.    */
DECL|method|shutdown ()
specifier|public
name|void
name|shutdown
parameter_list|()
block|{
name|stopMetricsLogger
argument_list|()
expr_stmt|;
if|if
condition|(
name|plugins
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ServicePlugin
name|p
range|:
name|plugins
control|)
block|{
try|try
block|{
name|p
operator|.
name|stop
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Stopped plug-in "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"ServicePlugin "
operator|+
name|p
operator|+
literal|" could not be stopped"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|List
argument_list|<
name|BPOfferService
argument_list|>
name|bposArray
init|=
operator|(
name|this
operator|.
name|blockPoolManager
operator|==
literal|null
operator|)
condition|?
operator|new
name|ArrayList
argument_list|<
name|BPOfferService
argument_list|>
argument_list|()
else|:
name|this
operator|.
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
decl_stmt|;
comment|// If shutdown is not for restart, set shouldRun to false early.
if|if
condition|(
operator|!
name|shutdownForUpgrade
condition|)
block|{
name|shouldRun
operator|=
literal|false
expr_stmt|;
block|}
comment|// When shutting down for restart, DataXceiverServer is interrupted
comment|// in order to avoid any further acceptance of requests, but the peers
comment|// for block writes are not closed until the clients are notified.
if|if
condition|(
name|dataXceiverServer
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|xserver
operator|.
name|sendOOBToPeers
argument_list|()
expr_stmt|;
operator|(
operator|(
name|DataXceiverServer
operator|)
name|this
operator|.
name|dataXceiverServer
operator|.
name|getRunnable
argument_list|()
operator|)
operator|.
name|kill
argument_list|()
expr_stmt|;
name|this
operator|.
name|dataXceiverServer
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Ignore, since the out of band messaging is advisory.
name|LOG
operator|.
name|trace
argument_list|(
literal|"Exception interrupting DataXceiverServer: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Interrupt the checkDiskErrorThread and terminate it.
if|if
condition|(
name|this
operator|.
name|checkDiskErrorThread
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|checkDiskErrorThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
comment|// Record the time of initial notification
name|long
name|timeNotified
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
if|if
condition|(
name|localDataXceiverServer
operator|!=
literal|null
condition|)
block|{
operator|(
operator|(
name|DataXceiverServer
operator|)
name|this
operator|.
name|localDataXceiverServer
operator|.
name|getRunnable
argument_list|()
operator|)
operator|.
name|kill
argument_list|()
expr_stmt|;
name|this
operator|.
name|localDataXceiverServer
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
comment|// Terminate directory scanner and block scanner
name|shutdownPeriodicScanners
argument_list|()
expr_stmt|;
comment|// Stop the web server
if|if
condition|(
name|httpServer
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|httpServer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception shutting down DataNode HttpServer"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|pauseMonitor
operator|!=
literal|null
condition|)
block|{
name|pauseMonitor
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
comment|// shouldRun is set to false here to prevent certain threads from exiting
comment|// before the restart prep is done.
name|this
operator|.
name|shouldRun
operator|=
literal|false
expr_stmt|;
comment|// wait reconfiguration thread, if any, to exit
name|shutdownReconfigurationTask
argument_list|()
expr_stmt|;
comment|// wait for all data receiver threads to exit
if|if
condition|(
name|this
operator|.
name|threadGroup
operator|!=
literal|null
condition|)
block|{
name|int
name|sleepMs
init|=
literal|2
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
comment|// When shutting down for restart, wait 2.5 seconds before forcing
comment|// termination of receiver threads.
if|if
condition|(
operator|!
name|this
operator|.
name|shutdownForUpgrade
operator|||
operator|(
name|this
operator|.
name|shutdownForUpgrade
operator|&&
operator|(
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|-
name|timeNotified
operator|>
literal|1000
operator|)
operator|)
condition|)
block|{
name|this
operator|.
name|threadGroup
operator|.
name|interrupt
argument_list|()
expr_stmt|;
break|break;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for threadgroup to exit, active threads is "
operator|+
name|this
operator|.
name|threadGroup
operator|.
name|activeCount
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|threadGroup
operator|.
name|activeCount
argument_list|()
operator|==
literal|0
condition|)
block|{
break|break;
block|}
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|sleepMs
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{}
name|sleepMs
operator|=
name|sleepMs
operator|*
literal|3
operator|/
literal|2
expr_stmt|;
comment|// exponential backoff
if|if
condition|(
name|sleepMs
operator|>
literal|200
condition|)
block|{
name|sleepMs
operator|=
literal|200
expr_stmt|;
block|}
block|}
name|this
operator|.
name|threadGroup
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|dataXceiverServer
operator|!=
literal|null
condition|)
block|{
comment|// wait for dataXceiverServer to terminate
try|try
block|{
name|this
operator|.
name|dataXceiverServer
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{       }
block|}
if|if
condition|(
name|this
operator|.
name|localDataXceiverServer
operator|!=
literal|null
condition|)
block|{
comment|// wait for localDataXceiverServer to terminate
try|try
block|{
name|this
operator|.
name|localDataXceiverServer
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{       }
block|}
if|if
condition|(
name|metrics
operator|!=
literal|null
condition|)
block|{
name|metrics
operator|.
name|setDataNodeActiveXceiversCount
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
comment|// IPC server needs to be shutdown late in the process, otherwise
comment|// shutdown command response won't get sent.
if|if
condition|(
name|ipcServer
operator|!=
literal|null
condition|)
block|{
name|ipcServer
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|blockPoolManager
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|blockPoolManager
operator|.
name|shutDownAll
argument_list|(
name|bposArray
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received exception in BlockPoolManager#shutDownAll: "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|storage
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|storage
operator|.
name|unlockAll
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception when unlocking storage: "
operator|+
name|ie
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|data
operator|!=
literal|null
condition|)
block|{
name|data
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|metrics
operator|!=
literal|null
condition|)
block|{
name|metrics
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|dataNodeInfoBeanName
operator|!=
literal|null
condition|)
block|{
name|MBeans
operator|.
name|unregister
argument_list|(
name|dataNodeInfoBeanName
argument_list|)
expr_stmt|;
name|dataNodeInfoBeanName
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|shortCircuitRegistry
operator|!=
literal|null
condition|)
name|shortCircuitRegistry
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Shutdown complete."
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
comment|// it is already false, but setting it again to avoid a findbug warning.
name|this
operator|.
name|shouldRun
operator|=
literal|false
expr_stmt|;
comment|// Notify the main thread.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
name|tracer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Check if there is a disk failure asynchronously and if so, handle the error    */
DECL|method|checkDiskErrorAsync ()
specifier|public
name|void
name|checkDiskErrorAsync
parameter_list|()
block|{
synchronized|synchronized
init|(
name|checkDiskErrorMutex
init|)
block|{
name|checkDiskErrorFlag
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|checkDiskErrorThread
operator|==
literal|null
condition|)
block|{
name|startCheckDiskErrorThread
argument_list|()
expr_stmt|;
name|checkDiskErrorThread
operator|.
name|start
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting CheckDiskError Thread"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|handleDiskError (String errMsgr)
specifier|private
name|void
name|handleDiskError
parameter_list|(
name|String
name|errMsgr
parameter_list|)
block|{
specifier|final
name|boolean
name|hasEnoughResources
init|=
name|data
operator|.
name|hasEnoughResource
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"DataNode.handleDiskError: Keep Running: "
operator|+
name|hasEnoughResources
argument_list|)
expr_stmt|;
comment|// If we have enough active valid volumes then we do not want to
comment|// shutdown the DN completely.
name|int
name|dpError
init|=
name|hasEnoughResources
condition|?
name|DatanodeProtocol
operator|.
name|DISK_ERROR
else|:
name|DatanodeProtocol
operator|.
name|FATAL_DISK_ERROR
decl_stmt|;
name|metrics
operator|.
name|incrVolumeFailures
argument_list|()
expr_stmt|;
comment|//inform NameNodes
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
name|bpos
operator|.
name|trySendErrorReport
argument_list|(
name|dpError
argument_list|,
name|errMsgr
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|hasEnoughResources
condition|)
block|{
name|scheduleAllBlockReport
argument_list|(
literal|0
argument_list|)
expr_stmt|;
return|return;
comment|// do not shutdown
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"DataNode is shutting down: "
operator|+
name|errMsgr
argument_list|)
expr_stmt|;
name|shouldRun
operator|=
literal|false
expr_stmt|;
block|}
comment|/** Number of concurrent xceivers per node. */
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getXceiverCount ()
specifier|public
name|int
name|getXceiverCount
parameter_list|()
block|{
return|return
name|threadGroup
operator|==
literal|null
condition|?
literal|0
else|:
name|threadGroup
operator|.
name|activeCount
argument_list|()
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getDatanodeNetworkCounts ()
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|>
name|getDatanodeNetworkCounts
parameter_list|()
block|{
return|return
name|datanodeNetworkCounts
operator|.
name|asMap
argument_list|()
return|;
block|}
DECL|method|incrDatanodeNetworkErrors (String host)
name|void
name|incrDatanodeNetworkErrors
parameter_list|(
name|String
name|host
parameter_list|)
block|{
name|metrics
operator|.
name|incrDatanodeNetworkErrors
argument_list|()
expr_stmt|;
comment|/*      * Synchronizing on the whole cache is a big hammer, but since it's only      * accumulating errors, it should be ok. If this is ever expanded to include      * non-error stats, then finer-grained concurrency should be applied.      */
synchronized|synchronized
init|(
name|datanodeNetworkCounts
init|)
block|{
try|try
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|curCount
init|=
name|datanodeNetworkCounts
operator|.
name|get
argument_list|(
name|host
argument_list|)
decl_stmt|;
name|curCount
operator|.
name|put
argument_list|(
literal|"networkErrors"
argument_list|,
name|curCount
operator|.
name|get
argument_list|(
literal|"networkErrors"
argument_list|)
operator|+
literal|1L
argument_list|)
expr_stmt|;
name|datanodeNetworkCounts
operator|.
name|put
argument_list|(
name|host
argument_list|,
name|curCount
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to increment network error counts for "
operator|+
name|host
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|getXmitsInProgress ()
name|int
name|getXmitsInProgress
parameter_list|()
block|{
return|return
name|xmitsInProgress
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Increments the xmitsInProgress count. xmitsInProgress count represents the    * number of data replication/reconstruction tasks running currently.    */
DECL|method|incrementXmitsInProgress ()
specifier|public
name|void
name|incrementXmitsInProgress
parameter_list|()
block|{
name|xmitsInProgress
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
block|}
comment|/**    * Decrements the xmitsInProgress count    */
DECL|method|decrementXmitsInProgress ()
specifier|public
name|void
name|decrementXmitsInProgress
parameter_list|()
block|{
name|xmitsInProgress
operator|.
name|getAndDecrement
argument_list|()
expr_stmt|;
block|}
DECL|method|reportBadBlock (final BPOfferService bpos, final ExtendedBlock block, final String msg)
specifier|private
name|void
name|reportBadBlock
parameter_list|(
specifier|final
name|BPOfferService
name|bpos
parameter_list|,
specifier|final
name|ExtendedBlock
name|block
parameter_list|,
specifier|final
name|String
name|msg
parameter_list|)
block|{
name|FsVolumeSpi
name|volume
init|=
name|getFSDataset
argument_list|()
operator|.
name|getVolume
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|bpos
operator|.
name|reportBadBlocks
argument_list|(
name|block
argument_list|,
name|volume
operator|.
name|getStorageID
argument_list|()
argument_list|,
name|volume
operator|.
name|getStorageType
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
DECL|method|transferBlock (ExtendedBlock block, DatanodeInfo[] xferTargets, StorageType[] xferTargetStorageTypes)
specifier|private
name|void
name|transferBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|DatanodeInfo
index|[]
name|xferTargets
parameter_list|,
name|StorageType
index|[]
name|xferTargetStorageTypes
parameter_list|)
throws|throws
name|IOException
block|{
name|BPOfferService
name|bpos
init|=
name|getBPOSForBlock
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|DatanodeRegistration
name|bpReg
init|=
name|getDNRegistrationForBP
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|replicaNotExist
init|=
literal|false
decl_stmt|;
name|boolean
name|replicaStateNotFinalized
init|=
literal|false
decl_stmt|;
name|boolean
name|blockFileNotExist
init|=
literal|false
decl_stmt|;
name|boolean
name|lengthTooShort
init|=
literal|false
decl_stmt|;
try|try
block|{
name|data
operator|.
name|checkBlock
argument_list|(
name|block
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|ReplicaState
operator|.
name|FINALIZED
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReplicaNotFoundException
name|e
parameter_list|)
block|{
name|replicaNotExist
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnexpectedReplicaStateException
name|e
parameter_list|)
block|{
name|replicaStateNotFinalized
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|blockFileNotExist
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|EOFException
name|e
parameter_list|)
block|{
name|lengthTooShort
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// The IOException indicates not being able to access block file,
comment|// treat it the same here as blockFileNotExist, to trigger
comment|// reporting it as a bad block
name|blockFileNotExist
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|replicaNotExist
operator|||
name|replicaStateNotFinalized
condition|)
block|{
name|String
name|errStr
init|=
literal|"Can't send invalid block "
operator|+
name|block
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|errStr
argument_list|)
expr_stmt|;
name|bpos
operator|.
name|trySendErrorReport
argument_list|(
name|DatanodeProtocol
operator|.
name|INVALID_BLOCK
argument_list|,
name|errStr
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|blockFileNotExist
condition|)
block|{
comment|// Report back to NN bad block caused by non-existent block file.
name|reportBadBlock
argument_list|(
name|bpos
argument_list|,
name|block
argument_list|,
literal|"Can't replicate block "
operator|+
name|block
operator|+
literal|" because the block file doesn't exist, or is not accessible"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|lengthTooShort
condition|)
block|{
comment|// Check if NN recorded length matches on-disk length
comment|// Shorter on-disk len indicates corruption so report NN the corrupt block
name|reportBadBlock
argument_list|(
name|bpos
argument_list|,
name|block
argument_list|,
literal|"Can't replicate block "
operator|+
name|block
operator|+
literal|" because on-disk length "
operator|+
name|data
operator|.
name|getLength
argument_list|(
name|block
argument_list|)
operator|+
literal|" is shorter than NameNode recorded length "
operator|+
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
name|int
name|numTargets
init|=
name|xferTargets
operator|.
name|length
decl_stmt|;
if|if
condition|(
name|numTargets
operator|>
literal|0
condition|)
block|{
name|StringBuilder
name|xfersBuilder
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numTargets
condition|;
name|i
operator|++
control|)
block|{
name|xfersBuilder
operator|.
name|append
argument_list|(
name|xferTargets
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|xfersBuilder
operator|.
name|append
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
name|bpReg
operator|+
literal|" Starting thread to transfer "
operator|+
name|block
operator|+
literal|" to "
operator|+
name|xfersBuilder
argument_list|)
expr_stmt|;
operator|new
name|Daemon
argument_list|(
operator|new
name|DataTransfer
argument_list|(
name|xferTargets
argument_list|,
name|xferTargetStorageTypes
argument_list|,
name|block
argument_list|,
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
argument_list|,
literal|""
argument_list|)
argument_list|)
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|transferBlocks (String poolId, Block blocks[], DatanodeInfo xferTargets[][], StorageType[][] xferTargetStorageTypes)
name|void
name|transferBlocks
parameter_list|(
name|String
name|poolId
parameter_list|,
name|Block
name|blocks
index|[]
parameter_list|,
name|DatanodeInfo
name|xferTargets
index|[]
index|[]
parameter_list|,
name|StorageType
index|[]
index|[]
name|xferTargetStorageTypes
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blocks
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|transferBlock
argument_list|(
operator|new
name|ExtendedBlock
argument_list|(
name|poolId
argument_list|,
name|blocks
index|[
name|i
index|]
argument_list|)
argument_list|,
name|xferTargets
index|[
name|i
index|]
argument_list|,
name|xferTargetStorageTypes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to transfer block "
operator|+
name|blocks
index|[
name|i
index|]
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/* ********************************************************************   Protocol when a client reads data from Datanode (Cur Ver: 9):      Client's Request :   =================          Processed in DataXceiver:      +----------------------------------------------+      | Common Header   | 1 byte OP == OP_READ_BLOCK |      +----------------------------------------------+            Processed in readBlock() :      +-------------------------------------------------------------------------+      | 8 byte Block ID | 8 byte genstamp | 8 byte start offset | 8 byte length |      +-------------------------------------------------------------------------+      |   vInt length   |<DFSClient id> |      +-----------------------------------+            Client sends optional response only at the end of receiving data.           DataNode Response :   ===================         In readBlock() :     If there is an error while initializing BlockSender :        +---------------------------+        | 2 byte OP_STATUS_ERROR    | and connection will be closed.        +---------------------------+     Otherwise        +---------------------------+        | 2 byte OP_STATUS_SUCCESS  |        +---------------------------+             Actual data, sent by BlockSender.sendBlock() :            ChecksumHeader :       +--------------------------------------------------+       | 1 byte CHECKSUM_TYPE | 4 byte BYTES_PER_CHECKSUM |       +--------------------------------------------------+       Followed by actual data in the form of PACKETS:        +------------------------------------+       | Sequence of data PACKETs ....      |       +------------------------------------+          A "PACKET" is defined further below.          The client reads data until it receives a packet with      "LastPacketInBlock" set to true or with a zero length. It then replies     to DataNode with one of the status codes:     - CHECKSUM_OK:    All the chunk checksums have been verified     - SUCCESS:        Data received; checksums not verified     - ERROR_CHECKSUM: (Currently not used) Detected invalid checksums        +---------------+       | 2 byte Status |       +---------------+          The DataNode expects all well behaved clients to send the 2 byte     status code. And if the the client doesn't, the DN will close the     connection. So the status code is optional in the sense that it     does not affect the correctness of the data. (And the client can     always reconnect.)          PACKET : Contains a packet header, checksum and data. Amount of data     ======== carried is set by BUFFER_SIZE.            +-----------------------------------------------------+       | 4 byte packet length (excluding packet header)      |       +-----------------------------------------------------+       | 8 byte offset in the block | 8 byte sequence number |       +-----------------------------------------------------+       | 1 byte isLastPacketInBlock                          |       +-----------------------------------------------------+       | 4 byte Length of actual data                        |       +-----------------------------------------------------+       | x byte checksum data. x is defined below            |       +-----------------------------------------------------+       | actual data ......                                  |       +-----------------------------------------------------+              x = (length of data + BYTE_PER_CHECKSUM - 1)/BYTES_PER_CHECKSUM *           CHECKSUM_SIZE                  CHECKSUM_SIZE depends on CHECKSUM_TYPE (usually, 4 for CRC32)              The above packet format is used while writing data to DFS also.       Not all the fields might be used while reading.         ************************************************************************ */
comment|/**    * Used for transferring a block of data.  This class    * sends a piece of data to another DataNode.    */
DECL|class|DataTransfer
specifier|private
class|class
name|DataTransfer
implements|implements
name|Runnable
block|{
DECL|field|targets
specifier|final
name|DatanodeInfo
index|[]
name|targets
decl_stmt|;
DECL|field|targetStorageTypes
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
decl_stmt|;
DECL|field|b
specifier|final
name|ExtendedBlock
name|b
decl_stmt|;
DECL|field|stage
specifier|final
name|BlockConstructionStage
name|stage
decl_stmt|;
DECL|field|bpReg
specifier|final
specifier|private
name|DatanodeRegistration
name|bpReg
decl_stmt|;
DECL|field|clientname
specifier|final
name|String
name|clientname
decl_stmt|;
DECL|field|cachingStrategy
specifier|final
name|CachingStrategy
name|cachingStrategy
decl_stmt|;
comment|/**      * Connect to the first item in the target list.  Pass along the       * entire target list, the block, and the data.      */
DECL|method|DataTransfer (DatanodeInfo targets[], StorageType[] targetStorageTypes, ExtendedBlock b, BlockConstructionStage stage, final String clientname)
name|DataTransfer
parameter_list|(
name|DatanodeInfo
name|targets
index|[]
parameter_list|,
name|StorageType
index|[]
name|targetStorageTypes
parameter_list|,
name|ExtendedBlock
name|b
parameter_list|,
name|BlockConstructionStage
name|stage
parameter_list|,
specifier|final
name|String
name|clientname
parameter_list|)
block|{
if|if
condition|(
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|debug
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|": "
operator|+
name|b
operator|+
literal|" (numBytes="
operator|+
name|b
operator|.
name|getNumBytes
argument_list|()
operator|+
literal|")"
operator|+
literal|", stage="
operator|+
name|stage
operator|+
literal|", clientname="
operator|+
name|clientname
operator|+
literal|", targets="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|targets
argument_list|)
operator|+
literal|", target storage types="
operator|+
operator|(
name|targetStorageTypes
operator|==
literal|null
condition|?
literal|"[]"
else|:
name|Arrays
operator|.
name|asList
argument_list|(
name|targetStorageTypes
argument_list|)
operator|)
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|targets
operator|=
name|targets
expr_stmt|;
name|this
operator|.
name|targetStorageTypes
operator|=
name|targetStorageTypes
expr_stmt|;
name|this
operator|.
name|b
operator|=
name|b
expr_stmt|;
name|this
operator|.
name|stage
operator|=
name|stage
expr_stmt|;
name|BPOfferService
name|bpos
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|b
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
decl_stmt|;
name|bpReg
operator|=
name|bpos
operator|.
name|bpRegistration
expr_stmt|;
name|this
operator|.
name|clientname
operator|=
name|clientname
expr_stmt|;
name|this
operator|.
name|cachingStrategy
operator|=
operator|new
name|CachingStrategy
argument_list|(
literal|true
argument_list|,
name|getDnConf
argument_list|()
operator|.
name|readaheadLength
argument_list|)
expr_stmt|;
block|}
comment|/**      * Do the deed, write the bytes      */
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|incrementXmitsInProgress
argument_list|()
expr_stmt|;
name|Socket
name|sock
init|=
literal|null
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
name|DataInputStream
name|in
init|=
literal|null
decl_stmt|;
name|BlockSender
name|blockSender
init|=
literal|null
decl_stmt|;
specifier|final
name|boolean
name|isClient
init|=
name|clientname
operator|.
name|length
argument_list|()
operator|>
literal|0
decl_stmt|;
try|try
block|{
specifier|final
name|String
name|dnAddr
init|=
name|targets
index|[
literal|0
index|]
operator|.
name|getXferAddr
argument_list|(
name|connectToDnViaHostname
argument_list|)
decl_stmt|;
name|InetSocketAddress
name|curTarget
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connecting to datanode "
operator|+
name|dnAddr
argument_list|)
expr_stmt|;
block|}
name|sock
operator|=
name|newSocket
argument_list|()
expr_stmt|;
name|NetUtils
operator|.
name|connect
argument_list|(
name|sock
argument_list|,
name|curTarget
argument_list|,
name|dnConf
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|targets
operator|.
name|length
operator|*
name|dnConf
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
comment|//
comment|// Header info
comment|//
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
init|=
name|getBlockAccessToken
argument_list|(
name|b
argument_list|,
name|EnumSet
operator|.
name|of
argument_list|(
name|BlockTokenIdentifier
operator|.
name|AccessMode
operator|.
name|WRITE
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|writeTimeout
init|=
name|dnConf
operator|.
name|socketWriteTimeout
operator|+
name|HdfsConstants
operator|.
name|WRITE_TIMEOUT_EXTENSION
operator|*
operator|(
name|targets
operator|.
name|length
operator|-
literal|1
operator|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|sock
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|sock
argument_list|)
decl_stmt|;
name|DataEncryptionKeyFactory
name|keyFactory
init|=
name|getDataEncryptionKeyFactoryForBlock
argument_list|(
name|b
argument_list|)
decl_stmt|;
name|IOStreamPair
name|saslStreams
init|=
name|saslClient
operator|.
name|socketSend
argument_list|(
name|sock
argument_list|,
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|keyFactory
argument_list|,
name|accessToken
argument_list|,
name|bpReg
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|saslStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|saslStreams
operator|.
name|in
expr_stmt|;
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|DFSUtilClient
operator|.
name|getSmallBufferSize
argument_list|(
name|conf
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
name|blockSender
operator|=
operator|new
name|BlockSender
argument_list|(
name|b
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getNumBytes
argument_list|()
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|DataNode
operator|.
name|this
argument_list|,
literal|null
argument_list|,
name|cachingStrategy
argument_list|)
expr_stmt|;
name|DatanodeInfo
name|srcNode
init|=
operator|new
name|DatanodeInfo
argument_list|(
name|bpReg
argument_list|)
decl_stmt|;
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|writeBlock
argument_list|(
name|b
argument_list|,
name|targetStorageTypes
index|[
literal|0
index|]
argument_list|,
name|accessToken
argument_list|,
name|clientname
argument_list|,
name|targets
argument_list|,
name|targetStorageTypes
argument_list|,
name|srcNode
argument_list|,
name|stage
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|blockSender
operator|.
name|getChecksum
argument_list|()
argument_list|,
name|cachingStrategy
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|// send data& checksum
name|blockSender
operator|.
name|sendBlock
argument_list|(
name|out
argument_list|,
name|unbufOut
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|// no response necessary
name|LOG
operator|.
name|info
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|": Transmitted "
operator|+
name|b
operator|+
literal|" (numBytes="
operator|+
name|b
operator|.
name|getNumBytes
argument_list|()
operator|+
literal|") to "
operator|+
name|curTarget
argument_list|)
expr_stmt|;
comment|// read ack
if|if
condition|(
name|isClient
condition|)
block|{
name|DNTransferAckProto
name|closeAck
init|=
name|DNTransferAckProto
operator|.
name|parseFrom
argument_list|(
name|PBHelperClient
operator|.
name|vintPrefixed
argument_list|(
name|in
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|": close-ack="
operator|+
name|closeAck
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|closeAck
operator|.
name|getStatus
argument_list|()
operator|!=
name|Status
operator|.
name|SUCCESS
condition|)
block|{
if|if
condition|(
name|closeAck
operator|.
name|getStatus
argument_list|()
operator|==
name|Status
operator|.
name|ERROR_ACCESS_TOKEN
condition|)
block|{
throw|throw
operator|new
name|InvalidBlockTokenException
argument_list|(
literal|"Got access token error for connect ack, targets="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|targets
argument_list|)
argument_list|)
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Bad connect ack, targets="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|targets
argument_list|)
operator|+
literal|" status="
operator|+
name|closeAck
operator|.
name|getStatus
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
else|else
block|{
name|metrics
operator|.
name|incrBlocksReplicated
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|bpReg
operator|+
literal|":Failed to transfer "
operator|+
name|b
operator|+
literal|" to "
operator|+
name|targets
index|[
literal|0
index|]
operator|+
literal|" got "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
comment|// check if there are any disk problem
name|checkDiskErrorAsync
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|decrementXmitsInProgress
argument_list|()
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|blockSender
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/***    * Use BlockTokenSecretManager to generate block token for current user.    */
DECL|method|getBlockAccessToken (ExtendedBlock b, EnumSet<AccessMode> mode)
specifier|public
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockAccessToken
parameter_list|(
name|ExtendedBlock
name|b
parameter_list|,
name|EnumSet
argument_list|<
name|AccessMode
argument_list|>
name|mode
parameter_list|)
throws|throws
name|IOException
block|{
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
init|=
name|BlockTokenSecretManager
operator|.
name|DUMMY_TOKEN
decl_stmt|;
if|if
condition|(
name|isBlockTokenEnabled
condition|)
block|{
name|accessToken
operator|=
name|blockPoolTokenSecretManager
operator|.
name|generateToken
argument_list|(
name|b
argument_list|,
name|mode
argument_list|)
expr_stmt|;
block|}
return|return
name|accessToken
return|;
block|}
comment|/**    * Returns a new DataEncryptionKeyFactory that generates a key from the    * BlockPoolTokenSecretManager, using the block pool ID of the given block.    *    * @param block for which the factory needs to create a key    * @return DataEncryptionKeyFactory for block's block pool ID    */
DECL|method|getDataEncryptionKeyFactoryForBlock ( final ExtendedBlock block)
specifier|public
name|DataEncryptionKeyFactory
name|getDataEncryptionKeyFactoryForBlock
parameter_list|(
specifier|final
name|ExtendedBlock
name|block
parameter_list|)
block|{
return|return
operator|new
name|DataEncryptionKeyFactory
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DataEncryptionKey
name|newDataEncryptionKey
parameter_list|()
block|{
return|return
name|dnConf
operator|.
name|encryptDataTransfer
condition|?
name|blockPoolTokenSecretManager
operator|.
name|generateDataEncryptionKey
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
else|:
literal|null
return|;
block|}
block|}
return|;
block|}
comment|/**    * After a block becomes finalized, a datanode increases metric counter,    * notifies namenode, and adds it to the block scanner    * @param block block to close    * @param delHint hint on which excess block to delete    * @param storageUuid UUID of the storage where block is stored    */
DECL|method|closeBlock (ExtendedBlock block, String delHint, String storageUuid, boolean isTransientStorage)
name|void
name|closeBlock
parameter_list|(
name|ExtendedBlock
name|block
parameter_list|,
name|String
name|delHint
parameter_list|,
name|String
name|storageUuid
parameter_list|,
name|boolean
name|isTransientStorage
parameter_list|)
block|{
name|metrics
operator|.
name|incrBlocksWritten
argument_list|()
expr_stmt|;
name|notifyNamenodeReceivedBlock
argument_list|(
name|block
argument_list|,
name|delHint
argument_list|,
name|storageUuid
argument_list|,
name|isTransientStorage
argument_list|)
expr_stmt|;
block|}
comment|/** Start a single datanode daemon and wait for it to finish.    *  If this thread is specifically interrupted, it will stop waiting.    */
DECL|method|runDatanodeDaemon ()
specifier|public
name|void
name|runDatanodeDaemon
parameter_list|()
throws|throws
name|IOException
block|{
name|blockPoolManager
operator|.
name|startAll
argument_list|()
expr_stmt|;
comment|// start dataXceiveServer
name|dataXceiverServer
operator|.
name|start
argument_list|()
expr_stmt|;
if|if
condition|(
name|localDataXceiverServer
operator|!=
literal|null
condition|)
block|{
name|localDataXceiverServer
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
name|ipcServer
operator|.
name|setTracer
argument_list|(
name|tracer
argument_list|)
expr_stmt|;
name|ipcServer
operator|.
name|start
argument_list|()
expr_stmt|;
name|startPlugins
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * A data node is considered to be up if one of the bp services is up    */
DECL|method|isDatanodeUp ()
specifier|public
name|boolean
name|isDatanodeUp
parameter_list|()
block|{
for|for
control|(
name|BPOfferService
name|bp
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
if|if
condition|(
name|bp
operator|.
name|isAlive
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/** Instantiate a single datanode object. This must be run by invoking    *  {@link DataNode#runDatanodeDaemon()} subsequently.     */
DECL|method|instantiateDataNode (String args[], Configuration conf)
specifier|public
specifier|static
name|DataNode
name|instantiateDataNode
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|instantiateDataNode
argument_list|(
name|args
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/** Instantiate a single datanode object, along with its secure resources.     * This must be run by invoking{@link DataNode#runDatanodeDaemon()}     * subsequently.     */
DECL|method|instantiateDataNode (String args [], Configuration conf, SecureResources resources)
specifier|public
specifier|static
name|DataNode
name|instantiateDataNode
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
name|conf
operator|=
operator|new
name|HdfsConfiguration
argument_list|()
expr_stmt|;
if|if
condition|(
name|args
operator|!=
literal|null
condition|)
block|{
comment|// parse generic hadoop options
name|GenericOptionsParser
name|hParser
init|=
operator|new
name|GenericOptionsParser
argument_list|(
name|conf
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|args
operator|=
name|hParser
operator|.
name|getRemainingArgs
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|parseArguments
argument_list|(
name|args
argument_list|,
name|conf
argument_list|)
condition|)
block|{
name|printUsage
argument_list|(
name|System
operator|.
name|err
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataLocations
init|=
name|getStorageLocations
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|UserGroupInformation
operator|.
name|setConfiguration
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|SecurityUtil
operator|.
name|login
argument_list|(
name|conf
argument_list|,
name|DFS_DATANODE_KEYTAB_FILE_KEY
argument_list|,
name|DFS_DATANODE_KERBEROS_PRINCIPAL_KEY
argument_list|,
name|getHostName
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|makeInstance
argument_list|(
name|dataLocations
argument_list|,
name|conf
argument_list|,
name|resources
argument_list|)
return|;
block|}
DECL|method|getStorageLocations (Configuration conf)
specifier|public
specifier|static
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|getStorageLocations
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|Collection
argument_list|<
name|String
argument_list|>
name|rawLocations
init|=
name|conf
operator|.
name|getTrimmedStringCollection
argument_list|(
name|DFS_DATANODE_DATA_DIR_KEY
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|locations
init|=
operator|new
name|ArrayList
argument_list|<
name|StorageLocation
argument_list|>
argument_list|(
name|rawLocations
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|locationString
range|:
name|rawLocations
control|)
block|{
specifier|final
name|StorageLocation
name|location
decl_stmt|;
try|try
block|{
name|location
operator|=
name|StorageLocation
operator|.
name|parse
argument_list|(
name|locationString
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to initialize storage directory "
operator|+
name|locationString
operator|+
literal|". Exception details: "
operator|+
name|ioe
argument_list|)
expr_stmt|;
comment|// Ignore the exception.
continue|continue;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|se
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to initialize storage directory "
operator|+
name|locationString
operator|+
literal|". Exception details: "
operator|+
name|se
argument_list|)
expr_stmt|;
comment|// Ignore the exception.
continue|continue;
block|}
name|locations
operator|.
name|add
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
return|return
name|locations
return|;
block|}
comment|/** Instantiate& Start a single datanode daemon and wait for it to finish.    *  If this thread is specifically interrupted, it will stop waiting.    */
annotation|@
name|VisibleForTesting
DECL|method|createDataNode (String args[], Configuration conf)
specifier|public
specifier|static
name|DataNode
name|createDataNode
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createDataNode
argument_list|(
name|args
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/** Instantiate& Start a single datanode daemon and wait for it to finish.    *  If this thread is specifically interrupted, it will stop waiting.    */
annotation|@
name|VisibleForTesting
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|method|createDataNode (String args[], Configuration conf, SecureResources resources)
specifier|public
specifier|static
name|DataNode
name|createDataNode
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|IOException
block|{
name|DataNode
name|dn
init|=
name|instantiateDataNode
argument_list|(
name|args
argument_list|,
name|conf
argument_list|,
name|resources
argument_list|)
decl_stmt|;
if|if
condition|(
name|dn
operator|!=
literal|null
condition|)
block|{
name|dn
operator|.
name|runDatanodeDaemon
argument_list|()
expr_stmt|;
block|}
return|return
name|dn
return|;
block|}
DECL|method|join ()
name|void
name|join
parameter_list|()
block|{
while|while
condition|(
name|shouldRun
condition|)
block|{
try|try
block|{
name|blockPoolManager
operator|.
name|joinAll
argument_list|()
expr_stmt|;
if|if
condition|(
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|shouldRun
operator|=
literal|false
expr_stmt|;
block|}
comment|// Terminate if shutdown is complete or 2 seconds after all BPs
comment|// are shutdown.
synchronized|synchronized
init|(
name|this
init|)
block|{
name|wait
argument_list|(
literal|2000
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received exception in Datanode#join: "
operator|+
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Small wrapper around the DiskChecker class that provides means to mock
comment|// DiskChecker static methods and unittest DataNode#getDataDirsFromURIs.
DECL|class|DataNodeDiskChecker
specifier|static
class|class
name|DataNodeDiskChecker
block|{
DECL|field|expectedPermission
specifier|private
specifier|final
name|FsPermission
name|expectedPermission
decl_stmt|;
DECL|method|DataNodeDiskChecker (FsPermission expectedPermission)
specifier|public
name|DataNodeDiskChecker
parameter_list|(
name|FsPermission
name|expectedPermission
parameter_list|)
block|{
name|this
operator|.
name|expectedPermission
operator|=
name|expectedPermission
expr_stmt|;
block|}
DECL|method|checkDir (LocalFileSystem localFS, Path path)
specifier|public
name|void
name|checkDir
parameter_list|(
name|LocalFileSystem
name|localFS
parameter_list|,
name|Path
name|path
parameter_list|)
throws|throws
name|DiskErrorException
throws|,
name|IOException
block|{
name|DiskChecker
operator|.
name|checkDir
argument_list|(
name|localFS
argument_list|,
name|path
argument_list|,
name|expectedPermission
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Make an instance of DataNode after ensuring that at least one of the    * given data directories (and their parent directories, if necessary)    * can be created.    * @param dataDirs List of directories, where the new DataNode instance should    * keep its files.    * @param conf Configuration instance to use.    * @param resources Secure resources needed to run under Kerberos    * @return DataNode instance for given list of data dirs and conf, or null if    * no directory from this directory list can be created.    * @throws IOException    */
DECL|method|makeInstance (Collection<StorageLocation> dataDirs, Configuration conf, SecureResources resources)
specifier|static
name|DataNode
name|makeInstance
parameter_list|(
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
throws|throws
name|IOException
block|{
name|LocalFileSystem
name|localFS
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FsPermission
name|permission
init|=
operator|new
name|FsPermission
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|DFS_DATANODE_DATA_DIR_PERMISSION_KEY
argument_list|,
name|DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT
argument_list|)
argument_list|)
decl_stmt|;
name|DataNodeDiskChecker
name|dataNodeDiskChecker
init|=
operator|new
name|DataNodeDiskChecker
argument_list|(
name|permission
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|locations
init|=
name|checkStorageLocations
argument_list|(
name|dataDirs
argument_list|,
name|localFS
argument_list|,
name|dataNodeDiskChecker
argument_list|)
decl_stmt|;
name|DefaultMetricsSystem
operator|.
name|initialize
argument_list|(
literal|"DataNode"
argument_list|)
expr_stmt|;
assert|assert
name|locations
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|:
literal|"number of data directories should be> 0"
assert|;
return|return
operator|new
name|DataNode
argument_list|(
name|conf
argument_list|,
name|locations
argument_list|,
name|resources
argument_list|)
return|;
block|}
comment|// DataNode ctor expects AbstractList instead of List or Collection...
DECL|method|checkStorageLocations ( Collection<StorageLocation> dataDirs, LocalFileSystem localFS, DataNodeDiskChecker dataNodeDiskChecker)
specifier|static
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|checkStorageLocations
parameter_list|(
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|LocalFileSystem
name|localFS
parameter_list|,
name|DataNodeDiskChecker
name|dataNodeDiskChecker
parameter_list|)
throws|throws
name|IOException
block|{
name|ArrayList
argument_list|<
name|StorageLocation
argument_list|>
name|locations
init|=
operator|new
name|ArrayList
argument_list|<
name|StorageLocation
argument_list|>
argument_list|()
decl_stmt|;
name|StringBuilder
name|invalidDirs
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|StorageLocation
name|location
range|:
name|dataDirs
control|)
block|{
specifier|final
name|URI
name|uri
init|=
name|location
operator|.
name|getUri
argument_list|()
decl_stmt|;
try|try
block|{
name|dataNodeDiskChecker
operator|.
name|checkDir
argument_list|(
name|localFS
argument_list|,
operator|new
name|Path
argument_list|(
name|uri
argument_list|)
argument_list|)
expr_stmt|;
name|locations
operator|.
name|add
argument_list|(
name|location
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid "
operator|+
name|DFS_DATANODE_DATA_DIR_KEY
operator|+
literal|" "
operator|+
name|location
operator|.
name|getFile
argument_list|()
operator|+
literal|" : "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|invalidDirs
operator|.
name|append
argument_list|(
literal|"\""
argument_list|)
operator|.
name|append
argument_list|(
name|uri
operator|.
name|getPath
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|"\" "
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|locations
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"All directories in "
operator|+
name|DFS_DATANODE_DATA_DIR_KEY
operator|+
literal|" are invalid: "
operator|+
name|invalidDirs
argument_list|)
throw|;
block|}
return|return
name|locations
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"DataNode{data="
operator|+
name|data
operator|+
literal|", localName='"
operator|+
name|getDisplayName
argument_list|()
operator|+
literal|"', datanodeUuid='"
operator|+
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
operator|+
literal|"', xmitsInProgress="
operator|+
name|xmitsInProgress
operator|.
name|get
argument_list|()
operator|+
literal|"}"
return|;
block|}
DECL|method|printUsage (PrintStream out)
specifier|private
specifier|static
name|void
name|printUsage
parameter_list|(
name|PrintStream
name|out
parameter_list|)
block|{
name|out
operator|.
name|println
argument_list|(
name|USAGE
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Parse and verify command line arguments and set configuration parameters.    *    * @return false if passed argements are incorrect    */
annotation|@
name|VisibleForTesting
DECL|method|parseArguments (String args[], Configuration conf)
specifier|static
name|boolean
name|parseArguments
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|StartupOption
name|startOpt
init|=
name|StartupOption
operator|.
name|REGULAR
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|args
operator|!=
literal|null
operator|&&
name|args
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
name|String
name|cmd
init|=
name|args
index|[
name|i
operator|++
index|]
decl_stmt|;
if|if
condition|(
literal|"-r"
operator|.
name|equalsIgnoreCase
argument_list|(
name|cmd
argument_list|)
operator|||
literal|"--rack"
operator|.
name|equalsIgnoreCase
argument_list|(
name|cmd
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"-r, --rack arguments are not supported anymore. RackID "
operator|+
literal|"resolution is handled by the NameNode."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
elseif|else
if|if
condition|(
name|StartupOption
operator|.
name|ROLLBACK
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|cmd
argument_list|)
condition|)
block|{
name|startOpt
operator|=
name|StartupOption
operator|.
name|ROLLBACK
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|StartupOption
operator|.
name|REGULAR
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|cmd
argument_list|)
condition|)
block|{
name|startOpt
operator|=
name|StartupOption
operator|.
name|REGULAR
expr_stmt|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
name|setStartupOption
argument_list|(
name|conf
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
return|return
operator|(
name|args
operator|==
literal|null
operator|||
name|i
operator|==
name|args
operator|.
name|length
operator|)
return|;
comment|// Fail if more than one cmd specified!
block|}
DECL|method|setStartupOption (Configuration conf, StartupOption opt)
specifier|private
specifier|static
name|void
name|setStartupOption
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|StartupOption
name|opt
parameter_list|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|DFS_DATANODE_STARTUP_KEY
argument_list|,
name|opt
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|getStartupOption (Configuration conf)
specifier|static
name|StartupOption
name|getStartupOption
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|value
init|=
name|conf
operator|.
name|get
argument_list|(
name|DFS_DATANODE_STARTUP_KEY
argument_list|,
name|StartupOption
operator|.
name|REGULAR
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|StartupOption
operator|.
name|getEnum
argument_list|(
name|value
argument_list|)
return|;
block|}
comment|/**    * This methods  arranges for the data node to send     * the block report at the next heartbeat.    */
DECL|method|scheduleAllBlockReport (long delay)
specifier|public
name|void
name|scheduleAllBlockReport
parameter_list|(
name|long
name|delay
parameter_list|)
block|{
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
name|bpos
operator|.
name|scheduleBlockReport
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Examples are adding and deleting blocks directly.    * The most common usage will be when the data node's storage is simulated.    *     * @return the fsdataset that stores the blocks    */
annotation|@
name|VisibleForTesting
DECL|method|getFSDataset ()
specifier|public
name|FsDatasetSpi
argument_list|<
name|?
argument_list|>
name|getFSDataset
parameter_list|()
block|{
return|return
name|data
return|;
block|}
annotation|@
name|VisibleForTesting
comment|/** @return the block scanner. */
DECL|method|getBlockScanner ()
specifier|public
name|BlockScanner
name|getBlockScanner
parameter_list|()
block|{
return|return
name|blockScanner
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getDirectoryScanner ()
name|DirectoryScanner
name|getDirectoryScanner
parameter_list|()
block|{
return|return
name|directoryScanner
return|;
block|}
DECL|method|secureMain (String args[], SecureResources resources)
specifier|public
specifier|static
name|void
name|secureMain
parameter_list|(
name|String
name|args
index|[]
parameter_list|,
name|SecureResources
name|resources
parameter_list|)
block|{
name|int
name|errorCode
init|=
literal|0
decl_stmt|;
try|try
block|{
name|StringUtils
operator|.
name|startupShutdownMessage
argument_list|(
name|DataNode
operator|.
name|class
argument_list|,
name|args
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
name|DataNode
name|datanode
init|=
name|createDataNode
argument_list|(
name|args
argument_list|,
literal|null
argument_list|,
name|resources
argument_list|)
decl_stmt|;
if|if
condition|(
name|datanode
operator|!=
literal|null
condition|)
block|{
name|datanode
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|errorCode
operator|=
literal|1
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception in secureMain"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|terminate
argument_list|(
literal|1
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// We need to terminate the process here because either shutdown was called
comment|// or some disk related conditions like volumes tolerated or volumes required
comment|// condition was not met. Also, In secure mode, control will go to Jsvc
comment|// and Datanode process hangs if it does not exit.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exiting Datanode"
argument_list|)
expr_stmt|;
name|terminate
argument_list|(
name|errorCode
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|main (String args[])
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
name|args
index|[]
parameter_list|)
block|{
if|if
condition|(
name|DFSUtil
operator|.
name|parseHelpArgument
argument_list|(
name|args
argument_list|,
name|DataNode
operator|.
name|USAGE
argument_list|,
name|System
operator|.
name|out
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|System
operator|.
name|exit
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|secureMain
argument_list|(
name|args
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|// InterDataNodeProtocol implementation
annotation|@
name|Override
comment|// InterDatanodeProtocol
DECL|method|initReplicaRecovery (RecoveringBlock rBlock)
specifier|public
name|ReplicaRecoveryInfo
name|initReplicaRecovery
parameter_list|(
name|RecoveringBlock
name|rBlock
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|data
operator|.
name|initReplicaRecovery
argument_list|(
name|rBlock
argument_list|)
return|;
block|}
comment|/**    * Update replica with the new generation stamp and length.      */
annotation|@
name|Override
comment|// InterDatanodeProtocol
DECL|method|updateReplicaUnderRecovery (final ExtendedBlock oldBlock, final long recoveryId, final long newBlockId, final long newLength)
specifier|public
name|String
name|updateReplicaUnderRecovery
parameter_list|(
specifier|final
name|ExtendedBlock
name|oldBlock
parameter_list|,
specifier|final
name|long
name|recoveryId
parameter_list|,
specifier|final
name|long
name|newBlockId
parameter_list|,
specifier|final
name|long
name|newLength
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Replica
name|r
init|=
name|data
operator|.
name|updateReplicaUnderRecovery
argument_list|(
name|oldBlock
argument_list|,
name|recoveryId
argument_list|,
name|newBlockId
argument_list|,
name|newLength
argument_list|)
decl_stmt|;
comment|// Notify the namenode of the updated block info. This is important
comment|// for HA, since otherwise the standby node may lose track of the
comment|// block locations until the next block report.
name|ExtendedBlock
name|newBlock
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|oldBlock
argument_list|)
decl_stmt|;
name|newBlock
operator|.
name|setGenerationStamp
argument_list|(
name|recoveryId
argument_list|)
expr_stmt|;
name|newBlock
operator|.
name|setBlockId
argument_list|(
name|newBlockId
argument_list|)
expr_stmt|;
name|newBlock
operator|.
name|setNumBytes
argument_list|(
name|newLength
argument_list|)
expr_stmt|;
specifier|final
name|String
name|storageID
init|=
name|r
operator|.
name|getStorageUuid
argument_list|()
decl_stmt|;
name|notifyNamenodeReceivedBlock
argument_list|(
name|newBlock
argument_list|,
literal|null
argument_list|,
name|storageID
argument_list|,
name|r
operator|.
name|isOnTransientStorage
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|storageID
return|;
block|}
annotation|@
name|Override
comment|// ClientDataNodeProtocol
DECL|method|getReplicaVisibleLength (final ExtendedBlock block)
specifier|public
name|long
name|getReplicaVisibleLength
parameter_list|(
specifier|final
name|ExtendedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadAccess
argument_list|(
name|block
argument_list|)
expr_stmt|;
return|return
name|data
operator|.
name|getReplicaVisibleLength
argument_list|(
name|block
argument_list|)
return|;
block|}
DECL|method|checkReadAccess (final ExtendedBlock block)
specifier|private
name|void
name|checkReadAccess
parameter_list|(
specifier|final
name|ExtendedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Make sure this node has registered for the block pool.
try|try
block|{
name|getDNRegistrationForBP
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// if it has not registered with the NN, throw an exception back.
throw|throw
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RetriableException
argument_list|(
literal|"Datanode not registered. Try again later."
argument_list|)
throw|;
block|}
if|if
condition|(
name|isBlockTokenEnabled
condition|)
block|{
name|Set
argument_list|<
name|TokenIdentifier
argument_list|>
name|tokenIds
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getTokenIdentifiers
argument_list|()
decl_stmt|;
if|if
condition|(
name|tokenIds
operator|.
name|size
argument_list|()
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Can't continue since none or more than one "
operator|+
literal|"BlockTokenIdentifier is found."
argument_list|)
throw|;
block|}
for|for
control|(
name|TokenIdentifier
name|tokenId
range|:
name|tokenIds
control|)
block|{
name|BlockTokenIdentifier
name|id
init|=
operator|(
name|BlockTokenIdentifier
operator|)
name|tokenId
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got: "
operator|+
name|id
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|blockPoolTokenSecretManager
operator|.
name|checkAccess
argument_list|(
name|id
argument_list|,
literal|null
argument_list|,
name|block
argument_list|,
name|BlockTokenIdentifier
operator|.
name|AccessMode
operator|.
name|READ
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Transfer a replica to the datanode targets.    * @param b the block to transfer.    *          The corresponding replica must be an RBW or a Finalized.    *          Its GS and numBytes will be set to    *          the stored GS and the visible length.     * @param targets targets to transfer the block to    * @param client client name    */
DECL|method|transferReplicaForPipelineRecovery (final ExtendedBlock b, final DatanodeInfo[] targets, final StorageType[] targetStorageTypes, final String client)
name|void
name|transferReplicaForPipelineRecovery
parameter_list|(
specifier|final
name|ExtendedBlock
name|b
parameter_list|,
specifier|final
name|DatanodeInfo
index|[]
name|targets
parameter_list|,
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
parameter_list|,
specifier|final
name|String
name|client
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|long
name|storedGS
decl_stmt|;
specifier|final
name|long
name|visible
decl_stmt|;
specifier|final
name|BlockConstructionStage
name|stage
decl_stmt|;
comment|//get replica information
synchronized|synchronized
init|(
name|data
init|)
block|{
name|Block
name|storedBlock
init|=
name|data
operator|.
name|getStoredBlock
argument_list|(
name|b
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|b
operator|.
name|getBlockId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|storedBlock
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|b
operator|+
literal|" not found in datanode."
argument_list|)
throw|;
block|}
name|storedGS
operator|=
name|storedBlock
operator|.
name|getGenerationStamp
argument_list|()
expr_stmt|;
if|if
condition|(
name|storedGS
operator|<
name|b
operator|.
name|getGenerationStamp
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|storedGS
operator|+
literal|" = storedGS< b.getGenerationStamp(), b="
operator|+
name|b
argument_list|)
throw|;
block|}
comment|// Update the genstamp with storedGS
name|b
operator|.
name|setGenerationStamp
argument_list|(
name|storedGS
argument_list|)
expr_stmt|;
if|if
condition|(
name|data
operator|.
name|isValidRbw
argument_list|(
name|b
argument_list|)
condition|)
block|{
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|TRANSFER_RBW
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|data
operator|.
name|isValidBlock
argument_list|(
name|b
argument_list|)
condition|)
block|{
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|TRANSFER_FINALIZED
expr_stmt|;
block|}
else|else
block|{
specifier|final
name|String
name|r
init|=
name|data
operator|.
name|getReplicaString
argument_list|(
name|b
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|b
operator|.
name|getBlockId
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|b
operator|+
literal|" is neither a RBW nor a Finalized, r="
operator|+
name|r
argument_list|)
throw|;
block|}
name|visible
operator|=
name|data
operator|.
name|getReplicaVisibleLength
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
comment|//set visible length
name|b
operator|.
name|setNumBytes
argument_list|(
name|visible
argument_list|)
expr_stmt|;
if|if
condition|(
name|targets
operator|.
name|length
operator|>
literal|0
condition|)
block|{
operator|new
name|DataTransfer
argument_list|(
name|targets
argument_list|,
name|targetStorageTypes
argument_list|,
name|b
argument_list|,
name|stage
argument_list|,
name|client
argument_list|)
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Finalize a pending upgrade in response to DNA_FINALIZE.    * @param blockPoolId the block pool to finalize    */
DECL|method|finalizeUpgradeForPool (String blockPoolId)
name|void
name|finalizeUpgradeForPool
parameter_list|(
name|String
name|blockPoolId
parameter_list|)
throws|throws
name|IOException
block|{
name|storage
operator|.
name|finalizeUpgrade
argument_list|(
name|blockPoolId
argument_list|)
expr_stmt|;
block|}
DECL|method|getStreamingAddr (Configuration conf)
specifier|static
name|InetSocketAddress
name|getStreamingAddr
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFS_DATANODE_ADDRESS_KEY
argument_list|,
name|DFS_DATANODE_ADDRESS_DEFAULT
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getSoftwareVersion ()
specifier|public
name|String
name|getSoftwareVersion
parameter_list|()
block|{
return|return
name|VersionInfo
operator|.
name|getVersion
argument_list|()
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getVersion ()
specifier|public
name|String
name|getVersion
parameter_list|()
block|{
return|return
name|VersionInfo
operator|.
name|getVersion
argument_list|()
operator|+
literal|", r"
operator|+
name|VersionInfo
operator|.
name|getRevision
argument_list|()
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getRpcPort ()
specifier|public
name|String
name|getRpcPort
parameter_list|()
block|{
name|InetSocketAddress
name|ipcAddr
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
name|DFS_DATANODE_IPC_ADDRESS_KEY
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|Integer
operator|.
name|toString
argument_list|(
name|ipcAddr
operator|.
name|getPort
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getHttpPort ()
specifier|public
name|String
name|getHttpPort
parameter_list|()
block|{
return|return
name|this
operator|.
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
literal|"dfs.datanode.info.port"
argument_list|)
return|;
block|}
DECL|method|getRevision ()
specifier|public
name|String
name|getRevision
parameter_list|()
block|{
return|return
name|VersionInfo
operator|.
name|getRevision
argument_list|()
return|;
block|}
comment|/**    * @return the datanode's http port    */
DECL|method|getInfoPort ()
specifier|public
name|int
name|getInfoPort
parameter_list|()
block|{
return|return
name|infoPort
return|;
block|}
comment|/**    * @return the datanode's https port    */
DECL|method|getInfoSecurePort ()
specifier|public
name|int
name|getInfoSecurePort
parameter_list|()
block|{
return|return
name|infoSecurePort
return|;
block|}
comment|/**    * Returned information is a JSON representation of a map with     * name node host name as the key and block pool Id as the value.    * Note that, if there are multiple NNs in an NA nameservice,    * a given block pool may be represented twice.    */
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getNamenodeAddresses ()
specifier|public
name|String
name|getNamenodeAddresses
parameter_list|()
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|info
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
if|if
condition|(
name|bpos
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|BPServiceActor
name|actor
range|:
name|bpos
operator|.
name|getBPServiceActors
argument_list|()
control|)
block|{
name|info
operator|.
name|put
argument_list|(
name|actor
operator|.
name|getNNSocketAddress
argument_list|()
operator|.
name|getHostName
argument_list|()
argument_list|,
name|bpos
operator|.
name|getBlockPoolId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|JSON
operator|.
name|toString
argument_list|(
name|info
argument_list|)
return|;
block|}
comment|/**    * Returned information is a JSON representation of a map with     * volume name as the key and value is a map of volume attribute     * keys to its values    */
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getVolumeInfo ()
specifier|public
name|String
name|getVolumeInfo
parameter_list|()
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|data
argument_list|,
literal|"Storage not yet initialized"
argument_list|)
expr_stmt|;
return|return
name|JSON
operator|.
name|toString
argument_list|(
name|data
operator|.
name|getVolumeInfoMap
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
comment|// DataNodeMXBean
DECL|method|getClusterId ()
specifier|public
specifier|synchronized
name|String
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
DECL|method|refreshNamenodes (Configuration conf)
specifier|public
name|void
name|refreshNamenodes
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|blockPoolManager
operator|.
name|refreshNamenodes
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol
DECL|method|refreshNamenodes ()
specifier|public
name|void
name|refreshNamenodes
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|conf
operator|=
operator|new
name|Configuration
argument_list|()
expr_stmt|;
name|refreshNamenodes
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol
DECL|method|deleteBlockPool (String blockPoolId, boolean force)
specifier|public
name|void
name|deleteBlockPool
parameter_list|(
name|String
name|blockPoolId
parameter_list|,
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"deleteBlockPool command received for block pool "
operator|+
name|blockPoolId
operator|+
literal|", force="
operator|+
name|force
argument_list|)
expr_stmt|;
if|if
condition|(
name|blockPoolManager
operator|.
name|get
argument_list|(
name|blockPoolId
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The block pool "
operator|+
name|blockPoolId
operator|+
literal|" is still running, cannot be deleted."
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The block pool is still running. First do a refreshNamenodes to "
operator|+
literal|"shutdown the block pool service"
argument_list|)
throw|;
block|}
name|data
operator|.
name|deleteBlockPool
argument_list|(
name|blockPoolId
argument_list|,
name|force
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol
DECL|method|shutdownDatanode (boolean forUpgrade)
specifier|public
specifier|synchronized
name|void
name|shutdownDatanode
parameter_list|(
name|boolean
name|forUpgrade
parameter_list|)
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"shutdownDatanode command received (upgrade="
operator|+
name|forUpgrade
operator|+
literal|"). Shutting down Datanode..."
argument_list|)
expr_stmt|;
comment|// Shutdown can be called only once.
if|if
condition|(
name|shutdownInProgress
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Shutdown already in progress."
argument_list|)
throw|;
block|}
name|shutdownInProgress
operator|=
literal|true
expr_stmt|;
name|shutdownForUpgrade
operator|=
name|forUpgrade
expr_stmt|;
comment|// Asynchronously start the shutdown process so that the rpc response can be
comment|// sent back.
name|Thread
name|shutdownThread
init|=
operator|new
name|Thread
argument_list|(
literal|"Async datanode shutdown thread"
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
if|if
condition|(
operator|!
name|shutdownForUpgrade
condition|)
block|{
comment|// Delay the shutdown a bit if not doing for restart.
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{ }
block|}
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
decl_stmt|;
name|shutdownThread
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|shutdownThread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
comment|//ClientDatanodeProtocol
DECL|method|evictWriters ()
specifier|public
name|void
name|evictWriters
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Evicting all writers."
argument_list|)
expr_stmt|;
name|xserver
operator|.
name|stopWriters
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
comment|//ClientDatanodeProtocol
DECL|method|getDatanodeInfo ()
specifier|public
name|DatanodeLocalInfo
name|getDatanodeInfo
parameter_list|()
block|{
name|long
name|uptime
init|=
name|ManagementFactory
operator|.
name|getRuntimeMXBean
argument_list|()
operator|.
name|getUptime
argument_list|()
operator|/
literal|1000
decl_stmt|;
return|return
operator|new
name|DatanodeLocalInfo
argument_list|(
name|VersionInfo
operator|.
name|getVersion
argument_list|()
argument_list|,
name|confVersion
argument_list|,
name|uptime
argument_list|)
return|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol& ReconfigurationProtocol
DECL|method|startReconfiguration ()
specifier|public
name|void
name|startReconfiguration
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|startReconfigurationTask
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol& ReconfigurationProtocol
DECL|method|getReconfigurationStatus ()
specifier|public
name|ReconfigurationTaskStatus
name|getReconfigurationStatus
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
return|return
name|getReconfigurationTaskStatus
argument_list|()
return|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol& ReconfigurationProtocol
DECL|method|listReconfigurableProperties ()
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|listReconfigurableProperties
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
return|return
name|RECONFIGURABLE_PROPERTIES
return|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol
DECL|method|triggerBlockReport (BlockReportOptions options)
specifier|public
name|void
name|triggerBlockReport
parameter_list|(
name|BlockReportOptions
name|options
parameter_list|)
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
if|if
condition|(
name|bpos
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|BPServiceActor
name|actor
range|:
name|bpos
operator|.
name|getBPServiceActors
argument_list|()
control|)
block|{
name|actor
operator|.
name|triggerBlockReport
argument_list|(
name|options
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * @param addr rpc address of the namenode    * @return true if the datanode is connected to a NameNode at the    * given address    */
DECL|method|isConnectedToNN (InetSocketAddress addr)
specifier|public
name|boolean
name|isConnectedToNN
parameter_list|(
name|InetSocketAddress
name|addr
parameter_list|)
block|{
for|for
control|(
name|BPOfferService
name|bpos
range|:
name|getAllBpOs
argument_list|()
control|)
block|{
for|for
control|(
name|BPServiceActor
name|bpsa
range|:
name|bpos
operator|.
name|getBPServiceActors
argument_list|()
control|)
block|{
if|if
condition|(
name|addr
operator|.
name|equals
argument_list|(
name|bpsa
operator|.
name|getNNSocketAddress
argument_list|()
argument_list|)
condition|)
block|{
return|return
name|bpsa
operator|.
name|isAlive
argument_list|()
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @param bpid block pool Id    * @return true - if BPOfferService thread is alive    */
DECL|method|isBPServiceAlive (String bpid)
specifier|public
name|boolean
name|isBPServiceAlive
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
name|BPOfferService
name|bp
init|=
name|blockPoolManager
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
return|return
name|bp
operator|!=
literal|null
condition|?
name|bp
operator|.
name|isAlive
argument_list|()
else|:
literal|false
return|;
block|}
DECL|method|isRestarting ()
name|boolean
name|isRestarting
parameter_list|()
block|{
return|return
name|shutdownForUpgrade
return|;
block|}
comment|/**    * A datanode is considered to be fully started if all the BP threads are    * alive and all the block pools are initialized.    *     * @return true - if the data node is fully started    */
DECL|method|isDatanodeFullyStarted ()
specifier|public
name|boolean
name|isDatanodeFullyStarted
parameter_list|()
block|{
for|for
control|(
name|BPOfferService
name|bp
range|:
name|blockPoolManager
operator|.
name|getAllNamenodeThreads
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|bp
operator|.
name|isInitialized
argument_list|()
operator|||
operator|!
name|bp
operator|.
name|isAlive
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getDatanodeId ()
specifier|public
name|DatanodeID
name|getDatanodeId
parameter_list|()
block|{
return|return
name|id
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|clearAllBlockSecretKeys ()
specifier|public
name|void
name|clearAllBlockSecretKeys
parameter_list|()
block|{
name|blockPoolTokenSecretManager
operator|.
name|clearAllKeysForTesting
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
comment|// ClientDatanodeProtocol
DECL|method|getBalancerBandwidth ()
specifier|public
name|long
name|getBalancerBandwidth
parameter_list|()
block|{
name|DataXceiverServer
name|dxcs
init|=
operator|(
name|DataXceiverServer
operator|)
name|this
operator|.
name|dataXceiverServer
operator|.
name|getRunnable
argument_list|()
decl_stmt|;
return|return
name|dxcs
operator|.
name|balanceThrottler
operator|.
name|getBandwidth
argument_list|()
return|;
block|}
DECL|method|getDnConf ()
specifier|public
name|DNConf
name|getDnConf
parameter_list|()
block|{
return|return
name|dnConf
return|;
block|}
DECL|method|getDatanodeUuid ()
specifier|public
name|String
name|getDatanodeUuid
parameter_list|()
block|{
return|return
name|storage
operator|==
literal|null
condition|?
literal|null
else|:
name|storage
operator|.
name|getDatanodeUuid
argument_list|()
return|;
block|}
DECL|method|shouldRun ()
name|boolean
name|shouldRun
parameter_list|()
block|{
return|return
name|shouldRun
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getStorage ()
name|DataStorage
name|getStorage
parameter_list|()
block|{
return|return
name|storage
return|;
block|}
DECL|method|getShortCircuitRegistry ()
specifier|public
name|ShortCircuitRegistry
name|getShortCircuitRegistry
parameter_list|()
block|{
return|return
name|shortCircuitRegistry
return|;
block|}
comment|/**    * Check the disk error    */
DECL|method|checkDiskError ()
specifier|private
name|void
name|checkDiskError
parameter_list|()
block|{
name|Set
argument_list|<
name|File
argument_list|>
name|unhealthyDataDirs
init|=
name|data
operator|.
name|checkDataDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|unhealthyDataDirs
operator|!=
literal|null
operator|&&
operator|!
name|unhealthyDataDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
comment|// Remove all unhealthy volumes from DataNode.
name|removeVolumes
argument_list|(
name|unhealthyDataDirs
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error occurred when removing unhealthy storage dirs: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"DataNode failed volumes:"
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|dataDir
range|:
name|unhealthyDataDirs
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|dataDir
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|";"
argument_list|)
expr_stmt|;
block|}
name|handleDiskError
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Starts a new thread which will check for disk error check request     * every 5 sec    */
DECL|method|startCheckDiskErrorThread ()
specifier|private
name|void
name|startCheckDiskErrorThread
parameter_list|()
block|{
name|checkDiskErrorThread
operator|=
operator|new
name|Thread
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
name|shouldRun
condition|)
block|{
name|boolean
name|tempFlag
decl_stmt|;
synchronized|synchronized
init|(
name|checkDiskErrorMutex
init|)
block|{
name|tempFlag
operator|=
name|checkDiskErrorFlag
expr_stmt|;
name|checkDiskErrorFlag
operator|=
literal|false
expr_stmt|;
block|}
if|if
condition|(
name|tempFlag
condition|)
block|{
try|try
block|{
name|checkDiskError
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unexpected exception occurred while checking disk error  "
operator|+
name|e
argument_list|)
expr_stmt|;
name|checkDiskErrorThread
operator|=
literal|null
expr_stmt|;
return|return;
block|}
synchronized|synchronized
init|(
name|checkDiskErrorMutex
init|)
block|{
name|lastDiskErrorCheck
operator|=
name|Time
operator|.
name|monotonicNow
argument_list|()
expr_stmt|;
block|}
block|}
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|checkDiskErrorInterval
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"InterruptedException in check disk error thread"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|checkDiskErrorThread
operator|=
literal|null
expr_stmt|;
return|return;
block|}
block|}
block|}
block|}
argument_list|)
expr_stmt|;
block|}
DECL|method|getLastDiskErrorCheck ()
specifier|public
name|long
name|getLastDiskErrorCheck
parameter_list|()
block|{
synchronized|synchronized
init|(
name|checkDiskErrorMutex
init|)
block|{
return|return
name|lastDiskErrorCheck
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|listSpanReceivers ()
specifier|public
name|SpanReceiverInfo
index|[]
name|listSpanReceivers
parameter_list|()
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
return|return
name|tracerConfigurationManager
operator|.
name|listSpanReceivers
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|addSpanReceiver (SpanReceiverInfo info)
specifier|public
name|long
name|addSpanReceiver
parameter_list|(
name|SpanReceiverInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
return|return
name|tracerConfigurationManager
operator|.
name|addSpanReceiver
argument_list|(
name|info
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|removeSpanReceiver (long id)
specifier|public
name|void
name|removeSpanReceiver
parameter_list|(
name|long
name|id
parameter_list|)
throws|throws
name|IOException
block|{
name|checkSuperuserPrivilege
argument_list|()
expr_stmt|;
name|tracerConfigurationManager
operator|.
name|removeSpanReceiver
argument_list|(
name|id
argument_list|)
expr_stmt|;
block|}
DECL|method|getBlockRecoveryWorker ()
specifier|public
name|BlockRecoveryWorker
name|getBlockRecoveryWorker
parameter_list|()
block|{
return|return
name|blockRecoveryWorker
return|;
block|}
DECL|method|getErasureCodingWorker ()
specifier|public
name|ErasureCodingWorker
name|getErasureCodingWorker
parameter_list|()
block|{
return|return
name|ecWorker
return|;
block|}
DECL|method|connectToDN (DatanodeInfo datanodeID, int timeout, ExtendedBlock block, Token<BlockTokenIdentifier> blockToken)
name|IOStreamPair
name|connectToDN
parameter_list|(
name|DatanodeInfo
name|datanodeID
parameter_list|,
name|int
name|timeout
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|DFSUtilClient
operator|.
name|connectToDN
argument_list|(
name|datanodeID
argument_list|,
name|timeout
argument_list|,
name|conf
argument_list|,
name|saslClient
argument_list|,
name|NetUtils
operator|.
name|getDefaultSocketFactory
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
literal|false
argument_list|,
name|getDataEncryptionKeyFactoryForBlock
argument_list|(
name|block
argument_list|)
argument_list|,
name|blockToken
argument_list|)
return|;
block|}
comment|/**    * Get timeout value of each OOB type from configuration    */
DECL|method|initOOBTimeout ()
specifier|private
name|void
name|initOOBTimeout
parameter_list|()
block|{
specifier|final
name|int
name|oobStart
init|=
name|Status
operator|.
name|OOB_RESTART_VALUE
decl_stmt|;
comment|// the first OOB type
specifier|final
name|int
name|oobEnd
init|=
name|Status
operator|.
name|OOB_RESERVED3_VALUE
decl_stmt|;
comment|// the last OOB type
specifier|final
name|int
name|numOobTypes
init|=
name|oobEnd
operator|-
name|oobStart
operator|+
literal|1
decl_stmt|;
name|oobTimeouts
operator|=
operator|new
name|long
index|[
name|numOobTypes
index|]
expr_stmt|;
specifier|final
name|String
index|[]
name|ele
init|=
name|conf
operator|.
name|get
argument_list|(
name|DFS_DATANODE_OOB_TIMEOUT_KEY
argument_list|,
name|DFS_DATANODE_OOB_TIMEOUT_DEFAULT
argument_list|)
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numOobTypes
condition|;
name|i
operator|++
control|)
block|{
name|oobTimeouts
index|[
name|i
index|]
operator|=
operator|(
name|i
operator|<
name|ele
operator|.
name|length
operator|)
condition|?
name|Long
operator|.
name|parseLong
argument_list|(
name|ele
index|[
name|i
index|]
argument_list|)
else|:
literal|0
expr_stmt|;
block|}
block|}
comment|/**    * Get the timeout to be used for transmitting the OOB type    * @return the timeout in milliseconds    */
DECL|method|getOOBTimeout (Status status)
specifier|public
name|long
name|getOOBTimeout
parameter_list|(
name|Status
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|status
operator|.
name|getNumber
argument_list|()
operator|<
name|Status
operator|.
name|OOB_RESTART_VALUE
operator|||
name|status
operator|.
name|getNumber
argument_list|()
operator|>
name|Status
operator|.
name|OOB_RESERVED3_VALUE
condition|)
block|{
comment|// Not an OOB.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Not an OOB status: "
operator|+
name|status
argument_list|)
throw|;
block|}
return|return
name|oobTimeouts
index|[
name|status
operator|.
name|getNumber
argument_list|()
operator|-
name|Status
operator|.
name|OOB_RESTART_VALUE
index|]
return|;
block|}
comment|/**    * Start a timer to periodically write DataNode metrics to the log file. This    * behavior can be disabled by configuration.    *    * @param metricConf    */
DECL|method|startMetricsLogger (Configuration metricConf)
specifier|protected
name|void
name|startMetricsLogger
parameter_list|(
name|Configuration
name|metricConf
parameter_list|)
block|{
name|long
name|metricsLoggerPeriodSec
init|=
name|metricConf
operator|.
name|getInt
argument_list|(
name|DFS_DATANODE_METRICS_LOGGER_PERIOD_SECONDS_KEY
argument_list|,
name|DFS_DATANODE_METRICS_LOGGER_PERIOD_SECONDS_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|metricsLoggerPeriodSec
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
name|MetricsLoggerTask
operator|.
name|makeMetricsLoggerAsync
argument_list|(
name|METRICS_LOG
argument_list|)
expr_stmt|;
comment|// Schedule the periodic logging.
name|metricsLoggerTimer
operator|=
operator|new
name|ScheduledThreadPoolExecutor
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|metricsLoggerTimer
operator|.
name|setExecuteExistingDelayedTasksAfterShutdownPolicy
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|metricsLoggerTimer
operator|.
name|scheduleWithFixedDelay
argument_list|(
operator|new
name|MetricsLoggerTask
argument_list|(
name|METRICS_LOG
argument_list|,
literal|"DataNode"
argument_list|,
operator|(
name|short
operator|)
literal|0
argument_list|)
argument_list|,
name|metricsLoggerPeriodSec
argument_list|,
name|metricsLoggerPeriodSec
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
expr_stmt|;
block|}
DECL|method|stopMetricsLogger ()
specifier|protected
name|void
name|stopMetricsLogger
parameter_list|()
block|{
if|if
condition|(
name|metricsLoggerTimer
operator|!=
literal|null
condition|)
block|{
name|metricsLoggerTimer
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|metricsLoggerTimer
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|getMetricsLoggerTimer ()
name|ScheduledThreadPoolExecutor
name|getMetricsLoggerTimer
parameter_list|()
block|{
return|return
name|metricsLoggerTimer
return|;
block|}
DECL|method|getTracer ()
specifier|public
name|Tracer
name|getTracer
parameter_list|()
block|{
return|return
name|tracer
return|;
block|}
block|}
end_class

end_unit

