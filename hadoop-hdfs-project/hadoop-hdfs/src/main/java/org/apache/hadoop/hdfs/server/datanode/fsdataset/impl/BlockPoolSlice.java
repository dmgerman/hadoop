begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.datanode.fsdataset.impl
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|fsdataset
operator|.
name|impl
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|RandomAccessFile
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Scanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|DU
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|Block
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|BlockMetadataHeader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DataStorage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DatanodeUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|FinalizedReplica
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|ReplicaInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|ReplicaBeingWritten
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|ReplicaWaitingToBeRecovered
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
operator|.
name|DiskErrorException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ShutdownHookManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_comment
comment|/**  * A block pool slice represents a portion of a block pool stored on a volume.    * Taken together, all BlockPoolSlices sharing a block pool ID across a   * cluster represent a single block pool.  *   * This class is synchronized by {@link FsVolumeImpl}.  */
end_comment

begin_class
DECL|class|BlockPoolSlice
class|class
name|BlockPoolSlice
block|{
DECL|field|bpid
specifier|private
specifier|final
name|String
name|bpid
decl_stmt|;
DECL|field|volume
specifier|private
specifier|final
name|FsVolumeImpl
name|volume
decl_stmt|;
comment|// volume to which this BlockPool belongs to
DECL|field|currentDir
specifier|private
specifier|final
name|File
name|currentDir
decl_stmt|;
comment|// StorageDirectory/current/bpid/current
comment|// directory where finalized replicas are stored
DECL|field|finalizedDir
specifier|private
specifier|final
name|File
name|finalizedDir
decl_stmt|;
DECL|field|lazypersistDir
specifier|private
specifier|final
name|File
name|lazypersistDir
decl_stmt|;
DECL|field|rbwDir
specifier|private
specifier|final
name|File
name|rbwDir
decl_stmt|;
comment|// directory store RBW replica
DECL|field|tmpDir
specifier|private
specifier|final
name|File
name|tmpDir
decl_stmt|;
comment|// directory store Temporary replica
DECL|field|DU_CACHE_FILE
specifier|private
specifier|static
specifier|final
name|String
name|DU_CACHE_FILE
init|=
literal|"dfsUsed"
decl_stmt|;
DECL|field|dfsUsedSaved
specifier|private
specifier|volatile
name|boolean
name|dfsUsedSaved
init|=
literal|false
decl_stmt|;
DECL|field|SHUTDOWN_HOOK_PRIORITY
specifier|private
specifier|static
specifier|final
name|int
name|SHUTDOWN_HOOK_PRIORITY
init|=
literal|30
decl_stmt|;
comment|// TODO:FEDERATION scalability issue - a thread per DU is needed
DECL|field|dfsUsage
specifier|private
specifier|final
name|DU
name|dfsUsage
decl_stmt|;
comment|/**    * Create a blook pool slice     * @param bpid Block pool Id    * @param volume {@link FsVolumeImpl} to which this BlockPool belongs to    * @param bpDir directory corresponding to the BlockPool    * @param conf configuration    * @throws IOException    */
DECL|method|BlockPoolSlice (String bpid, FsVolumeImpl volume, File bpDir, Configuration conf)
name|BlockPoolSlice
parameter_list|(
name|String
name|bpid
parameter_list|,
name|FsVolumeImpl
name|volume
parameter_list|,
name|File
name|bpDir
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|bpid
operator|=
name|bpid
expr_stmt|;
name|this
operator|.
name|volume
operator|=
name|volume
expr_stmt|;
name|this
operator|.
name|currentDir
operator|=
operator|new
name|File
argument_list|(
name|bpDir
argument_list|,
name|DataStorage
operator|.
name|STORAGE_DIR_CURRENT
argument_list|)
expr_stmt|;
name|this
operator|.
name|finalizedDir
operator|=
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|DataStorage
operator|.
name|STORAGE_DIR_FINALIZED
argument_list|)
expr_stmt|;
name|this
operator|.
name|lazypersistDir
operator|=
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|DataStorage
operator|.
name|STORAGE_DIR_LAZY_PERSIST
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|finalizedDir
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|finalizedDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to mkdirs "
operator|+
name|this
operator|.
name|finalizedDir
argument_list|)
throw|;
block|}
block|}
comment|// Files that were being written when the datanode was last shutdown
comment|// are now moved back to the data directory. It is possible that
comment|// in the future, we might want to do some sort of datanode-local
comment|// recovery for these blocks. For example, crc validation.
comment|//
name|this
operator|.
name|tmpDir
operator|=
operator|new
name|File
argument_list|(
name|bpDir
argument_list|,
name|DataStorage
operator|.
name|STORAGE_DIR_TMP
argument_list|)
expr_stmt|;
if|if
condition|(
name|tmpDir
operator|.
name|exists
argument_list|()
condition|)
block|{
name|FileUtil
operator|.
name|fullyDelete
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|rbwDir
operator|=
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|DataStorage
operator|.
name|STORAGE_DIR_RBW
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|rbwDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
comment|// create rbw directory if not exist
if|if
condition|(
operator|!
name|rbwDir
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mkdirs failed to create "
operator|+
name|rbwDir
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|tmpDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|tmpDir
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mkdirs failed to create "
operator|+
name|tmpDir
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|// Use cached value initially if available. Or the following call will
comment|// block until the initial du command completes.
name|this
operator|.
name|dfsUsage
operator|=
operator|new
name|DU
argument_list|(
name|bpDir
argument_list|,
name|conf
argument_list|,
name|loadDfsUsed
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|dfsUsage
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// Make the dfs usage to be saved during shutdown.
name|ShutdownHookManager
operator|.
name|get
argument_list|()
operator|.
name|addShutdownHook
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
if|if
condition|(
operator|!
name|dfsUsedSaved
condition|)
block|{
name|saveDfsUsed
argument_list|()
expr_stmt|;
block|}
block|}
block|}
argument_list|,
name|SHUTDOWN_HOOK_PRIORITY
argument_list|)
expr_stmt|;
block|}
DECL|method|getDirectory ()
name|File
name|getDirectory
parameter_list|()
block|{
return|return
name|currentDir
operator|.
name|getParentFile
argument_list|()
return|;
block|}
DECL|method|getFinalizedDir ()
name|File
name|getFinalizedDir
parameter_list|()
block|{
return|return
name|finalizedDir
return|;
block|}
DECL|method|getLazypersistDir ()
name|File
name|getLazypersistDir
parameter_list|()
block|{
return|return
name|lazypersistDir
return|;
block|}
DECL|method|getRbwDir ()
name|File
name|getRbwDir
parameter_list|()
block|{
return|return
name|rbwDir
return|;
block|}
comment|/** Run DU on local drives.  It must be synchronized from caller. */
DECL|method|decDfsUsed (long value)
name|void
name|decDfsUsed
parameter_list|(
name|long
name|value
parameter_list|)
block|{
name|dfsUsage
operator|.
name|decDfsUsed
argument_list|(
name|value
argument_list|)
expr_stmt|;
block|}
DECL|method|getDfsUsed ()
name|long
name|getDfsUsed
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|dfsUsage
operator|.
name|getUsed
argument_list|()
return|;
block|}
comment|/**    * Read in the cached DU value and return it if it is less than 600 seconds    * old (DU update interval). Slight imprecision of dfsUsed is not critical    * and skipping DU can significantly shorten the startup time.    * If the cached value is not available or too old, -1 is returned.    */
DECL|method|loadDfsUsed ()
name|long
name|loadDfsUsed
parameter_list|()
block|{
name|long
name|cachedDfsUsed
decl_stmt|;
name|long
name|mtime
decl_stmt|;
name|Scanner
name|sc
decl_stmt|;
try|try
block|{
name|sc
operator|=
operator|new
name|Scanner
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|DU_CACHE_FILE
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
return|return
operator|-
literal|1
return|;
block|}
try|try
block|{
comment|// Get the recorded dfsUsed from the file.
if|if
condition|(
name|sc
operator|.
name|hasNextLong
argument_list|()
condition|)
block|{
name|cachedDfsUsed
operator|=
name|sc
operator|.
name|nextLong
argument_list|()
expr_stmt|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
comment|// Get the recorded mtime from the file.
if|if
condition|(
name|sc
operator|.
name|hasNextLong
argument_list|()
condition|)
block|{
name|mtime
operator|=
name|sc
operator|.
name|nextLong
argument_list|()
expr_stmt|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
comment|// Return the cached value if mtime is okay.
if|if
condition|(
name|mtime
operator|>
literal|0
operator|&&
operator|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|mtime
operator|<
literal|600000L
operator|)
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Cached dfsUsed found for "
operator|+
name|currentDir
operator|+
literal|": "
operator|+
name|cachedDfsUsed
argument_list|)
expr_stmt|;
return|return
name|cachedDfsUsed
return|;
block|}
return|return
operator|-
literal|1
return|;
block|}
finally|finally
block|{
name|sc
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Write the current dfsUsed to the cache file.    */
DECL|method|saveDfsUsed ()
name|void
name|saveDfsUsed
parameter_list|()
block|{
name|File
name|outFile
init|=
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|DU_CACHE_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
name|outFile
operator|.
name|exists
argument_list|()
operator|&&
operator|!
name|outFile
operator|.
name|delete
argument_list|()
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to delete old dfsUsed file in "
operator|+
name|outFile
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|FileWriter
name|out
init|=
literal|null
decl_stmt|;
try|try
block|{
name|long
name|used
init|=
name|getDfsUsed
argument_list|()
decl_stmt|;
if|if
condition|(
name|used
operator|>
literal|0
condition|)
block|{
name|out
operator|=
operator|new
name|FileWriter
argument_list|(
name|outFile
argument_list|)
expr_stmt|;
comment|// mtime is written last, so that truncated writes won't be valid.
name|out
operator|.
name|write
argument_list|(
name|Long
operator|.
name|toString
argument_list|(
name|used
argument_list|)
operator|+
literal|" "
operator|+
name|Long
operator|.
name|toString
argument_list|(
name|Time
operator|.
name|now
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
name|out
operator|=
literal|null
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// If write failed, the volume might be bad. Since the cache file is
comment|// not critical, log the error and continue.
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to write dfsUsed to "
operator|+
name|outFile
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|cleanup
argument_list|(
literal|null
argument_list|,
name|out
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Temporary files. They get moved to the finalized block directory when    * the block is finalized.    */
DECL|method|createTmpFile (Block b)
name|File
name|createTmpFile
parameter_list|(
name|Block
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|f
init|=
operator|new
name|File
argument_list|(
name|tmpDir
argument_list|,
name|b
operator|.
name|getBlockName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|DatanodeUtil
operator|.
name|createTmpFile
argument_list|(
name|b
argument_list|,
name|f
argument_list|)
return|;
block|}
comment|/**    * RBW files. They get moved to the finalized block directory when    * the block is finalized.    */
DECL|method|createRbwFile (Block b)
name|File
name|createRbwFile
parameter_list|(
name|Block
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|f
init|=
operator|new
name|File
argument_list|(
name|rbwDir
argument_list|,
name|b
operator|.
name|getBlockName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|DatanodeUtil
operator|.
name|createTmpFile
argument_list|(
name|b
argument_list|,
name|f
argument_list|)
return|;
block|}
DECL|method|addBlock (Block b, File f)
name|File
name|addBlock
parameter_list|(
name|Block
name|b
parameter_list|,
name|File
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|blockDir
init|=
name|DatanodeUtil
operator|.
name|idToBlockDir
argument_list|(
name|finalizedDir
argument_list|,
name|b
operator|.
name|getBlockId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|blockDir
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|blockDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to mkdirs "
operator|+
name|blockDir
argument_list|)
throw|;
block|}
block|}
name|File
name|blockFile
init|=
name|FsDatasetImpl
operator|.
name|moveBlockFiles
argument_list|(
name|b
argument_list|,
name|f
argument_list|,
name|blockDir
argument_list|)
decl_stmt|;
name|File
name|metaFile
init|=
name|FsDatasetUtil
operator|.
name|getMetaFile
argument_list|(
name|blockFile
argument_list|,
name|b
operator|.
name|getGenerationStamp
argument_list|()
argument_list|)
decl_stmt|;
name|dfsUsage
operator|.
name|incDfsUsed
argument_list|(
name|b
operator|.
name|getNumBytes
argument_list|()
operator|+
name|metaFile
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|blockFile
return|;
block|}
comment|/**    * Save the given replica to persistent storage.    *    * @param replicaInfo    * @return The saved block file.    * @throws IOException    */
DECL|method|lazyPersistReplica (ReplicaInfo replicaInfo)
name|File
name|lazyPersistReplica
parameter_list|(
name|ReplicaInfo
name|replicaInfo
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|lazypersistDir
operator|.
name|exists
argument_list|()
operator|&&
operator|!
name|lazypersistDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to create "
operator|+
name|lazypersistDir
argument_list|)
expr_stmt|;
block|}
name|File
name|metaFile
init|=
name|FsDatasetImpl
operator|.
name|copyBlockFiles
argument_list|(
name|replicaInfo
argument_list|,
name|lazypersistDir
argument_list|)
decl_stmt|;
name|File
name|blockFile
init|=
name|Block
operator|.
name|metaToBlockFile
argument_list|(
name|metaFile
argument_list|)
decl_stmt|;
name|dfsUsage
operator|.
name|incDfsUsed
argument_list|(
name|replicaInfo
operator|.
name|getNumBytes
argument_list|()
operator|+
name|metaFile
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|blockFile
return|;
block|}
comment|/**    * Move a persisted replica from lazypersist directory to a subdirectory    * under finalized.    */
DECL|method|activateSavedReplica (Block b, File blockFile)
name|File
name|activateSavedReplica
parameter_list|(
name|Block
name|b
parameter_list|,
name|File
name|blockFile
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|File
name|blockDir
init|=
name|DatanodeUtil
operator|.
name|idToBlockDir
argument_list|(
name|finalizedDir
argument_list|,
name|b
operator|.
name|getBlockId
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|File
name|metaFile
init|=
name|FsDatasetUtil
operator|.
name|getMetaFile
argument_list|(
name|blockFile
argument_list|,
name|b
operator|.
name|getGenerationStamp
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|File
name|targetBlockFile
init|=
operator|new
name|File
argument_list|(
name|blockDir
argument_list|,
name|blockFile
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|File
name|targetMetaFile
init|=
operator|new
name|File
argument_list|(
name|blockDir
argument_list|,
name|metaFile
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|FileUtils
operator|.
name|moveFile
argument_list|(
name|blockFile
argument_list|,
name|targetBlockFile
argument_list|)
expr_stmt|;
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Moved "
operator|+
name|blockFile
operator|+
literal|" to "
operator|+
name|targetBlockFile
argument_list|)
expr_stmt|;
name|FileUtils
operator|.
name|moveFile
argument_list|(
name|metaFile
argument_list|,
name|targetMetaFile
argument_list|)
expr_stmt|;
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Moved "
operator|+
name|metaFile
operator|+
literal|" to "
operator|+
name|targetMetaFile
argument_list|)
expr_stmt|;
return|return
name|targetBlockFile
return|;
block|}
DECL|method|checkDirs ()
name|void
name|checkDirs
parameter_list|()
throws|throws
name|DiskErrorException
block|{
name|DiskChecker
operator|.
name|checkDirs
argument_list|(
name|finalizedDir
argument_list|)
expr_stmt|;
name|DiskChecker
operator|.
name|checkDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
name|DiskChecker
operator|.
name|checkDir
argument_list|(
name|rbwDir
argument_list|)
expr_stmt|;
block|}
DECL|method|getVolumeMap (ReplicaMap volumeMap, final LazyWriteReplicaTracker lazyWriteReplicaMap)
name|void
name|getVolumeMap
parameter_list|(
name|ReplicaMap
name|volumeMap
parameter_list|,
specifier|final
name|LazyWriteReplicaTracker
name|lazyWriteReplicaMap
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Recover lazy persist replicas, they will be added to the volumeMap
comment|// when we scan the finalized directory.
if|if
condition|(
name|lazypersistDir
operator|.
name|exists
argument_list|()
condition|)
block|{
name|int
name|numRecovered
init|=
name|moveLazyPersistReplicasToFinalized
argument_list|(
name|lazypersistDir
argument_list|)
decl_stmt|;
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Recovered "
operator|+
name|numRecovered
operator|+
literal|" replicas from "
operator|+
name|lazypersistDir
argument_list|)
expr_stmt|;
block|}
comment|// add finalized replicas
name|addToReplicasMap
argument_list|(
name|volumeMap
argument_list|,
name|finalizedDir
argument_list|,
name|lazyWriteReplicaMap
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// add rbw replicas
name|addToReplicasMap
argument_list|(
name|volumeMap
argument_list|,
name|rbwDir
argument_list|,
name|lazyWriteReplicaMap
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Recover an unlinked tmp file on datanode restart. If the original block    * does not exist, then the tmp file is renamed to be the    * original file name and the original name is returned; otherwise the tmp    * file is deleted and null is returned.    */
DECL|method|recoverTempUnlinkedBlock (File unlinkedTmp)
name|File
name|recoverTempUnlinkedBlock
parameter_list|(
name|File
name|unlinkedTmp
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|blockFile
init|=
name|FsDatasetUtil
operator|.
name|getOrigFile
argument_list|(
name|unlinkedTmp
argument_list|)
decl_stmt|;
if|if
condition|(
name|blockFile
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// If the original block file still exists, then no recovery is needed.
if|if
condition|(
operator|!
name|unlinkedTmp
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to cleanup unlinked tmp file "
operator|+
name|unlinkedTmp
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|unlinkedTmp
operator|.
name|renameTo
argument_list|(
name|blockFile
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename unlinked tmp file "
operator|+
name|unlinkedTmp
argument_list|)
throw|;
block|}
return|return
name|blockFile
return|;
block|}
block|}
comment|/**    * Move replicas in the lazy persist directory to their corresponding locations    * in the finalized directory.    * @return number of replicas recovered.    */
DECL|method|moveLazyPersistReplicasToFinalized (File source)
specifier|private
name|int
name|moveLazyPersistReplicasToFinalized
parameter_list|(
name|File
name|source
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|files
index|[]
init|=
name|FileUtil
operator|.
name|listFiles
argument_list|(
name|source
argument_list|)
decl_stmt|;
name|int
name|numRecovered
init|=
literal|0
decl_stmt|;
for|for
control|(
name|File
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
name|file
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|numRecovered
operator|+=
name|moveLazyPersistReplicasToFinalized
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Block
operator|.
name|isMetaFilename
argument_list|(
name|file
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|File
name|metaFile
init|=
name|file
decl_stmt|;
name|File
name|blockFile
init|=
name|Block
operator|.
name|metaToBlockFile
argument_list|(
name|metaFile
argument_list|)
decl_stmt|;
name|long
name|blockId
init|=
name|Block
operator|.
name|filename2id
argument_list|(
name|blockFile
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|File
name|targetDir
init|=
name|DatanodeUtil
operator|.
name|idToBlockDir
argument_list|(
name|finalizedDir
argument_list|,
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blockFile
operator|.
name|exists
argument_list|()
condition|)
block|{
name|File
name|targetBlockFile
init|=
operator|new
name|File
argument_list|(
name|targetDir
argument_list|,
name|blockFile
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|File
name|targetMetaFile
init|=
operator|new
name|File
argument_list|(
name|targetDir
argument_list|,
name|metaFile
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|targetDir
operator|.
name|exists
argument_list|()
operator|&&
operator|!
name|targetDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to move "
operator|+
name|blockFile
operator|+
literal|" to "
operator|+
name|targetDir
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|metaFile
operator|.
name|renameTo
argument_list|(
name|targetMetaFile
argument_list|)
expr_stmt|;
name|blockFile
operator|.
name|renameTo
argument_list|(
name|targetBlockFile
argument_list|)
expr_stmt|;
if|if
condition|(
name|targetBlockFile
operator|.
name|exists
argument_list|()
operator|&&
name|targetMetaFile
operator|.
name|exists
argument_list|()
condition|)
block|{
operator|++
name|numRecovered
expr_stmt|;
block|}
else|else
block|{
comment|// Failure should be rare.
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to move "
operator|+
name|blockFile
operator|+
literal|" to "
operator|+
name|targetDir
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|FileUtil
operator|.
name|fullyDelete
argument_list|(
name|source
argument_list|)
expr_stmt|;
return|return
name|numRecovered
return|;
block|}
comment|/**    * Add replicas under the given directory to the volume map    * @param volumeMap the replicas map    * @param dir an input directory    * @param lazyWriteReplicaMap Map of replicas on transient    *                                storage.    * @param isFinalized true if the directory has finalized replicas;    *                    false if the directory has rbw replicas    */
DECL|method|addToReplicasMap (ReplicaMap volumeMap, File dir, final LazyWriteReplicaTracker lazyWriteReplicaMap, boolean isFinalized)
name|void
name|addToReplicasMap
parameter_list|(
name|ReplicaMap
name|volumeMap
parameter_list|,
name|File
name|dir
parameter_list|,
specifier|final
name|LazyWriteReplicaTracker
name|lazyWriteReplicaMap
parameter_list|,
name|boolean
name|isFinalized
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|files
index|[]
init|=
name|FileUtil
operator|.
name|listFiles
argument_list|(
name|dir
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
name|file
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|addToReplicasMap
argument_list|(
name|volumeMap
argument_list|,
name|file
argument_list|,
name|lazyWriteReplicaMap
argument_list|,
name|isFinalized
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isFinalized
operator|&&
name|FsDatasetUtil
operator|.
name|isUnlinkTmpFile
argument_list|(
name|file
argument_list|)
condition|)
block|{
name|file
operator|=
name|recoverTempUnlinkedBlock
argument_list|(
name|file
argument_list|)
expr_stmt|;
if|if
condition|(
name|file
operator|==
literal|null
condition|)
block|{
comment|// the original block still exists, so we cover it
comment|// in another iteration and can continue here
continue|continue;
block|}
block|}
if|if
condition|(
operator|!
name|Block
operator|.
name|isBlockFilename
argument_list|(
name|file
argument_list|)
condition|)
continue|continue;
name|long
name|genStamp
init|=
name|FsDatasetUtil
operator|.
name|getGenerationStampFromFile
argument_list|(
name|files
argument_list|,
name|file
argument_list|)
decl_stmt|;
name|long
name|blockId
init|=
name|Block
operator|.
name|filename2id
argument_list|(
name|file
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|ReplicaInfo
name|newReplica
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isFinalized
condition|)
block|{
name|newReplica
operator|=
operator|new
name|FinalizedReplica
argument_list|(
name|blockId
argument_list|,
name|file
operator|.
name|length
argument_list|()
argument_list|,
name|genStamp
argument_list|,
name|volume
argument_list|,
name|file
operator|.
name|getParentFile
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|boolean
name|loadRwr
init|=
literal|true
decl_stmt|;
name|File
name|restartMeta
init|=
operator|new
name|File
argument_list|(
name|file
operator|.
name|getParent
argument_list|()
operator|+
name|File
operator|.
name|pathSeparator
operator|+
literal|"."
operator|+
name|file
operator|.
name|getName
argument_list|()
operator|+
literal|".restart"
argument_list|)
decl_stmt|;
name|Scanner
name|sc
init|=
literal|null
decl_stmt|;
try|try
block|{
name|sc
operator|=
operator|new
name|Scanner
argument_list|(
name|restartMeta
argument_list|)
expr_stmt|;
comment|// The restart meta file exists
if|if
condition|(
name|sc
operator|.
name|hasNextLong
argument_list|()
operator|&&
operator|(
name|sc
operator|.
name|nextLong
argument_list|()
operator|>
name|Time
operator|.
name|now
argument_list|()
operator|)
condition|)
block|{
comment|// It didn't expire. Load the replica as a RBW.
name|newReplica
operator|=
operator|new
name|ReplicaBeingWritten
argument_list|(
name|blockId
argument_list|,
name|validateIntegrityAndSetLength
argument_list|(
name|file
argument_list|,
name|genStamp
argument_list|)
argument_list|,
name|genStamp
argument_list|,
name|volume
argument_list|,
name|file
operator|.
name|getParentFile
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|loadRwr
operator|=
literal|false
expr_stmt|;
block|}
name|sc
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|restartMeta
operator|.
name|delete
argument_list|()
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to delete restart meta file: "
operator|+
name|restartMeta
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
comment|// nothing to do hereFile dir =
block|}
finally|finally
block|{
if|if
condition|(
name|sc
operator|!=
literal|null
condition|)
block|{
name|sc
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Restart meta doesn't exist or expired.
if|if
condition|(
name|loadRwr
condition|)
block|{
name|newReplica
operator|=
operator|new
name|ReplicaWaitingToBeRecovered
argument_list|(
name|blockId
argument_list|,
name|validateIntegrityAndSetLength
argument_list|(
name|file
argument_list|,
name|genStamp
argument_list|)
argument_list|,
name|genStamp
argument_list|,
name|volume
argument_list|,
name|file
operator|.
name|getParentFile
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|ReplicaInfo
name|oldReplica
init|=
name|volumeMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|,
name|newReplica
operator|.
name|getBlockId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldReplica
operator|==
literal|null
condition|)
block|{
name|volumeMap
operator|.
name|add
argument_list|(
name|bpid
argument_list|,
name|newReplica
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// We have multiple replicas of the same block so decide which one
comment|// to keep.
name|newReplica
operator|=
name|resolveDuplicateReplicas
argument_list|(
name|newReplica
argument_list|,
name|oldReplica
argument_list|,
name|volumeMap
argument_list|)
expr_stmt|;
block|}
comment|// If we are retaining a replica on transient storage make sure
comment|// it is in the lazyWriteReplicaMap so it can be persisted
comment|// eventually.
if|if
condition|(
name|newReplica
operator|.
name|getVolume
argument_list|()
operator|.
name|isTransientStorage
argument_list|()
condition|)
block|{
name|lazyWriteReplicaMap
operator|.
name|addReplica
argument_list|(
name|bpid
argument_list|,
name|blockId
argument_list|,
name|newReplica
operator|.
name|getVolume
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|lazyWriteReplicaMap
operator|.
name|discardReplica
argument_list|(
name|bpid
argument_list|,
name|blockId
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * This method is invoked during DN startup when volumes are scanned to    * build up the volumeMap.    *    * Given two replicas, decide which one to keep. The preference is as    * follows:    *   1. Prefer the replica with the higher generation stamp.    *   2. If generation stamps are equal, prefer the replica with the    *      larger on-disk length.    *   3. If on-disk length is the same, prefer the replica on persistent    *      storage volume.    *   4. All other factors being equal, keep replica1.    *    * The other replica is removed from the volumeMap and is deleted from    * its storage volume.    *    * @param replica1    * @param replica2    * @param volumeMap    * @return the replica that is retained.    * @throws IOException    */
DECL|method|resolveDuplicateReplicas ( final ReplicaInfo replica1, final ReplicaInfo replica2, final ReplicaMap volumeMap)
specifier|private
name|ReplicaInfo
name|resolveDuplicateReplicas
parameter_list|(
specifier|final
name|ReplicaInfo
name|replica1
parameter_list|,
specifier|final
name|ReplicaInfo
name|replica2
parameter_list|,
specifier|final
name|ReplicaMap
name|volumeMap
parameter_list|)
throws|throws
name|IOException
block|{
name|ReplicaInfo
name|replicaToKeep
decl_stmt|;
name|ReplicaInfo
name|replicaToDelete
decl_stmt|;
if|if
condition|(
name|replica1
operator|.
name|getGenerationStamp
argument_list|()
operator|!=
name|replica2
operator|.
name|getGenerationStamp
argument_list|()
condition|)
block|{
name|replicaToKeep
operator|=
name|replica1
operator|.
name|getGenerationStamp
argument_list|()
operator|>
name|replica2
operator|.
name|getGenerationStamp
argument_list|()
condition|?
name|replica1
else|:
name|replica2
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|replica1
operator|.
name|getNumBytes
argument_list|()
operator|!=
name|replica2
operator|.
name|getNumBytes
argument_list|()
condition|)
block|{
name|replicaToKeep
operator|=
name|replica1
operator|.
name|getNumBytes
argument_list|()
operator|>
name|replica2
operator|.
name|getNumBytes
argument_list|()
condition|?
name|replica1
else|:
name|replica2
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|replica1
operator|.
name|getVolume
argument_list|()
operator|.
name|isTransientStorage
argument_list|()
operator|&&
operator|!
name|replica2
operator|.
name|getVolume
argument_list|()
operator|.
name|isTransientStorage
argument_list|()
condition|)
block|{
name|replicaToKeep
operator|=
name|replica2
expr_stmt|;
block|}
else|else
block|{
name|replicaToKeep
operator|=
name|replica1
expr_stmt|;
block|}
name|replicaToDelete
operator|=
operator|(
name|replicaToKeep
operator|==
name|replica1
operator|)
condition|?
name|replica2
else|:
name|replica1
expr_stmt|;
comment|// Update volumeMap.
name|volumeMap
operator|.
name|add
argument_list|(
name|bpid
argument_list|,
name|replicaToKeep
argument_list|)
expr_stmt|;
comment|// Delete the files on disk. Failure here is okay.
name|replicaToDelete
operator|.
name|getBlockFile
argument_list|()
operator|.
name|delete
argument_list|()
expr_stmt|;
name|replicaToDelete
operator|.
name|getMetaFile
argument_list|()
operator|.
name|delete
argument_list|()
expr_stmt|;
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"resolveDuplicateReplicas keeping "
operator|+
name|replicaToKeep
operator|.
name|getBlockFile
argument_list|()
operator|+
literal|", deleting "
operator|+
name|replicaToDelete
operator|.
name|getBlockFile
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|replicaToKeep
return|;
block|}
comment|/**    * Find out the number of bytes in the block that match its crc.    *     * This algorithm assumes that data corruption caused by unexpected     * datanode shutdown occurs only in the last crc chunk. So it checks    * only the last chunk.    *     * @param blockFile the block file    * @param genStamp generation stamp of the block    * @return the number of valid bytes    */
DECL|method|validateIntegrityAndSetLength (File blockFile, long genStamp)
specifier|private
name|long
name|validateIntegrityAndSetLength
parameter_list|(
name|File
name|blockFile
parameter_list|,
name|long
name|genStamp
parameter_list|)
block|{
name|DataInputStream
name|checksumIn
init|=
literal|null
decl_stmt|;
name|InputStream
name|blockIn
init|=
literal|null
decl_stmt|;
try|try
block|{
specifier|final
name|File
name|metaFile
init|=
name|FsDatasetUtil
operator|.
name|getMetaFile
argument_list|(
name|blockFile
argument_list|,
name|genStamp
argument_list|)
decl_stmt|;
name|long
name|blockFileLen
init|=
name|blockFile
operator|.
name|length
argument_list|()
decl_stmt|;
name|long
name|metaFileLen
init|=
name|metaFile
operator|.
name|length
argument_list|()
decl_stmt|;
name|int
name|crcHeaderLen
init|=
name|DataChecksum
operator|.
name|getChecksumHeaderSize
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|blockFile
operator|.
name|exists
argument_list|()
operator|||
name|blockFileLen
operator|==
literal|0
operator|||
operator|!
name|metaFile
operator|.
name|exists
argument_list|()
operator|||
name|metaFileLen
operator|<
name|crcHeaderLen
condition|)
block|{
return|return
literal|0
return|;
block|}
name|checksumIn
operator|=
operator|new
name|DataInputStream
argument_list|(
operator|new
name|BufferedInputStream
argument_list|(
operator|new
name|FileInputStream
argument_list|(
name|metaFile
argument_list|)
argument_list|,
name|HdfsConstants
operator|.
name|IO_FILE_BUFFER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
comment|// read and handle the common header here. For now just a version
name|BlockMetadataHeader
name|header
init|=
name|BlockMetadataHeader
operator|.
name|readHeader
argument_list|(
name|checksumIn
argument_list|)
decl_stmt|;
name|short
name|version
init|=
name|header
operator|.
name|getVersion
argument_list|()
decl_stmt|;
if|if
condition|(
name|version
operator|!=
name|BlockMetadataHeader
operator|.
name|VERSION
condition|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Wrong version ("
operator|+
name|version
operator|+
literal|") for metadata file "
operator|+
name|metaFile
operator|+
literal|" ignoring ..."
argument_list|)
expr_stmt|;
block|}
name|DataChecksum
name|checksum
init|=
name|header
operator|.
name|getChecksum
argument_list|()
decl_stmt|;
name|int
name|bytesPerChecksum
init|=
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
decl_stmt|;
name|int
name|checksumSize
init|=
name|checksum
operator|.
name|getChecksumSize
argument_list|()
decl_stmt|;
name|long
name|numChunks
init|=
name|Math
operator|.
name|min
argument_list|(
operator|(
name|blockFileLen
operator|+
name|bytesPerChecksum
operator|-
literal|1
operator|)
operator|/
name|bytesPerChecksum
argument_list|,
operator|(
name|metaFileLen
operator|-
name|crcHeaderLen
operator|)
operator|/
name|checksumSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|numChunks
operator|==
literal|0
condition|)
block|{
return|return
literal|0
return|;
block|}
name|IOUtils
operator|.
name|skipFully
argument_list|(
name|checksumIn
argument_list|,
operator|(
name|numChunks
operator|-
literal|1
operator|)
operator|*
name|checksumSize
argument_list|)
expr_stmt|;
name|blockIn
operator|=
operator|new
name|FileInputStream
argument_list|(
name|blockFile
argument_list|)
expr_stmt|;
name|long
name|lastChunkStartPos
init|=
operator|(
name|numChunks
operator|-
literal|1
operator|)
operator|*
name|bytesPerChecksum
decl_stmt|;
name|IOUtils
operator|.
name|skipFully
argument_list|(
name|blockIn
argument_list|,
name|lastChunkStartPos
argument_list|)
expr_stmt|;
name|int
name|lastChunkSize
init|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|bytesPerChecksum
argument_list|,
name|blockFileLen
operator|-
name|lastChunkStartPos
argument_list|)
decl_stmt|;
name|byte
index|[]
name|buf
init|=
operator|new
name|byte
index|[
name|lastChunkSize
operator|+
name|checksumSize
index|]
decl_stmt|;
name|checksumIn
operator|.
name|readFully
argument_list|(
name|buf
argument_list|,
name|lastChunkSize
argument_list|,
name|checksumSize
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|readFully
argument_list|(
name|blockIn
argument_list|,
name|buf
argument_list|,
literal|0
argument_list|,
name|lastChunkSize
argument_list|)
expr_stmt|;
name|checksum
operator|.
name|update
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
name|lastChunkSize
argument_list|)
expr_stmt|;
name|long
name|validFileLength
decl_stmt|;
if|if
condition|(
name|checksum
operator|.
name|compare
argument_list|(
name|buf
argument_list|,
name|lastChunkSize
argument_list|)
condition|)
block|{
comment|// last chunk matches crc
name|validFileLength
operator|=
name|lastChunkStartPos
operator|+
name|lastChunkSize
expr_stmt|;
block|}
else|else
block|{
comment|// last chunck is corrupt
name|validFileLength
operator|=
name|lastChunkStartPos
expr_stmt|;
block|}
comment|// truncate if extra bytes are present without CRC
if|if
condition|(
name|blockFile
operator|.
name|length
argument_list|()
operator|>
name|validFileLength
condition|)
block|{
name|RandomAccessFile
name|blockRAF
init|=
operator|new
name|RandomAccessFile
argument_list|(
name|blockFile
argument_list|,
literal|"rw"
argument_list|)
decl_stmt|;
try|try
block|{
comment|// truncate blockFile
name|blockRAF
operator|.
name|setLength
argument_list|(
name|validFileLength
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockRAF
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|validFileLength
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|FsDatasetImpl
operator|.
name|LOG
operator|.
name|warn
argument_list|(
name|e
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|checksumIn
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|blockIn
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|currentDir
operator|.
name|getAbsolutePath
argument_list|()
return|;
block|}
DECL|method|shutdown ()
name|void
name|shutdown
parameter_list|()
block|{
name|saveDfsUsed
argument_list|()
expr_stmt|;
name|dfsUsedSaved
operator|=
literal|true
expr_stmt|;
name|dfsUsage
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
end_class

end_unit

