begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *   http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  *  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.diskbalancer.command
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|diskbalancer
operator|.
name|command
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|CommandLine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|HelpFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|codec
operator|.
name|digest
operator|.
name|DigestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ClientDatanodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|diskbalancer
operator|.
name|DiskBalancerException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|diskbalancer
operator|.
name|planner
operator|.
name|NodePlan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|tools
operator|.
name|DiskBalancer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_comment
comment|/**  * Cancels a running plan.  */
end_comment

begin_class
DECL|class|CancelCommand
specifier|public
class|class
name|CancelCommand
extends|extends
name|Command
block|{
comment|/**    * Contructs a cancel Command.    *    * @param conf - Conf    */
DECL|method|CancelCommand (Configuration conf)
specifier|public
name|CancelCommand
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|addValidCommandParameters
argument_list|(
name|DiskBalancer
operator|.
name|CANCEL
argument_list|,
literal|"Cancels a running plan."
argument_list|)
expr_stmt|;
name|addValidCommandParameters
argument_list|(
name|DiskBalancer
operator|.
name|NODE
argument_list|,
literal|"Node to run the command "
operator|+
literal|"against in node:port format."
argument_list|)
expr_stmt|;
block|}
comment|/**    * Executes the Client Calls.    *    * @param cmd - CommandLine    */
annotation|@
name|Override
DECL|method|execute (CommandLine cmd)
specifier|public
name|void
name|execute
parameter_list|(
name|CommandLine
name|cmd
parameter_list|)
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Executing \"Cancel plan\" command."
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|cmd
operator|.
name|hasOption
argument_list|(
name|DiskBalancer
operator|.
name|CANCEL
argument_list|)
argument_list|)
expr_stmt|;
name|verifyCommandOptions
argument_list|(
name|DiskBalancer
operator|.
name|CANCEL
argument_list|,
name|cmd
argument_list|)
expr_stmt|;
comment|// We can cancel a plan using datanode address and plan ID
comment|// that you can read from a datanode using queryStatus
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
name|DiskBalancer
operator|.
name|NODE
argument_list|)
condition|)
block|{
name|String
name|nodeAddress
init|=
name|cmd
operator|.
name|getOptionValue
argument_list|(
name|DiskBalancer
operator|.
name|NODE
argument_list|)
decl_stmt|;
name|String
name|planHash
init|=
name|cmd
operator|.
name|getOptionValue
argument_list|(
name|DiskBalancer
operator|.
name|CANCEL
argument_list|)
decl_stmt|;
name|cancelPlanUsingHash
argument_list|(
name|nodeAddress
argument_list|,
name|planHash
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Or you can cancel a plan using the plan file. If the user
comment|// points us to the plan file, we can compute the hash as well as read
comment|// the address of the datanode from the plan file.
name|String
name|planFile
init|=
name|cmd
operator|.
name|getOptionValue
argument_list|(
name|DiskBalancer
operator|.
name|CANCEL
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|planFile
operator|!=
literal|null
operator|&&
operator|!
name|planFile
operator|.
name|isEmpty
argument_list|()
argument_list|,
literal|"Invalid plan file specified."
argument_list|)
expr_stmt|;
name|String
name|planData
init|=
literal|null
decl_stmt|;
try|try
init|(
name|FSDataInputStream
name|plan
init|=
name|open
argument_list|(
name|planFile
argument_list|)
init|)
block|{
name|planData
operator|=
name|IOUtils
operator|.
name|toString
argument_list|(
name|plan
argument_list|)
expr_stmt|;
block|}
name|cancelPlan
argument_list|(
name|planData
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Cancels a running plan.    *    * @param planData - Plan data.    * @throws IOException    */
DECL|method|cancelPlan (String planData)
specifier|private
name|void
name|cancelPlan
parameter_list|(
name|String
name|planData
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|planData
argument_list|)
expr_stmt|;
name|NodePlan
name|plan
init|=
name|NodePlan
operator|.
name|parseJson
argument_list|(
name|planData
argument_list|)
decl_stmt|;
name|String
name|dataNodeAddress
init|=
name|plan
operator|.
name|getNodeName
argument_list|()
operator|+
literal|":"
operator|+
name|plan
operator|.
name|getPort
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|dataNodeAddress
argument_list|)
expr_stmt|;
name|ClientDatanodeProtocol
name|dataNode
init|=
name|getDataNodeProxy
argument_list|(
name|dataNodeAddress
argument_list|)
decl_stmt|;
name|String
name|planHash
init|=
name|DigestUtils
operator|.
name|shaHex
argument_list|(
name|planData
argument_list|)
decl_stmt|;
try|try
block|{
name|dataNode
operator|.
name|cancelDiskBalancePlan
argument_list|(
name|planHash
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DiskBalancerException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cancelling plan on  {} failed. Result: {}, Message: {}"
argument_list|,
name|plan
operator|.
name|getNodeName
argument_list|()
argument_list|,
name|ex
operator|.
name|getResult
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
comment|/**    * Cancels a running plan.    * @param nodeAddress - Address of the data node.    * @param hash - Sha512 hash of the plan, which can be read from datanode    *             using query status command.    * @throws IOException    */
DECL|method|cancelPlanUsingHash (String nodeAddress, String hash)
specifier|private
name|void
name|cancelPlanUsingHash
parameter_list|(
name|String
name|nodeAddress
parameter_list|,
name|String
name|hash
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|nodeAddress
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|hash
argument_list|)
expr_stmt|;
name|ClientDatanodeProtocol
name|dataNode
init|=
name|getDataNodeProxy
argument_list|(
name|nodeAddress
argument_list|)
decl_stmt|;
try|try
block|{
name|dataNode
operator|.
name|cancelDiskBalancePlan
argument_list|(
name|hash
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DiskBalancerException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cancelling plan on  {} failed. Result: {}, Message: {}"
argument_list|,
name|nodeAddress
argument_list|,
name|ex
operator|.
name|getResult
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
comment|/**    * Gets extended help for this command.    */
annotation|@
name|Override
DECL|method|printHelp ()
specifier|public
name|void
name|printHelp
parameter_list|()
block|{
name|String
name|header
init|=
literal|"Cancel command cancels a running disk balancer operation"
operator|+
literal|".\n\n"
decl_stmt|;
name|String
name|footer
init|=
literal|"\nCancel command can be run via pointing to a plan file,"
operator|+
literal|" or by reading the plan ID using the query command and then using "
operator|+
literal|"planID and hostname. Examples of how to run this command are \n"
operator|+
literal|"hdfs diskbalancer -cancel<planfile> \n"
operator|+
literal|"hdfs diskbalancer -cancel<planID> -node<hostname>"
decl_stmt|;
name|HelpFormatter
name|helpFormatter
init|=
operator|new
name|HelpFormatter
argument_list|()
decl_stmt|;
name|helpFormatter
operator|.
name|printHelp
argument_list|(
literal|"hdfs diskbalancer -cancel<planFile> | -cancel "
operator|+
literal|"<planID> -node<hostname>"
argument_list|,
name|header
argument_list|,
name|DiskBalancer
operator|.
name|getCancelOptions
argument_list|()
argument_list|,
name|footer
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

