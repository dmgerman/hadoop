begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.datanode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ComparisonChain
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Futures
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|HardLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|Block
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LayoutVersion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|NodeType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|StartupOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|InconsistentFSStateException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|StorageInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeStorage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamespaceInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|nativeio
operator|.
name|NativeIO
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|RandomAccessFile
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|FileLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|OverlappingFileLockException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_comment
comment|/**   * Data storage information file.  *<p>  * @see Storage  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DataStorage
specifier|public
class|class
name|DataStorage
extends|extends
name|Storage
block|{
DECL|field|BLOCK_SUBDIR_PREFIX
specifier|public
specifier|final
specifier|static
name|String
name|BLOCK_SUBDIR_PREFIX
init|=
literal|"subdir"
decl_stmt|;
DECL|field|STORAGE_DIR_DETACHED
specifier|final
specifier|static
name|String
name|STORAGE_DIR_DETACHED
init|=
literal|"detach"
decl_stmt|;
DECL|field|STORAGE_DIR_RBW
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_RBW
init|=
literal|"rbw"
decl_stmt|;
DECL|field|STORAGE_DIR_FINALIZED
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_FINALIZED
init|=
literal|"finalized"
decl_stmt|;
DECL|field|STORAGE_DIR_LAZY_PERSIST
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_LAZY_PERSIST
init|=
literal|"lazypersist"
decl_stmt|;
DECL|field|STORAGE_DIR_TMP
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_TMP
init|=
literal|"tmp"
decl_stmt|;
comment|/**    * Set of bpids for which 'trash' is currently enabled.    * When trash is enabled block files are moved under a separate    * 'trash' folder instead of being deleted right away. This can    * be useful during rolling upgrades, for example.    * The set is backed by a concurrent HashMap.    *    * Even if trash is enabled, it is not used if a layout upgrade    * is in progress for a storage directory i.e. if the previous    * directory exists.    */
DECL|field|trashEnabledBpids
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|trashEnabledBpids
decl_stmt|;
comment|/**    * Datanode UUID that this storage is currently attached to. This    *  is the same as the legacy StorageID for datanodes that were    *  upgraded from a pre-UUID version. For compatibility with prior    *  versions of Datanodes we cannot make this field a UUID.    */
DECL|field|datanodeUuid
specifier|private
name|String
name|datanodeUuid
init|=
literal|null
decl_stmt|;
comment|// Flag to ensure we only initialize storage once
DECL|field|initialized
specifier|private
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
comment|// Maps block pool IDs to block pool storage
DECL|field|bpStorageMap
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|BlockPoolSliceStorage
argument_list|>
name|bpStorageMap
init|=
name|Collections
operator|.
name|synchronizedMap
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|BlockPoolSliceStorage
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
DECL|method|DataStorage ()
name|DataStorage
parameter_list|()
block|{
name|super
argument_list|(
name|NodeType
operator|.
name|DATA_NODE
argument_list|)
expr_stmt|;
name|trashEnabledBpids
operator|=
name|Collections
operator|.
name|newSetFromMap
argument_list|(
operator|new
name|ConcurrentHashMap
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|getBPStorage (String bpid)
specifier|public
name|BlockPoolSliceStorage
name|getBPStorage
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
return|return
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
return|;
block|}
DECL|method|DataStorage (StorageInfo storageInfo)
specifier|public
name|DataStorage
parameter_list|(
name|StorageInfo
name|storageInfo
parameter_list|)
block|{
name|super
argument_list|(
name|storageInfo
argument_list|)
expr_stmt|;
block|}
DECL|method|getDatanodeUuid ()
specifier|public
specifier|synchronized
name|String
name|getDatanodeUuid
parameter_list|()
block|{
return|return
name|datanodeUuid
return|;
block|}
DECL|method|setDatanodeUuid (String newDatanodeUuid)
specifier|public
specifier|synchronized
name|void
name|setDatanodeUuid
parameter_list|(
name|String
name|newDatanodeUuid
parameter_list|)
block|{
name|this
operator|.
name|datanodeUuid
operator|=
name|newDatanodeUuid
expr_stmt|;
block|}
comment|/** Create an ID for this storage.    * @return true if a new storage ID was generated.    * */
DECL|method|createStorageID ( StorageDirectory sd, boolean regenerateStorageIds)
specifier|public
specifier|synchronized
name|boolean
name|createStorageID
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|boolean
name|regenerateStorageIds
parameter_list|)
block|{
specifier|final
name|String
name|oldStorageID
init|=
name|sd
operator|.
name|getStorageUuid
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldStorageID
operator|==
literal|null
operator|||
name|regenerateStorageIds
condition|)
block|{
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|DatanodeStorage
operator|.
name|generateUuid
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Generated new storageID "
operator|+
name|sd
operator|.
name|getStorageUuid
argument_list|()
operator|+
literal|" for directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
operator|(
name|oldStorageID
operator|==
literal|null
condition|?
literal|""
else|:
operator|(
literal|" to replace "
operator|+
name|oldStorageID
operator|)
operator|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Enable trash for the specified block pool storage. Even if trash is    * enabled by the caller, it is superseded by the 'previous' directory    * if a layout upgrade is in progress.    */
DECL|method|enableTrash (String bpid)
specifier|public
name|void
name|enableTrash
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
if|if
condition|(
name|trashEnabledBpids
operator|.
name|add
argument_list|(
name|bpid
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Enabled trash for bpid "
operator|+
name|bpid
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|clearTrash (String bpid)
specifier|public
name|void
name|clearTrash
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
if|if
condition|(
name|trashEnabledBpids
operator|.
name|contains
argument_list|(
name|bpid
argument_list|)
condition|)
block|{
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
operator|.
name|clearTrash
argument_list|()
expr_stmt|;
name|trashEnabledBpids
operator|.
name|remove
argument_list|(
name|bpid
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleared trash for bpid "
operator|+
name|bpid
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|trashEnabled (String bpid)
specifier|public
name|boolean
name|trashEnabled
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
return|return
name|trashEnabledBpids
operator|.
name|contains
argument_list|(
name|bpid
argument_list|)
return|;
block|}
DECL|method|setRollingUpgradeMarker (String bpid)
specifier|public
name|void
name|setRollingUpgradeMarker
parameter_list|(
name|String
name|bpid
parameter_list|)
throws|throws
name|IOException
block|{
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
operator|.
name|setRollingUpgradeMarkers
argument_list|(
name|storageDirs
argument_list|)
expr_stmt|;
block|}
DECL|method|clearRollingUpgradeMarker (String bpid)
specifier|public
name|void
name|clearRollingUpgradeMarker
parameter_list|(
name|String
name|bpid
parameter_list|)
throws|throws
name|IOException
block|{
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
operator|.
name|clearRollingUpgradeMarkers
argument_list|(
name|storageDirs
argument_list|)
expr_stmt|;
block|}
comment|/**    * If rolling upgrades are in progress then do not delete block files    * immediately. Instead we move the block files to an intermediate    * 'trash' directory. If there is a subsequent rollback, then the block    * files will be restored from trash.    *    * @return trash directory if rolling upgrade is in progress, null    *         otherwise.    */
DECL|method|getTrashDirectoryForBlockFile (String bpid, File blockFile)
specifier|public
name|String
name|getTrashDirectoryForBlockFile
parameter_list|(
name|String
name|bpid
parameter_list|,
name|File
name|blockFile
parameter_list|)
block|{
if|if
condition|(
name|trashEnabledBpids
operator|.
name|contains
argument_list|(
name|bpid
argument_list|)
condition|)
block|{
return|return
name|getBPStorage
argument_list|(
name|bpid
argument_list|)
operator|.
name|getTrashDirectory
argument_list|(
name|blockFile
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * VolumeBuilder holds the metadata (e.g., the storage directories) of the    * prepared volume returned from {@link prepareVolume()}. Calling {@link build()}    * to add the metadata to {@link DataStorage} so that this prepared volume can    * be active.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|class|VolumeBuilder
specifier|static
specifier|public
class|class
name|VolumeBuilder
block|{
DECL|field|storage
specifier|private
name|DataStorage
name|storage
decl_stmt|;
comment|/** Volume level storage directory. */
DECL|field|sd
specifier|private
name|StorageDirectory
name|sd
decl_stmt|;
comment|/** Mapping from block pool ID to an array of storage directories. */
DECL|field|bpStorageDirMap
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|StorageDirectory
argument_list|>
argument_list|>
name|bpStorageDirMap
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|method|VolumeBuilder (DataStorage storage, StorageDirectory sd)
specifier|public
name|VolumeBuilder
parameter_list|(
name|DataStorage
name|storage
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|)
block|{
name|this
operator|.
name|storage
operator|=
name|storage
expr_stmt|;
name|this
operator|.
name|sd
operator|=
name|sd
expr_stmt|;
block|}
DECL|method|getStorageDirectory ()
specifier|public
specifier|final
name|StorageDirectory
name|getStorageDirectory
parameter_list|()
block|{
return|return
name|this
operator|.
name|sd
return|;
block|}
DECL|method|addBpStorageDirectories (String bpid, List<StorageDirectory> dirs)
specifier|private
name|void
name|addBpStorageDirectories
parameter_list|(
name|String
name|bpid
parameter_list|,
name|List
argument_list|<
name|StorageDirectory
argument_list|>
name|dirs
parameter_list|)
block|{
name|bpStorageDirMap
operator|.
name|put
argument_list|(
name|bpid
argument_list|,
name|dirs
argument_list|)
expr_stmt|;
block|}
comment|/**      * Add loaded metadata of a data volume to {@link DataStorage}.      */
DECL|method|build ()
specifier|public
name|void
name|build
parameter_list|()
block|{
assert|assert
name|this
operator|.
name|sd
operator|!=
literal|null
assert|;
synchronized|synchronized
init|(
name|storage
init|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|StorageDirectory
argument_list|>
argument_list|>
name|e
range|:
name|bpStorageDirMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
specifier|final
name|String
name|bpid
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
init|=
name|this
operator|.
name|storage
operator|.
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
assert|assert
name|bpStorage
operator|!=
literal|null
assert|;
for|for
control|(
name|StorageDirectory
name|bpSd
range|:
name|e
operator|.
name|getValue
argument_list|()
control|)
block|{
name|bpStorage
operator|.
name|addStorageDir
argument_list|(
name|bpSd
argument_list|)
expr_stmt|;
block|}
block|}
name|storage
operator|.
name|addStorageDir
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|loadStorageDirectory (DataNode datanode, NamespaceInfo nsInfo, File dataDir, StartupOption startOpt)
specifier|private
name|StorageDirectory
name|loadStorageDirectory
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|File
name|dataDir
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
name|StorageDirectory
name|sd
init|=
operator|new
name|StorageDirectory
argument_list|(
name|dataDir
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
decl_stmt|;
try|try
block|{
name|StorageState
name|curState
init|=
name|sd
operator|.
name|analyzeStorage
argument_list|(
name|startOpt
argument_list|,
name|this
argument_list|)
decl_stmt|;
comment|// sd is locked but not opened
switch|switch
condition|(
name|curState
condition|)
block|{
case|case
name|NORMAL
case|:
break|break;
case|case
name|NON_EXISTENT
case|:
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" does not exist"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" does not exist"
argument_list|)
throw|;
case|case
name|NOT_FORMATTED
case|:
comment|// format
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" is not formatted for "
operator|+
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Formatting ..."
argument_list|)
expr_stmt|;
name|format
argument_list|(
name|sd
argument_list|,
name|nsInfo
argument_list|,
name|datanode
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// recovery part is common
name|sd
operator|.
name|doRecover
argument_list|(
name|curState
argument_list|)
expr_stmt|;
block|}
comment|// 2. Do transitions
comment|// Each storage directory is treated individually.
comment|// During startup some of them can upgrade or roll back
comment|// while others could be up-to-date for the regular startup.
name|doTransition
argument_list|(
name|datanode
argument_list|,
name|sd
argument_list|,
name|nsInfo
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
comment|// 3. Update successfully loaded storage.
name|setServiceLayoutVersion
argument_list|(
name|getServiceLayoutVersion
argument_list|()
argument_list|)
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
return|return
name|sd
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|sd
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
comment|/**    * Prepare a storage directory. It creates a builder which can be used to add    * to the volume. If the volume cannot be added, it is OK to discard the    * builder later.    *    * @param datanode DataNode object.    * @param volume the root path of a storage directory.    * @param nsInfos an array of namespace infos.    * @return a VolumeBuilder that holds the metadata of this storage directory    * and can be added to DataStorage later.    * @throws IOException if encounters I/O errors.    *    * Note that if there is IOException, the state of DataStorage is not modified.    */
DECL|method|prepareVolume (DataNode datanode, File volume, List<NamespaceInfo> nsInfos)
specifier|public
name|VolumeBuilder
name|prepareVolume
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|File
name|volume
parameter_list|,
name|List
argument_list|<
name|NamespaceInfo
argument_list|>
name|nsInfos
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|containsStorageDir
argument_list|(
name|volume
argument_list|)
condition|)
block|{
specifier|final
name|String
name|errorMessage
init|=
literal|"Storage directory is in use"
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|errorMessage
operator|+
literal|"."
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|errorMessage
argument_list|)
throw|;
block|}
name|StorageDirectory
name|sd
init|=
name|loadStorageDirectory
argument_list|(
name|datanode
argument_list|,
name|nsInfos
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|,
name|volume
argument_list|,
name|StartupOption
operator|.
name|HOTSWAP
argument_list|)
decl_stmt|;
name|VolumeBuilder
name|builder
init|=
operator|new
name|VolumeBuilder
argument_list|(
name|this
argument_list|,
name|sd
argument_list|)
decl_stmt|;
for|for
control|(
name|NamespaceInfo
name|nsInfo
range|:
name|nsInfos
control|)
block|{
name|List
argument_list|<
name|File
argument_list|>
name|bpDataDirs
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|bpDataDirs
operator|.
name|add
argument_list|(
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
operator|new
name|File
argument_list|(
name|volume
argument_list|,
name|STORAGE_DIR_CURRENT
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|makeBlockPoolDataDir
argument_list|(
name|bpDataDirs
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
decl_stmt|;
specifier|final
name|String
name|bpid
init|=
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|bpStorage
operator|=
name|this
operator|.
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
expr_stmt|;
if|if
condition|(
name|bpStorage
operator|==
literal|null
condition|)
block|{
name|bpStorage
operator|=
operator|new
name|BlockPoolSliceStorage
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|bpid
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
expr_stmt|;
name|addBlockPoolStorage
argument_list|(
name|bpid
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
block|}
name|builder
operator|.
name|addBpStorageDirectories
argument_list|(
name|bpid
argument_list|,
name|bpStorage
operator|.
name|loadBpStorageDirectories
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|bpDataDirs
argument_list|,
name|StartupOption
operator|.
name|HOTSWAP
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|builder
return|;
block|}
comment|/**    * Add a list of volumes to be managed by DataStorage. If the volume is empty,    * format it, otherwise recover it from previous transitions if required.    *    * @param datanode the reference to DataNode.    * @param nsInfo namespace information    * @param dataDirs array of data storage directories    * @param startOpt startup option    * @return a list of successfully loaded volumes.    * @throws IOException    */
annotation|@
name|VisibleForTesting
DECL|method|addStorageLocations (DataNode datanode, NamespaceInfo nsInfo, Collection<StorageLocation> dataDirs, StartupOption startOpt)
specifier|synchronized
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|addStorageLocations
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|bpid
init|=
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|StorageLocation
argument_list|>
name|successVolumes
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|StorageLocation
name|dataDir
range|:
name|dataDirs
control|)
block|{
name|File
name|root
init|=
name|dataDir
operator|.
name|getFile
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|containsStorageDir
argument_list|(
name|root
argument_list|)
condition|)
block|{
try|try
block|{
comment|// It first ensures the datanode level format is completed.
name|StorageDirectory
name|sd
init|=
name|loadStorageDirectory
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|root
argument_list|,
name|startOpt
argument_list|)
decl_stmt|;
name|addStorageDir
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" has already been used."
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|File
argument_list|>
name|bpDataDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|File
argument_list|>
argument_list|()
decl_stmt|;
name|bpDataDirs
operator|.
name|add
argument_list|(
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|bpid
argument_list|,
operator|new
name|File
argument_list|(
name|root
argument_list|,
name|STORAGE_DIR_CURRENT
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|makeBlockPoolDataDir
argument_list|(
name|bpDataDirs
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
init|=
name|this
operator|.
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
decl_stmt|;
if|if
condition|(
name|bpStorage
operator|==
literal|null
condition|)
block|{
name|bpStorage
operator|=
operator|new
name|BlockPoolSliceStorage
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|bpid
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|bpStorage
operator|.
name|recoverTransitionRead
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|bpDataDirs
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
name|addBlockPoolStorage
argument_list|(
name|bpid
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to add storage for block pool: "
operator|+
name|bpid
operator|+
literal|" : "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|successVolumes
operator|.
name|add
argument_list|(
name|dataDir
argument_list|)
expr_stmt|;
block|}
return|return
name|successVolumes
return|;
block|}
comment|/**    * Remove storage dirs from DataStorage. All storage dirs are removed even when the    * IOException is thrown.    *    * @param dirsToRemove a set of storage directories to be removed.    * @throws IOException if I/O error when unlocking storage directory.    */
DECL|method|removeVolumes (final Set<File> dirsToRemove)
specifier|synchronized
name|void
name|removeVolumes
parameter_list|(
specifier|final
name|Set
argument_list|<
name|File
argument_list|>
name|dirsToRemove
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|dirsToRemove
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|StringBuilder
name|errorMsgBuilder
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|it
init|=
name|this
operator|.
name|storageDirs
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageDirectory
name|sd
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|dirsToRemove
operator|.
name|contains
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|)
condition|)
block|{
comment|// Remove the block pool level storage first.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|BlockPoolSliceStorage
argument_list|>
name|entry
range|:
name|this
operator|.
name|bpStorageMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|bpid
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|BlockPoolSliceStorage
name|bpsStorage
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|File
name|bpRoot
init|=
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|bpid
argument_list|,
name|sd
operator|.
name|getCurrentDir
argument_list|()
argument_list|)
decl_stmt|;
name|bpsStorage
operator|.
name|remove
argument_list|(
name|bpRoot
operator|.
name|getAbsoluteFile
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
try|try
block|{
name|sd
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"I/O error attempting to unlock storage directory %s."
argument_list|,
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|errorMsgBuilder
operator|.
name|append
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Failed to remove %s: %s%n"
argument_list|,
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|errorMsgBuilder
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|errorMsgBuilder
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Analyze storage directories for a specific block pool.    * Recover from previous transitions if required.    * Perform fs state transition if necessary depending on the namespace info.    * Read storage info.    *<br>    * This method should be synchronized between multiple DN threads.  Only the    * first DN thread does DN level storage dir recoverTransitionRead.    *    * @param datanode DataNode    * @param nsInfo Namespace info of namenode corresponding to the block pool    * @param dataDirs Storage directories    * @param startOpt startup option    * @throws IOException on error    */
DECL|method|recoverTransitionRead (DataNode datanode, NamespaceInfo nsInfo, Collection<StorageLocation> dataDirs, StartupOption startOpt)
name|void
name|recoverTransitionRead
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|initialized
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"DataNode version: "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|" and NameNode layout version: "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|storageDirs
operator|=
operator|new
name|ArrayList
argument_list|<
name|StorageDirectory
argument_list|>
argument_list|(
name|dataDirs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// mark DN storage is initialized
name|this
operator|.
name|initialized
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|addStorageLocations
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|dataDirs
argument_list|,
name|startOpt
argument_list|)
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"All specified directories are failed to load."
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create physical directory for block pools on the data node    *     * @param dataDirs    *          List of data directories    * @param conf    *          Configuration instance to use.    * @throws IOException on errors    */
DECL|method|makeBlockPoolDataDir (Collection<File> dataDirs, Configuration conf)
specifier|static
name|void
name|makeBlockPoolDataDir
parameter_list|(
name|Collection
argument_list|<
name|File
argument_list|>
name|dataDirs
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
name|conf
operator|=
operator|new
name|HdfsConfiguration
argument_list|()
expr_stmt|;
name|LocalFileSystem
name|localFS
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FsPermission
name|permission
init|=
operator|new
name|FsPermission
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|data
range|:
name|dataDirs
control|)
block|{
try|try
block|{
name|DiskChecker
operator|.
name|checkDir
argument_list|(
name|localFS
argument_list|,
operator|new
name|Path
argument_list|(
name|data
operator|.
name|toURI
argument_list|()
argument_list|)
argument_list|,
name|permission
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid directory in: "
operator|+
name|data
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|format (StorageDirectory sd, NamespaceInfo nsInfo, String datanodeUuid)
name|void
name|format
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|String
name|datanodeUuid
parameter_list|)
throws|throws
name|IOException
block|{
name|sd
operator|.
name|clearDirectory
argument_list|()
expr_stmt|;
comment|// create directory
name|this
operator|.
name|layoutVersion
operator|=
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
expr_stmt|;
name|this
operator|.
name|clusterID
operator|=
name|nsInfo
operator|.
name|getClusterID
argument_list|()
expr_stmt|;
name|this
operator|.
name|namespaceID
operator|=
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
expr_stmt|;
name|this
operator|.
name|cTime
operator|=
literal|0
expr_stmt|;
name|setDatanodeUuid
argument_list|(
name|datanodeUuid
argument_list|)
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getStorageUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// Assign a new Storage UUID.
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|DatanodeStorage
operator|.
name|generateUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
comment|/*    * Set ClusterID, StorageID, StorageType, CTime into    * DataStorage VERSION file.    * Always called just before writing the properties to    * the VERSION file.   */
annotation|@
name|Override
DECL|method|setPropertiesFromFields (Properties props, StorageDirectory sd )
specifier|protected
name|void
name|setPropertiesFromFields
parameter_list|(
name|Properties
name|props
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"storageType"
argument_list|,
name|storageType
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"clusterID"
argument_list|,
name|clusterID
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"cTime"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|cTime
argument_list|)
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"layoutVersion"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|layoutVersion
argument_list|)
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"storageID"
argument_list|,
name|sd
operator|.
name|getStorageUuid
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|datanodeUuid
init|=
name|getDatanodeUuid
argument_list|()
decl_stmt|;
if|if
condition|(
name|datanodeUuid
operator|!=
literal|null
condition|)
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"datanodeUuid"
argument_list|,
name|datanodeUuid
argument_list|)
expr_stmt|;
block|}
comment|// Set NamespaceID in version before federation
if|if
condition|(
operator|!
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"namespaceID"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|namespaceID
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Read ClusterID, StorageID, StorageType, CTime from     * DataStorage VERSION file and verify them.    * Always called just after reading the properties from the VERSION file.    */
annotation|@
name|Override
DECL|method|setFieldsFromProperties (Properties props, StorageDirectory sd)
specifier|protected
name|void
name|setFieldsFromProperties
parameter_list|(
name|Properties
name|props
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|setFieldsFromProperties
argument_list|(
name|props
argument_list|,
name|sd
argument_list|,
literal|false
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
DECL|method|setFieldsFromProperties (Properties props, StorageDirectory sd, boolean overrideLayoutVersion, int toLayoutVersion)
specifier|private
name|void
name|setFieldsFromProperties
parameter_list|(
name|Properties
name|props
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|,
name|boolean
name|overrideLayoutVersion
parameter_list|,
name|int
name|toLayoutVersion
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|overrideLayoutVersion
condition|)
block|{
name|this
operator|.
name|layoutVersion
operator|=
name|toLayoutVersion
expr_stmt|;
block|}
else|else
block|{
name|setLayoutVersion
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
block|}
name|setcTime
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
name|checkStorageType
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
name|setClusterId
argument_list|(
name|props
argument_list|,
name|layoutVersion
argument_list|,
name|sd
argument_list|)
expr_stmt|;
comment|// Read NamespaceID in version before federation
if|if
condition|(
operator|!
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
name|setNamespaceID
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
block|}
comment|// valid storage id, storage id may be empty
name|String
name|ssid
init|=
name|props
operator|.
name|getProperty
argument_list|(
literal|"storageID"
argument_list|)
decl_stmt|;
if|if
condition|(
name|ssid
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"file "
operator|+
name|STORAGE_FILE_VERSION
operator|+
literal|" is invalid."
argument_list|)
throw|;
block|}
name|String
name|sid
init|=
name|sd
operator|.
name|getStorageUuid
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|sid
operator|==
literal|null
operator|||
name|sid
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|||
name|ssid
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|||
name|sid
operator|.
name|equals
argument_list|(
name|ssid
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"has incompatible storage Id."
argument_list|)
throw|;
block|}
if|if
condition|(
name|sid
operator|==
literal|null
condition|)
block|{
comment|// update id only if it was null
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|ssid
argument_list|)
expr_stmt|;
block|}
comment|// Update the datanode UUID if present.
if|if
condition|(
name|props
operator|.
name|getProperty
argument_list|(
literal|"datanodeUuid"
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|String
name|dnUuid
init|=
name|props
operator|.
name|getProperty
argument_list|(
literal|"datanodeUuid"
argument_list|)
decl_stmt|;
if|if
condition|(
name|getDatanodeUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
name|setDatanodeUuid
argument_list|(
name|dnUuid
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|getDatanodeUuid
argument_list|()
operator|.
name|compareTo
argument_list|(
name|dnUuid
argument_list|)
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"Root "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|": DatanodeUuid="
operator|+
name|dnUuid
operator|+
literal|", does not match "
operator|+
name|getDatanodeUuid
argument_list|()
operator|+
literal|" from other"
operator|+
literal|" StorageDirectory."
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|isPreUpgradableLayout (StorageDirectory sd)
specifier|public
name|boolean
name|isPreUpgradableLayout
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|oldF
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"storage"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldF
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// check the layout version inside the storage file
comment|// Lock and Read old storage file
try|try
init|(
name|RandomAccessFile
name|oldFile
init|=
operator|new
name|RandomAccessFile
argument_list|(
name|oldF
argument_list|,
literal|"rws"
argument_list|)
init|;
name|FileLock
name|oldLock
operator|=
name|oldFile
operator|.
name|getChannel
argument_list|()
operator|.
name|tryLock
argument_list|()
init|)
block|{
if|if
condition|(
literal|null
operator|==
name|oldLock
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to acquire file lock on path "
operator|+
name|oldF
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|OverlappingFileLockException
argument_list|()
throw|;
block|}
name|oldFile
operator|.
name|seek
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|int
name|oldVersion
init|=
name|oldFile
operator|.
name|readInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldVersion
operator|<
name|LAST_PRE_UPGRADE_LAYOUT_VERSION
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/** Read VERSION file for rollback */
DECL|method|readProperties (StorageDirectory sd, int rollbackLayoutVersion)
name|void
name|readProperties
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|int
name|rollbackLayoutVersion
parameter_list|)
throws|throws
name|IOException
block|{
name|Properties
name|props
init|=
name|readPropertiesFile
argument_list|(
name|sd
operator|.
name|getVersionFile
argument_list|()
argument_list|)
decl_stmt|;
name|setFieldsFromProperties
argument_list|(
name|props
argument_list|,
name|sd
argument_list|,
literal|true
argument_list|,
name|rollbackLayoutVersion
argument_list|)
expr_stmt|;
block|}
comment|/**    * Analize which and whether a transition of the fs state is required    * and perform it if necessary.    *     * Rollback if the rollback startup option was specified.    * Upgrade if this.LV> LAYOUT_VERSION    * Regular startup if this.LV = LAYOUT_VERSION    *     * @param datanode Datanode to which this storage belongs to    * @param sd  storage directory    * @param nsInfo  namespace info    * @param startOpt  startup option    * @throws IOException    */
DECL|method|doTransition ( DataNode datanode, StorageDirectory sd, NamespaceInfo nsInfo, StartupOption startOpt )
specifier|private
name|void
name|doTransition
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|startOpt
operator|==
name|StartupOption
operator|.
name|ROLLBACK
condition|)
block|{
name|doRollback
argument_list|(
name|sd
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
comment|// rollback if applicable
block|}
name|readProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|checkVersionUpgradable
argument_list|(
name|this
operator|.
name|layoutVersion
argument_list|)
expr_stmt|;
assert|assert
name|this
operator|.
name|layoutVersion
operator|>=
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|:
literal|"Future version is not allowed"
assert|;
name|boolean
name|federationSupported
init|=
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
decl_stmt|;
comment|// For pre-federation version - validate the namespaceID
if|if
condition|(
operator|!
name|federationSupported
operator|&&
name|getNamespaceID
argument_list|()
operator|!=
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible namespaceIDs in "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": namenode namespaceID = "
operator|+
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
operator|+
literal|"; datanode namespaceID = "
operator|+
name|getNamespaceID
argument_list|()
argument_list|)
throw|;
block|}
comment|// For version that supports federation, validate clusterID
if|if
condition|(
name|federationSupported
operator|&&
operator|!
name|getClusterID
argument_list|()
operator|.
name|equals
argument_list|(
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible clusterIDs in "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": namenode clusterID = "
operator|+
name|nsInfo
operator|.
name|getClusterID
argument_list|()
operator|+
literal|"; datanode clusterID = "
operator|+
name|getClusterID
argument_list|()
argument_list|)
throw|;
block|}
comment|// Clusters previously upgraded from layout versions earlier than
comment|// ADD_DATANODE_AND_STORAGE_UUIDS failed to correctly generate a
comment|// new storage ID. We check for that and fix it now.
name|boolean
name|haveValidStorageId
init|=
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|ADD_DATANODE_AND_STORAGE_UUIDS
argument_list|,
name|layoutVersion
argument_list|)
operator|&&
name|DatanodeStorage
operator|.
name|isValidStorageId
argument_list|(
name|sd
operator|.
name|getStorageUuid
argument_list|()
argument_list|)
decl_stmt|;
comment|// regular start up.
if|if
condition|(
name|this
operator|.
name|layoutVersion
operator|==
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
condition|)
block|{
name|createStorageID
argument_list|(
name|sd
argument_list|,
operator|!
name|haveValidStorageId
argument_list|)
expr_stmt|;
return|return;
comment|// regular startup
block|}
comment|// do upgrade
if|if
condition|(
name|this
operator|.
name|layoutVersion
operator|>
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
condition|)
block|{
name|doUpgrade
argument_list|(
name|datanode
argument_list|,
name|sd
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
comment|// upgrade
name|createStorageID
argument_list|(
name|sd
argument_list|,
operator|!
name|haveValidStorageId
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// layoutVersion< DATANODE_LAYOUT_VERSION. I.e. stored layout version is newer
comment|// than the version supported by datanode. This should have been caught
comment|// in readProperties(), even if rollback was not carried out or somehow
comment|// failed.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BUG: The stored LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" is newer than the supported LV = "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
argument_list|)
throw|;
block|}
comment|/**    * Upgrade -- Move current storage into a backup directory,    * and hardlink all its blocks into the new current directory.    *     * Upgrade from pre-0.22 to 0.22 or later release e.g. 0.19/0.20/ => 0.22/0.23    *<ul>    *<li> If<SD>/previous exists then delete it</li>    *<li> Rename<SD>/current to<SD>/previous.tmp</li>    *<li>Create new<SD>/current/<bpid>/current directory<li>    *<ul>    *<li> Hard links for block files are created from<SD>/previous.tmp     * to<SD>/current/<bpid>/current</li>    *<li> Saves new version file in<SD>/current/<bpid>/current directory</li>    *</ul>    *<li> Rename<SD>/previous.tmp to<SD>/previous</li>    *</ul>    *     * There should be only ONE namenode in the cluster for first     * time upgrade to 0.22    * @param sd  storage directory    * @throws IOException on error    */
DECL|method|doUpgrade (DataNode datanode, StorageDirectory sd, NamespaceInfo nsInfo)
name|void
name|doUpgrade
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If the existing on-disk layout version supportes federation, simply
comment|// update its layout version.
if|if
condition|(
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
comment|// The VERSION file is already read in. Override the layoutVersion
comment|// field and overwrite the file. The upgrade work is handled by
comment|// {@link BlockPoolSliceStorage#doUpgrade}
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating layout version from "
operator|+
name|layoutVersion
operator|+
literal|" to "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|" for storage "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|)
expr_stmt|;
name|layoutVersion
operator|=
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Upgrading storage directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|".\n   old LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; old CTime = "
operator|+
name|this
operator|.
name|getCTime
argument_list|()
operator|+
literal|".\n   new LV = "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|"; new CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
name|File
name|curDir
init|=
name|sd
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
name|File
name|bbwDir
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|Storage
operator|.
name|STORAGE_1_BBW
argument_list|)
decl_stmt|;
assert|assert
name|curDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Data node current directory must exist."
assert|;
comment|// Cleanup directory "detach"
name|cleanupDetachDir
argument_list|(
operator|new
name|File
argument_list|(
name|curDir
argument_list|,
name|STORAGE_DIR_DETACHED
argument_list|)
argument_list|)
expr_stmt|;
comment|// 1. delete<SD>/previous dir before upgrading
if|if
condition|(
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
name|deleteDir
argument_list|(
name|prevDir
argument_list|)
expr_stmt|;
comment|// get previous.tmp directory,<SD>/previous.tmp
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getPreviousTmp
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|tmpDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Data node previous.tmp directory must not exist."
assert|;
comment|// 2. Rename<SD>/current to<SD>/previous.tmp
name|rename
argument_list|(
name|curDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// 3. Format BP and hard link blocks from previous directory
name|File
name|curBpDir
init|=
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|curDir
argument_list|)
decl_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
init|=
operator|new
name|BlockPoolSliceStorage
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
decl_stmt|;
name|bpStorage
operator|.
name|format
argument_list|(
name|curDir
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
name|linkAllBlocks
argument_list|(
name|datanode
argument_list|,
name|tmpDir
argument_list|,
name|bbwDir
argument_list|,
operator|new
name|File
argument_list|(
name|curBpDir
argument_list|,
name|STORAGE_DIR_CURRENT
argument_list|)
argument_list|)
expr_stmt|;
comment|// 4. Write version file under<SD>/current
name|layoutVersion
operator|=
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
expr_stmt|;
name|clusterID
operator|=
name|nsInfo
operator|.
name|getClusterID
argument_list|()
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
comment|// 5. Rename<SD>/previous.tmp to<SD>/previous
name|rename
argument_list|(
name|tmpDir
argument_list|,
name|prevDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Upgrade of "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
name|addBlockPoolStorage
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cleanup the detachDir.     *     * If the directory is not empty report an error;     * Otherwise remove the directory.    *     * @param detachDir detach directory    * @throws IOException if the directory is not empty or it can not be removed    */
DECL|method|cleanupDetachDir (File detachDir)
specifier|private
name|void
name|cleanupDetachDir
parameter_list|(
name|File
name|detachDir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|APPEND_RBW_DIR
argument_list|,
name|layoutVersion
argument_list|)
operator|&&
name|detachDir
operator|.
name|exists
argument_list|()
operator|&&
name|detachDir
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|FileUtil
operator|.
name|list
argument_list|(
name|detachDir
argument_list|)
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Detached directory "
operator|+
name|detachDir
operator|+
literal|" is not empty. Please manually move each file under this "
operator|+
literal|"directory to the finalized directory if the finalized "
operator|+
literal|"directory tree does not have the file."
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|detachDir
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot remove directory "
operator|+
name|detachDir
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**     * Rolling back to a snapshot in previous directory by moving it to current    * directory.    * Rollback procedure:    *<br>    * If previous directory exists:    *<ol>    *<li> Rename current to removed.tmp</li>    *<li> Rename previous to current</li>    *<li> Remove removed.tmp</li>    *</ol>    *     * If previous directory does not exist and the current version supports    * federation, perform a simple rollback of layout version. This does not    * involve saving/restoration of actual data.    */
DECL|method|doRollback ( StorageDirectory sd, NamespaceInfo nsInfo )
name|void
name|doRollback
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
comment|// This is a regular startup or a post-federation rollback
if|if
condition|(
operator|!
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
argument_list|)
condition|)
block|{
name|readProperties
argument_list|(
name|sd
argument_list|,
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
argument_list|)
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Layout version rolled back to "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|" for storage "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|DataStorage
name|prevInfo
init|=
operator|new
name|DataStorage
argument_list|()
decl_stmt|;
name|prevInfo
operator|.
name|readPreviousVersionProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
comment|// We allow rollback to a state, which is either consistent with
comment|// the namespace state or can be further upgraded to it.
if|if
condition|(
operator|!
operator|(
name|prevInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|>=
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|&&
name|prevInfo
operator|.
name|getCTime
argument_list|()
operator|<=
name|nsInfo
operator|.
name|getCTime
argument_list|()
operator|)
condition|)
comment|// cannot rollback
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"Cannot rollback to a newer state.\nDatanode previous state: LV = "
operator|+
name|prevInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" CTime = "
operator|+
name|prevInfo
operator|.
name|getCTime
argument_list|()
operator|+
literal|" is newer than the namespace state: LV = "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|" CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
throw|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolling back storage directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|".\n   target LV = "
operator|+
name|HdfsServerConstants
operator|.
name|DATANODE_LAYOUT_VERSION
operator|+
literal|"; target CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getRemovedTmp
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|tmpDir
operator|.
name|exists
argument_list|()
operator|:
literal|"removed.tmp directory must not exist."
assert|;
comment|// rename current to tmp
name|File
name|curDir
init|=
name|sd
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
assert|assert
name|curDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Current directory must exist."
assert|;
name|rename
argument_list|(
name|curDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// rename previous to current
name|rename
argument_list|(
name|prevDir
argument_list|,
name|curDir
argument_list|)
expr_stmt|;
comment|// delete tmp dir
name|deleteDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rollback of "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Finalize procedure deletes an existing snapshot.    *<ol>    *<li>Rename previous to finalized.tmp directory</li>    *<li>Fully delete the finalized.tmp directory</li>    *</ol>    *     * Do nothing, if previous directory does not exist    */
DECL|method|doFinalize (StorageDirectory sd)
name|void
name|doFinalize
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
return|return;
comment|// already discarded
specifier|final
name|String
name|dataDirPath
init|=
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Finalizing upgrade for storage directory "
operator|+
name|dataDirPath
operator|+
literal|".\n   cur LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; cur CTime = "
operator|+
name|this
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
assert|assert
name|sd
operator|.
name|getCurrentDir
argument_list|()
operator|.
name|exists
argument_list|()
operator|:
literal|"Current directory must exist."
assert|;
specifier|final
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getFinalizedTmp
argument_list|()
decl_stmt|;
comment|//finalized.tmp directory
specifier|final
name|File
name|bbwDir
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|Storage
operator|.
name|STORAGE_1_BBW
argument_list|)
decl_stmt|;
comment|// 1. rename previous to finalized.tmp
name|rename
argument_list|(
name|prevDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// 2. delete finalized.tmp dir in a separate thread
comment|// Also delete the blocksBeingWritten from HDFS 1.x and earlier, if
comment|// it exists.
operator|new
name|Daemon
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|deleteDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|bbwDir
operator|.
name|exists
argument_list|()
condition|)
block|{
name|deleteDir
argument_list|(
name|bbwDir
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Finalize upgrade for "
operator|+
name|dataDirPath
operator|+
literal|" failed"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Finalize upgrade for "
operator|+
name|dataDirPath
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"Finalize "
operator|+
name|dataDirPath
return|;
block|}
block|}
argument_list|)
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/*    * Finalize the upgrade for a block pool    * This also empties trash created during rolling upgrade and disables    * trash functionality.    */
DECL|method|finalizeUpgrade (String bpID)
name|void
name|finalizeUpgrade
parameter_list|(
name|String
name|bpID
parameter_list|)
throws|throws
name|IOException
block|{
comment|// To handle finalizing a snapshot taken at datanode level while
comment|// upgrading to federation, if datanode level snapshot previous exists,
comment|// then finalize it. Else finalize the corresponding BP.
for|for
control|(
name|StorageDirectory
name|sd
range|:
name|storageDirs
control|)
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// data node level storage finalize
name|doFinalize
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// block pool storage finalize using specific bpID
name|BlockPoolSliceStorage
name|bpStorage
init|=
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpID
argument_list|)
decl_stmt|;
name|bpStorage
operator|.
name|doFinalize
argument_list|(
name|sd
operator|.
name|getCurrentDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Hardlink all finalized and RBW blocks in fromDir to toDir    *    * @param fromDir      The directory where the 'from' snapshot is stored    * @param fromBbwDir   In HDFS 1.x, the directory where blocks    *                     that are under construction are stored.    * @param toDir        The current data directory    *    * @throws IOException If error occurs during hardlink    */
DECL|method|linkAllBlocks (DataNode datanode, File fromDir, File fromBbwDir, File toDir)
specifier|private
name|void
name|linkAllBlocks
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|File
name|fromDir
parameter_list|,
name|File
name|fromBbwDir
parameter_list|,
name|File
name|toDir
parameter_list|)
throws|throws
name|IOException
block|{
name|HardLink
name|hardLink
init|=
operator|new
name|HardLink
argument_list|()
decl_stmt|;
comment|// do the link
name|int
name|diskLayoutVersion
init|=
name|this
operator|.
name|getLayoutVersion
argument_list|()
decl_stmt|;
if|if
condition|(
name|DataNodeLayoutVersion
operator|.
name|supports
argument_list|(
name|LayoutVersion
operator|.
name|Feature
operator|.
name|APPEND_RBW_DIR
argument_list|,
name|diskLayoutVersion
argument_list|)
condition|)
block|{
comment|// hardlink finalized blocks in tmpDir/finalized
name|linkBlocks
argument_list|(
name|datanode
argument_list|,
operator|new
name|File
argument_list|(
name|fromDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
comment|// hardlink rbw blocks in tmpDir/rbw
name|linkBlocks
argument_list|(
name|datanode
argument_list|,
operator|new
name|File
argument_list|(
name|fromDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// pre-RBW version
comment|// hardlink finalized blocks in tmpDir
name|linkBlocks
argument_list|(
name|datanode
argument_list|,
name|fromDir
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
if|if
condition|(
name|fromBbwDir
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|/*          * We need to put the 'blocksBeingWritten' from HDFS 1.x into the rbw          * directory.  It's a little messy, because the blocksBeingWriten was          * NOT underneath the 'current' directory in those releases.  See          * HDFS-3731 for details.          */
name|linkBlocks
argument_list|(
name|datanode
argument_list|,
name|fromBbwDir
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
name|hardLink
operator|.
name|linkStats
operator|.
name|report
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|class|LinkArgs
specifier|private
specifier|static
class|class
name|LinkArgs
block|{
DECL|field|src
name|File
name|src
decl_stmt|;
DECL|field|dst
name|File
name|dst
decl_stmt|;
DECL|method|LinkArgs (File src, File dst)
name|LinkArgs
parameter_list|(
name|File
name|src
parameter_list|,
name|File
name|dst
parameter_list|)
block|{
name|this
operator|.
name|src
operator|=
name|src
expr_stmt|;
name|this
operator|.
name|dst
operator|=
name|dst
expr_stmt|;
block|}
block|}
DECL|method|linkBlocks (DataNode datanode, File from, File to, int oldLV, HardLink hl)
specifier|static
name|void
name|linkBlocks
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|File
name|from
parameter_list|,
name|File
name|to
parameter_list|,
name|int
name|oldLV
parameter_list|,
name|HardLink
name|hl
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|upgradeToIdBasedLayout
init|=
literal|false
decl_stmt|;
comment|// If we are upgrading from a version older than the one where we introduced
comment|// block ID-based layout AND we're working with the finalized directory,
comment|// we'll need to upgrade from the old flat layout to the block ID-based one
if|if
condition|(
name|oldLV
operator|>
name|DataNodeLayoutVersion
operator|.
name|Feature
operator|.
name|BLOCKID_BASED_LAYOUT
operator|.
name|getInfo
argument_list|()
operator|.
name|getLayoutVersion
argument_list|()
operator|&&
name|to
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|STORAGE_DIR_FINALIZED
argument_list|)
condition|)
block|{
name|upgradeToIdBasedLayout
operator|=
literal|true
expr_stmt|;
block|}
specifier|final
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|idBasedLayoutSingleLinks
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|linkBlocksHelper
argument_list|(
name|from
argument_list|,
name|to
argument_list|,
name|oldLV
argument_list|,
name|hl
argument_list|,
name|upgradeToIdBasedLayout
argument_list|,
name|to
argument_list|,
name|idBasedLayoutSingleLinks
argument_list|)
expr_stmt|;
comment|// Detect and remove duplicate entries.
specifier|final
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|duplicates
init|=
name|findDuplicateEntries
argument_list|(
name|idBasedLayoutSingleLinks
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|duplicates
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"There are "
operator|+
name|duplicates
operator|.
name|size
argument_list|()
operator|+
literal|" duplicate block "
operator|+
literal|"entries within the same volume."
argument_list|)
expr_stmt|;
name|removeDuplicateEntries
argument_list|(
name|idBasedLayoutSingleLinks
argument_list|,
name|duplicates
argument_list|)
expr_stmt|;
block|}
name|int
name|numLinkWorkers
init|=
name|datanode
operator|.
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_BLOCK_ID_LAYOUT_UPGRADE_THREADS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_BLOCK_ID_LAYOUT_UPGRADE_THREADS
argument_list|)
decl_stmt|;
name|ExecutorService
name|linkWorkers
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|numLinkWorkers
argument_list|)
decl_stmt|;
specifier|final
name|int
name|step
init|=
name|idBasedLayoutSingleLinks
operator|.
name|size
argument_list|()
operator|/
name|numLinkWorkers
operator|+
literal|1
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|futures
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|idBasedLayoutSingleLinks
operator|.
name|size
argument_list|()
condition|;
name|i
operator|+=
name|step
control|)
block|{
specifier|final
name|int
name|iCopy
init|=
name|i
decl_stmt|;
name|futures
operator|.
name|add
argument_list|(
name|linkWorkers
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|upperBound
init|=
name|Math
operator|.
name|min
argument_list|(
name|iCopy
operator|+
name|step
argument_list|,
name|idBasedLayoutSingleLinks
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
name|iCopy
init|;
name|j
operator|<
name|upperBound
condition|;
name|j
operator|++
control|)
block|{
name|LinkArgs
name|cur
init|=
name|idBasedLayoutSingleLinks
operator|.
name|get
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|HardLink
operator|.
name|createHardLink
argument_list|(
name|cur
operator|.
name|src
argument_list|,
name|cur
operator|.
name|dst
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|linkWorkers
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|f
range|:
name|futures
control|)
block|{
name|Futures
operator|.
name|get
argument_list|(
name|f
argument_list|,
name|IOException
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Find duplicate entries with an array of LinkArgs.    * Duplicate entries are entries with the same last path component.    */
DECL|method|findDuplicateEntries (ArrayList<LinkArgs> all)
specifier|static
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|findDuplicateEntries
parameter_list|(
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|all
parameter_list|)
block|{
comment|// Find duplicates by sorting the list by the final path component.
name|Collections
operator|.
name|sort
argument_list|(
name|all
argument_list|,
operator|new
name|Comparator
argument_list|<
name|LinkArgs
argument_list|>
argument_list|()
block|{
comment|/**        * Compare two LinkArgs objects, such that objects with the same        * terminal source path components are grouped together.        */
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|LinkArgs
name|a
parameter_list|,
name|LinkArgs
name|b
parameter_list|)
block|{
return|return
name|ComparisonChain
operator|.
name|start
argument_list|()
operator|.
name|compare
argument_list|(
name|a
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|,
name|b
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|compare
argument_list|(
name|a
operator|.
name|src
argument_list|,
name|b
operator|.
name|src
argument_list|)
operator|.
name|compare
argument_list|(
name|a
operator|.
name|dst
argument_list|,
name|b
operator|.
name|dst
argument_list|)
operator|.
name|result
argument_list|()
return|;
block|}
block|}
argument_list|)
expr_stmt|;
specifier|final
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|duplicates
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|Long
name|prevBlockId
init|=
literal|null
decl_stmt|;
name|boolean
name|prevWasMeta
init|=
literal|false
decl_stmt|;
name|boolean
name|addedPrev
init|=
literal|false
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|all
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|LinkArgs
name|args
init|=
name|all
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|args
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|isMeta
init|=
name|Block
operator|.
name|isMetaFilename
argument_list|(
name|args
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|prevBlockId
operator|==
literal|null
operator|)
operator|||
operator|(
name|prevBlockId
operator|.
name|longValue
argument_list|()
operator|!=
name|blockId
operator|)
condition|)
block|{
name|prevBlockId
operator|=
name|blockId
expr_stmt|;
name|addedPrev
operator|=
literal|false
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isMeta
operator|==
name|prevWasMeta
condition|)
block|{
comment|// If we saw another file for the same block ID previously,
comment|// and it had the same meta-ness as this file, we have a
comment|// duplicate.
name|duplicates
operator|.
name|add
argument_list|(
name|args
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|addedPrev
condition|)
block|{
name|duplicates
operator|.
name|add
argument_list|(
name|all
operator|.
name|get
argument_list|(
name|i
operator|-
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|addedPrev
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|addedPrev
operator|=
literal|false
expr_stmt|;
block|}
name|prevWasMeta
operator|=
name|isMeta
expr_stmt|;
block|}
return|return
name|duplicates
return|;
block|}
comment|/**    * Remove duplicate entries from the list.    * We do this by choosing:    * 1. the entries with the highest genstamp (this takes priority),    * 2. the entries with the longest block files,    * 3. arbitrarily, if neither #1 nor #2 gives a clear winner.    *    * Block and metadata files form a pair-- if you take a metadata file from    * one subdirectory, you must also take the block file from that    * subdirectory.    */
DECL|method|removeDuplicateEntries (ArrayList<LinkArgs> all, ArrayList<LinkArgs> duplicates)
specifier|private
specifier|static
name|void
name|removeDuplicateEntries
parameter_list|(
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|all
parameter_list|,
name|ArrayList
argument_list|<
name|LinkArgs
argument_list|>
name|duplicates
parameter_list|)
block|{
comment|// Maps blockId -> metadata file with highest genstamp
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|List
argument_list|<
name|LinkArgs
argument_list|>
argument_list|>
name|highestGenstamps
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|List
argument_list|<
name|LinkArgs
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|LinkArgs
name|duplicate
range|:
name|duplicates
control|)
block|{
if|if
condition|(
operator|!
name|Block
operator|.
name|isMetaFilename
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|LinkArgs
argument_list|>
name|prevHighest
init|=
name|highestGenstamps
operator|.
name|get
argument_list|(
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|prevHighest
operator|==
literal|null
condition|)
block|{
name|List
argument_list|<
name|LinkArgs
argument_list|>
name|highest
init|=
operator|new
name|LinkedList
argument_list|<
name|LinkArgs
argument_list|>
argument_list|()
decl_stmt|;
name|highest
operator|.
name|add
argument_list|(
name|duplicate
argument_list|)
expr_stmt|;
name|highestGenstamps
operator|.
name|put
argument_list|(
name|blockId
argument_list|,
name|highest
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|long
name|prevGenstamp
init|=
name|Block
operator|.
name|getGenerationStamp
argument_list|(
name|prevHighest
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|genstamp
init|=
name|Block
operator|.
name|getGenerationStamp
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|genstamp
operator|<
name|prevGenstamp
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|genstamp
operator|>
name|prevGenstamp
condition|)
block|{
name|prevHighest
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|prevHighest
operator|.
name|add
argument_list|(
name|duplicate
argument_list|)
expr_stmt|;
block|}
comment|// Remove data / metadata entries that don't have the highest genstamp
comment|// from the duplicates list.
for|for
control|(
name|Iterator
argument_list|<
name|LinkArgs
argument_list|>
name|iter
init|=
name|duplicates
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|LinkArgs
name|duplicate
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|LinkArgs
argument_list|>
name|highest
init|=
name|highestGenstamps
operator|.
name|get
argument_list|(
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|highest
operator|!=
literal|null
condition|)
block|{
name|boolean
name|found
init|=
literal|false
decl_stmt|;
for|for
control|(
name|LinkArgs
name|high
range|:
name|highest
control|)
block|{
if|if
condition|(
name|high
operator|.
name|src
operator|.
name|getParent
argument_list|()
operator|.
name|equals
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getParent
argument_list|()
argument_list|)
condition|)
block|{
name|found
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|found
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unexpectedly low genstamp on "
operator|+
name|duplicate
operator|.
name|src
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|"."
argument_list|)
expr_stmt|;
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// Find the longest block files
comment|// We let the "last guy win" here, since we're only interested in
comment|// preserving one block file / metadata file pair.
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|LinkArgs
argument_list|>
name|longestBlockFiles
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|LinkArgs
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|LinkArgs
name|duplicate
range|:
name|duplicates
control|)
block|{
if|if
condition|(
name|Block
operator|.
name|isMetaFilename
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|duplicate
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|LinkArgs
name|prevLongest
init|=
name|longestBlockFiles
operator|.
name|get
argument_list|(
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|prevLongest
operator|==
literal|null
condition|)
block|{
name|longestBlockFiles
operator|.
name|put
argument_list|(
name|blockId
argument_list|,
name|duplicate
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|long
name|blockLength
init|=
name|duplicate
operator|.
name|src
operator|.
name|length
argument_list|()
decl_stmt|;
name|long
name|prevBlockLength
init|=
name|prevLongest
operator|.
name|src
operator|.
name|length
argument_list|()
decl_stmt|;
if|if
condition|(
name|blockLength
operator|<
name|prevBlockLength
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unexpectedly short length on "
operator|+
name|duplicate
operator|.
name|src
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|"."
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|blockLength
operator|>
name|prevBlockLength
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unexpectedly short length on "
operator|+
name|prevLongest
operator|.
name|src
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|"."
argument_list|)
expr_stmt|;
block|}
name|longestBlockFiles
operator|.
name|put
argument_list|(
name|blockId
argument_list|,
name|duplicate
argument_list|)
expr_stmt|;
block|}
comment|// Remove data / metadata entries that aren't the longest, or weren't
comment|// arbitrarily selected by us.
for|for
control|(
name|Iterator
argument_list|<
name|LinkArgs
argument_list|>
name|iter
init|=
name|all
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|LinkArgs
name|args
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|args
operator|.
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|LinkArgs
name|bestDuplicate
init|=
name|longestBlockFiles
operator|.
name|get
argument_list|(
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|bestDuplicate
operator|==
literal|null
condition|)
block|{
continue|continue;
comment|// file has no duplicates
block|}
if|if
condition|(
operator|!
name|bestDuplicate
operator|.
name|src
operator|.
name|getParent
argument_list|()
operator|.
name|equals
argument_list|(
name|args
operator|.
name|src
operator|.
name|getParent
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Discarding "
operator|+
name|args
operator|.
name|src
operator|.
name|getAbsolutePath
argument_list|()
operator|+
literal|"."
argument_list|)
expr_stmt|;
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|linkBlocksHelper (File from, File to, int oldLV, HardLink hl, boolean upgradeToIdBasedLayout, File blockRoot, List<LinkArgs> idBasedLayoutSingleLinks)
specifier|static
name|void
name|linkBlocksHelper
parameter_list|(
name|File
name|from
parameter_list|,
name|File
name|to
parameter_list|,
name|int
name|oldLV
parameter_list|,
name|HardLink
name|hl
parameter_list|,
name|boolean
name|upgradeToIdBasedLayout
parameter_list|,
name|File
name|blockRoot
parameter_list|,
name|List
argument_list|<
name|LinkArgs
argument_list|>
name|idBasedLayoutSingleLinks
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|from
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|from
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|HardLink
operator|.
name|createHardLink
argument_list|(
name|from
argument_list|,
name|to
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countSingleLinks
operator|++
expr_stmt|;
return|return;
block|}
comment|// from is a directory
name|hl
operator|.
name|linkStats
operator|.
name|countDirs
operator|++
expr_stmt|;
name|String
index|[]
name|blockNames
init|=
name|from
operator|.
name|list
argument_list|(
operator|new
name|java
operator|.
name|io
operator|.
name|FilenameFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|File
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
return|return
name|name
operator|.
name|startsWith
argument_list|(
name|Block
operator|.
name|BLOCK_FILE_PREFIX
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
comment|// If we are upgrading to block ID-based layout, we don't want to recreate
comment|// any subdirs from the source that contain blocks, since we have a new
comment|// directory structure
if|if
condition|(
operator|!
name|upgradeToIdBasedLayout
operator|||
operator|!
name|to
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|BLOCK_SUBDIR_PREFIX
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|to
operator|.
name|mkdirs
argument_list|()
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot create directory "
operator|+
name|to
argument_list|)
throw|;
block|}
comment|// Block files just need hard links with the same file names
comment|// but a different directory
if|if
condition|(
name|blockNames
operator|.
name|length
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|upgradeToIdBasedLayout
condition|)
block|{
for|for
control|(
name|String
name|blockName
range|:
name|blockNames
control|)
block|{
name|long
name|blockId
init|=
name|Block
operator|.
name|getBlockId
argument_list|(
name|blockName
argument_list|)
decl_stmt|;
name|File
name|blockLocation
init|=
name|DatanodeUtil
operator|.
name|idToBlockDir
argument_list|(
name|blockRoot
argument_list|,
name|blockId
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|blockLocation
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|blockLocation
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to mkdirs "
operator|+
name|blockLocation
argument_list|)
throw|;
block|}
block|}
name|idBasedLayoutSingleLinks
operator|.
name|add
argument_list|(
operator|new
name|LinkArgs
argument_list|(
operator|new
name|File
argument_list|(
name|from
argument_list|,
name|blockName
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|blockLocation
argument_list|,
name|blockName
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countSingleLinks
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
name|HardLink
operator|.
name|createHardLinkMult
argument_list|(
name|from
argument_list|,
name|blockNames
argument_list|,
name|to
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countMultLinks
operator|++
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countFilesMultLinks
operator|+=
name|blockNames
operator|.
name|length
expr_stmt|;
block|}
block|}
else|else
block|{
name|hl
operator|.
name|linkStats
operator|.
name|countEmptyDirs
operator|++
expr_stmt|;
block|}
comment|// Now take care of the rest of the files and subdirectories
name|String
index|[]
name|otherNames
init|=
name|from
operator|.
name|list
argument_list|(
operator|new
name|java
operator|.
name|io
operator|.
name|FilenameFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|File
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
return|return
name|name
operator|.
name|startsWith
argument_list|(
name|BLOCK_SUBDIR_PREFIX
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|otherNames
operator|.
name|length
condition|;
name|i
operator|++
control|)
name|linkBlocksHelper
argument_list|(
operator|new
name|File
argument_list|(
name|from
argument_list|,
name|otherNames
index|[
name|i
index|]
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|to
argument_list|,
name|otherNames
index|[
name|i
index|]
argument_list|)
argument_list|,
name|oldLV
argument_list|,
name|hl
argument_list|,
name|upgradeToIdBasedLayout
argument_list|,
name|blockRoot
argument_list|,
name|idBasedLayoutSingleLinks
argument_list|)
expr_stmt|;
block|}
comment|/**    * Add bpStorage into bpStorageMap    */
DECL|method|addBlockPoolStorage (String bpID, BlockPoolSliceStorage bpStorage )
specifier|private
name|void
name|addBlockPoolStorage
parameter_list|(
name|String
name|bpID
parameter_list|,
name|BlockPoolSliceStorage
name|bpStorage
parameter_list|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|bpStorageMap
operator|.
name|containsKey
argument_list|(
name|bpID
argument_list|)
condition|)
block|{
name|this
operator|.
name|bpStorageMap
operator|.
name|put
argument_list|(
name|bpID
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|removeBlockPoolStorage (String bpId)
specifier|synchronized
name|void
name|removeBlockPoolStorage
parameter_list|(
name|String
name|bpId
parameter_list|)
block|{
name|bpStorageMap
operator|.
name|remove
argument_list|(
name|bpId
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

