begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.datanode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|RandomAccessFile
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|FileLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|HardLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LayoutVersion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LayoutVersion
operator|.
name|Feature
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|NodeType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|StartupOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|InconsistentFSStateException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|StorageInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeStorage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamespaceInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DiskChecker
import|;
end_import

begin_comment
comment|/**   * Data storage information file.  *<p>  * @see Storage  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DataStorage
specifier|public
class|class
name|DataStorage
extends|extends
name|Storage
block|{
DECL|field|BLOCK_SUBDIR_PREFIX
specifier|public
specifier|final
specifier|static
name|String
name|BLOCK_SUBDIR_PREFIX
init|=
literal|"subdir"
decl_stmt|;
DECL|field|BLOCK_FILE_PREFIX
specifier|final
specifier|static
name|String
name|BLOCK_FILE_PREFIX
init|=
literal|"blk_"
decl_stmt|;
DECL|field|COPY_FILE_PREFIX
specifier|final
specifier|static
name|String
name|COPY_FILE_PREFIX
init|=
literal|"dncp_"
decl_stmt|;
DECL|field|STORAGE_DIR_DETACHED
specifier|final
specifier|static
name|String
name|STORAGE_DIR_DETACHED
init|=
literal|"detach"
decl_stmt|;
DECL|field|STORAGE_DIR_RBW
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_RBW
init|=
literal|"rbw"
decl_stmt|;
DECL|field|STORAGE_DIR_FINALIZED
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_FINALIZED
init|=
literal|"finalized"
decl_stmt|;
DECL|field|STORAGE_DIR_TMP
specifier|public
specifier|final
specifier|static
name|String
name|STORAGE_DIR_TMP
init|=
literal|"tmp"
decl_stmt|;
comment|/**    * Datanode UUID that this storage is currently attached to. This    *  is the same as the legacy StorageID for datanodes that were    *  upgraded from a pre-UUID version. For compatibility with prior    *  versions of Datanodes we cannot make this field a UUID.    */
DECL|field|datanodeUuid
specifier|private
name|String
name|datanodeUuid
init|=
literal|null
decl_stmt|;
comment|// Flag to ensure we only initialize storage once
DECL|field|initialized
specifier|private
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
comment|// Maps block pool IDs to block pool storage
DECL|field|bpStorageMap
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|BlockPoolSliceStorage
argument_list|>
name|bpStorageMap
init|=
name|Collections
operator|.
name|synchronizedMap
argument_list|(
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|BlockPoolSliceStorage
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
DECL|method|DataStorage ()
name|DataStorage
parameter_list|()
block|{
name|super
argument_list|(
name|NodeType
operator|.
name|DATA_NODE
argument_list|)
expr_stmt|;
block|}
DECL|method|getBPStorage (String bpid)
specifier|public
name|StorageInfo
name|getBPStorage
parameter_list|(
name|String
name|bpid
parameter_list|)
block|{
return|return
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpid
argument_list|)
return|;
block|}
DECL|method|DataStorage (StorageInfo storageInfo)
specifier|public
name|DataStorage
parameter_list|(
name|StorageInfo
name|storageInfo
parameter_list|)
block|{
name|super
argument_list|(
name|NodeType
operator|.
name|DATA_NODE
argument_list|,
name|storageInfo
argument_list|)
expr_stmt|;
block|}
DECL|method|getDatanodeUuid ()
specifier|public
specifier|synchronized
name|String
name|getDatanodeUuid
parameter_list|()
block|{
return|return
name|datanodeUuid
return|;
block|}
DECL|method|setDatanodeUuid (String newDatanodeUuid)
specifier|synchronized
name|void
name|setDatanodeUuid
parameter_list|(
name|String
name|newDatanodeUuid
parameter_list|)
block|{
name|this
operator|.
name|datanodeUuid
operator|=
name|newDatanodeUuid
expr_stmt|;
block|}
comment|/** Create an ID for this storage. */
DECL|method|createStorageID (StorageDirectory sd)
specifier|public
specifier|synchronized
name|void
name|createStorageID
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
block|{
if|if
condition|(
name|sd
operator|.
name|getStorageUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|DatanodeStorage
operator|.
name|newStorageID
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Analyze storage directories.    * Recover from previous transitions if required.     * Perform fs state transition if necessary depending on the namespace info.    * Read storage info.    *<br>    * This method should be synchronized between multiple DN threads.  Only the     * first DN thread does DN level storage dir recoverTransitionRead.    *     * @param nsInfo namespace information    * @param dataDirs array of data storage directories    * @param startOpt startup option    * @throws IOException    */
DECL|method|recoverTransitionRead (DataNode datanode, NamespaceInfo nsInfo, Collection<StorageLocation> dataDirs, StartupOption startOpt)
specifier|synchronized
name|void
name|recoverTransitionRead
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|initialized
condition|)
block|{
comment|// DN storage has been initialized, no need to do anything
return|return;
block|}
assert|assert
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|==
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|:
literal|"Data-node version "
operator|+
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|+
literal|" and name-node layout version "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" must be the same."
assert|;
comment|// 1. For each data directory calculate its state and
comment|// check whether all is consistent before transitioning.
comment|// Format and recover.
name|this
operator|.
name|storageDirs
operator|=
operator|new
name|ArrayList
argument_list|<
name|StorageDirectory
argument_list|>
argument_list|(
name|dataDirs
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|ArrayList
argument_list|<
name|StorageState
argument_list|>
name|dataDirStates
init|=
operator|new
name|ArrayList
argument_list|<
name|StorageState
argument_list|>
argument_list|(
name|dataDirs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|StorageLocation
argument_list|>
name|it
init|=
name|dataDirs
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|File
name|dataDir
init|=
name|it
operator|.
name|next
argument_list|()
operator|.
name|getFile
argument_list|()
decl_stmt|;
name|StorageDirectory
name|sd
init|=
operator|new
name|StorageDirectory
argument_list|(
name|dataDir
argument_list|)
decl_stmt|;
name|StorageState
name|curState
decl_stmt|;
try|try
block|{
name|curState
operator|=
name|sd
operator|.
name|analyzeStorage
argument_list|(
name|startOpt
argument_list|,
name|this
argument_list|)
expr_stmt|;
comment|// sd is locked but not opened
switch|switch
condition|(
name|curState
condition|)
block|{
case|case
name|NORMAL
case|:
break|break;
case|case
name|NON_EXISTENT
case|:
comment|// ignore this storage
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" does not exist"
argument_list|)
expr_stmt|;
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
continue|continue;
case|case
name|NOT_FORMATTED
case|:
comment|// format
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|dataDir
operator|+
literal|" is not formatted"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Formatting ..."
argument_list|)
expr_stmt|;
name|format
argument_list|(
name|sd
argument_list|,
name|nsInfo
argument_list|,
name|datanode
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// recovery part is common
name|sd
operator|.
name|doRecover
argument_list|(
name|curState
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|sd
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Ignoring storage directory "
operator|+
name|dataDir
operator|+
literal|" due to an exception"
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|//continue with other good dirs
continue|continue;
block|}
comment|// add to the storage list
name|addStorageDir
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|dataDirStates
operator|.
name|add
argument_list|(
name|curState
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dataDirs
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|||
name|dataDirStates
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
comment|// none of the data dirs exist
throw|throw
operator|new
name|IOException
argument_list|(
literal|"All specified directories are not accessible or do not exist."
argument_list|)
throw|;
comment|// 2. Do transitions
comment|// Each storage directory is treated individually.
comment|// During startup some of them can upgrade or rollback
comment|// while others could be uptodate for the regular startup.
for|for
control|(
name|int
name|idx
init|=
literal|0
init|;
name|idx
operator|<
name|getNumStorageDirs
argument_list|()
condition|;
name|idx
operator|++
control|)
block|{
name|doTransition
argument_list|(
name|datanode
argument_list|,
name|getStorageDir
argument_list|(
name|idx
argument_list|)
argument_list|,
name|nsInfo
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
assert|assert
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|==
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|:
literal|"Data-node and name-node layout versions must be the same."
assert|;
name|createStorageID
argument_list|(
name|getStorageDir
argument_list|(
name|idx
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// 3. Update all storages. Some of them might have just been formatted.
name|this
operator|.
name|writeAll
argument_list|()
expr_stmt|;
comment|// 4. mark DN storage is initilized
name|this
operator|.
name|initialized
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * recoverTransitionRead for a specific block pool    *     * @param datanode DataNode    * @param bpID Block pool Id    * @param nsInfo Namespace info of namenode corresponding to the block pool    * @param dataDirs Storage directories    * @param startOpt startup option    * @throws IOException on error    */
DECL|method|recoverTransitionRead (DataNode datanode, String bpID, NamespaceInfo nsInfo, Collection<StorageLocation> dataDirs, StartupOption startOpt)
name|void
name|recoverTransitionRead
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|String
name|bpID
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|Collection
argument_list|<
name|StorageLocation
argument_list|>
name|dataDirs
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
comment|// First ensure datanode level format/snapshot/rollback is completed
name|recoverTransitionRead
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|dataDirs
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
comment|// Create list of storage directories for the block pool
name|Collection
argument_list|<
name|File
argument_list|>
name|bpDataDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|File
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|StorageLocation
argument_list|>
name|it
init|=
name|dataDirs
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|File
name|dnRoot
init|=
name|it
operator|.
name|next
argument_list|()
operator|.
name|getFile
argument_list|()
decl_stmt|;
name|File
name|bpRoot
init|=
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|bpID
argument_list|,
operator|new
name|File
argument_list|(
name|dnRoot
argument_list|,
name|STORAGE_DIR_CURRENT
argument_list|)
argument_list|)
decl_stmt|;
name|bpDataDirs
operator|.
name|add
argument_list|(
name|bpRoot
argument_list|)
expr_stmt|;
block|}
comment|// mkdir for the list of BlockPoolStorage
name|makeBlockPoolDataDir
argument_list|(
name|bpDataDirs
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
init|=
operator|new
name|BlockPoolSliceStorage
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|bpID
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
decl_stmt|;
name|bpStorage
operator|.
name|recoverTransitionRead
argument_list|(
name|datanode
argument_list|,
name|nsInfo
argument_list|,
name|bpDataDirs
argument_list|,
name|startOpt
argument_list|)
expr_stmt|;
name|addBlockPoolStorage
argument_list|(
name|bpID
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create physical directory for block pools on the data node    *     * @param dataDirs    *          List of data directories    * @param conf    *          Configuration instance to use.    * @throws IOException on errors    */
DECL|method|makeBlockPoolDataDir (Collection<File> dataDirs, Configuration conf)
specifier|static
name|void
name|makeBlockPoolDataDir
parameter_list|(
name|Collection
argument_list|<
name|File
argument_list|>
name|dataDirs
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
name|conf
operator|=
operator|new
name|HdfsConfiguration
argument_list|()
expr_stmt|;
name|LocalFileSystem
name|localFS
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FsPermission
name|permission
init|=
operator|new
name|FsPermission
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DATA_DIR_PERMISSION_DEFAULT
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|data
range|:
name|dataDirs
control|)
block|{
try|try
block|{
name|DiskChecker
operator|.
name|checkDir
argument_list|(
name|localFS
argument_list|,
operator|new
name|Path
argument_list|(
name|data
operator|.
name|toURI
argument_list|()
argument_list|)
argument_list|,
name|permission
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid directory in: "
operator|+
name|data
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|format (StorageDirectory sd, NamespaceInfo nsInfo, String datanodeUuid)
name|void
name|format
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|String
name|datanodeUuid
parameter_list|)
throws|throws
name|IOException
block|{
name|sd
operator|.
name|clearDirectory
argument_list|()
expr_stmt|;
comment|// create directory
name|this
operator|.
name|layoutVersion
operator|=
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
expr_stmt|;
name|this
operator|.
name|clusterID
operator|=
name|nsInfo
operator|.
name|getClusterID
argument_list|()
expr_stmt|;
name|this
operator|.
name|namespaceID
operator|=
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
expr_stmt|;
name|this
operator|.
name|cTime
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|datanodeUuid
operator|=
name|datanodeUuid
expr_stmt|;
if|if
condition|(
name|sd
operator|.
name|getStorageUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// Assign a new Storage UUID.
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
comment|/*    * Set ClusterID, StorageID, StorageType, CTime into    * DataStorage VERSION file.    * Always called just before writing the properties to    * the VERSION file.   */
annotation|@
name|Override
DECL|method|setPropertiesFromFields (Properties props, StorageDirectory sd )
specifier|protected
name|void
name|setPropertiesFromFields
parameter_list|(
name|Properties
name|props
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"storageType"
argument_list|,
name|storageType
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"clusterID"
argument_list|,
name|clusterID
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"cTime"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|cTime
argument_list|)
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"layoutVersion"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|layoutVersion
argument_list|)
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
literal|"storageID"
argument_list|,
name|sd
operator|.
name|getStorageUuid
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|ADD_DATANODE_AND_STORAGE_UUIDS
argument_list|,
name|layoutVersion
argument_list|)
operator|&&
name|datanodeUuid
operator|!=
literal|null
condition|)
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"datanodeUuid"
argument_list|,
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Set NamespaceID in version before federation
if|if
condition|(
operator|!
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
name|props
operator|.
name|setProperty
argument_list|(
literal|"namespaceID"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|namespaceID
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Read ClusterID, StorageID, StorageType, CTime from     * DataStorage VERSION file and verify them.    * Always called just after reading the properties from the VERSION    * file.    */
annotation|@
name|Override
DECL|method|setFieldsFromProperties (Properties props, StorageDirectory sd)
specifier|protected
name|void
name|setFieldsFromProperties
parameter_list|(
name|Properties
name|props
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|setLayoutVersion
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
name|setcTime
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
name|setStorageType
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
name|setClusterId
argument_list|(
name|props
argument_list|,
name|layoutVersion
argument_list|,
name|sd
argument_list|)
expr_stmt|;
comment|// Read NamespaceID in version before federation
if|if
condition|(
operator|!
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
name|setNamespaceID
argument_list|(
name|props
argument_list|,
name|sd
argument_list|)
expr_stmt|;
block|}
comment|// valid storage id, storage id may be empty
name|String
name|ssid
init|=
name|props
operator|.
name|getProperty
argument_list|(
literal|"storageID"
argument_list|)
decl_stmt|;
if|if
condition|(
name|ssid
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"file "
operator|+
name|STORAGE_FILE_VERSION
operator|+
literal|" is invalid."
argument_list|)
throw|;
block|}
name|String
name|sid
init|=
name|sd
operator|.
name|getStorageUuid
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|sid
operator|==
literal|null
operator|||
name|sid
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|||
name|ssid
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
operator|||
name|sid
operator|.
name|equals
argument_list|(
name|ssid
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"has incompatible storage Id."
argument_list|)
throw|;
block|}
if|if
condition|(
name|sid
operator|==
literal|null
condition|)
block|{
comment|// update id only if it was null
name|sd
operator|.
name|setStorageUuid
argument_list|(
name|ssid
argument_list|)
expr_stmt|;
block|}
comment|// Update the datanode UUID if present.
if|if
condition|(
name|props
operator|.
name|getProperty
argument_list|(
literal|"datanodeUuid"
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|String
name|dnUuid
init|=
name|props
operator|.
name|getProperty
argument_list|(
literal|"datanodeUuid"
argument_list|)
decl_stmt|;
if|if
condition|(
name|getDatanodeUuid
argument_list|()
operator|==
literal|null
condition|)
block|{
name|setDatanodeUuid
argument_list|(
name|dnUuid
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|getDatanodeUuid
argument_list|()
operator|.
name|compareTo
argument_list|(
name|dnUuid
argument_list|)
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"Root "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|": DatanodeUuid="
operator|+
name|dnUuid
operator|+
literal|", does not match "
operator|+
name|getDatanodeUuid
argument_list|()
operator|+
literal|" from other"
operator|+
literal|" StorageDirectory."
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|isPreUpgradableLayout (StorageDirectory sd)
specifier|public
name|boolean
name|isPreUpgradableLayout
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|oldF
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"storage"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|oldF
operator|.
name|exists
argument_list|()
condition|)
return|return
literal|false
return|;
comment|// check the layout version inside the storage file
comment|// Lock and Read old storage file
name|RandomAccessFile
name|oldFile
init|=
operator|new
name|RandomAccessFile
argument_list|(
name|oldF
argument_list|,
literal|"rws"
argument_list|)
decl_stmt|;
name|FileLock
name|oldLock
init|=
name|oldFile
operator|.
name|getChannel
argument_list|()
operator|.
name|tryLock
argument_list|()
decl_stmt|;
try|try
block|{
name|oldFile
operator|.
name|seek
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|int
name|oldVersion
init|=
name|oldFile
operator|.
name|readInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|oldVersion
operator|<
name|LAST_PRE_UPGRADE_LAYOUT_VERSION
condition|)
return|return
literal|false
return|;
block|}
finally|finally
block|{
name|oldLock
operator|.
name|release
argument_list|()
expr_stmt|;
name|oldFile
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Analize which and whether a transition of the fs state is required    * and perform it if necessary.    *     * Rollback if previousLV>= LAYOUT_VERSION&& prevCTime<= namenode.cTime    * Upgrade if this.LV> LAYOUT_VERSION || this.cTime< namenode.cTime    * Regular startup if this.LV = LAYOUT_VERSION&& this.cTime = namenode.cTime    *     * @param datanode Datanode to which this storage belongs to    * @param sd  storage directory    * @param nsInfo  namespace info    * @param startOpt  startup option    * @throws IOException    */
DECL|method|doTransition ( DataNode datanode, StorageDirectory sd, NamespaceInfo nsInfo, StartupOption startOpt )
specifier|private
name|void
name|doTransition
parameter_list|(
name|DataNode
name|datanode
parameter_list|,
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|startOpt
operator|==
name|StartupOption
operator|.
name|ROLLBACK
condition|)
block|{
name|doRollback
argument_list|(
name|sd
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
comment|// rollback if applicable
block|}
name|readProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
name|checkVersionUpgradable
argument_list|(
name|this
operator|.
name|layoutVersion
argument_list|)
expr_stmt|;
assert|assert
name|this
operator|.
name|layoutVersion
operator|>=
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|:
literal|"Future version is not allowed"
assert|;
name|boolean
name|federationSupported
init|=
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
decl_stmt|;
comment|// For pre-federation version - validate the namespaceID
if|if
condition|(
operator|!
name|federationSupported
operator|&&
name|getNamespaceID
argument_list|()
operator|!=
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible namespaceIDs in "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": namenode namespaceID = "
operator|+
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
operator|+
literal|"; datanode namespaceID = "
operator|+
name|getNamespaceID
argument_list|()
argument_list|)
throw|;
block|}
comment|// For version that supports federation, validate clusterID
if|if
condition|(
name|federationSupported
operator|&&
operator|!
name|getClusterID
argument_list|()
operator|.
name|equals
argument_list|(
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incompatible clusterIDs in "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|": namenode clusterID = "
operator|+
name|nsInfo
operator|.
name|getClusterID
argument_list|()
operator|+
literal|"; datanode clusterID = "
operator|+
name|getClusterID
argument_list|()
argument_list|)
throw|;
block|}
comment|// regular start up
if|if
condition|(
name|this
operator|.
name|layoutVersion
operator|==
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|&&
name|this
operator|.
name|cTime
operator|==
name|nsInfo
operator|.
name|getCTime
argument_list|()
condition|)
return|return;
comment|// regular startup
comment|// do upgrade
if|if
condition|(
name|this
operator|.
name|layoutVersion
operator|>
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|||
name|this
operator|.
name|cTime
operator|<
name|nsInfo
operator|.
name|getCTime
argument_list|()
condition|)
block|{
name|doUpgrade
argument_list|(
name|sd
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
comment|// upgrade
return|return;
block|}
comment|// layoutVersion == LAYOUT_VERSION&& this.cTime> nsInfo.cTime
comment|// must shutdown
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Datanode state: LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" CTime = "
operator|+
name|this
operator|.
name|getCTime
argument_list|()
operator|+
literal|" is newer than the namespace state: LV = "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
throw|;
block|}
comment|/**    * Upgrade -- Move current storage into a backup directory,    * and hardlink all its blocks into the new current directory.    *     * Upgrade from pre-0.22 to 0.22 or later release e.g. 0.19/0.20/ => 0.22/0.23    *<ul>    *<li> If<SD>/previous exists then delete it</li>    *<li> Rename<SD>/current to<SD>/previous.tmp</li>    *<li>Create new<SD>/current/<bpid>/current directory<li>    *<ul>    *<li> Hard links for block files are created from<SD>/previous.tmp     * to<SD>/current/<bpid>/current</li>    *<li> Saves new version file in<SD>/current/<bpid>/current directory</li>    *</ul>    *<li> Rename<SD>/previous.tmp to<SD>/previous</li>    *</ul>    *     * There should be only ONE namenode in the cluster for first     * time upgrade to 0.22    * @param sd  storage directory    * @throws IOException on error    */
DECL|method|doUpgrade (StorageDirectory sd, NamespaceInfo nsInfo)
name|void
name|doUpgrade
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|FEDERATION
argument_list|,
name|layoutVersion
argument_list|)
condition|)
block|{
name|clusterID
operator|=
name|nsInfo
operator|.
name|getClusterID
argument_list|()
expr_stmt|;
name|layoutVersion
operator|=
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Upgrading storage directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|".\n   old LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; old CTime = "
operator|+
name|this
operator|.
name|getCTime
argument_list|()
operator|+
literal|".\n   new LV = "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; new CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
name|File
name|curDir
init|=
name|sd
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
name|File
name|bbwDir
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|Storage
operator|.
name|STORAGE_1_BBW
argument_list|)
decl_stmt|;
assert|assert
name|curDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Data node current directory must exist."
assert|;
comment|// Cleanup directory "detach"
name|cleanupDetachDir
argument_list|(
operator|new
name|File
argument_list|(
name|curDir
argument_list|,
name|STORAGE_DIR_DETACHED
argument_list|)
argument_list|)
expr_stmt|;
comment|// 1. delete<SD>/previous dir before upgrading
if|if
condition|(
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
name|deleteDir
argument_list|(
name|prevDir
argument_list|)
expr_stmt|;
comment|// get previous.tmp directory,<SD>/previous.tmp
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getPreviousTmp
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|tmpDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Data node previous.tmp directory must not exist."
assert|;
comment|// 2. Rename<SD>/current to<SD>/previous.tmp
name|rename
argument_list|(
name|curDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// 3. Format BP and hard link blocks from previous directory
name|File
name|curBpDir
init|=
name|BlockPoolSliceStorage
operator|.
name|getBpRoot
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|curDir
argument_list|)
decl_stmt|;
name|BlockPoolSliceStorage
name|bpStorage
init|=
operator|new
name|BlockPoolSliceStorage
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|,
name|nsInfo
operator|.
name|getClusterID
argument_list|()
argument_list|)
decl_stmt|;
name|bpStorage
operator|.
name|format
argument_list|(
name|curDir
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
name|linkAllBlocks
argument_list|(
name|tmpDir
argument_list|,
name|bbwDir
argument_list|,
operator|new
name|File
argument_list|(
name|curBpDir
argument_list|,
name|STORAGE_DIR_CURRENT
argument_list|)
argument_list|)
expr_stmt|;
comment|// 4. Write version file under<SD>/current
name|layoutVersion
operator|=
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
expr_stmt|;
name|clusterID
operator|=
name|nsInfo
operator|.
name|getClusterID
argument_list|()
expr_stmt|;
name|writeProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
comment|// 5. Rename<SD>/previous.tmp to<SD>/previous
name|rename
argument_list|(
name|tmpDir
argument_list|,
name|prevDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Upgrade of "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
name|addBlockPoolStorage
argument_list|(
name|nsInfo
operator|.
name|getBlockPoolID
argument_list|()
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cleanup the detachDir.     *     * If the directory is not empty report an error;     * Otherwise remove the directory.    *     * @param detachDir detach directory    * @throws IOException if the directory is not empty or it can not be removed    */
DECL|method|cleanupDetachDir (File detachDir)
specifier|private
name|void
name|cleanupDetachDir
parameter_list|(
name|File
name|detachDir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|APPEND_RBW_DIR
argument_list|,
name|layoutVersion
argument_list|)
operator|&&
name|detachDir
operator|.
name|exists
argument_list|()
operator|&&
name|detachDir
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|FileUtil
operator|.
name|list
argument_list|(
name|detachDir
argument_list|)
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Detached directory "
operator|+
name|detachDir
operator|+
literal|" is not empty. Please manually move each file under this "
operator|+
literal|"directory to the finalized directory if the finalized "
operator|+
literal|"directory tree does not have the file."
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|detachDir
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot remove directory "
operator|+
name|detachDir
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**     * Rolling back to a snapshot in previous directory by moving it to current    * directory.    * Rollback procedure:    *<br>    * If previous directory exists:    *<ol>    *<li> Rename current to removed.tmp</li>    *<li> Rename previous to current</li>    *<li> Remove removed.tmp</li>    *</ol>    *     * Do nothing, if previous directory does not exist.    */
DECL|method|doRollback ( StorageDirectory sd, NamespaceInfo nsInfo )
name|void
name|doRollback
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|,
name|NamespaceInfo
name|nsInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
comment|// regular startup if previous dir does not exist
if|if
condition|(
operator|!
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
return|return;
name|DataStorage
name|prevInfo
init|=
operator|new
name|DataStorage
argument_list|()
decl_stmt|;
name|prevInfo
operator|.
name|readPreviousVersionProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
comment|// We allow rollback to a state, which is either consistent with
comment|// the namespace state or can be further upgraded to it.
if|if
condition|(
operator|!
operator|(
name|prevInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|>=
name|HdfsConstants
operator|.
name|LAYOUT_VERSION
operator|&&
name|prevInfo
operator|.
name|getCTime
argument_list|()
operator|<=
name|nsInfo
operator|.
name|getCTime
argument_list|()
operator|)
condition|)
comment|// cannot rollback
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"Cannot rollback to a newer state.\nDatanode previous state: LV = "
operator|+
name|prevInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" CTime = "
operator|+
name|prevInfo
operator|.
name|getCTime
argument_list|()
operator|+
literal|" is newer than the namespace state: LV = "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|" CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
throw|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolling back storage directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|".\n   target LV = "
operator|+
name|nsInfo
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; target CTime = "
operator|+
name|nsInfo
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getRemovedTmp
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|tmpDir
operator|.
name|exists
argument_list|()
operator|:
literal|"removed.tmp directory must not exist."
assert|;
comment|// rename current to tmp
name|File
name|curDir
init|=
name|sd
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
assert|assert
name|curDir
operator|.
name|exists
argument_list|()
operator|:
literal|"Current directory must exist."
assert|;
name|rename
argument_list|(
name|curDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// rename previous to current
name|rename
argument_list|(
name|prevDir
argument_list|,
name|curDir
argument_list|)
expr_stmt|;
comment|// delete tmp dir
name|deleteDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rollback of "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Finalize procedure deletes an existing snapshot.    *<ol>    *<li>Rename previous to finalized.tmp directory</li>    *<li>Fully delete the finalized.tmp directory</li>    *</ol>    *     * Do nothing, if previous directory does not exist    */
DECL|method|doFinalize (StorageDirectory sd)
name|void
name|doFinalize
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
return|return;
comment|// already discarded
specifier|final
name|String
name|dataDirPath
init|=
name|sd
operator|.
name|getRoot
argument_list|()
operator|.
name|getCanonicalPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Finalizing upgrade for storage directory "
operator|+
name|dataDirPath
operator|+
literal|".\n   cur LV = "
operator|+
name|this
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; cur CTime = "
operator|+
name|this
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
assert|assert
name|sd
operator|.
name|getCurrentDir
argument_list|()
operator|.
name|exists
argument_list|()
operator|:
literal|"Current directory must exist."
assert|;
specifier|final
name|File
name|tmpDir
init|=
name|sd
operator|.
name|getFinalizedTmp
argument_list|()
decl_stmt|;
comment|//finalized.tmp directory
specifier|final
name|File
name|bbwDir
init|=
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|Storage
operator|.
name|STORAGE_1_BBW
argument_list|)
decl_stmt|;
comment|// 1. rename previous to finalized.tmp
name|rename
argument_list|(
name|prevDir
argument_list|,
name|tmpDir
argument_list|)
expr_stmt|;
comment|// 2. delete finalized.tmp dir in a separate thread
comment|// Also delete the blocksBeingWritten from HDFS 1.x and earlier, if
comment|// it exists.
operator|new
name|Daemon
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|deleteDir
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|bbwDir
operator|.
name|exists
argument_list|()
condition|)
block|{
name|deleteDir
argument_list|(
name|bbwDir
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Finalize upgrade for "
operator|+
name|dataDirPath
operator|+
literal|" failed"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Finalize upgrade for "
operator|+
name|dataDirPath
operator|+
literal|" is complete"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"Finalize "
operator|+
name|dataDirPath
return|;
block|}
block|}
argument_list|)
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/*    * Finalize the upgrade for a block pool    */
DECL|method|finalizeUpgrade (String bpID)
name|void
name|finalizeUpgrade
parameter_list|(
name|String
name|bpID
parameter_list|)
throws|throws
name|IOException
block|{
comment|// To handle finalizing a snapshot taken at datanode level while
comment|// upgrading to federation, if datanode level snapshot previous exists,
comment|// then finalize it. Else finalize the corresponding BP.
for|for
control|(
name|StorageDirectory
name|sd
range|:
name|storageDirs
control|)
block|{
name|File
name|prevDir
init|=
name|sd
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|prevDir
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// data node level storage finalize
name|doFinalize
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// block pool storage finalize using specific bpID
name|BlockPoolSliceStorage
name|bpStorage
init|=
name|bpStorageMap
operator|.
name|get
argument_list|(
name|bpID
argument_list|)
decl_stmt|;
name|bpStorage
operator|.
name|doFinalize
argument_list|(
name|sd
operator|.
name|getCurrentDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Hardlink all finalized and RBW blocks in fromDir to toDir    *    * @param fromDir      The directory where the 'from' snapshot is stored    * @param fromBbwDir   In HDFS 1.x, the directory where blocks    *                     that are under construction are stored.    * @param toDir        The current data directory    *    * @throws IOException If error occurs during hardlink    */
DECL|method|linkAllBlocks (File fromDir, File fromBbwDir, File toDir)
specifier|private
name|void
name|linkAllBlocks
parameter_list|(
name|File
name|fromDir
parameter_list|,
name|File
name|fromBbwDir
parameter_list|,
name|File
name|toDir
parameter_list|)
throws|throws
name|IOException
block|{
name|HardLink
name|hardLink
init|=
operator|new
name|HardLink
argument_list|()
decl_stmt|;
comment|// do the link
name|int
name|diskLayoutVersion
init|=
name|this
operator|.
name|getLayoutVersion
argument_list|()
decl_stmt|;
if|if
condition|(
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|APPEND_RBW_DIR
argument_list|,
name|diskLayoutVersion
argument_list|)
condition|)
block|{
comment|// hardlink finalized blocks in tmpDir/finalized
name|linkBlocks
argument_list|(
operator|new
name|File
argument_list|(
name|fromDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
comment|// hardlink rbw blocks in tmpDir/rbw
name|linkBlocks
argument_list|(
operator|new
name|File
argument_list|(
name|fromDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// pre-RBW version
comment|// hardlink finalized blocks in tmpDir
name|linkBlocks
argument_list|(
name|fromDir
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_FINALIZED
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
if|if
condition|(
name|fromBbwDir
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|/*          * We need to put the 'blocksBeingWritten' from HDFS 1.x into the rbw          * directory.  It's a little messy, because the blocksBeingWriten was          * NOT underneath the 'current' directory in those releases.  See          * HDFS-3731 for details.          */
name|linkBlocks
argument_list|(
name|fromBbwDir
argument_list|,
operator|new
name|File
argument_list|(
name|toDir
argument_list|,
name|STORAGE_DIR_RBW
argument_list|)
argument_list|,
name|diskLayoutVersion
argument_list|,
name|hardLink
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
name|hardLink
operator|.
name|linkStats
operator|.
name|report
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|linkBlocks (File from, File to, int oldLV, HardLink hl)
specifier|static
name|void
name|linkBlocks
parameter_list|(
name|File
name|from
parameter_list|,
name|File
name|to
parameter_list|,
name|int
name|oldLV
parameter_list|,
name|HardLink
name|hl
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|from
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|from
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|from
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|COPY_FILE_PREFIX
argument_list|)
condition|)
block|{
name|FileInputStream
name|in
init|=
operator|new
name|FileInputStream
argument_list|(
name|from
argument_list|)
decl_stmt|;
try|try
block|{
name|FileOutputStream
name|out
init|=
operator|new
name|FileOutputStream
argument_list|(
name|to
argument_list|)
decl_stmt|;
try|try
block|{
name|IOUtils
operator|.
name|copyBytes
argument_list|(
name|in
argument_list|,
name|out
argument_list|,
literal|16
operator|*
literal|1024
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countPhysicalFileCopies
operator|++
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|HardLink
operator|.
name|createHardLink
argument_list|(
name|from
argument_list|,
name|to
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countSingleLinks
operator|++
expr_stmt|;
block|}
return|return;
block|}
comment|// from is a directory
name|hl
operator|.
name|linkStats
operator|.
name|countDirs
operator|++
expr_stmt|;
if|if
condition|(
operator|!
name|to
operator|.
name|mkdirs
argument_list|()
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot create directory "
operator|+
name|to
argument_list|)
throw|;
name|String
index|[]
name|blockNames
init|=
name|from
operator|.
name|list
argument_list|(
operator|new
name|java
operator|.
name|io
operator|.
name|FilenameFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|File
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
return|return
name|name
operator|.
name|startsWith
argument_list|(
name|BLOCK_FILE_PREFIX
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
comment|// Block files just need hard links with the same file names
comment|// but a different directory
if|if
condition|(
name|blockNames
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|HardLink
operator|.
name|createHardLinkMult
argument_list|(
name|from
argument_list|,
name|blockNames
argument_list|,
name|to
argument_list|)
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countMultLinks
operator|++
expr_stmt|;
name|hl
operator|.
name|linkStats
operator|.
name|countFilesMultLinks
operator|+=
name|blockNames
operator|.
name|length
expr_stmt|;
block|}
else|else
block|{
name|hl
operator|.
name|linkStats
operator|.
name|countEmptyDirs
operator|++
expr_stmt|;
block|}
comment|// Now take care of the rest of the files and subdirectories
name|String
index|[]
name|otherNames
init|=
name|from
operator|.
name|list
argument_list|(
operator|new
name|java
operator|.
name|io
operator|.
name|FilenameFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|File
name|dir
parameter_list|,
name|String
name|name
parameter_list|)
block|{
return|return
name|name
operator|.
name|startsWith
argument_list|(
name|BLOCK_SUBDIR_PREFIX
argument_list|)
operator|||
name|name
operator|.
name|startsWith
argument_list|(
name|COPY_FILE_PREFIX
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|otherNames
operator|.
name|length
condition|;
name|i
operator|++
control|)
name|linkBlocks
argument_list|(
operator|new
name|File
argument_list|(
name|from
argument_list|,
name|otherNames
index|[
name|i
index|]
argument_list|)
argument_list|,
operator|new
name|File
argument_list|(
name|to
argument_list|,
name|otherNames
index|[
name|i
index|]
argument_list|)
argument_list|,
name|oldLV
argument_list|,
name|hl
argument_list|)
expr_stmt|;
block|}
comment|/**    * Add bpStorage into bpStorageMap    */
DECL|method|addBlockPoolStorage (String bpID, BlockPoolSliceStorage bpStorage )
specifier|private
name|void
name|addBlockPoolStorage
parameter_list|(
name|String
name|bpID
parameter_list|,
name|BlockPoolSliceStorage
name|bpStorage
parameter_list|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|bpStorageMap
operator|.
name|containsKey
argument_list|(
name|bpID
argument_list|)
condition|)
block|{
name|this
operator|.
name|bpStorageMap
operator|.
name|put
argument_list|(
name|bpID
argument_list|,
name|bpStorage
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|removeBlockPoolStorage (String bpId)
specifier|synchronized
name|void
name|removeBlockPoolStorage
parameter_list|(
name|String
name|bpId
parameter_list|)
block|{
name|bpStorageMap
operator|.
name|remove
argument_list|(
name|bpId
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

