begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.qjournal.server
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|server
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|ByteString
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStreamWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Files
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardCopyOption
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|PrivilegedExceptionAction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|Range
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|JournalNotFormattedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|JournalOutOfSyncException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
operator|.
name|GetJournaledEditsResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
operator|.
name|NewEpochResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
operator|.
name|PersistedRecoveryPaxosData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
operator|.
name|PrepareRecoveryResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|QJournalProtocolProtos
operator|.
name|SegmentStateProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|qjournal
operator|.
name|protocol
operator|.
name|RequestInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsServerConstants
operator|.
name|StartupOption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|StorageErrorReporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|StorageInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|EditLogOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|FileJournalManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|FileJournalManager
operator|.
name|EditLogFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|JournalManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|TransferFsImage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamespaceInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|RemoteEditLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|RemoteEditLogManifest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|util
operator|.
name|AtomicFileOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|util
operator|.
name|BestEffortLongFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|util
operator|.
name|PersistentLongFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StopWatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Charsets
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|TextFormat
import|;
end_import

begin_comment
comment|/**  * A JournalNode can manage journals for several clusters at once.  * Each such journal is entirely independent despite being hosted by  * the same JVM.  */
end_comment

begin_class
DECL|class|Journal
specifier|public
class|class
name|Journal
implements|implements
name|Closeable
block|{
DECL|field|LOG
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|Journal
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// Current writing state
DECL|field|curSegment
specifier|private
name|EditLogOutputStream
name|curSegment
decl_stmt|;
DECL|field|curSegmentTxId
specifier|private
name|long
name|curSegmentTxId
init|=
name|HdfsServerConstants
operator|.
name|INVALID_TXID
decl_stmt|;
DECL|field|curSegmentLayoutVersion
specifier|private
name|int
name|curSegmentLayoutVersion
init|=
literal|0
decl_stmt|;
DECL|field|nextTxId
specifier|private
name|long
name|nextTxId
init|=
name|HdfsServerConstants
operator|.
name|INVALID_TXID
decl_stmt|;
DECL|field|highestWrittenTxId
specifier|private
name|long
name|highestWrittenTxId
init|=
literal|0
decl_stmt|;
DECL|field|journalId
specifier|private
specifier|final
name|String
name|journalId
decl_stmt|;
DECL|field|storage
specifier|private
specifier|final
name|JNStorage
name|storage
decl_stmt|;
comment|/**    * When a new writer comes along, it asks each node to promise    * to ignore requests from any previous writer, as identified    * by epoch number. In order to make such a promise, the epoch    * number of that writer is stored persistently on disk.    */
DECL|field|lastPromisedEpoch
specifier|private
name|PersistentLongFile
name|lastPromisedEpoch
decl_stmt|;
comment|/**    * Each IPC that comes from a given client contains a serial number    * which only increases from the client's perspective. Whenever    * we switch epochs, we reset this back to -1. Whenever an IPC    * comes from a client, we ensure that it is strictly higher    * than any previous IPC. This guards against any bugs in the IPC    * layer that would re-order IPCs or cause a stale retry from an old    * request to resurface and confuse things.    */
DECL|field|currentEpochIpcSerial
specifier|private
name|long
name|currentEpochIpcSerial
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * The epoch number of the last writer to actually write a transaction.    * This is used to differentiate log segments after a crash at the very    * beginning of a segment. See the the 'testNewerVersionOfSegmentWins'    * test case.    */
DECL|field|lastWriterEpoch
specifier|private
name|PersistentLongFile
name|lastWriterEpoch
decl_stmt|;
comment|/**    * Lower-bound on the last committed transaction ID. This is not    * depended upon for correctness, but acts as a sanity check    * during the recovery procedures, and as a visibility mark    * for clients reading in-progress logs.    */
DECL|field|committedTxnId
specifier|private
name|BestEffortLongFile
name|committedTxnId
decl_stmt|;
DECL|field|LAST_PROMISED_FILENAME
specifier|public
specifier|static
specifier|final
name|String
name|LAST_PROMISED_FILENAME
init|=
literal|"last-promised-epoch"
decl_stmt|;
DECL|field|LAST_WRITER_EPOCH
specifier|public
specifier|static
specifier|final
name|String
name|LAST_WRITER_EPOCH
init|=
literal|"last-writer-epoch"
decl_stmt|;
DECL|field|COMMITTED_TXID_FILENAME
specifier|private
specifier|static
specifier|final
name|String
name|COMMITTED_TXID_FILENAME
init|=
literal|"committed-txid"
decl_stmt|;
DECL|field|fjm
specifier|private
specifier|final
name|FileJournalManager
name|fjm
decl_stmt|;
DECL|field|cache
specifier|private
specifier|final
name|JournaledEditsCache
name|cache
decl_stmt|;
DECL|field|metrics
specifier|private
specifier|final
name|JournalMetrics
name|metrics
decl_stmt|;
DECL|field|lastJournalTimestamp
specifier|private
name|long
name|lastJournalTimestamp
init|=
literal|0
decl_stmt|;
comment|// This variable tracks, have we tried to start journalsyncer
comment|// with nameServiceId. This will help not to start the journalsyncer
comment|// on each rpc call, if it has failed to start
DECL|field|triedJournalSyncerStartedwithnsId
specifier|private
name|boolean
name|triedJournalSyncerStartedwithnsId
init|=
literal|false
decl_stmt|;
comment|/**    * Time threshold for sync calls, beyond which a warning should be logged to the console.    */
DECL|field|WARN_SYNC_MILLIS_THRESHOLD
specifier|private
specifier|static
specifier|final
name|int
name|WARN_SYNC_MILLIS_THRESHOLD
init|=
literal|1000
decl_stmt|;
DECL|method|Journal (Configuration conf, File logDir, String journalId, StartupOption startOpt, StorageErrorReporter errorReporter)
name|Journal
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|File
name|logDir
parameter_list|,
name|String
name|journalId
parameter_list|,
name|StartupOption
name|startOpt
parameter_list|,
name|StorageErrorReporter
name|errorReporter
parameter_list|)
throws|throws
name|IOException
block|{
name|storage
operator|=
operator|new
name|JNStorage
argument_list|(
name|conf
argument_list|,
name|logDir
argument_list|,
name|startOpt
argument_list|,
name|errorReporter
argument_list|)
expr_stmt|;
name|this
operator|.
name|journalId
operator|=
name|journalId
expr_stmt|;
name|refreshCachedData
argument_list|()
expr_stmt|;
name|this
operator|.
name|fjm
operator|=
name|storage
operator|.
name|getJournalManager
argument_list|()
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_HA_TAILEDITS_INPROGRESS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_HA_TAILEDITS_INPROGRESS_DEFAULT
argument_list|)
condition|)
block|{
name|this
operator|.
name|cache
operator|=
operator|new
name|JournaledEditsCache
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|cache
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|metrics
operator|=
name|JournalMetrics
operator|.
name|create
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|EditLogFile
name|latest
init|=
name|scanStorageForLatestEdits
argument_list|()
decl_stmt|;
if|if
condition|(
name|latest
operator|!=
literal|null
condition|)
block|{
name|updateHighestWrittenTxId
argument_list|(
name|latest
operator|.
name|getLastTxId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|setTriedJournalSyncerStartedwithnsId (boolean started)
specifier|public
name|void
name|setTriedJournalSyncerStartedwithnsId
parameter_list|(
name|boolean
name|started
parameter_list|)
block|{
name|this
operator|.
name|triedJournalSyncerStartedwithnsId
operator|=
name|started
expr_stmt|;
block|}
DECL|method|getTriedJournalSyncerStartedwithnsId ()
specifier|public
name|boolean
name|getTriedJournalSyncerStartedwithnsId
parameter_list|()
block|{
return|return
name|triedJournalSyncerStartedwithnsId
return|;
block|}
comment|/**    * Reload any data that may have been cached. This is necessary    * when we first load the Journal, but also after any formatting    * operation, since the cached data is no longer relevant.    */
DECL|method|refreshCachedData ()
specifier|private
specifier|synchronized
name|void
name|refreshCachedData
parameter_list|()
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|committedTxnId
argument_list|)
expr_stmt|;
name|File
name|currentDir
init|=
name|storage
operator|.
name|getSingularStorageDir
argument_list|()
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
name|this
operator|.
name|lastPromisedEpoch
operator|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|LAST_PROMISED_FILENAME
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastWriterEpoch
operator|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|LAST_WRITER_EPOCH
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|committedTxnId
operator|=
operator|new
name|BestEffortLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|COMMITTED_TXID_FILENAME
argument_list|)
argument_list|,
name|HdfsServerConstants
operator|.
name|INVALID_TXID
argument_list|)
expr_stmt|;
block|}
comment|/**    * Scan the local storage directory, and return the segment containing    * the highest transaction.    * @return the EditLogFile with the highest transactions, or null    * if no files exist.    */
DECL|method|scanStorageForLatestEdits ()
specifier|private
specifier|synchronized
name|EditLogFile
name|scanStorageForLatestEdits
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fjm
operator|.
name|getStorageDirectory
argument_list|()
operator|.
name|getCurrentDir
argument_list|()
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Scanning storage "
operator|+
name|fjm
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|EditLogFile
argument_list|>
name|files
init|=
name|fjm
operator|.
name|getLogFiles
argument_list|(
literal|0
argument_list|)
decl_stmt|;
while|while
condition|(
operator|!
name|files
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|EditLogFile
name|latestLog
init|=
name|files
operator|.
name|remove
argument_list|(
name|files
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|latestLog
operator|.
name|scanLog
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Latest log is "
operator|+
name|latestLog
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
if|if
condition|(
name|latestLog
operator|.
name|getLastTxId
argument_list|()
operator|==
name|HdfsServerConstants
operator|.
name|INVALID_TXID
condition|)
block|{
comment|// the log contains no transactions
name|LOG
operator|.
name|warn
argument_list|(
literal|"Latest log "
operator|+
name|latestLog
operator|+
literal|" has no transactions. "
operator|+
literal|"moving it aside and looking for previous log"
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|latestLog
operator|.
name|moveAsideEmptyFile
argument_list|()
expr_stmt|;
block|}
else|else
block|{
return|return
name|latestLog
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"No files in "
operator|+
name|fjm
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|/**    * Format the local storage with the given namespace.    */
DECL|method|format (NamespaceInfo nsInfo, boolean force)
name|void
name|format
parameter_list|(
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkState
argument_list|(
name|nsInfo
operator|.
name|getNamespaceID
argument_list|()
operator|!=
literal|0
argument_list|,
literal|"can't format with uninitialized namespace info: %s"
argument_list|,
name|nsInfo
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Formatting journal id : "
operator|+
name|journalId
operator|+
literal|" with namespace info: "
operator|+
name|nsInfo
operator|+
literal|" and force: "
operator|+
name|force
argument_list|)
expr_stmt|;
name|storage
operator|.
name|format
argument_list|(
name|nsInfo
argument_list|,
name|force
argument_list|)
expr_stmt|;
name|refreshCachedData
argument_list|()
expr_stmt|;
block|}
comment|/**    * Unlock and release resources.    */
annotation|@
name|Override
comment|// Closeable
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|storage
operator|.
name|close
argument_list|()
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|committedTxnId
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|curSegment
argument_list|)
expr_stmt|;
block|}
DECL|method|getStorage ()
name|JNStorage
name|getStorage
parameter_list|()
block|{
return|return
name|storage
return|;
block|}
DECL|method|getJournalId ()
name|String
name|getJournalId
parameter_list|()
block|{
return|return
name|journalId
return|;
block|}
comment|/**    * @return the last epoch which this node has promised not to accept    * any lower epoch, or 0 if no promises have been made.    */
DECL|method|getLastPromisedEpoch ()
specifier|synchronized
name|long
name|getLastPromisedEpoch
parameter_list|()
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
return|return
name|lastPromisedEpoch
operator|.
name|get
argument_list|()
return|;
block|}
DECL|method|getLastWriterEpoch ()
specifier|synchronized
specifier|public
name|long
name|getLastWriterEpoch
parameter_list|()
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
return|return
name|lastWriterEpoch
operator|.
name|get
argument_list|()
return|;
block|}
DECL|method|getCommittedTxnId ()
specifier|synchronized
name|long
name|getCommittedTxnId
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|committedTxnId
operator|.
name|get
argument_list|()
return|;
block|}
DECL|method|getLastJournalTimestamp ()
specifier|synchronized
name|long
name|getLastJournalTimestamp
parameter_list|()
block|{
return|return
name|lastJournalTimestamp
return|;
block|}
DECL|method|getCurrentLagTxns ()
specifier|synchronized
name|long
name|getCurrentLagTxns
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|committed
init|=
name|committedTxnId
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|committed
operator|==
literal|0
condition|)
block|{
return|return
literal|0
return|;
block|}
return|return
name|Math
operator|.
name|max
argument_list|(
name|committed
operator|-
name|highestWrittenTxId
argument_list|,
literal|0L
argument_list|)
return|;
block|}
DECL|method|getHighestWrittenTxId ()
specifier|synchronized
name|long
name|getHighestWrittenTxId
parameter_list|()
block|{
return|return
name|highestWrittenTxId
return|;
block|}
comment|/**    * Update the highest Tx ID that has been written to the journal. Also update    * the {@link FileJournalManager#lastReadableTxId} of the underlying fjm.    * @param val The new value    */
DECL|method|updateHighestWrittenTxId (long val)
specifier|private
name|void
name|updateHighestWrittenTxId
parameter_list|(
name|long
name|val
parameter_list|)
block|{
name|highestWrittenTxId
operator|=
name|val
expr_stmt|;
name|fjm
operator|.
name|setLastReadableTxId
argument_list|(
name|val
argument_list|)
expr_stmt|;
block|}
DECL|method|getMetrics ()
name|JournalMetrics
name|getMetrics
parameter_list|()
block|{
return|return
name|metrics
return|;
block|}
comment|/**    * Try to create a new epoch for this journal.    * @param nsInfo the namespace, which is verified for consistency or used to    * format, if the Journal has not yet been written to.    * @param epoch the epoch to start    * @return the status information necessary to begin recovery    * @throws IOException if the node has already made a promise to another    * writer with a higher epoch number, if the namespace is inconsistent,    * or if a disk error occurs.    */
DECL|method|newEpoch ( NamespaceInfo nsInfo, long epoch)
specifier|synchronized
name|NewEpochResponseProto
name|newEpoch
parameter_list|(
name|NamespaceInfo
name|nsInfo
parameter_list|,
name|long
name|epoch
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|storage
operator|.
name|checkConsistentNamespace
argument_list|(
name|nsInfo
argument_list|)
expr_stmt|;
comment|// Check that the new epoch being proposed is in fact newer than
comment|// any other that we've promised.
if|if
condition|(
name|epoch
operator|<=
name|getLastPromisedEpoch
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Proposed epoch "
operator|+
name|epoch
operator|+
literal|"<= last promise "
operator|+
name|getLastPromisedEpoch
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
name|updateLastPromisedEpoch
argument_list|(
name|epoch
argument_list|)
expr_stmt|;
name|abortCurSegment
argument_list|()
expr_stmt|;
name|NewEpochResponseProto
operator|.
name|Builder
name|builder
init|=
name|NewEpochResponseProto
operator|.
name|newBuilder
argument_list|()
decl_stmt|;
name|EditLogFile
name|latestFile
init|=
name|scanStorageForLatestEdits
argument_list|()
decl_stmt|;
if|if
condition|(
name|latestFile
operator|!=
literal|null
condition|)
block|{
name|builder
operator|.
name|setLastSegmentTxId
argument_list|(
name|latestFile
operator|.
name|getFirstTxId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|builder
operator|.
name|build
argument_list|()
return|;
block|}
DECL|method|updateLastPromisedEpoch (long newEpoch)
specifier|private
name|void
name|updateLastPromisedEpoch
parameter_list|(
name|long
name|newEpoch
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating lastPromisedEpoch from "
operator|+
name|lastPromisedEpoch
operator|.
name|get
argument_list|()
operator|+
literal|" to "
operator|+
name|newEpoch
operator|+
literal|" for client "
operator|+
name|Server
operator|.
name|getRemoteIp
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|lastPromisedEpoch
operator|.
name|set
argument_list|(
name|newEpoch
argument_list|)
expr_stmt|;
comment|// Since we have a new writer, reset the IPC serial - it will start
comment|// counting again from 0 for this writer.
name|currentEpochIpcSerial
operator|=
operator|-
literal|1
expr_stmt|;
block|}
DECL|method|abortCurSegment ()
specifier|private
name|void
name|abortCurSegment
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|curSegment
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|curSegment
operator|.
name|abort
argument_list|()
expr_stmt|;
name|curSegment
operator|=
literal|null
expr_stmt|;
name|curSegmentTxId
operator|=
name|HdfsServerConstants
operator|.
name|INVALID_TXID
expr_stmt|;
name|curSegmentLayoutVersion
operator|=
literal|0
expr_stmt|;
block|}
comment|/**    * Write a batch of edits to the journal.    * {@see QJournalProtocol#journal(RequestInfo, long, long, int, byte[])}    */
DECL|method|journal (RequestInfo reqInfo, long segmentTxId, long firstTxnId, int numTxns, byte[] records)
specifier|synchronized
name|void
name|journal
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|long
name|segmentTxId
parameter_list|,
name|long
name|firstTxnId
parameter_list|,
name|int
name|numTxns
parameter_list|,
name|byte
index|[]
name|records
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkWriteRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
comment|// If numTxns is 0, it's actually a fake send which aims at updating
comment|// committedTxId only. So we can return early.
if|if
condition|(
name|numTxns
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|checkSync
argument_list|(
name|curSegment
operator|!=
literal|null
argument_list|,
literal|"Can't write, no segment open"
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
if|if
condition|(
name|curSegmentTxId
operator|!=
name|segmentTxId
condition|)
block|{
comment|// Sanity check: it is possible that the writer will fail IPCs
comment|// on both the finalize() and then the start() of the next segment.
comment|// This could cause us to continue writing to an old segment
comment|// instead of rolling to a new one, which breaks one of the
comment|// invariants in the design. If it happens, abort the segment
comment|// and throw an exception.
name|JournalOutOfSyncException
name|e
init|=
operator|new
name|JournalOutOfSyncException
argument_list|(
literal|"Writer out of sync: it thinks it is writing segment "
operator|+
name|segmentTxId
operator|+
literal|" but current segment is "
operator|+
name|curSegmentTxId
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
decl_stmt|;
name|abortCurSegment
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|checkSync
argument_list|(
name|nextTxId
operator|==
name|firstTxnId
argument_list|,
literal|"Can't write txid "
operator|+
name|firstTxnId
operator|+
literal|" expecting nextTxId="
operator|+
name|nextTxId
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|long
name|lastTxnId
init|=
name|firstTxnId
operator|+
name|numTxns
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Writing txid "
operator|+
name|firstTxnId
operator|+
literal|"-"
operator|+
name|lastTxnId
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cache
operator|!=
literal|null
condition|)
block|{
name|cache
operator|.
name|storeEdits
argument_list|(
name|records
argument_list|,
name|firstTxnId
argument_list|,
name|lastTxnId
argument_list|,
name|curSegmentLayoutVersion
argument_list|)
expr_stmt|;
block|}
comment|// If the edit has already been marked as committed, we know
comment|// it has been fsynced on a quorum of other nodes, and we are
comment|// "catching up" with the rest. Hence we do not need to fsync.
name|boolean
name|isLagging
init|=
name|lastTxnId
operator|<=
name|committedTxnId
operator|.
name|get
argument_list|()
decl_stmt|;
name|boolean
name|shouldFsync
init|=
operator|!
name|isLagging
decl_stmt|;
name|curSegment
operator|.
name|writeRaw
argument_list|(
name|records
argument_list|,
literal|0
argument_list|,
name|records
operator|.
name|length
argument_list|)
expr_stmt|;
name|curSegment
operator|.
name|setReadyToFlush
argument_list|()
expr_stmt|;
name|StopWatch
name|sw
init|=
operator|new
name|StopWatch
argument_list|()
decl_stmt|;
name|sw
operator|.
name|start
argument_list|()
expr_stmt|;
name|curSegment
operator|.
name|flush
argument_list|(
name|shouldFsync
argument_list|)
expr_stmt|;
name|sw
operator|.
name|stop
argument_list|()
expr_stmt|;
name|long
name|nanoSeconds
init|=
name|sw
operator|.
name|now
argument_list|()
decl_stmt|;
name|metrics
operator|.
name|addSync
argument_list|(
name|TimeUnit
operator|.
name|MICROSECONDS
operator|.
name|convert
argument_list|(
name|nanoSeconds
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|milliSeconds
init|=
name|TimeUnit
operator|.
name|MILLISECONDS
operator|.
name|convert
argument_list|(
name|nanoSeconds
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|milliSeconds
operator|>
name|WARN_SYNC_MILLIS_THRESHOLD
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Sync of transaction range "
operator|+
name|firstTxnId
operator|+
literal|"-"
operator|+
name|lastTxnId
operator|+
literal|" took "
operator|+
name|milliSeconds
operator|+
literal|"ms"
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isLagging
condition|)
block|{
comment|// This batch of edits has already been committed on a quorum of other
comment|// nodes. So, we are in "catch up" mode. This gets its own metric.
name|metrics
operator|.
name|batchesWrittenWhileLagging
operator|.
name|incr
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
name|metrics
operator|.
name|batchesWritten
operator|.
name|incr
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|bytesWritten
operator|.
name|incr
argument_list|(
name|records
operator|.
name|length
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|txnsWritten
operator|.
name|incr
argument_list|(
name|numTxns
argument_list|)
expr_stmt|;
name|updateHighestWrittenTxId
argument_list|(
name|lastTxnId
argument_list|)
expr_stmt|;
name|nextTxId
operator|=
name|lastTxnId
operator|+
literal|1
expr_stmt|;
name|lastJournalTimestamp
operator|=
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
block|}
DECL|method|heartbeat (RequestInfo reqInfo)
specifier|public
name|void
name|heartbeat
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
block|}
comment|/**    * Ensure that the given request is coming from the correct writer and in-order.    * @param reqInfo the request info    * @throws IOException if the request is invalid.    */
DECL|method|checkRequest (RequestInfo reqInfo)
specifier|private
specifier|synchronized
name|void
name|checkRequest
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Invariant 25 from ZAB paper
if|if
condition|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|<
name|lastPromisedEpoch
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"IPC's epoch "
operator|+
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|+
literal|" is less than the last promised epoch "
operator|+
name|lastPromisedEpoch
operator|.
name|get
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|>
name|lastPromisedEpoch
operator|.
name|get
argument_list|()
condition|)
block|{
comment|// A newer client has arrived. Fence any previous writers by updating
comment|// the promise.
name|updateLastPromisedEpoch
argument_list|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Ensure that the IPCs are arriving in-order as expected.
name|checkSync
argument_list|(
name|reqInfo
operator|.
name|getIpcSerialNumber
argument_list|()
operator|>
name|currentEpochIpcSerial
argument_list|,
literal|"IPC serial %s from client %s was not higher than prior highest "
operator|+
literal|"IPC serial %s ; journal id: %s"
argument_list|,
name|reqInfo
operator|.
name|getIpcSerialNumber
argument_list|()
argument_list|,
name|Server
operator|.
name|getRemoteIp
argument_list|()
argument_list|,
name|currentEpochIpcSerial
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
name|currentEpochIpcSerial
operator|=
name|reqInfo
operator|.
name|getIpcSerialNumber
argument_list|()
expr_stmt|;
if|if
condition|(
name|reqInfo
operator|.
name|hasCommittedTxId
argument_list|()
condition|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|reqInfo
operator|.
name|getCommittedTxId
argument_list|()
operator|>=
name|committedTxnId
operator|.
name|get
argument_list|()
argument_list|,
literal|"Client trying to move committed txid backward from "
operator|+
name|committedTxnId
operator|.
name|get
argument_list|()
operator|+
literal|" to "
operator|+
name|reqInfo
operator|.
name|getCommittedTxId
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|committedTxnId
operator|.
name|set
argument_list|(
name|reqInfo
operator|.
name|getCommittedTxId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|checkWriteRequest (RequestInfo reqInfo)
specifier|private
specifier|synchronized
name|void
name|checkWriteRequest
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
if|if
condition|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|!=
name|lastWriterEpoch
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"IPC's epoch "
operator|+
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|+
literal|" is not the current writer epoch  "
operator|+
name|lastWriterEpoch
operator|.
name|get
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
block|}
DECL|method|isFormatted ()
specifier|public
specifier|synchronized
name|boolean
name|isFormatted
parameter_list|()
block|{
return|return
name|storage
operator|.
name|isFormatted
argument_list|()
return|;
block|}
DECL|method|checkFormatted ()
specifier|private
name|void
name|checkFormatted
parameter_list|()
throws|throws
name|JournalNotFormattedException
block|{
if|if
condition|(
operator|!
name|isFormatted
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|JournalNotFormattedException
argument_list|(
literal|"Journal "
operator|+
name|storage
operator|.
name|getSingularStorageDir
argument_list|()
operator|+
literal|" not formatted"
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
block|}
comment|/**    * @throws JournalOutOfSyncException if the given expression is not true.    * The message of the exception is formatted using the 'msg' and    * 'formatArgs' parameters.    */
DECL|method|checkSync (boolean expression, String msg, Object... formatArgs)
specifier|private
name|void
name|checkSync
parameter_list|(
name|boolean
name|expression
parameter_list|,
name|String
name|msg
parameter_list|,
name|Object
modifier|...
name|formatArgs
parameter_list|)
throws|throws
name|JournalOutOfSyncException
block|{
if|if
condition|(
operator|!
name|expression
condition|)
block|{
throw|throw
operator|new
name|JournalOutOfSyncException
argument_list|(
name|String
operator|.
name|format
argument_list|(
name|msg
argument_list|,
name|formatArgs
argument_list|)
argument_list|)
throw|;
block|}
block|}
comment|/**    * @throws AssertionError if the given expression is not true.    * The message of the exception is formatted using the 'msg' and    * 'formatArgs' parameters.    *     * This should be used in preference to Java's built-in assert in    * non-performance-critical paths, where a failure of this invariant    * might cause the protocol to lose data.     */
DECL|method|alwaysAssert (boolean expression, String msg, Object... formatArgs)
specifier|private
name|void
name|alwaysAssert
parameter_list|(
name|boolean
name|expression
parameter_list|,
name|String
name|msg
parameter_list|,
name|Object
modifier|...
name|formatArgs
parameter_list|)
block|{
if|if
condition|(
operator|!
name|expression
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
name|String
operator|.
name|format
argument_list|(
name|msg
argument_list|,
name|formatArgs
argument_list|)
argument_list|)
throw|;
block|}
block|}
comment|/**    * Start a new segment at the given txid. The previous segment    * must have already been finalized.    */
DECL|method|startLogSegment (RequestInfo reqInfo, long txid, int layoutVersion)
specifier|public
specifier|synchronized
name|void
name|startLogSegment
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|long
name|txid
parameter_list|,
name|int
name|layoutVersion
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|fjm
operator|!=
literal|null
assert|;
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
if|if
condition|(
name|curSegment
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Client is requesting a new log segment "
operator|+
name|txid
operator|+
literal|" though we are already writing "
operator|+
name|curSegment
operator|+
literal|". "
operator|+
literal|"Aborting the current segment in order to begin the new one."
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
comment|// The writer may have lost a connection to us and is now
comment|// re-connecting after the connection came back.
comment|// We should abort our own old segment.
name|abortCurSegment
argument_list|()
expr_stmt|;
block|}
comment|// Paranoid sanity check: we should never overwrite a finalized log file.
comment|// Additionally, if it's in-progress, it should have at most 1 transaction.
comment|// This can happen if the writer crashes exactly at the start of a segment.
name|EditLogFile
name|existing
init|=
name|fjm
operator|.
name|getLogFile
argument_list|(
name|txid
argument_list|)
decl_stmt|;
if|if
condition|(
name|existing
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|existing
operator|.
name|isInProgress
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Already have a finalized segment "
operator|+
name|existing
operator|+
literal|" beginning at "
operator|+
name|txid
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
comment|// If it's in-progress, it should only contain one transaction,
comment|// because the "startLogSegment" transaction is written alone at the
comment|// start of each segment.
name|existing
operator|.
name|scanLog
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|existing
operator|.
name|getLastTxId
argument_list|()
operator|!=
name|existing
operator|.
name|getFirstTxId
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"The log file "
operator|+
name|existing
operator|+
literal|" seems to contain valid transactions"
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
block|}
name|long
name|curLastWriterEpoch
init|=
name|lastWriterEpoch
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|curLastWriterEpoch
operator|!=
name|reqInfo
operator|.
name|getEpoch
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Updating lastWriterEpoch from "
operator|+
name|curLastWriterEpoch
operator|+
literal|" to "
operator|+
name|reqInfo
operator|.
name|getEpoch
argument_list|()
operator|+
literal|" for client "
operator|+
name|Server
operator|.
name|getRemoteIp
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|lastWriterEpoch
operator|.
name|set
argument_list|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// The fact that we are starting a segment at this txid indicates
comment|// that any previous recovery for this same segment was aborted.
comment|// Otherwise, no writer would have started writing. So, we can
comment|// remove the record of the older segment here.
name|purgePaxosDecision
argument_list|(
name|txid
argument_list|)
expr_stmt|;
name|curSegment
operator|=
name|fjm
operator|.
name|startLogSegment
argument_list|(
name|txid
argument_list|,
name|layoutVersion
argument_list|)
expr_stmt|;
name|curSegmentTxId
operator|=
name|txid
expr_stmt|;
name|curSegmentLayoutVersion
operator|=
name|layoutVersion
expr_stmt|;
name|nextTxId
operator|=
name|txid
expr_stmt|;
block|}
comment|/**    * Finalize the log segment at the given transaction ID.    */
DECL|method|finalizeLogSegment (RequestInfo reqInfo, long startTxId, long endTxId)
specifier|public
specifier|synchronized
name|void
name|finalizeLogSegment
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|long
name|startTxId
parameter_list|,
name|long
name|endTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
name|boolean
name|needsValidation
init|=
literal|true
decl_stmt|;
comment|// Finalizing the log that the writer was just writing.
if|if
condition|(
name|startTxId
operator|==
name|curSegmentTxId
condition|)
block|{
if|if
condition|(
name|curSegment
operator|!=
literal|null
condition|)
block|{
name|curSegment
operator|.
name|close
argument_list|()
expr_stmt|;
name|curSegment
operator|=
literal|null
expr_stmt|;
name|curSegmentTxId
operator|=
name|HdfsServerConstants
operator|.
name|INVALID_TXID
expr_stmt|;
name|curSegmentLayoutVersion
operator|=
literal|0
expr_stmt|;
block|}
name|checkSync
argument_list|(
name|nextTxId
operator|==
name|endTxId
operator|+
literal|1
argument_list|,
literal|"Trying to finalize in-progress log segment %s to end at "
operator|+
literal|"txid %s but only written up to txid %s ; journal id: %s"
argument_list|,
name|startTxId
argument_list|,
name|endTxId
argument_list|,
name|nextTxId
operator|-
literal|1
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
comment|// No need to validate the edit log if the client is finalizing
comment|// the log segment that it was just writing to.
name|needsValidation
operator|=
literal|false
expr_stmt|;
block|}
name|FileJournalManager
operator|.
name|EditLogFile
name|elf
init|=
name|fjm
operator|.
name|getLogFile
argument_list|(
name|startTxId
argument_list|)
decl_stmt|;
if|if
condition|(
name|elf
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|JournalOutOfSyncException
argument_list|(
literal|"No log file to finalize at "
operator|+
literal|"transaction ID "
operator|+
name|startTxId
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
if|if
condition|(
name|elf
operator|.
name|isInProgress
argument_list|()
condition|)
block|{
if|if
condition|(
name|needsValidation
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Validating log segment "
operator|+
name|elf
operator|.
name|getFile
argument_list|()
operator|+
literal|" about to be "
operator|+
literal|"finalized ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|elf
operator|.
name|scanLog
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|checkSync
argument_list|(
name|elf
operator|.
name|getLastTxId
argument_list|()
operator|==
name|endTxId
argument_list|,
literal|"Trying to finalize in-progress log segment %s to end at "
operator|+
literal|"txid %s but log %s on disk only contains up to txid %s "
operator|+
literal|"; journal id: %s"
argument_list|,
name|startTxId
argument_list|,
name|endTxId
argument_list|,
name|elf
operator|.
name|getFile
argument_list|()
argument_list|,
name|elf
operator|.
name|getLastTxId
argument_list|()
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
block|}
name|fjm
operator|.
name|finalizeLogSegment
argument_list|(
name|startTxId
argument_list|,
name|endTxId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|endTxId
operator|==
name|elf
operator|.
name|getLastTxId
argument_list|()
argument_list|,
literal|"Trying to re-finalize already finalized log "
operator|+
name|elf
operator|+
literal|" with different endTxId "
operator|+
name|endTxId
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
comment|// Once logs are finalized, a different length will never be decided.
comment|// During recovery, we treat a finalized segment the same as an accepted
comment|// recovery. Thus, we no longer need to keep track of the previously-
comment|// accepted decision. The existence of the finalized log segment is enough.
name|purgePaxosDecision
argument_list|(
name|elf
operator|.
name|getFirstTxId
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * @see JournalManager#purgeLogsOlderThan(long)    */
DECL|method|purgeLogsOlderThan (RequestInfo reqInfo, long minTxIdToKeep)
specifier|public
specifier|synchronized
name|void
name|purgeLogsOlderThan
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|long
name|minTxIdToKeep
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
name|storage
operator|.
name|purgeDataOlderThan
argument_list|(
name|minTxIdToKeep
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove the previously-recorded 'accepted recovery' information    * for a given log segment, once it is no longer necessary.     * @param segmentTxId the transaction ID to purge    * @throws IOException if the file could not be deleted    */
DECL|method|purgePaxosDecision (long segmentTxId)
specifier|private
name|void
name|purgePaxosDecision
parameter_list|(
name|long
name|segmentTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|paxosFile
init|=
name|storage
operator|.
name|getPaxosFile
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
if|if
condition|(
name|paxosFile
operator|.
name|exists
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|paxosFile
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to delete paxos file "
operator|+
name|paxosFile
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * @see QJournalProtocol#getEditLogManifest(String, String, long, boolean)    */
DECL|method|getEditLogManifest (long sinceTxId, boolean inProgressOk)
specifier|public
name|RemoteEditLogManifest
name|getEditLogManifest
parameter_list|(
name|long
name|sinceTxId
parameter_list|,
name|boolean
name|inProgressOk
parameter_list|)
throws|throws
name|IOException
block|{
comment|// No need to checkRequest() here - anyone may ask for the list
comment|// of segments.
name|checkFormatted
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|RemoteEditLog
argument_list|>
name|logs
init|=
name|fjm
operator|.
name|getRemoteEditLogs
argument_list|(
name|sinceTxId
argument_list|,
name|inProgressOk
argument_list|)
decl_stmt|;
if|if
condition|(
name|inProgressOk
condition|)
block|{
name|RemoteEditLog
name|log
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|RemoteEditLog
argument_list|>
name|iter
init|=
name|logs
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|log
operator|=
name|iter
operator|.
name|next
argument_list|()
expr_stmt|;
if|if
condition|(
name|log
operator|.
name|isInProgress
argument_list|()
condition|)
block|{
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|log
operator|!=
literal|null
operator|&&
name|log
operator|.
name|isInProgress
argument_list|()
condition|)
block|{
name|logs
operator|.
name|add
argument_list|(
operator|new
name|RemoteEditLog
argument_list|(
name|log
operator|.
name|getStartTxId
argument_list|()
argument_list|,
name|getHighestWrittenTxId
argument_list|()
argument_list|,
literal|true
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|RemoteEditLogManifest
argument_list|(
name|logs
argument_list|,
name|getCommittedTxnId
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @see QJournalProtocol#getJournaledEdits(String, String, long, int)    */
DECL|method|getJournaledEdits (long sinceTxId, int maxTxns)
specifier|public
name|GetJournaledEditsResponseProto
name|getJournaledEdits
parameter_list|(
name|long
name|sinceTxId
parameter_list|,
name|int
name|maxTxns
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|cache
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The journal edits cache is not enabled, which "
operator|+
literal|"is a requirement to fetch journaled edits via RPC. Please enable "
operator|+
literal|"it via "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_HA_TAILEDITS_INPROGRESS_KEY
argument_list|)
throw|;
block|}
if|if
condition|(
name|sinceTxId
operator|>
name|getHighestWrittenTxId
argument_list|()
condition|)
block|{
comment|// Requested edits that don't exist yet; short-circuit the cache here
name|metrics
operator|.
name|rpcEmptyResponses
operator|.
name|incr
argument_list|()
expr_stmt|;
return|return
name|GetJournaledEditsResponseProto
operator|.
name|newBuilder
argument_list|()
operator|.
name|setTxnCount
argument_list|(
literal|0
argument_list|)
operator|.
name|build
argument_list|()
return|;
block|}
try|try
block|{
name|List
argument_list|<
name|ByteBuffer
argument_list|>
name|buffers
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|int
name|txnCount
init|=
name|cache
operator|.
name|retrieveEdits
argument_list|(
name|sinceTxId
argument_list|,
name|maxTxns
argument_list|,
name|buffers
argument_list|)
decl_stmt|;
name|int
name|totalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ByteBuffer
name|buf
range|:
name|buffers
control|)
block|{
name|totalSize
operator|+=
name|buf
operator|.
name|remaining
argument_list|()
expr_stmt|;
block|}
name|metrics
operator|.
name|txnsServedViaRpc
operator|.
name|incr
argument_list|(
name|txnCount
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|bytesServedViaRpc
operator|.
name|incr
argument_list|(
name|totalSize
argument_list|)
expr_stmt|;
name|ByteString
operator|.
name|Output
name|output
init|=
name|ByteString
operator|.
name|newOutput
argument_list|(
name|totalSize
argument_list|)
decl_stmt|;
for|for
control|(
name|ByteBuffer
name|buf
range|:
name|buffers
control|)
block|{
name|output
operator|.
name|write
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|position
argument_list|()
argument_list|,
name|buf
operator|.
name|remaining
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|GetJournaledEditsResponseProto
operator|.
name|newBuilder
argument_list|()
operator|.
name|setTxnCount
argument_list|(
name|txnCount
argument_list|)
operator|.
name|setEditLog
argument_list|(
name|output
operator|.
name|toByteString
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|JournaledEditsCache
operator|.
name|CacheMissException
name|cme
parameter_list|)
block|{
name|metrics
operator|.
name|rpcRequestCacheMissAmount
operator|.
name|add
argument_list|(
name|cme
operator|.
name|getCacheMissAmount
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|cme
throw|;
block|}
block|}
comment|/**    * @return the current state of the given segment, or null if the    * segment does not exist.    */
annotation|@
name|VisibleForTesting
DECL|method|getSegmentInfo (long segmentTxId)
name|SegmentStateProto
name|getSegmentInfo
parameter_list|(
name|long
name|segmentTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|EditLogFile
name|elf
init|=
name|fjm
operator|.
name|getLogFile
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
if|if
condition|(
name|elf
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|elf
operator|.
name|isInProgress
argument_list|()
condition|)
block|{
name|elf
operator|.
name|scanLog
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|elf
operator|.
name|getLastTxId
argument_list|()
operator|==
name|HdfsServerConstants
operator|.
name|INVALID_TXID
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Edit log file "
operator|+
name|elf
operator|+
literal|" appears to be empty. "
operator|+
literal|"Moving it aside..."
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|elf
operator|.
name|moveAsideEmptyFile
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
name|SegmentStateProto
name|ret
init|=
name|SegmentStateProto
operator|.
name|newBuilder
argument_list|()
operator|.
name|setStartTxId
argument_list|(
name|segmentTxId
argument_list|)
operator|.
name|setEndTxId
argument_list|(
name|elf
operator|.
name|getLastTxId
argument_list|()
argument_list|)
operator|.
name|setIsInProgress
argument_list|(
name|elf
operator|.
name|isInProgress
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"getSegmentInfo("
operator|+
name|segmentTxId
operator|+
literal|"): "
operator|+
name|elf
operator|+
literal|" -> "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|ret
argument_list|)
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
comment|/**    * @see QJournalProtocol#prepareRecovery(RequestInfo, long)    */
DECL|method|prepareRecovery ( RequestInfo reqInfo, long segmentTxId)
specifier|public
specifier|synchronized
name|PrepareRecoveryResponseProto
name|prepareRecovery
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|long
name|segmentTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
name|abortCurSegment
argument_list|()
expr_stmt|;
name|PrepareRecoveryResponseProto
operator|.
name|Builder
name|builder
init|=
name|PrepareRecoveryResponseProto
operator|.
name|newBuilder
argument_list|()
decl_stmt|;
name|PersistedRecoveryPaxosData
name|previouslyAccepted
init|=
name|getPersistedPaxosData
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
name|completeHalfDoneAcceptRecovery
argument_list|(
name|previouslyAccepted
argument_list|)
expr_stmt|;
name|SegmentStateProto
name|segInfo
init|=
name|getSegmentInfo
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
name|boolean
name|hasFinalizedSegment
init|=
name|segInfo
operator|!=
literal|null
operator|&&
operator|!
name|segInfo
operator|.
name|getIsInProgress
argument_list|()
decl_stmt|;
if|if
condition|(
name|previouslyAccepted
operator|!=
literal|null
operator|&&
operator|!
name|hasFinalizedSegment
condition|)
block|{
name|SegmentStateProto
name|acceptedState
init|=
name|previouslyAccepted
operator|.
name|getSegmentState
argument_list|()
decl_stmt|;
assert|assert
name|acceptedState
operator|.
name|getEndTxId
argument_list|()
operator|==
name|segInfo
operator|.
name|getEndTxId
argument_list|()
operator|:
literal|"prev accepted: "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|previouslyAccepted
argument_list|)
operator|+
literal|"\n"
operator|+
literal|"on disk:       "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segInfo
argument_list|)
assert|;
name|builder
operator|.
name|setAcceptedInEpoch
argument_list|(
name|previouslyAccepted
operator|.
name|getAcceptedInEpoch
argument_list|()
argument_list|)
operator|.
name|setSegmentState
argument_list|(
name|previouslyAccepted
operator|.
name|getSegmentState
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|segInfo
operator|!=
literal|null
condition|)
block|{
name|builder
operator|.
name|setSegmentState
argument_list|(
name|segInfo
argument_list|)
expr_stmt|;
block|}
block|}
name|builder
operator|.
name|setLastWriterEpoch
argument_list|(
name|lastWriterEpoch
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|committedTxnId
operator|.
name|get
argument_list|()
operator|!=
name|HdfsServerConstants
operator|.
name|INVALID_TXID
condition|)
block|{
name|builder
operator|.
name|setLastCommittedTxId
argument_list|(
name|committedTxnId
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|PrepareRecoveryResponseProto
name|resp
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Prepared recovery for segment "
operator|+
name|segmentTxId
operator|+
literal|": "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|resp
argument_list|)
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
return|return
name|resp
return|;
block|}
comment|/**    * @see QJournalProtocol#acceptRecovery(RequestInfo, QJournalProtocolProtos.SegmentStateProto, URL)    */
DECL|method|acceptRecovery (RequestInfo reqInfo, SegmentStateProto segment, URL fromUrl)
specifier|public
specifier|synchronized
name|void
name|acceptRecovery
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
name|SegmentStateProto
name|segment
parameter_list|,
name|URL
name|fromUrl
parameter_list|)
throws|throws
name|IOException
block|{
name|checkFormatted
argument_list|()
expr_stmt|;
name|checkRequest
argument_list|(
name|reqInfo
argument_list|)
expr_stmt|;
name|abortCurSegment
argument_list|()
expr_stmt|;
name|long
name|segmentTxId
init|=
name|segment
operator|.
name|getStartTxId
argument_list|()
decl_stmt|;
comment|// Basic sanity checks that the segment is well-formed and contains
comment|// at least one transaction.
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|segment
operator|.
name|getEndTxId
argument_list|()
operator|>
literal|0
operator|&&
name|segment
operator|.
name|getEndTxId
argument_list|()
operator|>=
name|segmentTxId
argument_list|,
literal|"bad recovery state for segment %s: %s ; journal id: %s"
argument_list|,
name|segmentTxId
argument_list|,
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
name|PersistedRecoveryPaxosData
name|oldData
init|=
name|getPersistedPaxosData
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
name|PersistedRecoveryPaxosData
name|newData
init|=
name|PersistedRecoveryPaxosData
operator|.
name|newBuilder
argument_list|()
operator|.
name|setAcceptedInEpoch
argument_list|(
name|reqInfo
operator|.
name|getEpoch
argument_list|()
argument_list|)
operator|.
name|setSegmentState
argument_list|(
name|segment
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
comment|// If we previously acted on acceptRecovery() from a higher-numbered writer,
comment|// this call is out of sync. We should never actually trigger this, since the
comment|// checkRequest() call above should filter non-increasing epoch numbers.
if|if
condition|(
name|oldData
operator|!=
literal|null
condition|)
block|{
name|alwaysAssert
argument_list|(
name|oldData
operator|.
name|getAcceptedInEpoch
argument_list|()
operator|<=
name|reqInfo
operator|.
name|getEpoch
argument_list|()
argument_list|,
literal|"Bad paxos transition, out-of-order epochs.\nOld: %s\nNew: "
operator|+
literal|"%s\nJournalId: %s\n"
argument_list|,
name|oldData
argument_list|,
name|newData
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
block|}
name|File
name|syncedFile
init|=
literal|null
decl_stmt|;
name|SegmentStateProto
name|currentSegment
init|=
name|getSegmentInfo
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
if|if
condition|(
name|currentSegment
operator|==
literal|null
operator|||
name|currentSegment
operator|.
name|getEndTxId
argument_list|()
operator|!=
name|segment
operator|.
name|getEndTxId
argument_list|()
condition|)
block|{
if|if
condition|(
name|currentSegment
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Synchronizing log "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
operator|+
literal|": no current segment in place ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
comment|// Update the highest txid for lag metrics
name|updateHighestWrittenTxId
argument_list|(
name|Math
operator|.
name|max
argument_list|(
name|segment
operator|.
name|getEndTxId
argument_list|()
argument_list|,
name|highestWrittenTxId
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Synchronizing log "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
operator|+
literal|": old segment "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|currentSegment
argument_list|)
operator|+
literal|" is not the right length ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
comment|// Paranoid sanity check: if the new log is shorter than the log we
comment|// currently have, we should not end up discarding any transactions
comment|// which are already Committed.
if|if
condition|(
name|txnRange
argument_list|(
name|currentSegment
argument_list|)
operator|.
name|contains
argument_list|(
name|committedTxnId
operator|.
name|get
argument_list|()
argument_list|)
operator|&&
operator|!
name|txnRange
argument_list|(
name|segment
argument_list|)
operator|.
name|contains
argument_list|(
name|committedTxnId
operator|.
name|get
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Cannot replace segment "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|currentSegment
argument_list|)
operator|+
literal|" with new segment "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
operator|+
literal|": would discard already-committed txn "
operator|+
name|committedTxnId
operator|.
name|get
argument_list|()
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
throw|;
block|}
comment|// Another paranoid check: we should not be asked to synchronize a log
comment|// on top of a finalized segment.
name|alwaysAssert
argument_list|(
name|currentSegment
operator|.
name|getIsInProgress
argument_list|()
argument_list|,
literal|"Should never be asked to synchronize a different log on top of "
operator|+
literal|"an already-finalized segment ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
comment|// If we're shortening the log, update our highest txid
comment|// used for lag metrics.
if|if
condition|(
name|txnRange
argument_list|(
name|currentSegment
argument_list|)
operator|.
name|contains
argument_list|(
name|highestWrittenTxId
argument_list|)
condition|)
block|{
name|updateHighestWrittenTxId
argument_list|(
name|segment
operator|.
name|getEndTxId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|syncedFile
operator|=
name|syncLog
argument_list|(
name|reqInfo
argument_list|,
name|segment
argument_list|,
name|fromUrl
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Skipping download of log "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
operator|+
literal|": already have up-to-date logs ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
comment|// This is one of the few places in the protocol where we have a single
comment|// RPC that results in two distinct actions:
comment|//
comment|// - 1) Downloads the new log segment data (above)
comment|// - 2) Records the new Paxos data about the synchronized segment (below)
comment|//
comment|// These need to be treated as a transaction from the perspective
comment|// of any external process. We do this by treating the persistPaxosData()
comment|// success as the "commit" of an atomic transaction. If we fail before
comment|// this point, the downloaded edit log will only exist at a temporary
comment|// path, and thus not change any externally visible state. If we fail
comment|// after this point, then any future prepareRecovery() call will see
comment|// the Paxos data, and by calling completeHalfDoneAcceptRecovery() will
comment|// roll forward the rename of the referenced log file.
comment|//
comment|// See also: HDFS-3955
comment|//
comment|// The fault points here are exercised by the randomized fault injection
comment|// test case to ensure that this atomic "transaction" operates correctly.
name|JournalFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|beforePersistPaxosData
argument_list|()
expr_stmt|;
name|persistPaxosData
argument_list|(
name|segmentTxId
argument_list|,
name|newData
argument_list|)
expr_stmt|;
name|JournalFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|afterPersistPaxosData
argument_list|()
expr_stmt|;
if|if
condition|(
name|syncedFile
operator|!=
literal|null
condition|)
block|{
name|FileUtil
operator|.
name|replaceFile
argument_list|(
name|syncedFile
argument_list|,
name|storage
operator|.
name|getInProgressEditLog
argument_list|(
name|segmentTxId
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Accepted recovery for segment "
operator|+
name|segmentTxId
operator|+
literal|": "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|newData
argument_list|)
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
DECL|method|txnRange (SegmentStateProto seg)
specifier|private
name|Range
argument_list|<
name|Long
argument_list|>
name|txnRange
parameter_list|(
name|SegmentStateProto
name|seg
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|seg
operator|.
name|hasEndTxId
argument_list|()
argument_list|,
literal|"invalid segment: %s ; journal id: %s"
argument_list|,
name|seg
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
return|return
name|Range
operator|.
name|between
argument_list|(
name|seg
operator|.
name|getStartTxId
argument_list|()
argument_list|,
name|seg
operator|.
name|getEndTxId
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Synchronize a log segment from another JournalNode. The log is    * downloaded from the provided URL into a temporary location on disk,    * which is named based on the current request's epoch.    *    * @return the temporary location of the downloaded file    */
DECL|method|syncLog (RequestInfo reqInfo, final SegmentStateProto segment, final URL url)
specifier|private
name|File
name|syncLog
parameter_list|(
name|RequestInfo
name|reqInfo
parameter_list|,
specifier|final
name|SegmentStateProto
name|segment
parameter_list|,
specifier|final
name|URL
name|url
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|File
name|tmpFile
init|=
name|storage
operator|.
name|getSyncLogTemporaryFile
argument_list|(
name|segment
operator|.
name|getStartTxId
argument_list|()
argument_list|,
name|reqInfo
operator|.
name|getEpoch
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|File
argument_list|>
name|localPaths
init|=
name|ImmutableList
operator|.
name|of
argument_list|(
name|tmpFile
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Synchronizing log "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|segment
argument_list|)
operator|+
literal|" from "
operator|+
name|url
argument_list|)
expr_stmt|;
name|SecurityUtil
operator|.
name|doAsLoginUser
argument_list|(
operator|new
name|PrivilegedExceptionAction
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|run
parameter_list|()
throws|throws
name|IOException
block|{
comment|// We may have lost our ticket since last checkpoint, log in again, just in case
if|if
condition|(
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|checkTGTAndReloginFromKeytab
argument_list|()
expr_stmt|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|TransferFsImage
operator|.
name|doGetUrl
argument_list|(
name|url
argument_list|,
name|localPaths
argument_list|,
name|storage
argument_list|,
literal|true
argument_list|)
expr_stmt|;
assert|assert
name|tmpFile
operator|.
name|exists
argument_list|()
assert|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
if|if
condition|(
operator|!
name|tmpFile
operator|.
name|delete
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to delete temporary file "
operator|+
name|tmpFile
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|tmpFile
return|;
block|}
comment|/**    * In the case the node crashes in between downloading a log segment    * and persisting the associated paxos recovery data, the log segment    * will be left in its temporary location on disk. Given the paxos data,    * we can check if this was indeed the case, and&quot;roll forward&quot;    * the atomic operation.    *     * See the inline comments in    * {@link #acceptRecovery(RequestInfo, SegmentStateProto, URL)} for more    * details.    *    * @throws IOException if the temporary file is unable to be renamed into    * place    */
DECL|method|completeHalfDoneAcceptRecovery ( PersistedRecoveryPaxosData paxosData)
specifier|private
name|void
name|completeHalfDoneAcceptRecovery
parameter_list|(
name|PersistedRecoveryPaxosData
name|paxosData
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|paxosData
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|long
name|segmentId
init|=
name|paxosData
operator|.
name|getSegmentState
argument_list|()
operator|.
name|getStartTxId
argument_list|()
decl_stmt|;
name|long
name|epoch
init|=
name|paxosData
operator|.
name|getAcceptedInEpoch
argument_list|()
decl_stmt|;
name|File
name|tmp
init|=
name|storage
operator|.
name|getSyncLogTemporaryFile
argument_list|(
name|segmentId
argument_list|,
name|epoch
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmp
operator|.
name|exists
argument_list|()
condition|)
block|{
name|File
name|dst
init|=
name|storage
operator|.
name|getInProgressEditLog
argument_list|(
name|segmentId
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolling forward previously half-completed synchronization: "
operator|+
name|tmp
operator|+
literal|" -> "
operator|+
name|dst
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
name|FileUtil
operator|.
name|replaceFile
argument_list|(
name|tmp
argument_list|,
name|dst
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Retrieve the persisted data for recovering the given segment from disk.    */
DECL|method|getPersistedPaxosData (long segmentTxId)
specifier|private
name|PersistedRecoveryPaxosData
name|getPersistedPaxosData
parameter_list|(
name|long
name|segmentTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|f
init|=
name|storage
operator|.
name|getPaxosFile
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|f
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// Default instance has no fields filled in (they're optional)
return|return
literal|null
return|;
block|}
name|InputStream
name|in
init|=
operator|new
name|FileInputStream
argument_list|(
name|f
argument_list|)
decl_stmt|;
try|try
block|{
name|PersistedRecoveryPaxosData
name|ret
init|=
name|PersistedRecoveryPaxosData
operator|.
name|parseDelimitedFrom
argument_list|(
name|in
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|ret
operator|!=
literal|null
operator|&&
name|ret
operator|.
name|getSegmentState
argument_list|()
operator|.
name|getStartTxId
argument_list|()
operator|==
name|segmentTxId
argument_list|,
literal|"Bad persisted data for segment %s: %s ; journal id: %s"
argument_list|,
name|segmentTxId
argument_list|,
name|ret
argument_list|,
name|journalId
argument_list|)
expr_stmt|;
return|return
name|ret
return|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Persist data for recovering the given segment from disk.    */
DECL|method|persistPaxosData (long segmentTxId, PersistedRecoveryPaxosData newData)
specifier|private
name|void
name|persistPaxosData
parameter_list|(
name|long
name|segmentTxId
parameter_list|,
name|PersistedRecoveryPaxosData
name|newData
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|f
init|=
name|storage
operator|.
name|getPaxosFile
argument_list|(
name|segmentTxId
argument_list|)
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|AtomicFileOutputStream
name|fos
init|=
operator|new
name|AtomicFileOutputStream
argument_list|(
name|f
argument_list|)
decl_stmt|;
try|try
block|{
name|newData
operator|.
name|writeDelimitedTo
argument_list|(
name|fos
argument_list|)
expr_stmt|;
name|fos
operator|.
name|write
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
comment|// Write human-readable data after the protobuf. This is only
comment|// to assist in debugging -- it's not parsed at all.
try|try
init|(
name|OutputStreamWriter
name|writer
init|=
operator|new
name|OutputStreamWriter
argument_list|(
name|fos
argument_list|,
name|Charsets
operator|.
name|UTF_8
argument_list|)
init|)
block|{
name|writer
operator|.
name|write
argument_list|(
name|String
operator|.
name|valueOf
argument_list|(
name|newData
argument_list|)
argument_list|)
expr_stmt|;
name|writer
operator|.
name|write
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
name|writer
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
name|fos
operator|.
name|flush
argument_list|()
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|success
condition|)
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|fos
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|fos
operator|.
name|abort
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|doPreUpgrade ()
specifier|public
specifier|synchronized
name|void
name|doPreUpgrade
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Do not hold file lock on committedTxnId, because the containing
comment|// directory will be renamed.  It will be reopened lazily on next access.
name|IOUtils
operator|.
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|committedTxnId
argument_list|)
expr_stmt|;
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|doPreUpgrade
argument_list|()
expr_stmt|;
block|}
DECL|method|doUpgrade (StorageInfo sInfo)
specifier|public
specifier|synchronized
name|void
name|doUpgrade
parameter_list|(
name|StorageInfo
name|sInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|oldCTime
init|=
name|storage
operator|.
name|getCTime
argument_list|()
decl_stmt|;
name|storage
operator|.
name|cTime
operator|=
name|sInfo
operator|.
name|cTime
expr_stmt|;
name|int
name|oldLV
init|=
name|storage
operator|.
name|getLayoutVersion
argument_list|()
decl_stmt|;
name|storage
operator|.
name|layoutVersion
operator|=
name|sInfo
operator|.
name|layoutVersion
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting upgrade of edits directory: "
operator|+
name|storage
operator|.
name|getRoot
argument_list|()
operator|+
literal|".\n   old LV = "
operator|+
name|oldLV
operator|+
literal|"; old CTime = "
operator|+
name|oldCTime
operator|+
literal|".\n   new LV = "
operator|+
name|storage
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; new CTime = "
operator|+
name|storage
operator|.
name|getCTime
argument_list|()
argument_list|)
expr_stmt|;
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|doUpgrade
argument_list|(
name|storage
argument_list|)
expr_stmt|;
name|storage
operator|.
name|createPaxosDir
argument_list|()
expr_stmt|;
comment|// Copy over the contents of the epoch data files to the new dir.
name|File
name|currentDir
init|=
name|storage
operator|.
name|getSingularStorageDir
argument_list|()
operator|.
name|getCurrentDir
argument_list|()
decl_stmt|;
name|File
name|previousDir
init|=
name|storage
operator|.
name|getSingularStorageDir
argument_list|()
operator|.
name|getPreviousDir
argument_list|()
decl_stmt|;
name|PersistentLongFile
name|prevLastPromisedEpoch
init|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|previousDir
argument_list|,
name|LAST_PROMISED_FILENAME
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|PersistentLongFile
name|prevLastWriterEpoch
init|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|previousDir
argument_list|,
name|LAST_WRITER_EPOCH
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|BestEffortLongFile
name|prevCommittedTxnId
init|=
operator|new
name|BestEffortLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|previousDir
argument_list|,
name|COMMITTED_TXID_FILENAME
argument_list|)
argument_list|,
name|HdfsServerConstants
operator|.
name|INVALID_TXID
argument_list|)
decl_stmt|;
name|lastPromisedEpoch
operator|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|LAST_PROMISED_FILENAME
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|lastWriterEpoch
operator|=
operator|new
name|PersistentLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|LAST_WRITER_EPOCH
argument_list|)
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|committedTxnId
operator|=
operator|new
name|BestEffortLongFile
argument_list|(
operator|new
name|File
argument_list|(
name|currentDir
argument_list|,
name|COMMITTED_TXID_FILENAME
argument_list|)
argument_list|,
name|HdfsServerConstants
operator|.
name|INVALID_TXID
argument_list|)
expr_stmt|;
try|try
block|{
name|lastPromisedEpoch
operator|.
name|set
argument_list|(
name|prevLastPromisedEpoch
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|lastWriterEpoch
operator|.
name|set
argument_list|(
name|prevLastWriterEpoch
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|committedTxnId
operator|.
name|set
argument_list|(
name|prevCommittedTxnId
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|prevCommittedTxnId
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|doFinalize ()
specifier|public
specifier|synchronized
name|void
name|doFinalize
parameter_list|()
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Finalizing upgrade for journal "
operator|+
name|storage
operator|.
name|getRoot
argument_list|()
operator|+
literal|"."
operator|+
operator|(
name|storage
operator|.
name|getLayoutVersion
argument_list|()
operator|==
literal|0
condition|?
literal|""
else|:
literal|"\n   cur LV = "
operator|+
name|storage
operator|.
name|getLayoutVersion
argument_list|()
operator|+
literal|"; cur CTime = "
operator|+
name|storage
operator|.
name|getCTime
argument_list|()
operator|)
argument_list|)
expr_stmt|;
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|doFinalize
argument_list|()
expr_stmt|;
block|}
DECL|method|canRollBack (StorageInfo storage, StorageInfo prevStorage, int targetLayoutVersion)
specifier|public
name|Boolean
name|canRollBack
parameter_list|(
name|StorageInfo
name|storage
parameter_list|,
name|StorageInfo
name|prevStorage
parameter_list|,
name|int
name|targetLayoutVersion
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|this
operator|.
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|canRollBack
argument_list|(
name|storage
argument_list|,
name|prevStorage
argument_list|,
name|targetLayoutVersion
argument_list|)
return|;
block|}
DECL|method|doRollback ()
specifier|public
specifier|synchronized
name|void
name|doRollback
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Do not hold file lock on committedTxnId, because the containing
comment|// directory will be renamed.  It will be reopened lazily on next access.
name|IOUtils
operator|.
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|committedTxnId
argument_list|)
expr_stmt|;
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|doRollback
argument_list|()
expr_stmt|;
block|}
DECL|method|discardSegments (long startTxId)
specifier|synchronized
name|void
name|discardSegments
parameter_list|(
name|long
name|startTxId
parameter_list|)
throws|throws
name|IOException
block|{
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|discardSegments
argument_list|(
name|startTxId
argument_list|)
expr_stmt|;
comment|// we delete all the segments after the startTxId. let's reset committedTxnId
name|committedTxnId
operator|.
name|set
argument_list|(
name|startTxId
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
DECL|method|moveTmpSegmentToCurrent (File tmpFile, File finalFile, long endTxId)
specifier|synchronized
name|boolean
name|moveTmpSegmentToCurrent
parameter_list|(
name|File
name|tmpFile
parameter_list|,
name|File
name|finalFile
parameter_list|,
name|long
name|endTxId
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|boolean
name|success
decl_stmt|;
if|if
condition|(
name|endTxId
operator|<=
name|committedTxnId
operator|.
name|get
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|finalFile
operator|.
name|getParentFile
argument_list|()
operator|.
name|exists
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|finalFile
operator|.
name|getParentFile
argument_list|()
operator|+
literal|" doesn't exist. Aborting tmp "
operator|+
literal|"segment move to current directory ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|Files
operator|.
name|move
argument_list|(
name|tmpFile
operator|.
name|toPath
argument_list|()
argument_list|,
name|finalFile
operator|.
name|toPath
argument_list|()
argument_list|,
name|StandardCopyOption
operator|.
name|ATOMIC_MOVE
argument_list|)
expr_stmt|;
if|if
condition|(
name|finalFile
operator|.
name|exists
argument_list|()
operator|&&
name|FileUtil
operator|.
name|canRead
argument_list|(
name|finalFile
argument_list|)
condition|)
block|{
name|success
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|success
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to move edits file from "
operator|+
name|tmpFile
operator|+
literal|" to "
operator|+
name|finalFile
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|success
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"The endTxId of the temporary file is not less than the "
operator|+
literal|"last committed transaction id. Aborting move to final file"
operator|+
name|finalFile
operator|+
literal|" ; journal id: "
operator|+
name|journalId
argument_list|)
expr_stmt|;
block|}
return|return
name|success
return|;
block|}
DECL|method|getJournalCTime ()
specifier|public
name|Long
name|getJournalCTime
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|storage
operator|.
name|getJournalManager
argument_list|()
operator|.
name|getJournalCTime
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getJournaledEditsCache ()
name|JournaledEditsCache
name|getJournaledEditsCache
parameter_list|()
block|{
return|return
name|cache
return|;
block|}
block|}
end_class

end_unit

