begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.blockmanagement
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeProtocol
operator|.
name|DNA_ERASURE_CODING_RECONSTRUCTION
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
operator|.
name|monotonicNow
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|net
operator|.
name|InetAddresses
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|HadoopIllegalArgumentException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|net
operator|.
name|DFSNetworkTopology
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
operator|.
name|DatanodeReportType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|DatanodeDescriptor
operator|.
name|BlockTargetPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|DatanodeDescriptor
operator|.
name|CachedBlocksList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Util
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|CachedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NameNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|Namesystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|BlockECReconstructionCommand
operator|.
name|BlockECReconstructionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|BlockRecoveryCommand
operator|.
name|RecoveringBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|BlockRecoveryCommand
operator|.
name|RecoveringStripedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetworkTopology
operator|.
name|InvalidTopologyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Timer
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nonnull
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|UnknownHostException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadLocalRandom
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_comment
comment|/**  * Manage datanodes, include decommission and other activities.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|DatanodeManager
specifier|public
class|class
name|DatanodeManager
block|{
DECL|field|LOG
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|DatanodeManager
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|namesystem
specifier|private
specifier|final
name|Namesystem
name|namesystem
decl_stmt|;
DECL|field|blockManager
specifier|private
specifier|final
name|BlockManager
name|blockManager
decl_stmt|;
DECL|field|datanodeAdminManager
specifier|private
specifier|final
name|DatanodeAdminManager
name|datanodeAdminManager
decl_stmt|;
DECL|field|heartbeatManager
specifier|private
specifier|final
name|HeartbeatManager
name|heartbeatManager
decl_stmt|;
DECL|field|fsClusterStats
specifier|private
specifier|final
name|FSClusterStats
name|fsClusterStats
decl_stmt|;
DECL|field|heartbeatIntervalSeconds
specifier|private
specifier|volatile
name|long
name|heartbeatIntervalSeconds
decl_stmt|;
DECL|field|heartbeatRecheckInterval
specifier|private
specifier|volatile
name|int
name|heartbeatRecheckInterval
decl_stmt|;
comment|/**    * Stores the datanode -> block map.      *<p>    * Done by storing a set of {@link DatanodeDescriptor} objects, sorted by     * storage id. In order to keep the storage map consistent it tracks     * all storages ever registered with the namenode.    * A descriptor corresponding to a specific storage id can be    *<ul>     *<li>added to the map if it is a new storage id;</li>    *<li>updated with a new datanode started as a replacement for the old one     * with the same storage id; and</li>    *<li>removed if and only if an existing datanode is restarted to serve a    * different storage id.</li>    *</ul><br>     *<p>    * Mapping: StorageID -> DatanodeDescriptor    */
DECL|field|datanodeMap
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|DatanodeDescriptor
argument_list|>
name|datanodeMap
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|/** Cluster network topology. */
DECL|field|networktopology
specifier|private
specifier|final
name|NetworkTopology
name|networktopology
decl_stmt|;
comment|/** Host names to datanode descriptors mapping. */
DECL|field|host2DatanodeMap
specifier|private
specifier|final
name|Host2NodesMap
name|host2DatanodeMap
init|=
operator|new
name|Host2NodesMap
argument_list|()
decl_stmt|;
DECL|field|dnsToSwitchMapping
specifier|private
specifier|final
name|DNSToSwitchMapping
name|dnsToSwitchMapping
decl_stmt|;
DECL|field|rejectUnresolvedTopologyDN
specifier|private
specifier|final
name|boolean
name|rejectUnresolvedTopologyDN
decl_stmt|;
DECL|field|defaultXferPort
specifier|private
specifier|final
name|int
name|defaultXferPort
decl_stmt|;
DECL|field|defaultInfoPort
specifier|private
specifier|final
name|int
name|defaultInfoPort
decl_stmt|;
DECL|field|defaultInfoSecurePort
specifier|private
specifier|final
name|int
name|defaultInfoSecurePort
decl_stmt|;
DECL|field|defaultIpcPort
specifier|private
specifier|final
name|int
name|defaultIpcPort
decl_stmt|;
comment|/** Read include/exclude files. */
DECL|field|hostConfigManager
specifier|private
name|HostConfigManager
name|hostConfigManager
decl_stmt|;
comment|/** The period to wait for datanode heartbeat.*/
DECL|field|heartbeatExpireInterval
specifier|private
name|long
name|heartbeatExpireInterval
decl_stmt|;
comment|/** Ask Datanode only up to this many blocks to delete. */
DECL|field|blockInvalidateLimit
specifier|private
specifier|volatile
name|int
name|blockInvalidateLimit
decl_stmt|;
comment|/** The interval for judging stale DataNodes for read/write */
DECL|field|staleInterval
specifier|private
specifier|final
name|long
name|staleInterval
decl_stmt|;
comment|/** Whether or not to avoid using stale DataNodes for reading */
DECL|field|avoidStaleDataNodesForRead
specifier|private
specifier|final
name|boolean
name|avoidStaleDataNodesForRead
decl_stmt|;
comment|/**    * Whether or not to avoid using stale DataNodes for writing.    * Note that, even if this is configured, the policy may be    * temporarily disabled when a high percentage of the nodes    * are marked as stale.    */
DECL|field|avoidStaleDataNodesForWrite
specifier|private
specifier|final
name|boolean
name|avoidStaleDataNodesForWrite
decl_stmt|;
comment|/**    * When the ratio of stale datanodes reaches this number, stop avoiding     * writing to stale datanodes, i.e., continue using stale nodes for writing.    */
DECL|field|ratioUseStaleDataNodesForWrite
specifier|private
specifier|final
name|float
name|ratioUseStaleDataNodesForWrite
decl_stmt|;
comment|/** The number of stale DataNodes */
DECL|field|numStaleNodes
specifier|private
specifier|volatile
name|int
name|numStaleNodes
decl_stmt|;
comment|/** The number of stale storages */
DECL|field|numStaleStorages
specifier|private
specifier|volatile
name|int
name|numStaleStorages
decl_stmt|;
comment|/**    * Number of blocks to check for each postponedMisreplicatedBlocks iteration    */
DECL|field|blocksPerPostponedMisreplicatedBlocksRescan
specifier|private
specifier|final
name|long
name|blocksPerPostponedMisreplicatedBlocksRescan
decl_stmt|;
comment|/**    * Whether or not this cluster has ever consisted of more than 1 rack,    * according to the NetworkTopology.    */
DECL|field|hasClusterEverBeenMultiRack
specifier|private
name|boolean
name|hasClusterEverBeenMultiRack
init|=
literal|false
decl_stmt|;
DECL|field|checkIpHostnameInRegistration
specifier|private
specifier|final
name|boolean
name|checkIpHostnameInRegistration
decl_stmt|;
comment|/**    * Whether we should tell datanodes what to cache in replies to    * heartbeat messages.    */
DECL|field|shouldSendCachingCommands
specifier|private
name|boolean
name|shouldSendCachingCommands
init|=
literal|false
decl_stmt|;
comment|/**    * The number of datanodes for each software version. This list should change    * during rolling upgrades.    * Software version -> Number of datanodes with this version    */
DECL|field|datanodesSoftwareVersions
specifier|private
specifier|final
name|HashMap
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
name|datanodesSoftwareVersions
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
literal|4
argument_list|,
literal|0.75f
argument_list|)
decl_stmt|;
comment|/**    * True if we should process latency metrics from downstream peers.    */
DECL|field|dataNodePeerStatsEnabled
specifier|private
specifier|final
name|boolean
name|dataNodePeerStatsEnabled
decl_stmt|;
comment|/**    *  True if we should process latency metrics from individual DN disks.    */
DECL|field|dataNodeDiskStatsEnabled
specifier|private
specifier|final
name|boolean
name|dataNodeDiskStatsEnabled
decl_stmt|;
comment|/**    * If we use DfsNetworkTopology to choose nodes for placing replicas.    */
DECL|field|useDfsNetworkTopology
specifier|private
specifier|final
name|boolean
name|useDfsNetworkTopology
decl_stmt|;
annotation|@
name|Nullable
DECL|field|slowPeerTracker
specifier|private
specifier|final
name|SlowPeerTracker
name|slowPeerTracker
decl_stmt|;
annotation|@
name|Nullable
DECL|field|slowDiskTracker
specifier|private
specifier|final
name|SlowDiskTracker
name|slowDiskTracker
decl_stmt|;
comment|/**    * The minimum time between resending caching directives to Datanodes,    * in milliseconds.    *    * Note that when a rescan happens, we will send the new directives    * as soon as possible.  This timeout only applies to resending     * directives that we've already sent.    */
DECL|field|timeBetweenResendingCachingDirectivesMs
specifier|private
specifier|final
name|long
name|timeBetweenResendingCachingDirectivesMs
decl_stmt|;
DECL|method|DatanodeManager (final BlockManager blockManager, final Namesystem namesystem, final Configuration conf)
name|DatanodeManager
parameter_list|(
specifier|final
name|BlockManager
name|blockManager
parameter_list|,
specifier|final
name|Namesystem
name|namesystem
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|namesystem
operator|=
name|namesystem
expr_stmt|;
name|this
operator|.
name|blockManager
operator|=
name|blockManager
expr_stmt|;
comment|// TODO: Enables DFSNetworkTopology by default after more stress
comment|// testings/validations.
name|this
operator|.
name|useDfsNetworkTopology
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_USE_DFS_NETWORK_TOPOLOGY_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_USE_DFS_NETWORK_TOPOLOGY_DEFAULT
argument_list|)
expr_stmt|;
if|if
condition|(
name|useDfsNetworkTopology
condition|)
block|{
name|networktopology
operator|=
name|DFSNetworkTopology
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|networktopology
operator|=
name|NetworkTopology
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|heartbeatManager
operator|=
operator|new
name|HeartbeatManager
argument_list|(
name|namesystem
argument_list|,
name|blockManager
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|datanodeAdminManager
operator|=
operator|new
name|DatanodeAdminManager
argument_list|(
name|namesystem
argument_list|,
name|blockManager
argument_list|,
name|heartbeatManager
argument_list|)
expr_stmt|;
name|this
operator|.
name|fsClusterStats
operator|=
name|newFSClusterStats
argument_list|()
expr_stmt|;
name|this
operator|.
name|dataNodePeerStatsEnabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_PEER_STATS_ENABLED_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_PEER_STATS_ENABLED_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|dataNodeDiskStatsEnabled
operator|=
name|Util
operator|.
name|isDiskStatsEnabled
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_FILEIO_PROFILING_SAMPLING_PERCENTAGE_DEFAULT
argument_list|)
argument_list|)
expr_stmt|;
specifier|final
name|Timer
name|timer
init|=
operator|new
name|Timer
argument_list|()
decl_stmt|;
name|this
operator|.
name|slowPeerTracker
operator|=
name|dataNodePeerStatsEnabled
condition|?
operator|new
name|SlowPeerTracker
argument_list|(
name|conf
argument_list|,
name|timer
argument_list|)
else|:
literal|null
expr_stmt|;
name|this
operator|.
name|slowDiskTracker
operator|=
name|dataNodeDiskStatsEnabled
condition|?
operator|new
name|SlowDiskTracker
argument_list|(
name|conf
argument_list|,
name|timer
argument_list|)
else|:
literal|null
expr_stmt|;
name|this
operator|.
name|defaultXferPort
operator|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_ADDRESS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_ADDRESS_DEFAULT
argument_list|)
argument_list|)
operator|.
name|getPort
argument_list|()
expr_stmt|;
name|this
operator|.
name|defaultInfoPort
operator|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_ADDRESS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_ADDRESS_DEFAULT
argument_list|)
argument_list|)
operator|.
name|getPort
argument_list|()
expr_stmt|;
name|this
operator|.
name|defaultInfoSecurePort
operator|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTPS_ADDRESS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTPS_ADDRESS_DEFAULT
argument_list|)
argument_list|)
operator|.
name|getPort
argument_list|()
expr_stmt|;
name|this
operator|.
name|defaultIpcPort
operator|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_IPC_ADDRESS_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_IPC_ADDRESS_DEFAULT
argument_list|)
argument_list|)
operator|.
name|getPort
argument_list|()
expr_stmt|;
name|this
operator|.
name|hostConfigManager
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClass
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_HOSTS_PROVIDER_CLASSNAME_KEY
argument_list|,
name|HostFileManager
operator|.
name|class
argument_list|,
name|HostConfigManager
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|hostConfigManager
operator|.
name|refresh
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error reading hosts files: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|dnsToSwitchMapping
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClass
argument_list|(
name|DFSConfigKeys
operator|.
name|NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY
argument_list|,
name|ScriptBasedMapping
operator|.
name|class
argument_list|,
name|DNSToSwitchMapping
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|rejectUnresolvedTopologyDN
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_REJECT_UNRESOLVED_DN_TOPOLOGY_MAPPING_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_REJECT_UNRESOLVED_DN_TOPOLOGY_MAPPING_DEFAULT
argument_list|)
expr_stmt|;
comment|// If the dns to switch mapping supports cache, resolve network
comment|// locations of those hosts in the include list and store the mapping
comment|// in the cache; so future calls to resolve will be fast.
if|if
condition|(
name|dnsToSwitchMapping
operator|instanceof
name|CachedDNSToSwitchMapping
condition|)
block|{
specifier|final
name|ArrayList
argument_list|<
name|String
argument_list|>
name|locations
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|InetSocketAddress
name|addr
range|:
name|hostConfigManager
operator|.
name|getIncludes
argument_list|()
control|)
block|{
name|locations
operator|.
name|add
argument_list|(
name|addr
operator|.
name|getAddress
argument_list|()
operator|.
name|getHostAddress
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|dnsToSwitchMapping
operator|.
name|resolve
argument_list|(
name|locations
argument_list|)
expr_stmt|;
block|}
name|heartbeatIntervalSeconds
operator|=
name|conf
operator|.
name|getTimeDuration
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_DEFAULT
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
expr_stmt|;
name|heartbeatRecheckInterval
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_DEFAULT
argument_list|)
expr_stmt|;
comment|// 5 minutes
name|this
operator|.
name|heartbeatExpireInterval
operator|=
literal|2
operator|*
name|heartbeatRecheckInterval
operator|+
literal|10
operator|*
literal|1000
operator|*
name|heartbeatIntervalSeconds
expr_stmt|;
comment|// Effected block invalidate limit is the bigger value between
comment|// value configured in hdfs-site.xml, and 20 * HB interval.
specifier|final
name|int
name|configuredBlockInvalidateLimit
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_INVALIDATE_LIMIT_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_INVALIDATE_LIMIT_DEFAULT
argument_list|)
decl_stmt|;
specifier|final
name|int
name|countedBlockInvalidateLimit
init|=
literal|20
operator|*
call|(
name|int
call|)
argument_list|(
name|heartbeatIntervalSeconds
argument_list|)
decl_stmt|;
name|this
operator|.
name|blockInvalidateLimit
operator|=
name|Math
operator|.
name|max
argument_list|(
name|countedBlockInvalidateLimit
argument_list|,
name|configuredBlockInvalidateLimit
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_BLOCK_INVALIDATE_LIMIT_KEY
operator|+
literal|": configured="
operator|+
name|configuredBlockInvalidateLimit
operator|+
literal|", counted="
operator|+
name|countedBlockInvalidateLimit
operator|+
literal|", effected="
operator|+
name|blockInvalidateLimit
argument_list|)
expr_stmt|;
name|this
operator|.
name|checkIpHostnameInRegistration
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_DEFAULT
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_DATANODE_REGISTRATION_IP_HOSTNAME_CHECK_KEY
operator|+
literal|"="
operator|+
name|checkIpHostnameInRegistration
argument_list|)
expr_stmt|;
name|this
operator|.
name|avoidStaleDataNodesForRead
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_READ_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_READ_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|avoidStaleDataNodesForWrite
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|staleInterval
operator|=
name|getStaleIntervalFromConf
argument_list|(
name|conf
argument_list|,
name|heartbeatExpireInterval
argument_list|)
expr_stmt|;
name|this
operator|.
name|ratioUseStaleDataNodesForWrite
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_DEFAULT
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|(
name|ratioUseStaleDataNodesForWrite
operator|>
literal|0
operator|&&
name|ratioUseStaleDataNodesForWrite
operator|<=
literal|1.0f
operator|)
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_USE_STALE_DATANODE_FOR_WRITE_RATIO_KEY
operator|+
literal|" = '"
operator|+
name|ratioUseStaleDataNodesForWrite
operator|+
literal|"' is invalid. "
operator|+
literal|"It should be a positive non-zero float value, not greater than 1.0f."
argument_list|)
expr_stmt|;
name|this
operator|.
name|timeBetweenResendingCachingDirectivesMs
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_PATH_BASED_CACHE_RETRY_INTERVAL_MS
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_PATH_BASED_CACHE_RETRY_INTERVAL_MS_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|blocksPerPostponedMisreplicatedBlocksRescan
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_BLOCKS_PER_POSTPONEDBLOCKS_RESCAN_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_BLOCKS_PER_POSTPONEDBLOCKS_RESCAN_KEY_DEFAULT
argument_list|)
expr_stmt|;
block|}
DECL|method|getStaleIntervalFromConf (Configuration conf, long heartbeatExpireInterval)
specifier|private
specifier|static
name|long
name|getStaleIntervalFromConf
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|long
name|heartbeatExpireInterval
parameter_list|)
block|{
name|long
name|staleInterval
init|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_INTERVAL_DEFAULT
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|staleInterval
operator|>
literal|0
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY
operator|+
literal|" = '"
operator|+
name|staleInterval
operator|+
literal|"' is invalid. "
operator|+
literal|"It should be a positive non-zero value."
argument_list|)
expr_stmt|;
specifier|final
name|long
name|heartbeatIntervalSeconds
init|=
name|conf
operator|.
name|getTimeDuration
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_DEFAULT
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
decl_stmt|;
comment|// The stale interval value cannot be smaller than
comment|// 3 times of heartbeat interval
specifier|final
name|long
name|minStaleInterval
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_DEFAULT
argument_list|)
operator|*
name|heartbeatIntervalSeconds
operator|*
literal|1000
decl_stmt|;
if|if
condition|(
name|staleInterval
operator|<
name|minStaleInterval
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The given interval for marking stale datanode = "
operator|+
name|staleInterval
operator|+
literal|", which is less than "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_MINIMUM_INTERVAL_DEFAULT
operator|+
literal|" heartbeat intervals. This may cause too frequent changes of "
operator|+
literal|"stale states of DataNodes since a heartbeat msg may be missing "
operator|+
literal|"due to temporary short-term failures. Reset stale interval to "
operator|+
name|minStaleInterval
operator|+
literal|"."
argument_list|)
expr_stmt|;
name|staleInterval
operator|=
name|minStaleInterval
expr_stmt|;
block|}
if|if
condition|(
name|staleInterval
operator|>
name|heartbeatExpireInterval
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The given interval for marking stale datanode = "
operator|+
name|staleInterval
operator|+
literal|", which is larger than heartbeat expire interval "
operator|+
name|heartbeatExpireInterval
operator|+
literal|"."
argument_list|)
expr_stmt|;
block|}
return|return
name|staleInterval
return|;
block|}
DECL|method|activate (final Configuration conf)
name|void
name|activate
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
block|{
name|datanodeAdminManager
operator|.
name|activate
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|heartbeatManager
operator|.
name|activate
argument_list|()
expr_stmt|;
block|}
DECL|method|close ()
name|void
name|close
parameter_list|()
block|{
name|datanodeAdminManager
operator|.
name|close
argument_list|()
expr_stmt|;
name|heartbeatManager
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/** @return the network topology. */
DECL|method|getNetworkTopology ()
specifier|public
name|NetworkTopology
name|getNetworkTopology
parameter_list|()
block|{
return|return
name|networktopology
return|;
block|}
comment|/** @return the heartbeat manager. */
DECL|method|getHeartbeatManager ()
name|HeartbeatManager
name|getHeartbeatManager
parameter_list|()
block|{
return|return
name|heartbeatManager
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getDatanodeAdminManager ()
specifier|public
name|DatanodeAdminManager
name|getDatanodeAdminManager
parameter_list|()
block|{
return|return
name|datanodeAdminManager
return|;
block|}
DECL|method|getHostConfigManager ()
specifier|public
name|HostConfigManager
name|getHostConfigManager
parameter_list|()
block|{
return|return
name|hostConfigManager
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setHeartbeatExpireInterval (long expiryMs)
specifier|public
name|void
name|setHeartbeatExpireInterval
parameter_list|(
name|long
name|expiryMs
parameter_list|)
block|{
name|this
operator|.
name|heartbeatExpireInterval
operator|=
name|expiryMs
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getFSClusterStats ()
specifier|public
name|FSClusterStats
name|getFSClusterStats
parameter_list|()
block|{
return|return
name|fsClusterStats
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getBlockInvalidateLimit ()
specifier|public
name|int
name|getBlockInvalidateLimit
parameter_list|()
block|{
return|return
name|blockInvalidateLimit
return|;
block|}
comment|/** @return the datanode statistics. */
DECL|method|getDatanodeStatistics ()
specifier|public
name|DatanodeStatistics
name|getDatanodeStatistics
parameter_list|()
block|{
return|return
name|heartbeatManager
return|;
block|}
DECL|method|isInactive (DatanodeInfo datanode)
specifier|private
name|boolean
name|isInactive
parameter_list|(
name|DatanodeInfo
name|datanode
parameter_list|)
block|{
return|return
name|datanode
operator|.
name|isDecommissioned
argument_list|()
operator|||
operator|(
name|avoidStaleDataNodesForRead
operator|&&
name|datanode
operator|.
name|isStale
argument_list|(
name|staleInterval
argument_list|)
operator|)
return|;
block|}
comment|/**    * Sort the non-striped located blocks by the distance to the target host.    *    * For striped blocks, it will only move decommissioned/stale nodes to the    * bottom. For example, assume we have storage list:    * d0, d1, d2, d3, d4, d5, d6, d7, d8, d9    * mapping to block indices:    * 0, 1, 2, 3, 4, 5, 6, 7, 8, 2    *    * Here the internal block b2 is duplicated, locating in d2 and d9. If d2 is    * a decommissioning node then should switch d2 and d9 in the storage list.    * After sorting locations, will update corresponding block indices    * and block tokens.    */
DECL|method|sortLocatedBlocks (final String targetHost, final List<LocatedBlock> locatedBlocks)
specifier|public
name|void
name|sortLocatedBlocks
parameter_list|(
specifier|final
name|String
name|targetHost
parameter_list|,
specifier|final
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|locatedBlocks
parameter_list|)
block|{
name|Comparator
argument_list|<
name|DatanodeInfo
argument_list|>
name|comparator
init|=
name|avoidStaleDataNodesForRead
condition|?
operator|new
name|DFSUtil
operator|.
name|ServiceAndStaleComparator
argument_list|(
name|staleInterval
argument_list|)
else|:
operator|new
name|DFSUtil
operator|.
name|ServiceComparator
argument_list|()
decl_stmt|;
comment|// sort located block
for|for
control|(
name|LocatedBlock
name|lb
range|:
name|locatedBlocks
control|)
block|{
if|if
condition|(
name|lb
operator|.
name|isStriped
argument_list|()
condition|)
block|{
name|sortLocatedStripedBlock
argument_list|(
name|lb
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sortLocatedBlock
argument_list|(
name|lb
argument_list|,
name|targetHost
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Move decommissioned/stale datanodes to the bottom. After sorting it will    * update block indices and block tokens respectively.    *    * @param lb located striped block    * @param comparator dn comparator    */
DECL|method|sortLocatedStripedBlock (final LocatedBlock lb, Comparator<DatanodeInfo> comparator)
specifier|private
name|void
name|sortLocatedStripedBlock
parameter_list|(
specifier|final
name|LocatedBlock
name|lb
parameter_list|,
name|Comparator
argument_list|<
name|DatanodeInfo
argument_list|>
name|comparator
parameter_list|)
block|{
name|DatanodeInfo
index|[]
name|di
init|=
name|lb
operator|.
name|getLocations
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|DatanodeInfo
argument_list|,
name|Byte
argument_list|>
name|locToIndex
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|DatanodeInfo
argument_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
argument_list|>
name|locToToken
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|LocatedStripedBlock
name|lsb
init|=
operator|(
name|LocatedStripedBlock
operator|)
name|lb
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|di
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|locToIndex
operator|.
name|put
argument_list|(
name|di
index|[
name|i
index|]
argument_list|,
name|lsb
operator|.
name|getBlockIndices
argument_list|()
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|locToToken
operator|.
name|put
argument_list|(
name|di
index|[
name|i
index|]
argument_list|,
name|lsb
operator|.
name|getBlockTokens
argument_list|()
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// Move decommissioned/stale datanodes to the bottom
name|Arrays
operator|.
name|sort
argument_list|(
name|di
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
comment|// must update cache since we modified locations array
name|lb
operator|.
name|updateCachedStorageInfo
argument_list|()
expr_stmt|;
comment|// must update block indices and block tokens respectively
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|di
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|lsb
operator|.
name|getBlockIndices
argument_list|()
index|[
name|i
index|]
operator|=
name|locToIndex
operator|.
name|get
argument_list|(
name|di
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|lsb
operator|.
name|getBlockTokens
argument_list|()
index|[
name|i
index|]
operator|=
name|locToToken
operator|.
name|get
argument_list|(
name|di
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Move decommissioned/stale datanodes to the bottom. Also, sort nodes by    * network distance.    *    * @param lb located block    * @param targetHost target host    * @param comparator dn comparator    */
DECL|method|sortLocatedBlock (final LocatedBlock lb, String targetHost, Comparator<DatanodeInfo> comparator)
specifier|private
name|void
name|sortLocatedBlock
parameter_list|(
specifier|final
name|LocatedBlock
name|lb
parameter_list|,
name|String
name|targetHost
parameter_list|,
name|Comparator
argument_list|<
name|DatanodeInfo
argument_list|>
name|comparator
parameter_list|)
block|{
comment|// As it is possible for the separation of node manager and datanode,
comment|// here we should get node but not datanode only .
name|boolean
name|nonDatanodeReader
init|=
literal|false
decl_stmt|;
name|Node
name|client
init|=
name|getDatanodeByHost
argument_list|(
name|targetHost
argument_list|)
decl_stmt|;
if|if
condition|(
name|client
operator|==
literal|null
condition|)
block|{
name|nonDatanodeReader
operator|=
literal|true
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|hosts
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|hosts
operator|.
name|add
argument_list|(
name|targetHost
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|resolvedHosts
init|=
name|dnsToSwitchMapping
operator|.
name|resolve
argument_list|(
name|hosts
argument_list|)
decl_stmt|;
if|if
condition|(
name|resolvedHosts
operator|!=
literal|null
operator|&&
operator|!
name|resolvedHosts
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|String
name|rName
init|=
name|resolvedHosts
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|rName
operator|!=
literal|null
condition|)
block|{
name|client
operator|=
operator|new
name|NodeBase
argument_list|(
name|rName
operator|+
name|NodeBase
operator|.
name|PATH_SEPARATOR_STR
operator|+
name|targetHost
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Node Resolution failed. Please make sure that rack "
operator|+
literal|"awareness scripts are functional."
argument_list|)
expr_stmt|;
block|}
block|}
name|DatanodeInfo
index|[]
name|di
init|=
name|lb
operator|.
name|getLocations
argument_list|()
decl_stmt|;
comment|// Move decommissioned/stale datanodes to the bottom
name|Arrays
operator|.
name|sort
argument_list|(
name|di
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
comment|// Sort nodes by network distance only for located blocks
name|int
name|lastActiveIndex
init|=
name|di
operator|.
name|length
operator|-
literal|1
decl_stmt|;
while|while
condition|(
name|lastActiveIndex
operator|>
literal|0
operator|&&
name|isInactive
argument_list|(
name|di
index|[
name|lastActiveIndex
index|]
argument_list|)
condition|)
block|{
operator|--
name|lastActiveIndex
expr_stmt|;
block|}
name|int
name|activeLen
init|=
name|lastActiveIndex
operator|+
literal|1
decl_stmt|;
if|if
condition|(
name|nonDatanodeReader
condition|)
block|{
name|networktopology
operator|.
name|sortByDistanceUsingNetworkLocation
argument_list|(
name|client
argument_list|,
name|lb
operator|.
name|getLocations
argument_list|()
argument_list|,
name|activeLen
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|networktopology
operator|.
name|sortByDistance
argument_list|(
name|client
argument_list|,
name|lb
operator|.
name|getLocations
argument_list|()
argument_list|,
name|activeLen
argument_list|)
expr_stmt|;
block|}
comment|// must update cache since we modified locations array
name|lb
operator|.
name|updateCachedStorageInfo
argument_list|()
expr_stmt|;
block|}
comment|/** @return the datanode descriptor for the host. */
DECL|method|getDatanodeByHost (final String host)
specifier|public
name|DatanodeDescriptor
name|getDatanodeByHost
parameter_list|(
specifier|final
name|String
name|host
parameter_list|)
block|{
return|return
name|host2DatanodeMap
operator|.
name|getDatanodeByHost
argument_list|(
name|host
argument_list|)
return|;
block|}
comment|/** @return the datanode descriptor for the host. */
DECL|method|getDatanodeByXferAddr (String host, int xferPort)
specifier|public
name|DatanodeDescriptor
name|getDatanodeByXferAddr
parameter_list|(
name|String
name|host
parameter_list|,
name|int
name|xferPort
parameter_list|)
block|{
return|return
name|host2DatanodeMap
operator|.
name|getDatanodeByXferAddr
argument_list|(
name|host
argument_list|,
name|xferPort
argument_list|)
return|;
block|}
comment|/** @return the datanode descriptors for all nodes. */
DECL|method|getDatanodes ()
specifier|public
name|Set
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|getDatanodes
parameter_list|()
block|{
specifier|final
name|Set
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|datanodes
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|datanodes
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|datanodeMap
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|datanodes
return|;
block|}
comment|/** @return the Host2NodesMap */
DECL|method|getHost2DatanodeMap ()
specifier|public
name|Host2NodesMap
name|getHost2DatanodeMap
parameter_list|()
block|{
return|return
name|this
operator|.
name|host2DatanodeMap
return|;
block|}
comment|/**    * Given datanode address or host name, returns the DatanodeDescriptor for the    * same, or if it doesn't find the datanode, it looks for a machine local and    * then rack local datanode, if a rack local datanode is not possible either,    * it returns the DatanodeDescriptor of any random node in the cluster.    *    * @param address hostaddress:transfer address    * @return the best match for the given datanode    */
DECL|method|getDatanodeDescriptor (String address)
name|DatanodeDescriptor
name|getDatanodeDescriptor
parameter_list|(
name|String
name|address
parameter_list|)
block|{
name|DatanodeID
name|dnId
init|=
name|parseDNFromHostsEntry
argument_list|(
name|address
argument_list|)
decl_stmt|;
name|String
name|host
init|=
name|dnId
operator|.
name|getIpAddr
argument_list|()
decl_stmt|;
name|int
name|xferPort
init|=
name|dnId
operator|.
name|getXferPort
argument_list|()
decl_stmt|;
name|DatanodeDescriptor
name|node
init|=
name|getDatanodeByXferAddr
argument_list|(
name|host
argument_list|,
name|xferPort
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
name|node
operator|=
name|getDatanodeByHost
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
name|String
name|networkLocation
init|=
name|resolveNetworkLocationWithFallBackToDefaultLocation
argument_list|(
name|dnId
argument_list|)
decl_stmt|;
comment|// If the current cluster doesn't contain the node, fallback to
comment|// something machine local and then rack local.
name|List
argument_list|<
name|Node
argument_list|>
name|rackNodes
init|=
name|getNetworkTopology
argument_list|()
operator|.
name|getDatanodesInRack
argument_list|(
name|networkLocation
argument_list|)
decl_stmt|;
if|if
condition|(
name|rackNodes
operator|!=
literal|null
condition|)
block|{
comment|// Try something machine local.
for|for
control|(
name|Node
name|rackNode
range|:
name|rackNodes
control|)
block|{
if|if
condition|(
operator|(
operator|(
name|DatanodeDescriptor
operator|)
name|rackNode
operator|)
operator|.
name|getIpAddr
argument_list|()
operator|.
name|equals
argument_list|(
name|host
argument_list|)
condition|)
block|{
name|node
operator|=
operator|(
name|DatanodeDescriptor
operator|)
name|rackNode
expr_stmt|;
break|break;
block|}
block|}
comment|// Try something rack local.
if|if
condition|(
name|node
operator|==
literal|null
operator|&&
operator|!
name|rackNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|node
operator|=
call|(
name|DatanodeDescriptor
call|)
argument_list|(
name|rackNodes
operator|.
name|get
argument_list|(
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextInt
argument_list|(
name|rackNodes
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we can't even choose rack local, just choose any node in the
comment|// cluster.
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
name|node
operator|=
operator|(
name|DatanodeDescriptor
operator|)
name|getNetworkTopology
argument_list|()
operator|.
name|chooseRandom
argument_list|(
name|NodeBase
operator|.
name|ROOT
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|node
return|;
block|}
comment|/** Get a datanode descriptor given corresponding DatanodeUUID */
DECL|method|getDatanode (final String datanodeUuid)
specifier|public
name|DatanodeDescriptor
name|getDatanode
parameter_list|(
specifier|final
name|String
name|datanodeUuid
parameter_list|)
block|{
if|if
condition|(
name|datanodeUuid
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
return|return
name|datanodeMap
operator|.
name|get
argument_list|(
name|datanodeUuid
argument_list|)
return|;
block|}
block|}
comment|/**    * Get data node by datanode ID.    *     * @param nodeID datanode ID    * @return DatanodeDescriptor or null if the node is not found.    * @throws UnregisteredNodeException    */
DECL|method|getDatanode (DatanodeID nodeID)
specifier|public
name|DatanodeDescriptor
name|getDatanode
parameter_list|(
name|DatanodeID
name|nodeID
parameter_list|)
throws|throws
name|UnregisteredNodeException
block|{
specifier|final
name|DatanodeDescriptor
name|node
init|=
name|getDatanode
argument_list|(
name|nodeID
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
return|return
literal|null
return|;
if|if
condition|(
operator|!
name|node
operator|.
name|getXferAddr
argument_list|()
operator|.
name|equals
argument_list|(
name|nodeID
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
specifier|final
name|UnregisteredNodeException
name|e
init|=
operator|new
name|UnregisteredNodeException
argument_list|(
name|nodeID
argument_list|,
name|node
argument_list|)
decl_stmt|;
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|error
argument_list|(
literal|"BLOCK* NameSystem.getDatanode: "
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return
name|node
return|;
block|}
DECL|method|getDatanodeStorageInfos ( DatanodeID[] datanodeID, String[] storageIDs, String format, Object... args)
specifier|public
name|DatanodeStorageInfo
index|[]
name|getDatanodeStorageInfos
parameter_list|(
name|DatanodeID
index|[]
name|datanodeID
parameter_list|,
name|String
index|[]
name|storageIDs
parameter_list|,
name|String
name|format
parameter_list|,
name|Object
modifier|...
name|args
parameter_list|)
throws|throws
name|UnregisteredNodeException
block|{
name|storageIDs
operator|=
name|storageIDs
operator|==
literal|null
condition|?
operator|new
name|String
index|[
literal|0
index|]
else|:
name|storageIDs
expr_stmt|;
if|if
condition|(
name|datanodeID
operator|.
name|length
operator|!=
name|storageIDs
operator|.
name|length
condition|)
block|{
comment|// Error for pre-2.0.0-alpha clients.
specifier|final
name|String
name|err
init|=
operator|(
name|storageIDs
operator|.
name|length
operator|==
literal|0
condition|?
literal|"Missing storageIDs: It is likely that the HDFS client,"
operator|+
literal|" who made this call, is running in an older version of Hadoop"
operator|+
literal|"(pre-2.0.0-alpha)  which does not support storageIDs."
else|:
literal|"Length mismatched: storageIDs.length="
operator|+
name|storageIDs
operator|.
name|length
operator|+
literal|" != "
operator|)
operator|+
literal|" datanodeID.length="
operator|+
name|datanodeID
operator|.
name|length
decl_stmt|;
throw|throw
operator|new
name|HadoopIllegalArgumentException
argument_list|(
name|err
operator|+
literal|", "
operator|+
name|String
operator|.
name|format
argument_list|(
name|format
argument_list|,
name|args
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|datanodeID
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
specifier|final
name|DatanodeStorageInfo
index|[]
name|storages
init|=
operator|new
name|DatanodeStorageInfo
index|[
name|datanodeID
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|datanodeID
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|datanodeID
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
name|DatanodeID
operator|.
name|EMPTY_DATANODE_ID
argument_list|)
condition|)
block|{
name|storages
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
specifier|final
name|DatanodeDescriptor
name|dd
init|=
name|getDatanode
argument_list|(
name|datanodeID
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|dd
operator|!=
literal|null
condition|)
block|{
name|storages
index|[
name|i
index|]
operator|=
name|dd
operator|.
name|getStorageInfo
argument_list|(
name|storageIDs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|storages
return|;
block|}
comment|/** Prints information about all datanodes. */
DECL|method|datanodeDump (final PrintWriter out)
name|void
name|datanodeDump
parameter_list|(
specifier|final
name|PrintWriter
name|out
parameter_list|)
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|DatanodeDescriptor
argument_list|>
name|sortedDatanodeMap
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|sortedDatanodeMap
operator|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|datanodeMap
argument_list|)
expr_stmt|;
block|}
name|out
operator|.
name|println
argument_list|(
literal|"Metasave: Number of datanodes: "
operator|+
name|sortedDatanodeMap
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|DatanodeDescriptor
name|node
range|:
name|sortedDatanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
name|out
operator|.
name|println
argument_list|(
name|node
operator|.
name|dumpDatanode
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Remove a datanode descriptor.    * @param nodeInfo datanode descriptor.    */
DECL|method|removeDatanode (DatanodeDescriptor nodeInfo)
specifier|private
name|void
name|removeDatanode
parameter_list|(
name|DatanodeDescriptor
name|nodeInfo
parameter_list|)
block|{
name|removeDatanode
argument_list|(
name|nodeInfo
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove a datanode descriptor.    * @param nodeInfo datanode descriptor.    */
DECL|method|removeDatanode (DatanodeDescriptor nodeInfo, boolean removeBlocksFromBlocksMap)
specifier|private
name|void
name|removeDatanode
parameter_list|(
name|DatanodeDescriptor
name|nodeInfo
parameter_list|,
name|boolean
name|removeBlocksFromBlocksMap
parameter_list|)
block|{
assert|assert
name|namesystem
operator|.
name|hasWriteLock
argument_list|()
assert|;
name|heartbeatManager
operator|.
name|removeDatanode
argument_list|(
name|nodeInfo
argument_list|)
expr_stmt|;
if|if
condition|(
name|removeBlocksFromBlocksMap
condition|)
block|{
name|blockManager
operator|.
name|removeBlocksAssociatedTo
argument_list|(
name|nodeInfo
argument_list|)
expr_stmt|;
block|}
name|networktopology
operator|.
name|remove
argument_list|(
name|nodeInfo
argument_list|)
expr_stmt|;
name|decrementVersionCount
argument_list|(
name|nodeInfo
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
name|blockManager
operator|.
name|getBlockReportLeaseManager
argument_list|()
operator|.
name|unregister
argument_list|(
name|nodeInfo
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"remove datanode "
operator|+
name|nodeInfo
argument_list|)
expr_stmt|;
block|}
name|blockManager
operator|.
name|checkSafeMode
argument_list|()
expr_stmt|;
block|}
comment|/**    * Remove a datanode    * @throws UnregisteredNodeException     */
DECL|method|removeDatanode (final DatanodeID node)
specifier|public
name|void
name|removeDatanode
parameter_list|(
specifier|final
name|DatanodeID
name|node
parameter_list|)
throws|throws
name|UnregisteredNodeException
block|{
name|namesystem
operator|.
name|writeLock
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|DatanodeDescriptor
name|descriptor
init|=
name|getDatanode
argument_list|(
name|node
argument_list|)
decl_stmt|;
if|if
condition|(
name|descriptor
operator|!=
literal|null
condition|)
block|{
name|removeDatanode
argument_list|(
name|descriptor
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|warn
argument_list|(
literal|"BLOCK* removeDatanode: "
operator|+
name|node
operator|+
literal|" does not exist"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|namesystem
operator|.
name|writeUnlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** Remove a dead datanode. */
DECL|method|removeDeadDatanode (final DatanodeID nodeID, boolean removeBlocksFromBlockMap)
name|void
name|removeDeadDatanode
parameter_list|(
specifier|final
name|DatanodeID
name|nodeID
parameter_list|,
name|boolean
name|removeBlocksFromBlockMap
parameter_list|)
block|{
name|DatanodeDescriptor
name|d
decl_stmt|;
try|try
block|{
name|d
operator|=
name|getDatanode
argument_list|(
name|nodeID
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|d
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|d
operator|!=
literal|null
operator|&&
name|isDatanodeDead
argument_list|(
name|d
argument_list|)
condition|)
block|{
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|info
argument_list|(
literal|"BLOCK* removeDeadDatanode: lost heartbeat from "
operator|+
name|d
operator|+
literal|", removeBlocksFromBlockMap "
operator|+
name|removeBlocksFromBlockMap
argument_list|)
expr_stmt|;
name|removeDatanode
argument_list|(
name|d
argument_list|,
name|removeBlocksFromBlockMap
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Is the datanode dead? */
DECL|method|isDatanodeDead (DatanodeDescriptor node)
name|boolean
name|isDatanodeDead
parameter_list|(
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
return|return
operator|(
name|node
operator|.
name|getLastUpdateMonotonic
argument_list|()
operator|<
operator|(
name|monotonicNow
argument_list|()
operator|-
name|heartbeatExpireInterval
operator|)
operator|)
return|;
block|}
comment|/** Add a datanode. */
DECL|method|addDatanode (final DatanodeDescriptor node)
name|void
name|addDatanode
parameter_list|(
specifier|final
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
comment|// To keep host2DatanodeMap consistent with datanodeMap,
comment|// remove  from host2DatanodeMap the datanodeDescriptor removed
comment|// from datanodeMap before adding node to host2DatanodeMap.
synchronized|synchronized
init|(
name|this
init|)
block|{
name|host2DatanodeMap
operator|.
name|remove
argument_list|(
name|datanodeMap
operator|.
name|put
argument_list|(
name|node
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|,
name|node
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|networktopology
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
comment|// may throw InvalidTopologyException
name|host2DatanodeMap
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|checkIfClusterIsNowMultiRack
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|resolveUpgradeDomain
argument_list|(
name|node
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|".addDatanode: "
operator|+
literal|"node "
operator|+
name|node
operator|+
literal|" is added to datanodeMap."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Physically remove node from datanodeMap. */
DECL|method|wipeDatanode (final DatanodeID node)
specifier|private
name|void
name|wipeDatanode
parameter_list|(
specifier|final
name|DatanodeID
name|node
parameter_list|)
block|{
specifier|final
name|String
name|key
init|=
name|node
operator|.
name|getDatanodeUuid
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|host2DatanodeMap
operator|.
name|remove
argument_list|(
name|datanodeMap
operator|.
name|remove
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|".wipeDatanode("
operator|+
name|node
operator|+
literal|"): storage "
operator|+
name|key
operator|+
literal|" is removed from datanodeMap."
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|incrementVersionCount (String version)
specifier|private
name|void
name|incrementVersionCount
parameter_list|(
name|String
name|version
parameter_list|)
block|{
if|if
condition|(
name|version
operator|==
literal|null
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
name|Integer
name|count
init|=
name|this
operator|.
name|datanodesSoftwareVersions
operator|.
name|get
argument_list|(
name|version
argument_list|)
decl_stmt|;
name|count
operator|=
name|count
operator|==
literal|null
condition|?
literal|1
else|:
name|count
operator|+
literal|1
expr_stmt|;
name|this
operator|.
name|datanodesSoftwareVersions
operator|.
name|put
argument_list|(
name|version
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|decrementVersionCount (String version)
specifier|private
name|void
name|decrementVersionCount
parameter_list|(
name|String
name|version
parameter_list|)
block|{
if|if
condition|(
name|version
operator|==
literal|null
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
name|Integer
name|count
init|=
name|this
operator|.
name|datanodesSoftwareVersions
operator|.
name|get
argument_list|(
name|version
argument_list|)
decl_stmt|;
if|if
condition|(
name|count
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|count
operator|>
literal|1
condition|)
block|{
name|this
operator|.
name|datanodesSoftwareVersions
operator|.
name|put
argument_list|(
name|version
argument_list|,
name|count
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|datanodesSoftwareVersions
operator|.
name|remove
argument_list|(
name|version
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Will return true for all Datanodes which have a non-null software    * version and are considered alive (by {@link DatanodeDescriptor#isAlive()}),    * indicating the node has not yet been removed. Use {@code isAlive}    * rather than {@link DatanodeManager#isDatanodeDead(DatanodeDescriptor)}    * to ensure that the version is decremented even if the datanode    * hasn't issued a heartbeat recently.    *    * @param node The datanode in question    * @return True iff its version count should be decremented    */
DECL|method|shouldCountVersion (DatanodeDescriptor node)
specifier|private
name|boolean
name|shouldCountVersion
parameter_list|(
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
return|return
name|node
operator|.
name|getSoftwareVersion
argument_list|()
operator|!=
literal|null
operator|&&
name|node
operator|.
name|isAlive
argument_list|()
return|;
block|}
DECL|method|countSoftwareVersions ()
specifier|private
name|void
name|countSoftwareVersions
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
name|datanodesSoftwareVersions
operator|.
name|clear
argument_list|()
expr_stmt|;
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|shouldCountVersion
argument_list|(
name|dn
argument_list|)
condition|)
block|{
name|Integer
name|num
init|=
name|datanodesSoftwareVersions
operator|.
name|get
argument_list|(
name|dn
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
decl_stmt|;
name|num
operator|=
name|num
operator|==
literal|null
condition|?
literal|1
else|:
name|num
operator|+
literal|1
expr_stmt|;
name|datanodesSoftwareVersions
operator|.
name|put
argument_list|(
name|dn
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|,
name|num
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|getDatanodesSoftwareVersions ()
specifier|public
name|HashMap
argument_list|<
name|String
argument_list|,
name|Integer
argument_list|>
name|getDatanodesSoftwareVersions
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
return|return
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|this
operator|.
name|datanodesSoftwareVersions
argument_list|)
return|;
block|}
block|}
DECL|method|resolveUpgradeDomain (DatanodeDescriptor node)
name|void
name|resolveUpgradeDomain
parameter_list|(
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
name|String
name|upgradeDomain
init|=
name|hostConfigManager
operator|.
name|getUpgradeDomain
argument_list|(
name|node
argument_list|)
decl_stmt|;
if|if
condition|(
name|upgradeDomain
operator|!=
literal|null
operator|&&
name|upgradeDomain
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|node
operator|.
name|setUpgradeDomain
argument_list|(
name|upgradeDomain
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    *  Resolve a node's network location. If the DNS to switch mapping fails     *  then this method guarantees default rack location.     *  @param node to resolve to network location    *  @return network location path    */
DECL|method|resolveNetworkLocationWithFallBackToDefaultLocation ( DatanodeID node)
specifier|private
name|String
name|resolveNetworkLocationWithFallBackToDefaultLocation
parameter_list|(
name|DatanodeID
name|node
parameter_list|)
block|{
name|String
name|networkLocation
decl_stmt|;
try|try
block|{
name|networkLocation
operator|=
name|resolveNetworkLocation
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnresolvedTopologyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unresolved topology mapping. Using "
operator|+
name|NetworkTopology
operator|.
name|DEFAULT_RACK
operator|+
literal|" for host "
operator|+
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
expr_stmt|;
name|networkLocation
operator|=
name|NetworkTopology
operator|.
name|DEFAULT_RACK
expr_stmt|;
block|}
return|return
name|networkLocation
return|;
block|}
comment|/**    * Resolve a node's network location. If the DNS to switch mapping fails,     * then this method throws UnresolvedTopologyException.     * @param node to resolve to network location    * @return network location path.    * @throws UnresolvedTopologyException if the DNS to switch mapping fails     *    to resolve network location.    */
DECL|method|resolveNetworkLocation (DatanodeID node)
specifier|private
name|String
name|resolveNetworkLocation
parameter_list|(
name|DatanodeID
name|node
parameter_list|)
throws|throws
name|UnresolvedTopologyException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|names
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|dnsToSwitchMapping
operator|instanceof
name|CachedDNSToSwitchMapping
condition|)
block|{
name|names
operator|.
name|add
argument_list|(
name|node
operator|.
name|getIpAddr
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|names
operator|.
name|add
argument_list|(
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|rName
init|=
name|resolveNetworkLocation
argument_list|(
name|names
argument_list|)
decl_stmt|;
name|String
name|networkLocation
decl_stmt|;
if|if
condition|(
name|rName
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"The resolve call returned null!"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|UnresolvedTopologyException
argument_list|(
literal|"Unresolved topology mapping for host "
operator|+
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
throw|;
block|}
else|else
block|{
name|networkLocation
operator|=
name|rName
operator|.
name|get
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
return|return
name|networkLocation
return|;
block|}
comment|/**    * Resolve network locations for specified hosts    *    * @return Network locations if available, Else returns null    */
DECL|method|resolveNetworkLocation (List<String> names)
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|resolveNetworkLocation
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|names
parameter_list|)
block|{
comment|// resolve its network location
return|return
name|dnsToSwitchMapping
operator|.
name|resolve
argument_list|(
name|names
argument_list|)
return|;
block|}
comment|/**    * Resolve a node's dependencies in the network. If the DNS to switch     * mapping fails then this method returns empty list of dependencies     * @param node to get dependencies for    * @return List of dependent host names    */
DECL|method|getNetworkDependenciesWithDefault (DatanodeInfo node)
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|getNetworkDependenciesWithDefault
parameter_list|(
name|DatanodeInfo
name|node
parameter_list|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|dependencies
decl_stmt|;
try|try
block|{
name|dependencies
operator|=
name|getNetworkDependencies
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnresolvedTopologyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unresolved dependency mapping for host "
operator|+
name|node
operator|.
name|getHostName
argument_list|()
operator|+
literal|". Continuing with an empty dependency list"
argument_list|)
expr_stmt|;
name|dependencies
operator|=
name|Collections
operator|.
name|emptyList
argument_list|()
expr_stmt|;
block|}
return|return
name|dependencies
return|;
block|}
comment|/**    * Resolves a node's dependencies in the network. If the DNS to switch     * mapping fails to get dependencies, then this method throws     * UnresolvedTopologyException.     * @param node to get dependencies for    * @return List of dependent host names     * @throws UnresolvedTopologyException if the DNS to switch mapping fails    */
DECL|method|getNetworkDependencies (DatanodeInfo node)
specifier|private
name|List
argument_list|<
name|String
argument_list|>
name|getNetworkDependencies
parameter_list|(
name|DatanodeInfo
name|node
parameter_list|)
throws|throws
name|UnresolvedTopologyException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|dependencies
init|=
name|Collections
operator|.
name|emptyList
argument_list|()
decl_stmt|;
if|if
condition|(
name|dnsToSwitchMapping
operator|instanceof
name|DNSToSwitchMappingWithDependency
condition|)
block|{
comment|//Get dependencies
name|dependencies
operator|=
operator|(
operator|(
name|DNSToSwitchMappingWithDependency
operator|)
name|dnsToSwitchMapping
operator|)
operator|.
name|getDependency
argument_list|(
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|dependencies
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"The dependency call returned null for host "
operator|+
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|UnresolvedTopologyException
argument_list|(
literal|"The dependency call returned "
operator|+
literal|"null for host "
operator|+
name|node
operator|.
name|getHostName
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
name|dependencies
return|;
block|}
comment|/**    * Remove decommissioned datanode from the the list of live or dead nodes.    * This is used to not to display a decommissioned datanode to the operators.    * @param nodeList , array list of live or dead nodes.    */
DECL|method|removeDecomNodeFromList ( final List<DatanodeDescriptor> nodeList)
specifier|private
specifier|static
name|void
name|removeDecomNodeFromList
parameter_list|(
specifier|final
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|nodeList
parameter_list|)
block|{
for|for
control|(
name|Iterator
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|it
init|=
name|nodeList
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|DatanodeDescriptor
name|node
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|node
operator|.
name|isDecommissioned
argument_list|()
condition|)
block|{
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Decommission the node if it is in the host exclude list.    *    * @param nodeReg datanode    */
DECL|method|startAdminOperationIfNecessary (DatanodeDescriptor nodeReg)
name|void
name|startAdminOperationIfNecessary
parameter_list|(
name|DatanodeDescriptor
name|nodeReg
parameter_list|)
block|{
name|long
name|maintenanceExpireTimeInMS
init|=
name|hostConfigManager
operator|.
name|getMaintenanceExpirationTimeInMS
argument_list|(
name|nodeReg
argument_list|)
decl_stmt|;
comment|// If the registered node is in exclude list, then decommission it
if|if
condition|(
name|getHostConfigManager
argument_list|()
operator|.
name|isExcluded
argument_list|(
name|nodeReg
argument_list|)
condition|)
block|{
name|datanodeAdminManager
operator|.
name|startDecommission
argument_list|(
name|nodeReg
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|nodeReg
operator|.
name|maintenanceNotExpired
argument_list|(
name|maintenanceExpireTimeInMS
argument_list|)
condition|)
block|{
name|datanodeAdminManager
operator|.
name|startMaintenance
argument_list|(
name|nodeReg
argument_list|,
name|maintenanceExpireTimeInMS
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Register the given datanode with the namenode. NB: the given    * registration is mutated and given back to the datanode.    *    * @param nodeReg the datanode registration    * @throws DisallowedDatanodeException if the registration request is    *    denied because the datanode does not match includes/excludes    * @throws UnresolvedTopologyException if the registration request is     *    denied because resolving datanode network location fails.    */
DECL|method|registerDatanode (DatanodeRegistration nodeReg)
specifier|public
name|void
name|registerDatanode
parameter_list|(
name|DatanodeRegistration
name|nodeReg
parameter_list|)
throws|throws
name|DisallowedDatanodeException
throws|,
name|UnresolvedTopologyException
block|{
name|InetAddress
name|dnAddress
init|=
name|Server
operator|.
name|getRemoteIp
argument_list|()
decl_stmt|;
if|if
condition|(
name|dnAddress
operator|!=
literal|null
condition|)
block|{
comment|// Mostly called inside an RPC, update ip and peer hostname
name|String
name|hostname
init|=
name|dnAddress
operator|.
name|getHostName
argument_list|()
decl_stmt|;
name|String
name|ip
init|=
name|dnAddress
operator|.
name|getHostAddress
argument_list|()
decl_stmt|;
if|if
condition|(
name|checkIpHostnameInRegistration
operator|&&
operator|!
name|isNameResolved
argument_list|(
name|dnAddress
argument_list|)
condition|)
block|{
comment|// Reject registration of unresolved datanode to prevent performance
comment|// impact of repetitive DNS lookups later.
specifier|final
name|String
name|message
init|=
literal|"hostname cannot be resolved (ip="
operator|+
name|ip
operator|+
literal|", hostname="
operator|+
name|hostname
operator|+
literal|")"
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unresolved datanode registration: "
operator|+
name|message
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|DisallowedDatanodeException
argument_list|(
name|nodeReg
argument_list|,
name|message
argument_list|)
throw|;
block|}
comment|// update node registration with the ip and hostname from rpc request
name|nodeReg
operator|.
name|setIpAddr
argument_list|(
name|ip
argument_list|)
expr_stmt|;
name|nodeReg
operator|.
name|setPeerHostName
argument_list|(
name|hostname
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|nodeReg
operator|.
name|setExportedKeys
argument_list|(
name|blockManager
operator|.
name|getBlockKeys
argument_list|()
argument_list|)
expr_stmt|;
comment|// Checks if the node is not on the hosts list.  If it is not, then
comment|// it will be disallowed from registering.
if|if
condition|(
operator|!
name|hostConfigManager
operator|.
name|isIncluded
argument_list|(
name|nodeReg
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|DisallowedDatanodeException
argument_list|(
name|nodeReg
argument_list|)
throw|;
block|}
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|info
argument_list|(
literal|"BLOCK* registerDatanode: from "
operator|+
name|nodeReg
operator|+
literal|" storage "
operator|+
name|nodeReg
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
name|DatanodeDescriptor
name|nodeS
init|=
name|getDatanode
argument_list|(
name|nodeReg
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
decl_stmt|;
name|DatanodeDescriptor
name|nodeN
init|=
name|host2DatanodeMap
operator|.
name|getDatanodeByXferAddr
argument_list|(
name|nodeReg
operator|.
name|getIpAddr
argument_list|()
argument_list|,
name|nodeReg
operator|.
name|getXferPort
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|nodeN
operator|!=
literal|null
operator|&&
name|nodeN
operator|!=
name|nodeS
condition|)
block|{
name|NameNode
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"BLOCK* registerDatanode: "
operator|+
name|nodeN
argument_list|)
expr_stmt|;
comment|// nodeN previously served a different data storage,
comment|// which is not served by anybody anymore.
name|removeDatanode
argument_list|(
name|nodeN
argument_list|)
expr_stmt|;
comment|// physically remove node from datanodeMap
name|wipeDatanode
argument_list|(
name|nodeN
argument_list|)
expr_stmt|;
name|nodeN
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|nodeS
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|nodeN
operator|==
name|nodeS
condition|)
block|{
comment|// The same datanode has been just restarted to serve the same data
comment|// storage. We do not need to remove old data blocks, the delta will
comment|// be calculated on the next block report from the datanode
if|if
condition|(
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|debug
argument_list|(
literal|"BLOCK* registerDatanode: "
operator|+
literal|"node restarted."
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// nodeS is found
comment|/* The registering datanode is a replacement node for the existing              data storage, which from now on will be served by a new node.             If this message repeats, both nodes might have same storageID              by (insanely rare) random chance. User needs to restart one of the             nodes with its data cleared (or user can just remove the StorageID             value in "VERSION" file under the data directory of the datanode,             but this is might not work if VERSION file format has changed           */
name|NameNode
operator|.
name|stateChangeLog
operator|.
name|info
argument_list|(
literal|"BLOCK* registerDatanode: "
operator|+
name|nodeS
operator|+
literal|" is replaced by "
operator|+
name|nodeReg
operator|+
literal|" with the same storageID "
operator|+
name|nodeReg
operator|.
name|getDatanodeUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// update cluster map
name|getNetworkTopology
argument_list|()
operator|.
name|remove
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldCountVersion
argument_list|(
name|nodeS
argument_list|)
condition|)
block|{
name|decrementVersionCount
argument_list|(
name|nodeS
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|nodeS
operator|.
name|updateRegInfo
argument_list|(
name|nodeReg
argument_list|)
expr_stmt|;
name|nodeS
operator|.
name|setSoftwareVersion
argument_list|(
name|nodeReg
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
name|nodeS
operator|.
name|setDisallowed
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// Node is in the include list
comment|// resolve network location
if|if
condition|(
name|this
operator|.
name|rejectUnresolvedTopologyDN
condition|)
block|{
name|nodeS
operator|.
name|setNetworkLocation
argument_list|(
name|resolveNetworkLocation
argument_list|(
name|nodeS
argument_list|)
argument_list|)
expr_stmt|;
name|nodeS
operator|.
name|setDependentHostNames
argument_list|(
name|getNetworkDependencies
argument_list|(
name|nodeS
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|nodeS
operator|.
name|setNetworkLocation
argument_list|(
name|resolveNetworkLocationWithFallBackToDefaultLocation
argument_list|(
name|nodeS
argument_list|)
argument_list|)
expr_stmt|;
name|nodeS
operator|.
name|setDependentHostNames
argument_list|(
name|getNetworkDependenciesWithDefault
argument_list|(
name|nodeS
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|getNetworkTopology
argument_list|()
operator|.
name|add
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
name|resolveUpgradeDomain
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
comment|// also treat the registration message as a heartbeat
name|heartbeatManager
operator|.
name|register
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
name|incrementVersionCount
argument_list|(
name|nodeS
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
name|startAdminOperationIfNecessary
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|removeDatanode
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
name|wipeDatanode
argument_list|(
name|nodeS
argument_list|)
expr_stmt|;
name|countSoftwareVersions
argument_list|()
expr_stmt|;
block|}
block|}
return|return;
block|}
name|DatanodeDescriptor
name|nodeDescr
init|=
operator|new
name|DatanodeDescriptor
argument_list|(
name|nodeReg
argument_list|,
name|NetworkTopology
operator|.
name|DEFAULT_RACK
argument_list|)
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// resolve network location
if|if
condition|(
name|this
operator|.
name|rejectUnresolvedTopologyDN
condition|)
block|{
name|nodeDescr
operator|.
name|setNetworkLocation
argument_list|(
name|resolveNetworkLocation
argument_list|(
name|nodeDescr
argument_list|)
argument_list|)
expr_stmt|;
name|nodeDescr
operator|.
name|setDependentHostNames
argument_list|(
name|getNetworkDependencies
argument_list|(
name|nodeDescr
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|nodeDescr
operator|.
name|setNetworkLocation
argument_list|(
name|resolveNetworkLocationWithFallBackToDefaultLocation
argument_list|(
name|nodeDescr
argument_list|)
argument_list|)
expr_stmt|;
name|nodeDescr
operator|.
name|setDependentHostNames
argument_list|(
name|getNetworkDependenciesWithDefault
argument_list|(
name|nodeDescr
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|networktopology
operator|.
name|add
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|nodeDescr
operator|.
name|setSoftwareVersion
argument_list|(
name|nodeReg
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
name|resolveUpgradeDomain
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
comment|// register new datanode
name|addDatanode
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|blockManager
operator|.
name|getBlockReportLeaseManager
argument_list|()
operator|.
name|register
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
comment|// also treat the registration message as a heartbeat
comment|// no need to update its timestamp
comment|// because its is done when the descriptor is created
name|heartbeatManager
operator|.
name|addDatanode
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|heartbeatManager
operator|.
name|updateDnStat
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|incrementVersionCount
argument_list|(
name|nodeReg
operator|.
name|getSoftwareVersion
argument_list|()
argument_list|)
expr_stmt|;
name|startAdminOperationIfNecessary
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|removeDatanode
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|wipeDatanode
argument_list|(
name|nodeDescr
argument_list|)
expr_stmt|;
name|countSoftwareVersions
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InvalidTopologyException
name|e
parameter_list|)
block|{
comment|// If the network location is invalid, clear the cached mappings
comment|// so that we have a chance to re-add this DataNode with the
comment|// correct network location later.
name|List
argument_list|<
name|String
argument_list|>
name|invalidNodeNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|3
argument_list|)
decl_stmt|;
comment|// clear cache for nodes in IP or Hostname
name|invalidNodeNames
operator|.
name|add
argument_list|(
name|nodeReg
operator|.
name|getIpAddr
argument_list|()
argument_list|)
expr_stmt|;
name|invalidNodeNames
operator|.
name|add
argument_list|(
name|nodeReg
operator|.
name|getHostName
argument_list|()
argument_list|)
expr_stmt|;
name|invalidNodeNames
operator|.
name|add
argument_list|(
name|nodeReg
operator|.
name|getPeerHostName
argument_list|()
argument_list|)
expr_stmt|;
name|dnsToSwitchMapping
operator|.
name|reloadCachedMappings
argument_list|(
name|invalidNodeNames
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Rereads conf to get hosts and exclude list file names.    * Rereads the files to update the hosts and exclude lists.  It    * checks if any of the hosts have changed states:    */
DECL|method|refreshNodes (final Configuration conf)
specifier|public
name|void
name|refreshNodes
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|refreshHostsReader
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|namesystem
operator|.
name|writeLock
argument_list|()
expr_stmt|;
try|try
block|{
name|refreshDatanodes
argument_list|()
expr_stmt|;
name|countSoftwareVersions
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|namesystem
operator|.
name|writeUnlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** Reread include/exclude files. */
DECL|method|refreshHostsReader (Configuration conf)
specifier|private
name|void
name|refreshHostsReader
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Reread the conf to get dfs.hosts and dfs.hosts.exclude filenames.
comment|// Update the file names and refresh internal includes and excludes list.
if|if
condition|(
name|conf
operator|==
literal|null
condition|)
block|{
name|conf
operator|=
operator|new
name|HdfsConfiguration
argument_list|()
expr_stmt|;
name|this
operator|.
name|hostConfigManager
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|hostConfigManager
operator|.
name|refresh
argument_list|()
expr_stmt|;
block|}
comment|/**    * Reload datanode membership and the desired admin operations from    * host files. If a node isn't allowed, hostConfigManager.isIncluded returns    * false and the node can't be used.    * If a node is allowed and the desired admin operation is defined,    * it will transition to the desired admin state.    * If a node is allowed and upgrade domain is defined,    * the upgrade domain will be set on the node.    * To use maintenance mode or upgrade domain, set    * DFS_NAMENODE_HOSTS_PROVIDER_CLASSNAME_KEY to    * CombinedHostFileManager.class.    */
DECL|method|refreshDatanodes ()
specifier|private
name|void
name|refreshDatanodes
parameter_list|()
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|DatanodeDescriptor
argument_list|>
name|copy
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|copy
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|datanodeMap
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|DatanodeDescriptor
name|node
range|:
name|copy
operator|.
name|values
argument_list|()
control|)
block|{
comment|// Check if not include.
if|if
condition|(
operator|!
name|hostConfigManager
operator|.
name|isIncluded
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|node
operator|.
name|setDisallowed
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|long
name|maintenanceExpireTimeInMS
init|=
name|hostConfigManager
operator|.
name|getMaintenanceExpirationTimeInMS
argument_list|(
name|node
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|.
name|maintenanceNotExpired
argument_list|(
name|maintenanceExpireTimeInMS
argument_list|)
condition|)
block|{
name|datanodeAdminManager
operator|.
name|startMaintenance
argument_list|(
name|node
argument_list|,
name|maintenanceExpireTimeInMS
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|hostConfigManager
operator|.
name|isExcluded
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|datanodeAdminManager
operator|.
name|startDecommission
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|datanodeAdminManager
operator|.
name|stopMaintenance
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|datanodeAdminManager
operator|.
name|stopDecommission
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
block|}
name|node
operator|.
name|setUpgradeDomain
argument_list|(
name|hostConfigManager
operator|.
name|getUpgradeDomain
argument_list|(
name|node
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** @return the number of live datanodes. */
DECL|method|getNumLiveDataNodes ()
specifier|public
name|int
name|getNumLiveDataNodes
parameter_list|()
block|{
name|int
name|numLive
init|=
literal|0
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|isDatanodeDead
argument_list|(
name|dn
argument_list|)
condition|)
block|{
name|numLive
operator|++
expr_stmt|;
block|}
block|}
block|}
return|return
name|numLive
return|;
block|}
comment|/** @return the number of dead datanodes. */
DECL|method|getNumDeadDataNodes ()
specifier|public
name|int
name|getNumDeadDataNodes
parameter_list|()
block|{
return|return
name|getDatanodeListForReport
argument_list|(
name|DatanodeReportType
operator|.
name|DEAD
argument_list|)
operator|.
name|size
argument_list|()
return|;
block|}
comment|/** @return list of datanodes where decommissioning is in progress. */
DECL|method|getDecommissioningNodes ()
specifier|public
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|getDecommissioningNodes
parameter_list|()
block|{
comment|// There is no need to take namesystem reader lock as
comment|// getDatanodeListForReport will synchronize on datanodeMap
comment|// A decommissioning DN may be "alive" or "dead".
return|return
name|getDatanodeListForReport
argument_list|(
name|DatanodeReportType
operator|.
name|DECOMMISSIONING
argument_list|)
return|;
block|}
comment|/** @return list of datanodes that are entering maintenance. */
DECL|method|getEnteringMaintenanceNodes ()
specifier|public
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|getEnteringMaintenanceNodes
parameter_list|()
block|{
return|return
name|getDatanodeListForReport
argument_list|(
name|DatanodeReportType
operator|.
name|ENTERING_MAINTENANCE
argument_list|)
return|;
block|}
comment|/* Getter and Setter for stale DataNodes related attributes */
comment|/**    * Whether stale datanodes should be avoided as targets on the write path.    * The result of this function may change if the number of stale datanodes    * eclipses a configurable threshold.    *     * @return whether stale datanodes should be avoided on the write path    */
DECL|method|shouldAvoidStaleDataNodesForWrite ()
specifier|public
name|boolean
name|shouldAvoidStaleDataNodesForWrite
parameter_list|()
block|{
comment|// If # stale exceeds maximum staleness ratio, disable stale
comment|// datanode avoidance on the write path
return|return
name|avoidStaleDataNodesForWrite
operator|&&
operator|(
name|numStaleNodes
operator|<=
name|heartbeatManager
operator|.
name|getLiveDatanodeCount
argument_list|()
operator|*
name|ratioUseStaleDataNodesForWrite
operator|)
return|;
block|}
DECL|method|getBlocksPerPostponedMisreplicatedBlocksRescan ()
specifier|public
name|long
name|getBlocksPerPostponedMisreplicatedBlocksRescan
parameter_list|()
block|{
return|return
name|blocksPerPostponedMisreplicatedBlocksRescan
return|;
block|}
comment|/**    * @return The time interval used to mark DataNodes as stale.    */
DECL|method|getStaleInterval ()
name|long
name|getStaleInterval
parameter_list|()
block|{
return|return
name|staleInterval
return|;
block|}
DECL|method|getHeartbeatInterval ()
specifier|public
name|long
name|getHeartbeatInterval
parameter_list|()
block|{
return|return
name|this
operator|.
name|heartbeatIntervalSeconds
return|;
block|}
DECL|method|getHeartbeatRecheckInterval ()
specifier|public
name|long
name|getHeartbeatRecheckInterval
parameter_list|()
block|{
return|return
name|this
operator|.
name|heartbeatRecheckInterval
return|;
block|}
comment|/**    * Set the number of current stale DataNodes. The HeartbeatManager got this    * number based on DataNodes' heartbeats.    *     * @param numStaleNodes    *          The number of stale DataNodes to be set.    */
DECL|method|setNumStaleNodes (int numStaleNodes)
name|void
name|setNumStaleNodes
parameter_list|(
name|int
name|numStaleNodes
parameter_list|)
block|{
name|this
operator|.
name|numStaleNodes
operator|=
name|numStaleNodes
expr_stmt|;
block|}
comment|/**    * @return Return the current number of stale DataNodes (detected by    * HeartbeatManager).     */
DECL|method|getNumStaleNodes ()
specifier|public
name|int
name|getNumStaleNodes
parameter_list|()
block|{
return|return
name|this
operator|.
name|numStaleNodes
return|;
block|}
comment|/**    * Get the number of content stale storages.    */
DECL|method|getNumStaleStorages ()
specifier|public
name|int
name|getNumStaleStorages
parameter_list|()
block|{
return|return
name|numStaleStorages
return|;
block|}
comment|/**    * Set the number of content stale storages.    *    * @param numStaleStorages The number of content stale storages.    */
DECL|method|setNumStaleStorages (int numStaleStorages)
name|void
name|setNumStaleStorages
parameter_list|(
name|int
name|numStaleStorages
parameter_list|)
block|{
name|this
operator|.
name|numStaleStorages
operator|=
name|numStaleStorages
expr_stmt|;
block|}
comment|/** Fetch live and dead datanodes. */
DECL|method|fetchDatanodes (final List<DatanodeDescriptor> live, final List<DatanodeDescriptor> dead, final boolean removeDecommissionNode)
specifier|public
name|void
name|fetchDatanodes
parameter_list|(
specifier|final
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|live
parameter_list|,
specifier|final
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|dead
parameter_list|,
specifier|final
name|boolean
name|removeDecommissionNode
parameter_list|)
block|{
if|if
condition|(
name|live
operator|==
literal|null
operator|&&
name|dead
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|HadoopIllegalArgumentException
argument_list|(
literal|"Both live and dead lists are null"
argument_list|)
throw|;
block|}
comment|// There is no need to take namesystem reader lock as
comment|// getDatanodeListForReport will synchronize on datanodeMap
specifier|final
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|results
init|=
name|getDatanodeListForReport
argument_list|(
name|DatanodeReportType
operator|.
name|ALL
argument_list|)
decl_stmt|;
for|for
control|(
name|DatanodeDescriptor
name|node
range|:
name|results
control|)
block|{
if|if
condition|(
name|isDatanodeDead
argument_list|(
name|node
argument_list|)
condition|)
block|{
if|if
condition|(
name|dead
operator|!=
literal|null
condition|)
block|{
name|dead
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|live
operator|!=
literal|null
condition|)
block|{
name|live
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|removeDecommissionNode
condition|)
block|{
if|if
condition|(
name|live
operator|!=
literal|null
condition|)
block|{
name|removeDecomNodeFromList
argument_list|(
name|live
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dead
operator|!=
literal|null
condition|)
block|{
name|removeDecomNodeFromList
argument_list|(
name|dead
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Check if the cluster now consists of multiple racks. If it does, and this    * is the first time it's consisted of multiple racks, then process blocks    * that may now be misreplicated.    *     * @param node DN which caused cluster to become multi-rack. Used for logging.    */
annotation|@
name|VisibleForTesting
DECL|method|checkIfClusterIsNowMultiRack (DatanodeDescriptor node)
name|void
name|checkIfClusterIsNowMultiRack
parameter_list|(
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
if|if
condition|(
operator|!
name|hasClusterEverBeenMultiRack
operator|&&
name|networktopology
operator|.
name|getNumOfRacks
argument_list|()
operator|>
literal|1
condition|)
block|{
name|String
name|message
init|=
literal|"DN "
operator|+
name|node
operator|+
literal|" joining cluster has expanded a formerly "
operator|+
literal|"single-rack cluster to be multi-rack. "
decl_stmt|;
if|if
condition|(
name|blockManager
operator|.
name|isPopulatingReplQueues
argument_list|()
condition|)
block|{
name|message
operator|+=
literal|"Re-checking all blocks for replication, since they should "
operator|+
literal|"now be replicated cross-rack"
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|message
operator|+=
literal|"Not checking for mis-replicated blocks because this NN is "
operator|+
literal|"not yet processing repl queues."
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
name|hasClusterEverBeenMultiRack
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|blockManager
operator|.
name|isPopulatingReplQueues
argument_list|()
condition|)
block|{
name|blockManager
operator|.
name|processMisReplicatedBlocks
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Parse a DatanodeID from a hosts file entry    * @param hostLine of form [hostname|ip][:port]?    * @return DatanodeID constructed from the given string    */
DECL|method|parseDNFromHostsEntry (String hostLine)
specifier|private
name|DatanodeID
name|parseDNFromHostsEntry
parameter_list|(
name|String
name|hostLine
parameter_list|)
block|{
name|DatanodeID
name|dnId
decl_stmt|;
name|String
name|hostStr
decl_stmt|;
name|int
name|port
decl_stmt|;
name|int
name|idx
init|=
name|hostLine
operator|.
name|indexOf
argument_list|(
literal|':'
argument_list|)
decl_stmt|;
if|if
condition|(
operator|-
literal|1
operator|==
name|idx
condition|)
block|{
name|hostStr
operator|=
name|hostLine
expr_stmt|;
name|port
operator|=
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DEFAULT_PORT
expr_stmt|;
block|}
else|else
block|{
name|hostStr
operator|=
name|hostLine
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|idx
argument_list|)
expr_stmt|;
name|port
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|hostLine
operator|.
name|substring
argument_list|(
name|idx
operator|+
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|InetAddresses
operator|.
name|isInetAddress
argument_list|(
name|hostStr
argument_list|)
condition|)
block|{
comment|// The IP:port is sufficient for listing in a report
name|dnId
operator|=
operator|new
name|DatanodeID
argument_list|(
name|hostStr
argument_list|,
literal|""
argument_list|,
literal|""
argument_list|,
name|port
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_DEFAULT_PORT
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTPS_DEFAULT_PORT
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_IPC_DEFAULT_PORT
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|ipAddr
init|=
literal|""
decl_stmt|;
try|try
block|{
name|ipAddr
operator|=
name|InetAddress
operator|.
name|getByName
argument_list|(
name|hostStr
argument_list|)
operator|.
name|getHostAddress
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnknownHostException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid hostname "
operator|+
name|hostStr
operator|+
literal|" in hosts file"
argument_list|)
expr_stmt|;
block|}
name|dnId
operator|=
operator|new
name|DatanodeID
argument_list|(
name|ipAddr
argument_list|,
name|hostStr
argument_list|,
literal|""
argument_list|,
name|port
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTP_DEFAULT_PORT
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_HTTPS_DEFAULT_PORT
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_IPC_DEFAULT_PORT
argument_list|)
expr_stmt|;
block|}
return|return
name|dnId
return|;
block|}
comment|/** For generating datanode reports */
DECL|method|getDatanodeListForReport ( final DatanodeReportType type)
specifier|public
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|getDatanodeListForReport
parameter_list|(
specifier|final
name|DatanodeReportType
name|type
parameter_list|)
block|{
specifier|final
name|boolean
name|listLiveNodes
init|=
name|type
operator|==
name|DatanodeReportType
operator|.
name|ALL
operator|||
name|type
operator|==
name|DatanodeReportType
operator|.
name|LIVE
decl_stmt|;
specifier|final
name|boolean
name|listDeadNodes
init|=
name|type
operator|==
name|DatanodeReportType
operator|.
name|ALL
operator|||
name|type
operator|==
name|DatanodeReportType
operator|.
name|DEAD
decl_stmt|;
specifier|final
name|boolean
name|listDecommissioningNodes
init|=
name|type
operator|==
name|DatanodeReportType
operator|.
name|ALL
operator|||
name|type
operator|==
name|DatanodeReportType
operator|.
name|DECOMMISSIONING
decl_stmt|;
specifier|final
name|boolean
name|listEnteringMaintenanceNodes
init|=
name|type
operator|==
name|DatanodeReportType
operator|.
name|ALL
operator|||
name|type
operator|==
name|DatanodeReportType
operator|.
name|ENTERING_MAINTENANCE
decl_stmt|;
specifier|final
name|boolean
name|listInMaintenanceNodes
init|=
name|type
operator|==
name|DatanodeReportType
operator|.
name|ALL
operator|||
name|type
operator|==
name|DatanodeReportType
operator|.
name|IN_MAINTENANCE
decl_stmt|;
name|ArrayList
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|nodes
decl_stmt|;
specifier|final
name|HostSet
name|foundNodes
init|=
operator|new
name|HostSet
argument_list|()
decl_stmt|;
specifier|final
name|Iterable
argument_list|<
name|InetSocketAddress
argument_list|>
name|includedNodes
init|=
name|hostConfigManager
operator|.
name|getIncludes
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|nodes
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|datanodeMap
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
specifier|final
name|boolean
name|isDead
init|=
name|isDatanodeDead
argument_list|(
name|dn
argument_list|)
decl_stmt|;
specifier|final
name|boolean
name|isDecommissioning
init|=
name|dn
operator|.
name|isDecommissionInProgress
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|isEnteringMaintenance
init|=
name|dn
operator|.
name|isEnteringMaintenance
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|isInMaintenance
init|=
name|dn
operator|.
name|isInMaintenance
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
operator|(
name|listLiveNodes
operator|&&
operator|!
name|isDead
operator|)
operator|||
operator|(
name|listDeadNodes
operator|&&
name|isDead
operator|)
operator|||
operator|(
name|listDecommissioningNodes
operator|&&
name|isDecommissioning
operator|)
operator|||
operator|(
name|listEnteringMaintenanceNodes
operator|&&
name|isEnteringMaintenance
operator|)
operator|||
operator|(
name|listInMaintenanceNodes
operator|&&
name|isInMaintenance
operator|)
operator|)
operator|&&
name|hostConfigManager
operator|.
name|isIncluded
argument_list|(
name|dn
argument_list|)
condition|)
block|{
name|nodes
operator|.
name|add
argument_list|(
name|dn
argument_list|)
expr_stmt|;
block|}
name|foundNodes
operator|.
name|add
argument_list|(
name|dn
operator|.
name|getResolvedAddress
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|Collections
operator|.
name|sort
argument_list|(
name|nodes
argument_list|)
expr_stmt|;
if|if
condition|(
name|listDeadNodes
condition|)
block|{
for|for
control|(
name|InetSocketAddress
name|addr
range|:
name|includedNodes
control|)
block|{
if|if
condition|(
name|foundNodes
operator|.
name|matchedBy
argument_list|(
name|addr
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|// The remaining nodes are ones that are referenced by the hosts
comment|// files but that we do not know about, ie that we have never
comment|// head from. Eg. an entry that is no longer part of the cluster
comment|// or a bogus entry was given in the hosts files
comment|//
comment|// If the host file entry specified the xferPort, we use that.
comment|// Otherwise, we guess that it is the default xfer port.
comment|// We can't ask the DataNode what it had configured, because it's
comment|// dead.
name|DatanodeDescriptor
name|dn
init|=
operator|new
name|DatanodeDescriptor
argument_list|(
operator|new
name|DatanodeID
argument_list|(
name|addr
operator|.
name|getAddress
argument_list|()
operator|.
name|getHostAddress
argument_list|()
argument_list|,
name|addr
operator|.
name|getHostName
argument_list|()
argument_list|,
literal|""
argument_list|,
name|addr
operator|.
name|getPort
argument_list|()
operator|==
literal|0
condition|?
name|defaultXferPort
else|:
name|addr
operator|.
name|getPort
argument_list|()
argument_list|,
name|defaultInfoPort
argument_list|,
name|defaultInfoSecurePort
argument_list|,
name|defaultIpcPort
argument_list|)
argument_list|)
decl_stmt|;
name|setDatanodeDead
argument_list|(
name|dn
argument_list|)
expr_stmt|;
if|if
condition|(
name|hostConfigManager
operator|.
name|isExcluded
argument_list|(
name|dn
argument_list|)
condition|)
block|{
name|dn
operator|.
name|setDecommissioned
argument_list|()
expr_stmt|;
block|}
name|nodes
operator|.
name|add
argument_list|(
name|dn
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"getDatanodeListForReport with "
operator|+
literal|"includedNodes = "
operator|+
name|hostConfigManager
operator|.
name|getIncludes
argument_list|()
operator|+
literal|", excludedNodes = "
operator|+
name|hostConfigManager
operator|.
name|getExcludes
argument_list|()
operator|+
literal|", foundNodes = "
operator|+
name|foundNodes
operator|+
literal|", nodes = "
operator|+
name|nodes
argument_list|)
expr_stmt|;
block|}
return|return
name|nodes
return|;
block|}
comment|/**    * Checks if name resolution was successful for the given address.  If IP    * address and host name are the same, then it means name resolution has    * failed.  As a special case, local addresses are also considered    * acceptable.  This is particularly important on Windows, where 127.0.0.1 does    * not resolve to "localhost".    *    * @param address InetAddress to check    * @return boolean true if name resolution successful or address is local    */
DECL|method|isNameResolved (InetAddress address)
specifier|private
specifier|static
name|boolean
name|isNameResolved
parameter_list|(
name|InetAddress
name|address
parameter_list|)
block|{
name|String
name|hostname
init|=
name|address
operator|.
name|getHostName
argument_list|()
decl_stmt|;
name|String
name|ip
init|=
name|address
operator|.
name|getHostAddress
argument_list|()
decl_stmt|;
return|return
operator|!
name|hostname
operator|.
name|equals
argument_list|(
name|ip
argument_list|)
operator|||
name|NetUtils
operator|.
name|isLocalAddress
argument_list|(
name|address
argument_list|)
return|;
block|}
DECL|method|setDatanodeDead (DatanodeDescriptor node)
specifier|private
name|void
name|setDatanodeDead
parameter_list|(
name|DatanodeDescriptor
name|node
parameter_list|)
block|{
name|node
operator|.
name|setLastUpdate
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|node
operator|.
name|setLastUpdateMonotonic
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
DECL|method|getBlockRecoveryCommand (String blockPoolId, DatanodeDescriptor nodeinfo)
specifier|private
name|BlockRecoveryCommand
name|getBlockRecoveryCommand
parameter_list|(
name|String
name|blockPoolId
parameter_list|,
name|DatanodeDescriptor
name|nodeinfo
parameter_list|)
block|{
name|BlockInfo
index|[]
name|blocks
init|=
name|nodeinfo
operator|.
name|getLeaseRecoveryCommand
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
decl_stmt|;
if|if
condition|(
name|blocks
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|BlockRecoveryCommand
name|brCommand
init|=
operator|new
name|BlockRecoveryCommand
argument_list|(
name|blocks
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|BlockInfo
name|b
range|:
name|blocks
control|)
block|{
name|BlockUnderConstructionFeature
name|uc
init|=
name|b
operator|.
name|getUnderConstructionFeature
argument_list|()
decl_stmt|;
assert|assert
name|uc
operator|!=
literal|null
assert|;
specifier|final
name|DatanodeStorageInfo
index|[]
name|storages
init|=
name|uc
operator|.
name|getExpectedStorageLocations
argument_list|()
decl_stmt|;
comment|// Skip stale nodes during recovery
specifier|final
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|recoveryLocations
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|storages
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|DatanodeStorageInfo
name|storage
range|:
name|storages
control|)
block|{
if|if
condition|(
operator|!
name|storage
operator|.
name|getDatanodeDescriptor
argument_list|()
operator|.
name|isStale
argument_list|(
name|staleInterval
argument_list|)
condition|)
block|{
name|recoveryLocations
operator|.
name|add
argument_list|(
name|storage
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we are performing a truncate recovery than set recovery fields
comment|// to old block.
name|boolean
name|truncateRecovery
init|=
name|uc
operator|.
name|getTruncateBlock
argument_list|()
operator|!=
literal|null
decl_stmt|;
name|boolean
name|copyOnTruncateRecovery
init|=
name|truncateRecovery
operator|&&
name|uc
operator|.
name|getTruncateBlock
argument_list|()
operator|.
name|getBlockId
argument_list|()
operator|!=
name|b
operator|.
name|getBlockId
argument_list|()
decl_stmt|;
name|ExtendedBlock
name|primaryBlock
init|=
operator|(
name|copyOnTruncateRecovery
operator|)
condition|?
operator|new
name|ExtendedBlock
argument_list|(
name|blockPoolId
argument_list|,
name|uc
operator|.
name|getTruncateBlock
argument_list|()
argument_list|)
else|:
operator|new
name|ExtendedBlock
argument_list|(
name|blockPoolId
argument_list|,
name|b
argument_list|)
decl_stmt|;
comment|// If we only get 1 replica after eliminating stale nodes, choose all
comment|// replicas for recovery and let the primary data node handle failures.
name|DatanodeInfo
index|[]
name|recoveryInfos
decl_stmt|;
if|if
condition|(
name|recoveryLocations
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
if|if
condition|(
name|recoveryLocations
operator|.
name|size
argument_list|()
operator|!=
name|storages
operator|.
name|length
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Skipped stale nodes for recovery : "
operator|+
operator|(
name|storages
operator|.
name|length
operator|-
name|recoveryLocations
operator|.
name|size
argument_list|()
operator|)
argument_list|)
expr_stmt|;
block|}
name|recoveryInfos
operator|=
name|DatanodeStorageInfo
operator|.
name|toDatanodeInfos
argument_list|(
name|recoveryLocations
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// If too many replicas are stale, then choose all replicas to
comment|// participate in block recovery.
name|recoveryInfos
operator|=
name|DatanodeStorageInfo
operator|.
name|toDatanodeInfos
argument_list|(
name|storages
argument_list|)
expr_stmt|;
block|}
name|RecoveringBlock
name|rBlock
decl_stmt|;
if|if
condition|(
name|truncateRecovery
condition|)
block|{
name|Block
name|recoveryBlock
init|=
operator|(
name|copyOnTruncateRecovery
operator|)
condition|?
name|b
else|:
name|uc
operator|.
name|getTruncateBlock
argument_list|()
decl_stmt|;
name|rBlock
operator|=
operator|new
name|RecoveringBlock
argument_list|(
name|primaryBlock
argument_list|,
name|recoveryInfos
argument_list|,
name|recoveryBlock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|rBlock
operator|=
operator|new
name|RecoveringBlock
argument_list|(
name|primaryBlock
argument_list|,
name|recoveryInfos
argument_list|,
name|uc
operator|.
name|getBlockRecoveryId
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|.
name|isStriped
argument_list|()
condition|)
block|{
name|rBlock
operator|=
operator|new
name|RecoveringStripedBlock
argument_list|(
name|rBlock
argument_list|,
name|uc
operator|.
name|getBlockIndices
argument_list|()
argument_list|,
operator|(
operator|(
name|BlockInfoStriped
operator|)
name|b
operator|)
operator|.
name|getErasureCodingPolicy
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|brCommand
operator|.
name|add
argument_list|(
name|rBlock
argument_list|)
expr_stmt|;
block|}
return|return
name|brCommand
return|;
block|}
DECL|method|addCacheCommands (String blockPoolId, DatanodeDescriptor nodeinfo, List<DatanodeCommand> cmds)
specifier|private
name|void
name|addCacheCommands
parameter_list|(
name|String
name|blockPoolId
parameter_list|,
name|DatanodeDescriptor
name|nodeinfo
parameter_list|,
name|List
argument_list|<
name|DatanodeCommand
argument_list|>
name|cmds
parameter_list|)
block|{
name|boolean
name|sendingCachingCommands
init|=
literal|false
decl_stmt|;
specifier|final
name|long
name|nowMs
init|=
name|monotonicNow
argument_list|()
decl_stmt|;
if|if
condition|(
name|shouldSendCachingCommands
operator|&&
operator|(
operator|(
name|nowMs
operator|-
name|nodeinfo
operator|.
name|getLastCachingDirectiveSentTimeMs
argument_list|()
operator|)
operator|>=
name|timeBetweenResendingCachingDirectivesMs
operator|)
condition|)
block|{
name|DatanodeCommand
name|pendingCacheCommand
init|=
name|getCacheCommand
argument_list|(
name|nodeinfo
operator|.
name|getPendingCached
argument_list|()
argument_list|,
name|DatanodeProtocol
operator|.
name|DNA_CACHE
argument_list|,
name|blockPoolId
argument_list|)
decl_stmt|;
if|if
condition|(
name|pendingCacheCommand
operator|!=
literal|null
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
name|pendingCacheCommand
argument_list|)
expr_stmt|;
name|sendingCachingCommands
operator|=
literal|true
expr_stmt|;
block|}
name|DatanodeCommand
name|pendingUncacheCommand
init|=
name|getCacheCommand
argument_list|(
name|nodeinfo
operator|.
name|getPendingUncached
argument_list|()
argument_list|,
name|DatanodeProtocol
operator|.
name|DNA_UNCACHE
argument_list|,
name|blockPoolId
argument_list|)
decl_stmt|;
if|if
condition|(
name|pendingUncacheCommand
operator|!=
literal|null
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
name|pendingUncacheCommand
argument_list|)
expr_stmt|;
name|sendingCachingCommands
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|sendingCachingCommands
condition|)
block|{
name|nodeinfo
operator|.
name|setLastCachingDirectiveSentTimeMs
argument_list|(
name|nowMs
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/** Handle heartbeat from datanodes. */
DECL|method|handleHeartbeat (DatanodeRegistration nodeReg, StorageReport[] reports, final String blockPoolId, long cacheCapacity, long cacheUsed, int xceiverCount, int maxTransfers, int failedVolumes, VolumeFailureSummary volumeFailureSummary, @Nonnull SlowPeerReports slowPeers, @Nonnull SlowDiskReports slowDisks)
specifier|public
name|DatanodeCommand
index|[]
name|handleHeartbeat
parameter_list|(
name|DatanodeRegistration
name|nodeReg
parameter_list|,
name|StorageReport
index|[]
name|reports
parameter_list|,
specifier|final
name|String
name|blockPoolId
parameter_list|,
name|long
name|cacheCapacity
parameter_list|,
name|long
name|cacheUsed
parameter_list|,
name|int
name|xceiverCount
parameter_list|,
name|int
name|maxTransfers
parameter_list|,
name|int
name|failedVolumes
parameter_list|,
name|VolumeFailureSummary
name|volumeFailureSummary
parameter_list|,
annotation|@
name|Nonnull
name|SlowPeerReports
name|slowPeers
parameter_list|,
annotation|@
name|Nonnull
name|SlowDiskReports
name|slowDisks
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|DatanodeDescriptor
name|nodeinfo
decl_stmt|;
try|try
block|{
name|nodeinfo
operator|=
name|getDatanode
argument_list|(
name|nodeReg
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnregisteredNodeException
name|e
parameter_list|)
block|{
return|return
operator|new
name|DatanodeCommand
index|[]
block|{
name|RegisterCommand
operator|.
name|REGISTER
block|}
return|;
block|}
comment|// Check if this datanode should actually be shutdown instead.
if|if
condition|(
name|nodeinfo
operator|!=
literal|null
operator|&&
name|nodeinfo
operator|.
name|isDisallowed
argument_list|()
condition|)
block|{
name|setDatanodeDead
argument_list|(
name|nodeinfo
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|DisallowedDatanodeException
argument_list|(
name|nodeinfo
argument_list|)
throw|;
block|}
if|if
condition|(
name|nodeinfo
operator|==
literal|null
operator|||
operator|!
name|nodeinfo
operator|.
name|isRegistered
argument_list|()
condition|)
block|{
return|return
operator|new
name|DatanodeCommand
index|[]
block|{
name|RegisterCommand
operator|.
name|REGISTER
block|}
return|;
block|}
name|heartbeatManager
operator|.
name|updateHeartbeat
argument_list|(
name|nodeinfo
argument_list|,
name|reports
argument_list|,
name|cacheCapacity
argument_list|,
name|cacheUsed
argument_list|,
name|xceiverCount
argument_list|,
name|failedVolumes
argument_list|,
name|volumeFailureSummary
argument_list|)
expr_stmt|;
comment|// If we are in safemode, do not send back any recovery / replication
comment|// requests. Don't even drain the existing queue of work.
if|if
condition|(
name|namesystem
operator|.
name|isInSafeMode
argument_list|()
condition|)
block|{
return|return
operator|new
name|DatanodeCommand
index|[
literal|0
index|]
return|;
block|}
comment|// block recovery command
specifier|final
name|BlockRecoveryCommand
name|brCommand
init|=
name|getBlockRecoveryCommand
argument_list|(
name|blockPoolId
argument_list|,
name|nodeinfo
argument_list|)
decl_stmt|;
if|if
condition|(
name|brCommand
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|DatanodeCommand
index|[]
block|{
name|brCommand
block|}
return|;
block|}
specifier|final
name|List
argument_list|<
name|DatanodeCommand
argument_list|>
name|cmds
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// check pending replication
name|List
argument_list|<
name|BlockTargetPair
argument_list|>
name|pendingList
init|=
name|nodeinfo
operator|.
name|getReplicationCommand
argument_list|(
name|maxTransfers
argument_list|)
decl_stmt|;
if|if
condition|(
name|pendingList
operator|!=
literal|null
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
operator|new
name|BlockCommand
argument_list|(
name|DatanodeProtocol
operator|.
name|DNA_TRANSFER
argument_list|,
name|blockPoolId
argument_list|,
name|pendingList
argument_list|)
argument_list|)
expr_stmt|;
name|maxTransfers
operator|-=
name|pendingList
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
comment|// check pending erasure coding tasks
name|List
argument_list|<
name|BlockECReconstructionInfo
argument_list|>
name|pendingECList
init|=
name|nodeinfo
operator|.
name|getErasureCodeCommand
argument_list|(
name|maxTransfers
argument_list|)
decl_stmt|;
if|if
condition|(
name|pendingECList
operator|!=
literal|null
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
operator|new
name|BlockECReconstructionCommand
argument_list|(
name|DNA_ERASURE_CODING_RECONSTRUCTION
argument_list|,
name|pendingECList
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// check block invalidation
name|Block
index|[]
name|blks
init|=
name|nodeinfo
operator|.
name|getInvalidateBlocks
argument_list|(
name|blockInvalidateLimit
argument_list|)
decl_stmt|;
if|if
condition|(
name|blks
operator|!=
literal|null
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
operator|new
name|BlockCommand
argument_list|(
name|DatanodeProtocol
operator|.
name|DNA_INVALIDATE
argument_list|,
name|blockPoolId
argument_list|,
name|blks
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// cache commands
name|addCacheCommands
argument_list|(
name|blockPoolId
argument_list|,
name|nodeinfo
argument_list|,
name|cmds
argument_list|)
expr_stmt|;
comment|// key update command
name|blockManager
operator|.
name|addKeyUpdateCommand
argument_list|(
name|cmds
argument_list|,
name|nodeinfo
argument_list|)
expr_stmt|;
comment|// check for balancer bandwidth update
if|if
condition|(
name|nodeinfo
operator|.
name|getBalancerBandwidth
argument_list|()
operator|>
literal|0
condition|)
block|{
name|cmds
operator|.
name|add
argument_list|(
operator|new
name|BalancerBandwidthCommand
argument_list|(
name|nodeinfo
operator|.
name|getBalancerBandwidth
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// set back to 0 to indicate that datanode has been sent the new value
name|nodeinfo
operator|.
name|setBalancerBandwidth
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|slowPeerTracker
operator|!=
literal|null
condition|)
block|{
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Double
argument_list|>
name|slowPeersMap
init|=
name|slowPeers
operator|.
name|getSlowPeers
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|slowPeersMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataNode "
operator|+
name|nodeReg
operator|+
literal|" reported slow peers: "
operator|+
name|slowPeersMap
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|slowNodeId
range|:
name|slowPeersMap
operator|.
name|keySet
argument_list|()
control|)
block|{
name|slowPeerTracker
operator|.
name|addReport
argument_list|(
name|slowNodeId
argument_list|,
name|nodeReg
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|slowDiskTracker
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|slowDisks
operator|.
name|getSlowDisks
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataNode "
operator|+
name|nodeReg
operator|+
literal|" reported slow disks: "
operator|+
name|slowDisks
operator|.
name|getSlowDisks
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|slowDiskTracker
operator|.
name|addSlowDiskReport
argument_list|(
name|nodeReg
operator|.
name|getIpcAddr
argument_list|(
literal|false
argument_list|)
argument_list|,
name|slowDisks
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|cmds
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|cmds
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeCommand
index|[
name|cmds
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
return|return
operator|new
name|DatanodeCommand
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Handles a lifeline message sent by a DataNode.    *    * @param nodeReg registration info for DataNode sending the lifeline    * @param reports storage reports from DataNode    * @param blockPoolId block pool ID    * @param cacheCapacity cache capacity at DataNode    * @param cacheUsed cache used at DataNode    * @param xceiverCount estimated count of transfer threads running at DataNode    * @param maxTransfers count of transfers running at DataNode    * @param failedVolumes count of failed volumes at DataNode    * @param volumeFailureSummary info on failed volumes at DataNode    * @throws IOException if there is an error    */
DECL|method|handleLifeline (DatanodeRegistration nodeReg, StorageReport[] reports, String blockPoolId, long cacheCapacity, long cacheUsed, int xceiverCount, int maxTransfers, int failedVolumes, VolumeFailureSummary volumeFailureSummary)
specifier|public
name|void
name|handleLifeline
parameter_list|(
name|DatanodeRegistration
name|nodeReg
parameter_list|,
name|StorageReport
index|[]
name|reports
parameter_list|,
name|String
name|blockPoolId
parameter_list|,
name|long
name|cacheCapacity
parameter_list|,
name|long
name|cacheUsed
parameter_list|,
name|int
name|xceiverCount
parameter_list|,
name|int
name|maxTransfers
parameter_list|,
name|int
name|failedVolumes
parameter_list|,
name|VolumeFailureSummary
name|volumeFailureSummary
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Received handleLifeline from nodeReg = "
operator|+
name|nodeReg
argument_list|)
expr_stmt|;
block|}
name|DatanodeDescriptor
name|nodeinfo
init|=
name|getDatanode
argument_list|(
name|nodeReg
argument_list|)
decl_stmt|;
if|if
condition|(
name|nodeinfo
operator|==
literal|null
operator|||
operator|!
name|nodeinfo
operator|.
name|isRegistered
argument_list|()
condition|)
block|{
comment|// This can happen if the lifeline message comes when DataNode is either
comment|// not registered at all or its marked dead at NameNode and expectes
comment|// re-registration. Ignore lifeline messages without registration.
comment|// Lifeline message handling can't send commands back to the DataNode to
comment|// tell it to register, so simply exit.
return|return;
block|}
if|if
condition|(
name|nodeinfo
operator|.
name|isDisallowed
argument_list|()
condition|)
block|{
comment|// This is highly unlikely, because heartbeat handling is much more
comment|// frequent and likely would have already sent the disallowed error.
comment|// Lifeline messages are not intended to send any kind of control response
comment|// back to the DataNode, so simply exit.
return|return;
block|}
name|heartbeatManager
operator|.
name|updateLifeline
argument_list|(
name|nodeinfo
argument_list|,
name|reports
argument_list|,
name|cacheCapacity
argument_list|,
name|cacheUsed
argument_list|,
name|xceiverCount
argument_list|,
name|failedVolumes
argument_list|,
name|volumeFailureSummary
argument_list|)
expr_stmt|;
block|}
comment|/**    * Convert a CachedBlockList into a DatanodeCommand with a list of blocks.    *    * @param list       The {@link CachedBlocksList}.  This function     *                   clears the list.    * @param action     The action to perform in the command.    * @param poolId     The block pool id.    * @return           A DatanodeCommand to be sent back to the DN, or null if    *                   there is nothing to be done.    */
DECL|method|getCacheCommand (CachedBlocksList list, int action, String poolId)
specifier|private
name|DatanodeCommand
name|getCacheCommand
parameter_list|(
name|CachedBlocksList
name|list
parameter_list|,
name|int
name|action
parameter_list|,
name|String
name|poolId
parameter_list|)
block|{
name|int
name|length
init|=
name|list
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|length
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Read the existing cache commands.
name|long
index|[]
name|blockIds
init|=
operator|new
name|long
index|[
name|length
index|]
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|CachedBlock
name|cachedBlock
range|:
name|list
control|)
block|{
name|blockIds
index|[
name|i
operator|++
index|]
operator|=
name|cachedBlock
operator|.
name|getBlockId
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|BlockIdCommand
argument_list|(
name|action
argument_list|,
name|poolId
argument_list|,
name|blockIds
argument_list|)
return|;
block|}
comment|/**    * Tell all datanodes to use a new, non-persistent bandwidth value for    * dfs.datanode.balance.bandwidthPerSec.    *    * A system administrator can tune the balancer bandwidth parameter    * (dfs.datanode.balance.bandwidthPerSec) dynamically by calling    * "dfsadmin -setBalanacerBandwidth newbandwidth", at which point the    * following 'bandwidth' variable gets updated with the new value for each    * node. Once the heartbeat command is issued to update the value on the    * specified datanode, this value will be set back to 0.    *    * @param bandwidth Blanacer bandwidth in bytes per second for all datanodes.    * @throws IOException    */
DECL|method|setBalancerBandwidth (long bandwidth)
specifier|public
name|void
name|setBalancerBandwidth
parameter_list|(
name|long
name|bandwidth
parameter_list|)
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|nodeInfo
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
name|nodeInfo
operator|.
name|setBalancerBandwidth
argument_list|(
name|bandwidth
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|markAllDatanodesStale ()
specifier|public
name|void
name|markAllDatanodesStale
parameter_list|()
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Marking all datandoes as stale"
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|DatanodeStorageInfo
name|storage
range|:
name|dn
operator|.
name|getStorageInfos
argument_list|()
control|)
block|{
name|storage
operator|.
name|markStaleAfterFailover
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Clear any actions that are queued up to be sent to the DNs    * on their next heartbeats. This includes block invalidations,    * recoveries, and replication requests.    */
DECL|method|clearPendingQueues ()
specifier|public
name|void
name|clearPendingQueues
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
name|dn
operator|.
name|clearBlockQueues
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Reset the lastCachingDirectiveSentTimeMs field of all the DataNodes we    * know about.    */
DECL|method|resetLastCachingDirectiveSentTime ()
specifier|public
name|void
name|resetLastCachingDirectiveSentTime
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
name|dn
operator|.
name|setLastCachingDirectiveSentTimeMs
argument_list|(
literal|0L
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|": "
operator|+
name|host2DatanodeMap
return|;
block|}
DECL|method|clearPendingCachingCommands ()
specifier|public
name|void
name|clearPendingCachingCommands
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
for|for
control|(
name|DatanodeDescriptor
name|dn
range|:
name|datanodeMap
operator|.
name|values
argument_list|()
control|)
block|{
name|dn
operator|.
name|getPendingCached
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
name|dn
operator|.
name|getPendingUncached
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|setShouldSendCachingCommands (boolean shouldSendCachingCommands)
specifier|public
name|void
name|setShouldSendCachingCommands
parameter_list|(
name|boolean
name|shouldSendCachingCommands
parameter_list|)
block|{
name|this
operator|.
name|shouldSendCachingCommands
operator|=
name|shouldSendCachingCommands
expr_stmt|;
block|}
DECL|method|newFSClusterStats ()
name|FSClusterStats
name|newFSClusterStats
parameter_list|()
block|{
return|return
operator|new
name|FSClusterStats
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|getTotalLoad
parameter_list|()
block|{
return|return
name|heartbeatManager
operator|.
name|getXceiverCount
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isAvoidingStaleDataNodesForWrite
parameter_list|()
block|{
return|return
name|shouldAvoidStaleDataNodesForWrite
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getNumDatanodesInService
parameter_list|()
block|{
return|return
name|heartbeatManager
operator|.
name|getNumDatanodesInService
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|double
name|getInServiceXceiverAverage
parameter_list|()
block|{
name|double
name|avgLoad
init|=
literal|0
decl_stmt|;
specifier|final
name|int
name|nodes
init|=
name|getNumDatanodesInService
argument_list|()
decl_stmt|;
if|if
condition|(
name|nodes
operator|!=
literal|0
condition|)
block|{
specifier|final
name|int
name|xceivers
init|=
name|heartbeatManager
operator|.
name|getInServiceXceiverCount
argument_list|()
decl_stmt|;
name|avgLoad
operator|=
operator|(
name|double
operator|)
name|xceivers
operator|/
name|nodes
expr_stmt|;
block|}
return|return
name|avgLoad
return|;
block|}
block|}
return|;
block|}
DECL|method|setHeartbeatInterval (long intervalSeconds)
specifier|public
name|void
name|setHeartbeatInterval
parameter_list|(
name|long
name|intervalSeconds
parameter_list|)
block|{
name|setHeartbeatInterval
argument_list|(
name|intervalSeconds
argument_list|,
name|this
operator|.
name|heartbeatRecheckInterval
argument_list|)
expr_stmt|;
block|}
DECL|method|setHeartbeatRecheckInterval (int recheckInterval)
specifier|public
name|void
name|setHeartbeatRecheckInterval
parameter_list|(
name|int
name|recheckInterval
parameter_list|)
block|{
name|setHeartbeatInterval
argument_list|(
name|this
operator|.
name|heartbeatIntervalSeconds
argument_list|,
name|recheckInterval
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set parameters derived from heartbeat interval.    */
DECL|method|setHeartbeatInterval (long intervalSeconds, int recheckInterval)
specifier|private
name|void
name|setHeartbeatInterval
parameter_list|(
name|long
name|intervalSeconds
parameter_list|,
name|int
name|recheckInterval
parameter_list|)
block|{
name|this
operator|.
name|heartbeatIntervalSeconds
operator|=
name|intervalSeconds
expr_stmt|;
name|this
operator|.
name|heartbeatRecheckInterval
operator|=
name|recheckInterval
expr_stmt|;
name|this
operator|.
name|heartbeatExpireInterval
operator|=
literal|2L
operator|*
name|recheckInterval
operator|+
literal|10
operator|*
literal|1000
operator|*
name|intervalSeconds
expr_stmt|;
name|this
operator|.
name|blockInvalidateLimit
operator|=
name|Math
operator|.
name|max
argument_list|(
literal|20
operator|*
call|(
name|int
call|)
argument_list|(
name|intervalSeconds
argument_list|)
argument_list|,
name|blockInvalidateLimit
argument_list|)
expr_stmt|;
block|}
comment|/**    * Retrieve information about slow peers as a JSON.    * Returns null if we are not tracking slow peers.    * @return    */
DECL|method|getSlowPeersReport ()
specifier|public
name|String
name|getSlowPeersReport
parameter_list|()
block|{
return|return
name|slowPeerTracker
operator|!=
literal|null
condition|?
name|slowPeerTracker
operator|.
name|getJson
argument_list|()
else|:
literal|null
return|;
block|}
comment|/**    * Use only for testing.    */
annotation|@
name|VisibleForTesting
DECL|method|getSlowDiskTracker ()
specifier|public
name|SlowDiskTracker
name|getSlowDiskTracker
parameter_list|()
block|{
return|return
name|slowDiskTracker
return|;
block|}
comment|/**    * Retrieve information about slow disks as a JSON.    * Returns null if we are not tracking slow disks.    * @return    */
DECL|method|getSlowDisksReport ()
specifier|public
name|String
name|getSlowDisksReport
parameter_list|()
block|{
return|return
name|slowDiskTracker
operator|!=
literal|null
condition|?
name|slowDiskTracker
operator|.
name|getSlowDiskReportAsJsonString
argument_list|()
else|:
literal|null
return|;
block|}
block|}
end_class

end_unit

