begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.blockmanagement
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
operator|.
name|now
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|StorageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|Block
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|FSClusterStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|DatanodeStorage
operator|.
name|State
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetworkTopology
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NodeBase
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_comment
comment|/**  * The class is responsible for choosing the desired number of targets  * for placing block replicas.  * The replica placement strategy is that if the writer is on a datanode,  * the 1st replica is placed on the local machine,   * otherwise a random datanode. The 2nd replica is placed on a datanode  * that is on a different rack. The 3rd replica is placed on a datanode  * which is on a different node of the rack as the second replica.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|BlockPlacementPolicyDefault
specifier|public
class|class
name|BlockPlacementPolicyDefault
extends|extends
name|BlockPlacementPolicy
block|{
DECL|field|enableDebugLogging
specifier|private
specifier|static
specifier|final
name|String
name|enableDebugLogging
init|=
literal|"For more information, please enable DEBUG log level on "
operator|+
name|BlockPlacementPolicy
operator|.
name|class
operator|.
name|getName
argument_list|()
decl_stmt|;
DECL|field|debugLoggingBuilder
specifier|private
specifier|static
specifier|final
name|ThreadLocal
argument_list|<
name|StringBuilder
argument_list|>
name|debugLoggingBuilder
init|=
operator|new
name|ThreadLocal
argument_list|<
name|StringBuilder
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|protected
name|StringBuilder
name|initialValue
parameter_list|()
block|{
return|return
operator|new
name|StringBuilder
argument_list|()
return|;
block|}
block|}
decl_stmt|;
DECL|field|considerLoad
specifier|protected
name|boolean
name|considerLoad
decl_stmt|;
DECL|field|preferLocalNode
specifier|private
name|boolean
name|preferLocalNode
init|=
literal|true
decl_stmt|;
DECL|field|clusterMap
specifier|protected
name|NetworkTopology
name|clusterMap
decl_stmt|;
DECL|field|stats
specifier|private
name|FSClusterStats
name|stats
decl_stmt|;
DECL|field|heartbeatInterval
specifier|protected
name|long
name|heartbeatInterval
decl_stmt|;
comment|// interval for DataNode heartbeats
DECL|field|staleInterval
specifier|private
name|long
name|staleInterval
decl_stmt|;
comment|// interval used to identify stale DataNodes
comment|/**    * A miss of that many heartbeats is tolerated for replica deletion policy.    */
DECL|field|tolerateHeartbeatMultiplier
specifier|protected
name|int
name|tolerateHeartbeatMultiplier
decl_stmt|;
DECL|method|BlockPlacementPolicyDefault (Configuration conf, FSClusterStats stats, NetworkTopology clusterMap)
specifier|protected
name|BlockPlacementPolicyDefault
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|FSClusterStats
name|stats
parameter_list|,
name|NetworkTopology
name|clusterMap
parameter_list|)
block|{
name|initialize
argument_list|(
name|conf
argument_list|,
name|stats
argument_list|,
name|clusterMap
argument_list|)
expr_stmt|;
block|}
DECL|method|BlockPlacementPolicyDefault ()
specifier|protected
name|BlockPlacementPolicyDefault
parameter_list|()
block|{   }
annotation|@
name|Override
DECL|method|initialize (Configuration conf, FSClusterStats stats, NetworkTopology clusterMap)
specifier|public
name|void
name|initialize
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|FSClusterStats
name|stats
parameter_list|,
name|NetworkTopology
name|clusterMap
parameter_list|)
block|{
name|this
operator|.
name|considerLoad
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_REPLICATION_CONSIDERLOAD_KEY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|stats
operator|=
name|stats
expr_stmt|;
name|this
operator|.
name|clusterMap
operator|=
name|clusterMap
expr_stmt|;
name|this
operator|.
name|heartbeatInterval
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_HEARTBEAT_INTERVAL_DEFAULT
argument_list|)
operator|*
literal|1000
expr_stmt|;
name|this
operator|.
name|tolerateHeartbeatMultiplier
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_TOLERATE_HEARTBEAT_MULTIPLIER_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_TOLERATE_HEARTBEAT_MULTIPLIER_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|staleInterval
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_INTERVAL_KEY
argument_list|,
name|DFSConfigKeys
operator|.
name|DFS_NAMENODE_STALE_DATANODE_INTERVAL_DEFAULT
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|chooseTarget (String srcPath, int numOfReplicas, Node writer, List<DatanodeStorageInfo> chosenNodes, boolean returnChosenNodes, Set<Node> excludedNodes, long blocksize, StorageType storageType)
specifier|public
name|DatanodeStorageInfo
index|[]
name|chooseTarget
parameter_list|(
name|String
name|srcPath
parameter_list|,
name|int
name|numOfReplicas
parameter_list|,
name|Node
name|writer
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|chosenNodes
parameter_list|,
name|boolean
name|returnChosenNodes
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
return|return
name|chooseTarget
argument_list|(
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
name|chosenNodes
argument_list|,
name|returnChosenNodes
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|storageType
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|chooseTarget (String src, int numOfReplicas, Node writer, Set<Node> excludedNodes, long blocksize, List<DatanodeDescriptor> favoredNodes, StorageType storageType)
name|DatanodeStorageInfo
index|[]
name|chooseTarget
parameter_list|(
name|String
name|src
parameter_list|,
name|int
name|numOfReplicas
parameter_list|,
name|Node
name|writer
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|List
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|favoredNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|favoredNodes
operator|==
literal|null
operator|||
name|favoredNodes
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// Favored nodes not specified, fall back to regular block placement.
return|return
name|chooseTarget
argument_list|(
name|src
argument_list|,
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|DatanodeStorageInfo
argument_list|>
argument_list|(
name|numOfReplicas
argument_list|)
argument_list|,
literal|false
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|storageType
argument_list|)
return|;
block|}
name|Set
argument_list|<
name|Node
argument_list|>
name|favoriteAndExcludedNodes
init|=
name|excludedNodes
operator|==
literal|null
condition|?
operator|new
name|HashSet
argument_list|<
name|Node
argument_list|>
argument_list|()
else|:
operator|new
name|HashSet
argument_list|<
name|Node
argument_list|>
argument_list|(
name|excludedNodes
argument_list|)
decl_stmt|;
comment|// Choose favored nodes
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeStorageInfo
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|avoidStaleNodes
init|=
name|stats
operator|!=
literal|null
operator|&&
name|stats
operator|.
name|isAvoidingStaleDataNodesForWrite
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|Math
operator|.
name|min
argument_list|(
name|favoredNodes
operator|.
name|size
argument_list|()
argument_list|,
name|numOfReplicas
argument_list|)
condition|;
name|i
operator|++
control|)
block|{
name|DatanodeDescriptor
name|favoredNode
init|=
name|favoredNodes
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// Choose a single node which is local to favoredNode.
comment|// 'results' is updated within chooseLocalNode
specifier|final
name|DatanodeStorageInfo
name|target
init|=
name|chooseLocalStorage
argument_list|(
name|favoredNode
argument_list|,
name|favoriteAndExcludedNodes
argument_list|,
name|blocksize
argument_list|,
name|getMaxNodesPerRack
argument_list|(
name|results
operator|.
name|size
argument_list|()
argument_list|,
name|numOfReplicas
argument_list|)
index|[
literal|1
index|]
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
decl_stmt|;
if|if
condition|(
name|target
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not find a target for file "
operator|+
name|src
operator|+
literal|" with favored node "
operator|+
name|favoredNode
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|favoriteAndExcludedNodes
operator|.
name|add
argument_list|(
name|target
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|results
operator|.
name|size
argument_list|()
operator|<
name|numOfReplicas
condition|)
block|{
comment|// Not enough favored nodes, choose other nodes.
name|numOfReplicas
operator|-=
name|results
operator|.
name|size
argument_list|()
expr_stmt|;
name|DatanodeStorageInfo
index|[]
name|remainingTargets
init|=
name|chooseTarget
argument_list|(
name|src
argument_list|,
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
name|results
argument_list|,
literal|false
argument_list|,
name|favoriteAndExcludedNodes
argument_list|,
name|blocksize
argument_list|,
name|storageType
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|remainingTargets
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|results
operator|.
name|add
argument_list|(
name|remainingTargets
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|getPipeline
argument_list|(
name|writer
argument_list|,
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeStorageInfo
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NotEnoughReplicasException
name|nr
parameter_list|)
block|{
comment|// Fall back to regular block placement disregarding favored nodes hint
return|return
name|chooseTarget
argument_list|(
name|src
argument_list|,
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
operator|new
name|ArrayList
argument_list|<
name|DatanodeStorageInfo
argument_list|>
argument_list|(
name|numOfReplicas
argument_list|)
argument_list|,
literal|false
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|storageType
argument_list|)
return|;
block|}
block|}
comment|/** This is the implementation. */
DECL|method|chooseTarget (int numOfReplicas, Node writer, List<DatanodeStorageInfo> chosenStorage, boolean returnChosenNodes, Set<Node> excludedNodes, long blocksize, StorageType storageType)
specifier|private
name|DatanodeStorageInfo
index|[]
name|chooseTarget
parameter_list|(
name|int
name|numOfReplicas
parameter_list|,
name|Node
name|writer
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|chosenStorage
parameter_list|,
name|boolean
name|returnChosenNodes
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
if|if
condition|(
name|numOfReplicas
operator|==
literal|0
operator|||
name|clusterMap
operator|.
name|getNumOfLeaves
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
name|DatanodeStorageInfo
operator|.
name|EMPTY_ARRAY
return|;
block|}
if|if
condition|(
name|excludedNodes
operator|==
literal|null
condition|)
block|{
name|excludedNodes
operator|=
operator|new
name|HashSet
argument_list|<
name|Node
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|int
index|[]
name|result
init|=
name|getMaxNodesPerRack
argument_list|(
name|chosenStorage
operator|.
name|size
argument_list|()
argument_list|,
name|numOfReplicas
argument_list|)
decl_stmt|;
name|numOfReplicas
operator|=
name|result
index|[
literal|0
index|]
expr_stmt|;
name|int
name|maxNodesPerRack
init|=
name|result
index|[
literal|1
index|]
decl_stmt|;
specifier|final
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeStorageInfo
argument_list|>
argument_list|(
name|chosenStorage
argument_list|)
decl_stmt|;
for|for
control|(
name|DatanodeStorageInfo
name|storage
range|:
name|chosenStorage
control|)
block|{
comment|// add localMachine and related nodes to excludedNodes
name|addToExcludedNodes
argument_list|(
name|storage
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|,
name|excludedNodes
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|clusterMap
operator|.
name|contains
argument_list|(
name|writer
argument_list|)
condition|)
block|{
name|writer
operator|=
literal|null
expr_stmt|;
block|}
name|boolean
name|avoidStaleNodes
init|=
operator|(
name|stats
operator|!=
literal|null
operator|&&
name|stats
operator|.
name|isAvoidingStaleDataNodesForWrite
argument_list|()
operator|)
decl_stmt|;
name|Node
name|localNode
init|=
name|chooseTarget
argument_list|(
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|returnChosenNodes
condition|)
block|{
name|results
operator|.
name|removeAll
argument_list|(
name|chosenStorage
argument_list|)
expr_stmt|;
block|}
comment|// sorting nodes to form a pipeline
return|return
name|getPipeline
argument_list|(
operator|(
name|writer
operator|==
literal|null
operator|)
condition|?
name|localNode
else|:
name|writer
argument_list|,
name|results
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeStorageInfo
index|[
name|results
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
return|;
block|}
DECL|method|getMaxNodesPerRack (int numOfChosen, int numOfReplicas)
specifier|private
name|int
index|[]
name|getMaxNodesPerRack
parameter_list|(
name|int
name|numOfChosen
parameter_list|,
name|int
name|numOfReplicas
parameter_list|)
block|{
name|int
name|clusterSize
init|=
name|clusterMap
operator|.
name|getNumOfLeaves
argument_list|()
decl_stmt|;
name|int
name|totalNumOfReplicas
init|=
name|numOfChosen
operator|+
name|numOfReplicas
decl_stmt|;
if|if
condition|(
name|totalNumOfReplicas
operator|>
name|clusterSize
condition|)
block|{
name|numOfReplicas
operator|-=
operator|(
name|totalNumOfReplicas
operator|-
name|clusterSize
operator|)
expr_stmt|;
name|totalNumOfReplicas
operator|=
name|clusterSize
expr_stmt|;
block|}
name|int
name|maxNodesPerRack
init|=
operator|(
name|totalNumOfReplicas
operator|-
literal|1
operator|)
operator|/
name|clusterMap
operator|.
name|getNumOfRacks
argument_list|()
operator|+
literal|2
decl_stmt|;
return|return
operator|new
name|int
index|[]
block|{
name|numOfReplicas
block|,
name|maxNodesPerRack
block|}
return|;
block|}
comment|/**    * choose<i>numOfReplicas</i> from all data nodes    * @param numOfReplicas additional number of replicas wanted    * @param writer the writer's machine, could be a non-DatanodeDescriptor node    * @param excludedNodes datanodes that should not be considered as targets    * @param blocksize size of the data to be written    * @param maxNodesPerRack max nodes allowed per rack    * @param results the target nodes already chosen    * @param avoidStaleNodes avoid stale nodes in replica choosing    * @return local node of writer (not chosen node)    */
DECL|method|chooseTarget (int numOfReplicas, Node writer, Set<Node> excludedNodes, long blocksize, int maxNodesPerRack, List<DatanodeStorageInfo> results, final boolean avoidStaleNodes, StorageType storageType)
specifier|private
name|Node
name|chooseTarget
parameter_list|(
name|int
name|numOfReplicas
parameter_list|,
name|Node
name|writer
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
specifier|final
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
if|if
condition|(
name|numOfReplicas
operator|==
literal|0
operator|||
name|clusterMap
operator|.
name|getNumOfLeaves
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
name|writer
return|;
block|}
name|int
name|totalReplicasExpected
init|=
name|numOfReplicas
operator|+
name|results
operator|.
name|size
argument_list|()
decl_stmt|;
name|int
name|numOfResults
init|=
name|results
operator|.
name|size
argument_list|()
decl_stmt|;
name|boolean
name|newBlock
init|=
operator|(
name|numOfResults
operator|==
literal|0
operator|)
decl_stmt|;
if|if
condition|(
operator|(
name|writer
operator|==
literal|null
operator|||
operator|!
operator|(
name|writer
operator|instanceof
name|DatanodeDescriptor
operator|)
operator|)
operator|&&
operator|!
name|newBlock
condition|)
block|{
name|writer
operator|=
name|results
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getDatanodeDescriptor
argument_list|()
expr_stmt|;
block|}
comment|// Keep a copy of original excludedNodes
specifier|final
name|Set
argument_list|<
name|Node
argument_list|>
name|oldExcludedNodes
init|=
name|avoidStaleNodes
condition|?
operator|new
name|HashSet
argument_list|<
name|Node
argument_list|>
argument_list|(
name|excludedNodes
argument_list|)
else|:
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|numOfResults
operator|==
literal|0
condition|)
block|{
name|writer
operator|=
name|chooseLocalStorage
argument_list|(
name|writer
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
operator|.
name|getDatanodeDescriptor
argument_list|()
expr_stmt|;
if|if
condition|(
operator|--
name|numOfReplicas
operator|==
literal|0
condition|)
block|{
return|return
name|writer
return|;
block|}
block|}
specifier|final
name|DatanodeDescriptor
name|dn0
init|=
name|results
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getDatanodeDescriptor
argument_list|()
decl_stmt|;
if|if
condition|(
name|numOfResults
operator|<=
literal|1
condition|)
block|{
name|chooseRemoteRack
argument_list|(
literal|1
argument_list|,
name|dn0
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
if|if
condition|(
operator|--
name|numOfReplicas
operator|==
literal|0
condition|)
block|{
return|return
name|writer
return|;
block|}
block|}
if|if
condition|(
name|numOfResults
operator|<=
literal|2
condition|)
block|{
specifier|final
name|DatanodeDescriptor
name|dn1
init|=
name|results
operator|.
name|get
argument_list|(
literal|1
argument_list|)
operator|.
name|getDatanodeDescriptor
argument_list|()
decl_stmt|;
if|if
condition|(
name|clusterMap
operator|.
name|isOnSameRack
argument_list|(
name|dn0
argument_list|,
name|dn1
argument_list|)
condition|)
block|{
name|chooseRemoteRack
argument_list|(
literal|1
argument_list|,
name|dn0
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|newBlock
condition|)
block|{
name|chooseLocalRack
argument_list|(
name|dn1
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|chooseLocalRack
argument_list|(
name|writer
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|--
name|numOfReplicas
operator|==
literal|0
condition|)
block|{
return|return
name|writer
return|;
block|}
block|}
name|chooseRandom
argument_list|(
name|numOfReplicas
argument_list|,
name|NodeBase
operator|.
name|ROOT
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NotEnoughReplicasException
name|e
parameter_list|)
block|{
specifier|final
name|String
name|message
init|=
literal|"Failed to place enough replicas, still in need of "
operator|+
operator|(
name|totalReplicasExpected
operator|-
name|results
operator|.
name|size
argument_list|()
operator|)
operator|+
literal|" to reach "
operator|+
name|totalReplicasExpected
operator|+
literal|"."
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|message
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|message
operator|+
literal|" "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|avoidStaleNodes
condition|)
block|{
comment|// Retry chooseTarget again, this time not avoiding stale nodes.
comment|// excludedNodes contains the initial excludedNodes and nodes that were
comment|// not chosen because they were stale, decommissioned, etc.
comment|// We need to additionally exclude the nodes that were added to the
comment|// result list in the successful calls to choose*() above.
for|for
control|(
name|DatanodeStorageInfo
name|resultStorage
range|:
name|results
control|)
block|{
name|oldExcludedNodes
operator|.
name|add
argument_list|(
name|resultStorage
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Set numOfReplicas, since it can get out of sync with the result list
comment|// if the NotEnoughReplicasException was thrown in chooseRandom().
name|numOfReplicas
operator|=
name|totalReplicasExpected
operator|-
name|results
operator|.
name|size
argument_list|()
expr_stmt|;
return|return
name|chooseTarget
argument_list|(
name|numOfReplicas
argument_list|,
name|writer
argument_list|,
name|oldExcludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
literal|false
argument_list|,
name|storageType
argument_list|)
return|;
block|}
block|}
return|return
name|writer
return|;
block|}
comment|/**    * Choose<i>localMachine</i> as the target.    * if<i>localMachine</i> is not available,     * choose a node on the same rack    * @return the chosen storage    */
DECL|method|chooseLocalStorage (Node localMachine, Set<Node> excludedNodes, long blocksize, int maxNodesPerRack, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|protected
name|DatanodeStorageInfo
name|chooseLocalStorage
parameter_list|(
name|Node
name|localMachine
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
throws|throws
name|NotEnoughReplicasException
block|{
comment|// if no local machine, randomly choose one node
if|if
condition|(
name|localMachine
operator|==
literal|null
condition|)
return|return
name|chooseRandom
argument_list|(
name|NodeBase
operator|.
name|ROOT
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
if|if
condition|(
name|preferLocalNode
operator|&&
name|localMachine
operator|instanceof
name|DatanodeDescriptor
condition|)
block|{
name|DatanodeDescriptor
name|localDatanode
init|=
operator|(
name|DatanodeDescriptor
operator|)
name|localMachine
decl_stmt|;
comment|// otherwise try local machine first
if|if
condition|(
name|excludedNodes
operator|.
name|add
argument_list|(
name|localMachine
argument_list|)
condition|)
block|{
comment|// was not in the excluded list
for|for
control|(
name|DatanodeStorageInfo
name|localStorage
range|:
name|DFSUtil
operator|.
name|shuffle
argument_list|(
name|localDatanode
operator|.
name|getStorageInfos
argument_list|()
argument_list|)
control|)
block|{
if|if
condition|(
name|addIfIsGoodTarget
argument_list|(
name|localStorage
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
literal|false
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
operator|>=
literal|0
condition|)
block|{
return|return
name|localStorage
return|;
block|}
block|}
block|}
block|}
comment|// try a node on local rack
return|return
name|chooseLocalRack
argument_list|(
name|localMachine
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
comment|/**    * Add<i>localMachine</i> and related nodes to<i>excludedNodes</i>    * for next replica choosing. In sub class, we can add more nodes within    * the same failure domain of localMachine    * @return number of new excluded nodes    */
DECL|method|addToExcludedNodes (DatanodeDescriptor localMachine, Set<Node> excludedNodes)
specifier|protected
name|int
name|addToExcludedNodes
parameter_list|(
name|DatanodeDescriptor
name|localMachine
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|)
block|{
return|return
name|excludedNodes
operator|.
name|add
argument_list|(
name|localMachine
argument_list|)
condition|?
literal|1
else|:
literal|0
return|;
block|}
comment|/**    * Choose one node from the rack that<i>localMachine</i> is on.    * if no such node is available, choose one node from the rack where    * a second replica is on.    * if still no such node is available, choose a random node     * in the cluster.    * @return the chosen node    */
DECL|method|chooseLocalRack (Node localMachine, Set<Node> excludedNodes, long blocksize, int maxNodesPerRack, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|protected
name|DatanodeStorageInfo
name|chooseLocalRack
parameter_list|(
name|Node
name|localMachine
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
throws|throws
name|NotEnoughReplicasException
block|{
comment|// no local machine, so choose a random machine
if|if
condition|(
name|localMachine
operator|==
literal|null
condition|)
block|{
return|return
name|chooseRandom
argument_list|(
name|NodeBase
operator|.
name|ROOT
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
comment|// choose one from the local rack
try|try
block|{
return|return
name|chooseRandom
argument_list|(
name|localMachine
operator|.
name|getNetworkLocation
argument_list|()
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NotEnoughReplicasException
name|e1
parameter_list|)
block|{
comment|// find the second replica
name|DatanodeDescriptor
name|newLocal
init|=
literal|null
decl_stmt|;
for|for
control|(
name|DatanodeStorageInfo
name|resultStorage
range|:
name|results
control|)
block|{
name|DatanodeDescriptor
name|nextNode
init|=
name|resultStorage
operator|.
name|getDatanodeDescriptor
argument_list|()
decl_stmt|;
if|if
condition|(
name|nextNode
operator|!=
name|localMachine
condition|)
block|{
name|newLocal
operator|=
name|nextNode
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|newLocal
operator|!=
literal|null
condition|)
block|{
try|try
block|{
return|return
name|chooseRandom
argument_list|(
name|newLocal
operator|.
name|getNetworkLocation
argument_list|()
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|NotEnoughReplicasException
name|e2
parameter_list|)
block|{
comment|//otherwise randomly choose one from the network
return|return
name|chooseRandom
argument_list|(
name|NodeBase
operator|.
name|ROOT
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
block|}
else|else
block|{
comment|//otherwise randomly choose one from the network
return|return
name|chooseRandom
argument_list|(
name|NodeBase
operator|.
name|ROOT
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
block|}
block|}
comment|/**     * Choose<i>numOfReplicas</i> nodes from the racks     * that<i>localMachine</i> is NOT on.    * if not enough nodes are available, choose the remaining ones     * from the local rack    */
DECL|method|chooseRemoteRack (int numOfReplicas, DatanodeDescriptor localMachine, Set<Node> excludedNodes, long blocksize, int maxReplicasPerRack, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|protected
name|void
name|chooseRemoteRack
parameter_list|(
name|int
name|numOfReplicas
parameter_list|,
name|DatanodeDescriptor
name|localMachine
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxReplicasPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
throws|throws
name|NotEnoughReplicasException
block|{
name|int
name|oldNumOfReplicas
init|=
name|results
operator|.
name|size
argument_list|()
decl_stmt|;
comment|// randomly choose one node from remote racks
try|try
block|{
name|chooseRandom
argument_list|(
name|numOfReplicas
argument_list|,
literal|"~"
operator|+
name|localMachine
operator|.
name|getNetworkLocation
argument_list|()
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxReplicasPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NotEnoughReplicasException
name|e
parameter_list|)
block|{
name|chooseRandom
argument_list|(
name|numOfReplicas
operator|-
operator|(
name|results
operator|.
name|size
argument_list|()
operator|-
name|oldNumOfReplicas
operator|)
argument_list|,
name|localMachine
operator|.
name|getNetworkLocation
argument_list|()
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxReplicasPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Randomly choose one target from the given<i>scope</i>.    * @return the chosen storage, if there is any.    */
DECL|method|chooseRandom (String scope, Set<Node> excludedNodes, long blocksize, int maxNodesPerRack, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|protected
name|DatanodeStorageInfo
name|chooseRandom
parameter_list|(
name|String
name|scope
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
throws|throws
name|NotEnoughReplicasException
block|{
return|return
name|chooseRandom
argument_list|(
literal|1
argument_list|,
name|scope
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
return|;
block|}
comment|/**    * Randomly choose<i>numOfReplicas</i> targets from the given<i>scope</i>.    * @return the first chosen node, if there is any.    */
DECL|method|chooseRandom (int numOfReplicas, String scope, Set<Node> excludedNodes, long blocksize, int maxNodesPerRack, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|protected
name|DatanodeStorageInfo
name|chooseRandom
parameter_list|(
name|int
name|numOfReplicas
parameter_list|,
name|String
name|scope
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blocksize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
throws|throws
name|NotEnoughReplicasException
block|{
name|int
name|numOfAvailableNodes
init|=
name|clusterMap
operator|.
name|countNumOfAvailableNodes
argument_list|(
name|scope
argument_list|,
name|excludedNodes
argument_list|)
decl_stmt|;
name|StringBuilder
name|builder
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|builder
operator|=
name|debugLoggingBuilder
operator|.
name|get
argument_list|()
expr_stmt|;
name|builder
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|builder
operator|.
name|append
argument_list|(
literal|"["
argument_list|)
expr_stmt|;
block|}
name|boolean
name|badTarget
init|=
literal|false
decl_stmt|;
name|DatanodeStorageInfo
name|firstChosen
init|=
literal|null
decl_stmt|;
while|while
condition|(
name|numOfReplicas
operator|>
literal|0
operator|&&
name|numOfAvailableNodes
operator|>
literal|0
condition|)
block|{
name|DatanodeDescriptor
name|chosenNode
init|=
operator|(
name|DatanodeDescriptor
operator|)
name|clusterMap
operator|.
name|chooseRandom
argument_list|(
name|scope
argument_list|)
decl_stmt|;
if|if
condition|(
name|excludedNodes
operator|.
name|add
argument_list|(
name|chosenNode
argument_list|)
condition|)
block|{
comment|//was not in the excluded list
name|numOfAvailableNodes
operator|--
expr_stmt|;
specifier|final
name|DatanodeStorageInfo
index|[]
name|storages
init|=
name|DFSUtil
operator|.
name|shuffle
argument_list|(
name|chosenNode
operator|.
name|getStorageInfos
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|i
decl_stmt|;
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|storages
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
specifier|final
name|int
name|newExcludedNodes
init|=
name|addIfIsGoodTarget
argument_list|(
name|storages
index|[
name|i
index|]
argument_list|,
name|excludedNodes
argument_list|,
name|blocksize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|considerLoad
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
decl_stmt|;
if|if
condition|(
name|newExcludedNodes
operator|>=
literal|0
condition|)
block|{
name|numOfReplicas
operator|--
expr_stmt|;
if|if
condition|(
name|firstChosen
operator|==
literal|null
condition|)
block|{
name|firstChosen
operator|=
name|storages
index|[
name|i
index|]
expr_stmt|;
block|}
name|numOfAvailableNodes
operator|-=
name|newExcludedNodes
expr_stmt|;
break|break;
block|}
block|}
comment|// If no candidate storage was found on this DN then set badTarget.
name|badTarget
operator|=
operator|(
name|i
operator|==
name|storages
operator|.
name|length
operator|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|numOfReplicas
operator|>
literal|0
condition|)
block|{
name|String
name|detail
init|=
name|enableDebugLogging
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|badTarget
operator|&&
name|builder
operator|!=
literal|null
condition|)
block|{
name|detail
operator|=
name|builder
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
name|builder
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
else|else
name|detail
operator|=
literal|""
expr_stmt|;
block|}
throw|throw
operator|new
name|NotEnoughReplicasException
argument_list|(
name|detail
argument_list|)
throw|;
block|}
return|return
name|firstChosen
return|;
block|}
comment|/**    * If the given storage is a good target, add it to the result list and    * update the set of excluded nodes.    * @return -1 if the given is not a good target;    *         otherwise, return the number of nodes added to excludedNodes set.    */
DECL|method|addIfIsGoodTarget (DatanodeStorageInfo storage, Set<Node> excludedNodes, long blockSize, int maxNodesPerRack, boolean considerLoad, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
name|int
name|addIfIsGoodTarget
parameter_list|(
name|DatanodeStorageInfo
name|storage
parameter_list|,
name|Set
argument_list|<
name|Node
argument_list|>
name|excludedNodes
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|int
name|maxNodesPerRack
parameter_list|,
name|boolean
name|considerLoad
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
if|if
condition|(
name|isGoodTarget
argument_list|(
name|storage
argument_list|,
name|blockSize
argument_list|,
name|maxNodesPerRack
argument_list|,
name|considerLoad
argument_list|,
name|results
argument_list|,
name|avoidStaleNodes
argument_list|,
name|storageType
argument_list|)
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
name|storage
argument_list|)
expr_stmt|;
comment|// add node and related nodes to excludedNode
return|return
name|addToExcludedNodes
argument_list|(
name|storage
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|,
name|excludedNodes
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
DECL|method|logNodeIsNotChosen (DatanodeStorageInfo storage, String reason)
specifier|private
specifier|static
name|void
name|logNodeIsNotChosen
parameter_list|(
name|DatanodeStorageInfo
name|storage
parameter_list|,
name|String
name|reason
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
specifier|final
name|DatanodeDescriptor
name|node
init|=
name|storage
operator|.
name|getDatanodeDescriptor
argument_list|()
decl_stmt|;
comment|// build the error message for later use.
name|debugLoggingBuilder
operator|.
name|get
argument_list|()
operator|.
name|append
argument_list|(
name|node
argument_list|)
operator|.
name|append
argument_list|(
literal|": "
argument_list|)
operator|.
name|append
argument_list|(
literal|"Storage "
argument_list|)
operator|.
name|append
argument_list|(
name|storage
argument_list|)
operator|.
name|append
argument_list|(
literal|"at node "
argument_list|)
operator|.
name|append
argument_list|(
name|NodeBase
operator|.
name|getPath
argument_list|(
name|node
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" is not chosen because "
argument_list|)
operator|.
name|append
argument_list|(
name|reason
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Determine if a storage is a good target.     *     * @param storage The target storage    * @param blockSize Size of block    * @param maxTargetPerRack Maximum number of targets per rack. The value of     *                       this parameter depends on the number of racks in     *                       the cluster and total number of replicas for a block    * @param considerLoad whether or not to consider load of the target node    * @param results A list containing currently chosen nodes. Used to check if     *                too many nodes has been chosen in the target rack.    * @param avoidStaleNodes Whether or not to avoid choosing stale nodes    * @return Return true if<i>node</i> has enough space,     *         does not have too much load,     *         and the rack does not have too many nodes.    */
DECL|method|isGoodTarget (DatanodeStorageInfo storage, long blockSize, int maxTargetPerRack, boolean considerLoad, List<DatanodeStorageInfo> results, boolean avoidStaleNodes, StorageType storageType)
specifier|private
name|boolean
name|isGoodTarget
parameter_list|(
name|DatanodeStorageInfo
name|storage
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|int
name|maxTargetPerRack
parameter_list|,
name|boolean
name|considerLoad
parameter_list|,
name|List
argument_list|<
name|DatanodeStorageInfo
argument_list|>
name|results
parameter_list|,
name|boolean
name|avoidStaleNodes
parameter_list|,
name|StorageType
name|storageType
parameter_list|)
block|{
if|if
condition|(
name|storage
operator|.
name|getStorageType
argument_list|()
operator|!=
name|storageType
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"storage types do not match, where the expected storage type is "
operator|+
name|storageType
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|storage
operator|.
name|getState
argument_list|()
operator|==
name|State
operator|.
name|READ_ONLY
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"storage is read-only"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|DatanodeDescriptor
name|node
init|=
name|storage
operator|.
name|getDatanodeDescriptor
argument_list|()
decl_stmt|;
comment|// check if the node is (being) decommissioned
if|if
condition|(
name|node
operator|.
name|isDecommissionInProgress
argument_list|()
operator|||
name|node
operator|.
name|isDecommissioned
argument_list|()
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"the node is (being) decommissioned "
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|avoidStaleNodes
condition|)
block|{
if|if
condition|(
name|node
operator|.
name|isStale
argument_list|(
name|this
operator|.
name|staleInterval
argument_list|)
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"the node is stale "
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
specifier|final
name|long
name|requiredSize
init|=
name|blockSize
operator|*
name|HdfsConstants
operator|.
name|MIN_BLOCKS_FOR_WRITE
decl_stmt|;
specifier|final
name|long
name|scheduledSize
init|=
name|blockSize
operator|*
name|node
operator|.
name|getBlocksScheduled
argument_list|()
decl_stmt|;
if|if
condition|(
name|requiredSize
operator|>
name|node
operator|.
name|getRemaining
argument_list|()
operator|-
name|scheduledSize
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"the node does not have enough space "
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// check the communication traffic of the target machine
if|if
condition|(
name|considerLoad
condition|)
block|{
name|double
name|avgLoad
init|=
literal|0
decl_stmt|;
name|int
name|size
init|=
name|clusterMap
operator|.
name|getNumOfLeaves
argument_list|()
decl_stmt|;
if|if
condition|(
name|size
operator|!=
literal|0
operator|&&
name|stats
operator|!=
literal|null
condition|)
block|{
name|avgLoad
operator|=
operator|(
name|double
operator|)
name|stats
operator|.
name|getTotalLoad
argument_list|()
operator|/
name|size
expr_stmt|;
block|}
if|if
condition|(
name|node
operator|.
name|getXceiverCount
argument_list|()
operator|>
operator|(
literal|2.0
operator|*
name|avgLoad
operator|)
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"the node is too busy "
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|// check if the target rack has chosen too many nodes
name|String
name|rackname
init|=
name|node
operator|.
name|getNetworkLocation
argument_list|()
decl_stmt|;
name|int
name|counter
init|=
literal|1
decl_stmt|;
for|for
control|(
name|DatanodeStorageInfo
name|resultStorage
range|:
name|results
control|)
block|{
if|if
condition|(
name|rackname
operator|.
name|equals
argument_list|(
name|resultStorage
operator|.
name|getDatanodeDescriptor
argument_list|()
operator|.
name|getNetworkLocation
argument_list|()
argument_list|)
condition|)
block|{
name|counter
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|counter
operator|>
name|maxTargetPerRack
condition|)
block|{
name|logNodeIsNotChosen
argument_list|(
name|storage
argument_list|,
literal|"the rack has too many chosen nodes "
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Return a pipeline of nodes.    * The pipeline is formed finding a shortest path that     * starts from the writer and traverses all<i>nodes</i>    * This is basically a traveling salesman problem.    */
DECL|method|getPipeline (Node writer, DatanodeStorageInfo[] storages)
specifier|private
name|DatanodeStorageInfo
index|[]
name|getPipeline
parameter_list|(
name|Node
name|writer
parameter_list|,
name|DatanodeStorageInfo
index|[]
name|storages
parameter_list|)
block|{
if|if
condition|(
name|storages
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
name|storages
return|;
block|}
synchronized|synchronized
init|(
name|clusterMap
init|)
block|{
name|int
name|index
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|writer
operator|==
literal|null
operator|||
operator|!
name|clusterMap
operator|.
name|contains
argument_list|(
name|writer
argument_list|)
condition|)
block|{
name|writer
operator|=
name|storages
index|[
literal|0
index|]
operator|.
name|getDatanodeDescriptor
argument_list|()
expr_stmt|;
block|}
for|for
control|(
init|;
name|index
operator|<
name|storages
operator|.
name|length
condition|;
name|index
operator|++
control|)
block|{
name|DatanodeStorageInfo
name|shortestStorage
init|=
name|storages
index|[
name|index
index|]
decl_stmt|;
name|int
name|shortestDistance
init|=
name|clusterMap
operator|.
name|getDistance
argument_list|(
name|writer
argument_list|,
name|shortestStorage
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|shortestIndex
init|=
name|index
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|index
operator|+
literal|1
init|;
name|i
operator|<
name|storages
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|int
name|currentDistance
init|=
name|clusterMap
operator|.
name|getDistance
argument_list|(
name|writer
argument_list|,
name|storages
index|[
name|i
index|]
operator|.
name|getDatanodeDescriptor
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|shortestDistance
operator|>
name|currentDistance
condition|)
block|{
name|shortestDistance
operator|=
name|currentDistance
expr_stmt|;
name|shortestStorage
operator|=
name|storages
index|[
name|i
index|]
expr_stmt|;
name|shortestIndex
operator|=
name|i
expr_stmt|;
block|}
block|}
comment|//switch position index& shortestIndex
if|if
condition|(
name|index
operator|!=
name|shortestIndex
condition|)
block|{
name|storages
index|[
name|shortestIndex
index|]
operator|=
name|storages
index|[
name|index
index|]
expr_stmt|;
name|storages
index|[
name|index
index|]
operator|=
name|shortestStorage
expr_stmt|;
block|}
name|writer
operator|=
name|shortestStorage
operator|.
name|getDatanodeDescriptor
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|storages
return|;
block|}
annotation|@
name|Override
DECL|method|verifyBlockPlacement (String srcPath, LocatedBlock lBlk, int numberOfReplicas)
specifier|public
name|BlockPlacementStatus
name|verifyBlockPlacement
parameter_list|(
name|String
name|srcPath
parameter_list|,
name|LocatedBlock
name|lBlk
parameter_list|,
name|int
name|numberOfReplicas
parameter_list|)
block|{
name|DatanodeInfo
index|[]
name|locs
init|=
name|lBlk
operator|.
name|getLocations
argument_list|()
decl_stmt|;
if|if
condition|(
name|locs
operator|==
literal|null
condition|)
name|locs
operator|=
name|DatanodeDescriptor
operator|.
name|EMPTY_ARRAY
expr_stmt|;
name|int
name|numRacks
init|=
name|clusterMap
operator|.
name|getNumOfRacks
argument_list|()
decl_stmt|;
if|if
condition|(
name|numRacks
operator|<=
literal|1
condition|)
comment|// only one rack
return|return
operator|new
name|BlockPlacementStatusDefault
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|numRacks
argument_list|,
name|numberOfReplicas
argument_list|)
argument_list|,
name|numRacks
argument_list|)
return|;
name|int
name|minRacks
init|=
name|Math
operator|.
name|min
argument_list|(
literal|2
argument_list|,
name|numberOfReplicas
argument_list|)
decl_stmt|;
comment|// 1. Check that all locations are different.
comment|// 2. Count locations on different racks.
name|Set
argument_list|<
name|String
argument_list|>
name|racks
init|=
operator|new
name|TreeSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|dn
range|:
name|locs
control|)
name|racks
operator|.
name|add
argument_list|(
name|dn
operator|.
name|getNetworkLocation
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|BlockPlacementStatusDefault
argument_list|(
name|racks
operator|.
name|size
argument_list|()
argument_list|,
name|minRacks
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|chooseReplicaToDelete (BlockCollection bc, Block block, short replicationFactor, Collection<DatanodeDescriptor> first, Collection<DatanodeDescriptor> second)
specifier|public
name|DatanodeDescriptor
name|chooseReplicaToDelete
parameter_list|(
name|BlockCollection
name|bc
parameter_list|,
name|Block
name|block
parameter_list|,
name|short
name|replicationFactor
parameter_list|,
name|Collection
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|first
parameter_list|,
name|Collection
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|second
parameter_list|)
block|{
name|long
name|oldestHeartbeat
init|=
name|now
argument_list|()
operator|-
name|heartbeatInterval
operator|*
name|tolerateHeartbeatMultiplier
decl_stmt|;
name|DatanodeDescriptor
name|oldestHeartbeatNode
init|=
literal|null
decl_stmt|;
name|long
name|minSpace
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|DatanodeDescriptor
name|minSpaceNode
init|=
literal|null
decl_stmt|;
comment|// Pick the node with the oldest heartbeat or with the least free space,
comment|// if all hearbeats are within the tolerable heartbeat interval
for|for
control|(
name|DatanodeDescriptor
name|node
range|:
name|pickupReplicaSet
argument_list|(
name|first
argument_list|,
name|second
argument_list|)
control|)
block|{
name|long
name|free
init|=
name|node
operator|.
name|getRemaining
argument_list|()
decl_stmt|;
name|long
name|lastHeartbeat
init|=
name|node
operator|.
name|getLastUpdate
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastHeartbeat
operator|<
name|oldestHeartbeat
condition|)
block|{
name|oldestHeartbeat
operator|=
name|lastHeartbeat
expr_stmt|;
name|oldestHeartbeatNode
operator|=
name|node
expr_stmt|;
block|}
if|if
condition|(
name|minSpace
operator|>
name|free
condition|)
block|{
name|minSpace
operator|=
name|free
expr_stmt|;
name|minSpaceNode
operator|=
name|node
expr_stmt|;
block|}
block|}
return|return
name|oldestHeartbeatNode
operator|!=
literal|null
condition|?
name|oldestHeartbeatNode
else|:
name|minSpaceNode
return|;
block|}
comment|/**    * Pick up replica node set for deleting replica as over-replicated.     * First set contains replica nodes on rack with more than one    * replica while second set contains remaining replica nodes.    * So pick up first set if not empty. If first is empty, then pick second.    */
DECL|method|pickupReplicaSet ( Collection<DatanodeDescriptor> first, Collection<DatanodeDescriptor> second)
specifier|protected
name|Collection
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|pickupReplicaSet
parameter_list|(
name|Collection
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|first
parameter_list|,
name|Collection
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|second
parameter_list|)
block|{
return|return
name|first
operator|.
name|isEmpty
argument_list|()
condition|?
name|second
else|:
name|first
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setPreferLocalNode (boolean prefer)
name|void
name|setPreferLocalNode
parameter_list|(
name|boolean
name|prefer
parameter_list|)
block|{
name|this
operator|.
name|preferLocalNode
operator|=
name|prefer
expr_stmt|;
block|}
block|}
end_class

end_unit

