begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
operator|.
name|SUCCESS
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|ClosedChannelException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|HadoopIllegalArgumentException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|crypto
operator|.
name|CryptoProtocolVersion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CanSetDropBehind
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSOutputSummer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileEncryptionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ParentNotDirectoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StorageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Syncable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsDataOutputStream
operator|.
name|SyncFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|BlockStoragePolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|QuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|NSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|SnapshotAccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|UnresolvedPathException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|BlockConstructionStage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtoUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|IOStreamPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|InvalidEncryptionKeyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PacketHeader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PipelineAck
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|Sender
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|BlockOpResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|PBHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|BlockStoragePolicySuite
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|CachingStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NotReplicatedYetException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|RetryStartFileException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|SafeModeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|util
operator|.
name|ByteArrayManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|EnumSetWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|AccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
operator|.
name|Type
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|Span
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|Trace
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|TraceScope
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|LoadingCache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalNotification
import|;
end_import

begin_comment
comment|/****************************************************************  * DFSOutputStream creates files from a stream of bytes.  *  * The client application writes data that is cached internally by  * this stream. Data is broken up into packets, each packet is  * typically 64K in size. A packet comprises of chunks. Each chunk  * is typically 512 bytes and has an associated checksum with it.  *  * When a client application fills up the currentPacket, it is  * enqueued into dataQueue.  The DataStreamer thread picks up  * packets from the dataQueue, sends it to the first datanode in  * the pipeline and moves it from the dataQueue to the ackQueue.  * The ResponseProcessor receives acks from the datanodes. When an  * successful ack for a packet is received from all datanodes, the  * ResponseProcessor removes the corresponding packet from the  * ackQueue.  *  * In case of error, all outstanding packets and moved from  * ackQueue. A new pipeline is setup by eliminating the bad  * datanode from the original pipeline. The DataStreamer now  * starts sending packets from the dataQueue. ****************************************************************/
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DFSOutputStream
specifier|public
class|class
name|DFSOutputStream
extends|extends
name|FSOutputSummer
implements|implements
name|Syncable
implements|,
name|CanSetDropBehind
block|{
comment|/**    * Number of times to retry creating a file when there are transient     * errors (typically related to encryption zones and KeyProvider operations).    */
annotation|@
name|VisibleForTesting
DECL|field|CREATE_RETRY_COUNT
specifier|static
specifier|final
name|int
name|CREATE_RETRY_COUNT
init|=
literal|10
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|SUPPORTED_CRYPTO_VERSIONS
specifier|static
name|CryptoProtocolVersion
index|[]
name|SUPPORTED_CRYPTO_VERSIONS
init|=
name|CryptoProtocolVersion
operator|.
name|supported
argument_list|()
decl_stmt|;
DECL|field|dfsClient
specifier|private
specifier|final
name|DFSClient
name|dfsClient
decl_stmt|;
DECL|field|dfsclientSlowLogThresholdMs
specifier|private
specifier|final
name|long
name|dfsclientSlowLogThresholdMs
decl_stmt|;
DECL|field|byteArrayManager
specifier|private
specifier|final
name|ByteArrayManager
name|byteArrayManager
decl_stmt|;
DECL|field|s
specifier|private
name|Socket
name|s
decl_stmt|;
comment|// closed is accessed by different threads under different locks.
DECL|field|closed
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
DECL|field|src
specifier|private
name|String
name|src
decl_stmt|;
DECL|field|fileId
specifier|private
specifier|final
name|long
name|fileId
decl_stmt|;
DECL|field|blockSize
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
comment|/** Only for DataTransferProtocol.writeBlock(..) */
DECL|field|checksum4WriteBlock
specifier|private
specifier|final
name|DataChecksum
name|checksum4WriteBlock
decl_stmt|;
DECL|field|bytesPerChecksum
specifier|private
specifier|final
name|int
name|bytesPerChecksum
decl_stmt|;
comment|// both dataQueue and ackQueue are protected by dataQueue lock
DECL|field|dataQueue
specifier|private
specifier|final
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
name|dataQueue
init|=
operator|new
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|ackQueue
specifier|private
specifier|final
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
name|ackQueue
init|=
operator|new
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|currentPacket
specifier|private
name|DFSPacket
name|currentPacket
init|=
literal|null
decl_stmt|;
DECL|field|streamer
specifier|private
name|DataStreamer
name|streamer
decl_stmt|;
DECL|field|currentSeqno
specifier|private
name|long
name|currentSeqno
init|=
literal|0
decl_stmt|;
DECL|field|lastQueuedSeqno
specifier|private
name|long
name|lastQueuedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|lastAckedSeqno
specifier|private
name|long
name|lastAckedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|bytesCurBlock
specifier|private
name|long
name|bytesCurBlock
init|=
literal|0
decl_stmt|;
comment|// bytes written in current block
DECL|field|packetSize
specifier|private
name|int
name|packetSize
init|=
literal|0
decl_stmt|;
comment|// write packet size, not including the header.
DECL|field|chunksPerPacket
specifier|private
name|int
name|chunksPerPacket
init|=
literal|0
decl_stmt|;
DECL|field|lastException
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|IOException
argument_list|>
name|lastException
init|=
operator|new
name|AtomicReference
argument_list|<
name|IOException
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|artificialSlowdown
specifier|private
name|long
name|artificialSlowdown
init|=
literal|0
decl_stmt|;
DECL|field|lastFlushOffset
specifier|private
name|long
name|lastFlushOffset
init|=
literal|0
decl_stmt|;
comment|// offset when flush was invoked
comment|//persist blocks on namenode
DECL|field|persistBlocks
specifier|private
specifier|final
name|AtomicBoolean
name|persistBlocks
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|appendChunk
specifier|private
specifier|volatile
name|boolean
name|appendChunk
init|=
literal|false
decl_stmt|;
comment|// appending to existing partial block
DECL|field|initialFileSize
specifier|private
name|long
name|initialFileSize
init|=
literal|0
decl_stmt|;
comment|// at time of file open
DECL|field|progress
specifier|private
specifier|final
name|Progressable
name|progress
decl_stmt|;
DECL|field|blockReplication
specifier|private
specifier|final
name|short
name|blockReplication
decl_stmt|;
comment|// replication factor of file
DECL|field|shouldSyncBlock
specifier|private
name|boolean
name|shouldSyncBlock
init|=
literal|false
decl_stmt|;
comment|// force blocks to disk upon close
DECL|field|cachingStrategy
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
name|cachingStrategy
decl_stmt|;
DECL|field|failPacket
specifier|private
name|boolean
name|failPacket
init|=
literal|false
decl_stmt|;
DECL|field|fileEncryptionInfo
specifier|private
name|FileEncryptionInfo
name|fileEncryptionInfo
decl_stmt|;
DECL|field|blockStoragePolicySuite
specifier|private
specifier|static
specifier|final
name|BlockStoragePolicySuite
name|blockStoragePolicySuite
init|=
name|BlockStoragePolicySuite
operator|.
name|createDefaultSuite
argument_list|()
decl_stmt|;
comment|/** Use {@link ByteArrayManager} to create buffer for non-heartbeat packets.*/
DECL|method|createPacket (int packetSize, int chunksPerPkt, long offsetInBlock, long seqno, boolean lastPacketInBlock)
specifier|private
name|DFSPacket
name|createPacket
parameter_list|(
name|int
name|packetSize
parameter_list|,
name|int
name|chunksPerPkt
parameter_list|,
name|long
name|offsetInBlock
parameter_list|,
name|long
name|seqno
parameter_list|,
name|boolean
name|lastPacketInBlock
parameter_list|)
throws|throws
name|InterruptedIOException
block|{
specifier|final
name|byte
index|[]
name|buf
decl_stmt|;
specifier|final
name|int
name|bufferSize
init|=
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
operator|+
name|packetSize
decl_stmt|;
try|try
block|{
name|buf
operator|=
name|byteArrayManager
operator|.
name|newByteArray
argument_list|(
name|bufferSize
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
specifier|final
name|InterruptedIOException
name|iioe
init|=
operator|new
name|InterruptedIOException
argument_list|(
literal|"seqno="
operator|+
name|seqno
argument_list|)
decl_stmt|;
name|iioe
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
throw|throw
name|iioe
throw|;
block|}
return|return
operator|new
name|DFSPacket
argument_list|(
name|buf
argument_list|,
name|chunksPerPkt
argument_list|,
name|offsetInBlock
argument_list|,
name|seqno
argument_list|,
name|getChecksumSize
argument_list|()
argument_list|,
name|lastPacketInBlock
argument_list|)
return|;
block|}
comment|/**    * For heartbeat packets, create buffer directly by new byte[]    * since heartbeats should not be blocked.    */
DECL|method|createHeartbeatPacket ()
specifier|private
name|DFSPacket
name|createHeartbeatPacket
parameter_list|()
throws|throws
name|InterruptedIOException
block|{
specifier|final
name|byte
index|[]
name|buf
init|=
operator|new
name|byte
index|[
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
index|]
decl_stmt|;
return|return
operator|new
name|DFSPacket
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
argument_list|,
name|getChecksumSize
argument_list|()
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|//
comment|// The DataStreamer class is responsible for sending data packets to the
comment|// datanodes in the pipeline. It retrieves a new blockid and block locations
comment|// from the namenode, and starts streaming packets to the pipeline of
comment|// Datanodes. Every packet has a sequence number associated with
comment|// it. When all the packets for a block are sent out and acks for each
comment|// if them are received, the DataStreamer closes the current block.
comment|//
DECL|class|DataStreamer
class|class
name|DataStreamer
extends|extends
name|Daemon
block|{
DECL|field|streamerClosed
specifier|private
specifier|volatile
name|boolean
name|streamerClosed
init|=
literal|false
decl_stmt|;
DECL|field|block
specifier|private
name|ExtendedBlock
name|block
decl_stmt|;
comment|// its length is number of bytes acked
DECL|field|accessToken
specifier|private
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
decl_stmt|;
DECL|field|blockStream
specifier|private
name|DataOutputStream
name|blockStream
decl_stmt|;
DECL|field|blockReplyStream
specifier|private
name|DataInputStream
name|blockReplyStream
decl_stmt|;
DECL|field|response
specifier|private
name|ResponseProcessor
name|response
init|=
literal|null
decl_stmt|;
DECL|field|nodes
specifier|private
specifier|volatile
name|DatanodeInfo
index|[]
name|nodes
init|=
literal|null
decl_stmt|;
comment|// list of targets for current block
DECL|field|storageTypes
specifier|private
specifier|volatile
name|StorageType
index|[]
name|storageTypes
init|=
literal|null
decl_stmt|;
DECL|field|storageIDs
specifier|private
specifier|volatile
name|String
index|[]
name|storageIDs
init|=
literal|null
decl_stmt|;
DECL|field|excludedNodes
specifier|private
specifier|final
name|LoadingCache
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|excludedNodes
init|=
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|expireAfterWrite
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|excludedNodesCacheExpiry
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
operator|.
name|removalListener
argument_list|(
operator|new
name|RemovalListener
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|onRemoval
parameter_list|(
name|RemovalNotification
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|notification
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Removing node "
operator|+
name|notification
operator|.
name|getKey
argument_list|()
operator|+
literal|" from the excluded nodes list"
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
operator|.
name|build
argument_list|(
operator|new
name|CacheLoader
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DatanodeInfo
name|load
parameter_list|(
name|DatanodeInfo
name|key
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|key
return|;
block|}
block|}
argument_list|)
decl_stmt|;
DECL|field|favoredNodes
specifier|private
name|String
index|[]
name|favoredNodes
decl_stmt|;
DECL|field|hasError
specifier|volatile
name|boolean
name|hasError
init|=
literal|false
decl_stmt|;
DECL|field|errorIndex
specifier|volatile
name|int
name|errorIndex
init|=
operator|-
literal|1
decl_stmt|;
comment|// Restarting node index
DECL|field|restartingNodeIndex
name|AtomicInteger
name|restartingNodeIndex
init|=
operator|new
name|AtomicInteger
argument_list|(
operator|-
literal|1
argument_list|)
decl_stmt|;
DECL|field|restartDeadline
specifier|private
name|long
name|restartDeadline
init|=
literal|0
decl_stmt|;
comment|// Deadline of DN restart
DECL|field|stage
specifier|private
name|BlockConstructionStage
name|stage
decl_stmt|;
comment|// block construction stage
DECL|field|bytesSent
specifier|private
name|long
name|bytesSent
init|=
literal|0
decl_stmt|;
comment|// number of bytes that've been sent
DECL|field|isLazyPersistFile
specifier|private
specifier|final
name|boolean
name|isLazyPersistFile
decl_stmt|;
comment|/** Nodes have been used in the pipeline before and have failed. */
DECL|field|failed
specifier|private
specifier|final
name|List
argument_list|<
name|DatanodeInfo
argument_list|>
name|failed
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|()
decl_stmt|;
comment|/** The last ack sequence number before pipeline failure. */
DECL|field|lastAckedSeqnoBeforeFailure
specifier|private
name|long
name|lastAckedSeqnoBeforeFailure
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|pipelineRecoveryCount
specifier|private
name|int
name|pipelineRecoveryCount
init|=
literal|0
decl_stmt|;
comment|/** Has the current block been hflushed? */
DECL|field|isHflushed
specifier|private
name|boolean
name|isHflushed
init|=
literal|false
decl_stmt|;
comment|/** Append on an existing block? */
DECL|field|isAppend
specifier|private
specifier|final
name|boolean
name|isAppend
decl_stmt|;
DECL|field|traceSpan
specifier|private
specifier|final
name|Span
name|traceSpan
decl_stmt|;
comment|/**      * construction with tracing info      */
DECL|method|DataStreamer (HdfsFileStatus stat, ExtendedBlock block, Span span)
specifier|private
name|DataStreamer
parameter_list|(
name|HdfsFileStatus
name|stat
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|,
name|Span
name|span
parameter_list|)
block|{
name|isAppend
operator|=
literal|false
expr_stmt|;
name|isLazyPersistFile
operator|=
name|isLazyPersist
argument_list|(
name|stat
argument_list|)
expr_stmt|;
name|this
operator|.
name|block
operator|=
name|block
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
name|traceSpan
operator|=
name|span
expr_stmt|;
block|}
comment|/**      * Construct a data streamer for appending to the last partial block      * @param lastBlock last block of the file to be appended      * @param stat status of the file to be appended      * @param bytesPerChecksum number of bytes per checksum      * @throws IOException if error occurs      */
DECL|method|DataStreamer (LocatedBlock lastBlock, HdfsFileStatus stat, int bytesPerChecksum, Span span)
specifier|private
name|DataStreamer
parameter_list|(
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|int
name|bytesPerChecksum
parameter_list|,
name|Span
name|span
parameter_list|)
throws|throws
name|IOException
block|{
name|isAppend
operator|=
literal|true
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
expr_stmt|;
name|traceSpan
operator|=
name|span
expr_stmt|;
name|block
operator|=
name|lastBlock
operator|.
name|getBlock
argument_list|()
expr_stmt|;
name|bytesSent
operator|=
name|block
operator|.
name|getNumBytes
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lastBlock
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
name|isLazyPersistFile
operator|=
name|isLazyPersist
argument_list|(
name|stat
argument_list|)
expr_stmt|;
name|long
name|usedInLastBlock
init|=
name|stat
operator|.
name|getLen
argument_list|()
operator|%
name|blockSize
decl_stmt|;
name|int
name|freeInLastBlock
init|=
call|(
name|int
call|)
argument_list|(
name|blockSize
operator|-
name|usedInLastBlock
argument_list|)
decl_stmt|;
comment|// calculate the amount of free space in the pre-existing
comment|// last crc chunk
name|int
name|usedInCksum
init|=
call|(
name|int
call|)
argument_list|(
name|stat
operator|.
name|getLen
argument_list|()
operator|%
name|bytesPerChecksum
argument_list|)
decl_stmt|;
name|int
name|freeInCksum
init|=
name|bytesPerChecksum
operator|-
name|usedInCksum
decl_stmt|;
comment|// if there is space in the last block, then we have to
comment|// append to that block
if|if
condition|(
name|freeInLastBlock
operator|==
name|blockSize
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The last block for file "
operator|+
name|src
operator|+
literal|" is full."
argument_list|)
throw|;
block|}
if|if
condition|(
name|usedInCksum
operator|>
literal|0
operator|&&
name|freeInCksum
operator|>
literal|0
condition|)
block|{
comment|// if there is space in the last partial chunk, then
comment|// setup in such a way that the next packet will have only
comment|// one chunk that fills up the partial chunk.
comment|//
name|computePacketChunkSize
argument_list|(
literal|0
argument_list|,
name|freeInCksum
argument_list|)
expr_stmt|;
name|setChecksumBufSize
argument_list|(
name|freeInCksum
argument_list|)
expr_stmt|;
name|appendChunk
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|// if the remaining space in the block is smaller than
comment|// that expected size of of a packet, then create
comment|// smaller size packet.
comment|//
name|computePacketChunkSize
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|freeInLastBlock
argument_list|)
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
comment|// setup pipeline to append to the last block XXX retries??
name|setPipeline
argument_list|(
name|lastBlock
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
comment|// no errors yet.
if|if
condition|(
name|nodes
operator|.
name|length
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to retrieve blocks locations "
operator|+
literal|" for last block "
operator|+
name|block
operator|+
literal|"of file "
operator|+
name|src
argument_list|)
throw|;
block|}
block|}
DECL|method|setPipeline (LocatedBlock lb)
specifier|private
name|void
name|setPipeline
parameter_list|(
name|LocatedBlock
name|lb
parameter_list|)
block|{
name|setPipeline
argument_list|(
name|lb
operator|.
name|getLocations
argument_list|()
argument_list|,
name|lb
operator|.
name|getStorageTypes
argument_list|()
argument_list|,
name|lb
operator|.
name|getStorageIDs
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|setPipeline (DatanodeInfo[] nodes, StorageType[] storageTypes, String[] storageIDs)
specifier|private
name|void
name|setPipeline
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|StorageType
index|[]
name|storageTypes
parameter_list|,
name|String
index|[]
name|storageIDs
parameter_list|)
block|{
name|this
operator|.
name|nodes
operator|=
name|nodes
expr_stmt|;
name|this
operator|.
name|storageTypes
operator|=
name|storageTypes
expr_stmt|;
name|this
operator|.
name|storageIDs
operator|=
name|storageIDs
expr_stmt|;
block|}
DECL|method|setFavoredNodes (String[] favoredNodes)
specifier|private
name|void
name|setFavoredNodes
parameter_list|(
name|String
index|[]
name|favoredNodes
parameter_list|)
block|{
name|this
operator|.
name|favoredNodes
operator|=
name|favoredNodes
expr_stmt|;
block|}
comment|/**      * Initialize for data streaming      */
DECL|method|initDataStreaming ()
specifier|private
name|void
name|initDataStreaming
parameter_list|()
block|{
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
operator|+
literal|" block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|response
operator|=
operator|new
name|ResponseProcessor
argument_list|(
name|nodes
argument_list|)
expr_stmt|;
name|response
operator|.
name|start
argument_list|()
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
expr_stmt|;
block|}
DECL|method|endBlock ()
specifier|private
name|void
name|endBlock
parameter_list|()
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing old block "
operator|+
name|block
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
argument_list|)
expr_stmt|;
name|closeResponder
argument_list|()
expr_stmt|;
name|closeStream
argument_list|()
expr_stmt|;
name|setPipeline
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
block|}
comment|/*      * streamer thread is the only thread that opens streams to datanode,       * and closes them. Any error recovery is also done by this thread.      */
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|long
name|lastPacket
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
name|TraceScope
name|traceScope
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|traceSpan
operator|!=
literal|null
condition|)
block|{
name|traceScope
operator|=
name|Trace
operator|.
name|continueSpan
argument_list|(
name|traceSpan
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
comment|// if the Responder encountered an error, shutdown Responder
if|if
condition|(
name|hasError
operator|&&
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
name|response
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|DFSPacket
name|one
decl_stmt|;
try|try
block|{
comment|// process datanode IO errors if any
name|boolean
name|doSleep
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|hasError
operator|&&
operator|(
name|errorIndex
operator|>=
literal|0
operator|||
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|>=
literal|0
operator|)
condition|)
block|{
name|doSleep
operator|=
name|processDatanodeError
argument_list|()
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// wait for a packet to be sent.
name|long
name|now
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
while|while
condition|(
operator|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|dfsClient
operator|.
name|clientRunning
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
operator|(
name|stage
operator|!=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|&&
name|now
operator|-
name|lastPacket
operator|<
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
operator|/
literal|2
operator|)
operator|)
operator|||
name|doSleep
condition|)
block|{
name|long
name|timeout
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
operator|/
literal|2
operator|-
operator|(
name|now
operator|-
name|lastPacket
operator|)
decl_stmt|;
name|timeout
operator|=
name|timeout
operator|<=
literal|0
condition|?
literal|1000
else|:
name|timeout
expr_stmt|;
name|timeout
operator|=
operator|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|)
condition|?
name|timeout
else|:
literal|1000
expr_stmt|;
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|doSleep
operator|=
literal|false
expr_stmt|;
name|now
operator|=
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
comment|// get packet to be sent.
if|if
condition|(
name|dataQueue
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|one
operator|=
name|createHeartbeatPacket
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|one
operator|=
name|dataQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
comment|// regular data packet
block|}
block|}
assert|assert
name|one
operator|!=
literal|null
assert|;
comment|// get new block from namenode.
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Allocating new block"
argument_list|)
expr_stmt|;
block|}
name|setPipeline
argument_list|(
name|nextBlockOutputStream
argument_list|()
argument_list|)
expr_stmt|;
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Append to block "
operator|+
name|block
argument_list|)
expr_stmt|;
block|}
name|setupPipelineForAppendOrRecovery
argument_list|()
expr_stmt|;
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
name|long
name|lastByteOffsetInBlock
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastByteOffsetInBlock
operator|>
name|blockSize
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlockSize "
operator|+
name|blockSize
operator|+
literal|" is smaller than data size. "
operator|+
literal|" Offset of packet in block "
operator|+
name|lastByteOffsetInBlock
operator|+
literal|" Aborting file "
operator|+
name|src
argument_list|)
throw|;
block|}
if|if
condition|(
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
condition|)
block|{
comment|// wait for all data packets have been successfully acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
try|try
block|{
comment|// wait for acks to arrive from datanodes
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
expr_stmt|;
block|}
comment|// send the packet
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// move packet from dataQueue to ackQueue
if|if
condition|(
operator|!
name|one
operator|.
name|isHeartbeatPacket
argument_list|()
condition|)
block|{
name|dataQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|ackQueue
operator|.
name|addLast
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataStreamer block "
operator|+
name|block
operator|+
literal|" sending packet "
operator|+
name|one
argument_list|)
expr_stmt|;
block|}
comment|// write out data to remote datanode
try|try
block|{
name|one
operator|.
name|writeTo
argument_list|(
name|blockStream
argument_list|)
expr_stmt|;
name|blockStream
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// HDFS-3398 treat primary DN is down since client is unable to
comment|// write to primary DN. If a failed or restarting node has already
comment|// been recorded by the responder, the following call will have no
comment|// effect. Pipeline recovery can handle only one node error at a
comment|// time. If the primary node fails again during the recovery, it
comment|// will be taken out then.
name|tryMarkPrimaryDatanodeFailed
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|lastPacket
operator|=
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
comment|// update bytesSent
name|long
name|tmpBytesSent
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|bytesSent
operator|<
name|tmpBytesSent
condition|)
block|{
name|bytesSent
operator|=
name|tmpBytesSent
expr_stmt|;
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
comment|// Is this block full?
if|if
condition|(
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
condition|)
block|{
comment|// wait for the close packet has been acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// wait for acks to arrive from datanodes
block|}
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|progress
operator|!=
literal|null
condition|)
block|{
name|progress
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
comment|// This is used by unit test to trigger race conditions.
if|if
condition|(
name|artificialSlowdown
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|artificialSlowdown
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
comment|// Log warning if there was a real error.
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|// Since their messages are descriptive enough, do not always
comment|// log a verbose stack-trace WARN for quota exceptions.
if|if
condition|(
name|e
operator|instanceof
name|QuotaExceededException
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataStreamer Quota Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DataStreamer Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|setLastException
argument_list|(
operator|(
name|IOException
operator|)
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|setLastException
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"DataStreamer Exception: "
argument_list|,
name|e
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|errorIndex
operator|==
operator|-
literal|1
operator|&&
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
comment|// Not a datanode issue
name|streamerClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|traceScope
operator|!=
literal|null
condition|)
block|{
name|traceScope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|closeInternal
argument_list|()
expr_stmt|;
block|}
DECL|method|closeInternal ()
specifier|private
name|void
name|closeInternal
parameter_list|()
block|{
name|closeResponder
argument_list|()
expr_stmt|;
comment|// close and join
name|closeStream
argument_list|()
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
name|setClosed
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*      * close both streamer and DFSOutputStream, should be called only       * by an external thread and only after all data to be sent has       * been flushed to datanode.      *       * Interrupt this data streamer if force is true      *       * @param force if this data stream is forced to be closed       */
DECL|method|close (boolean force)
name|void
name|close
parameter_list|(
name|boolean
name|force
parameter_list|)
block|{
name|streamerClosed
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|force
condition|)
block|{
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|closeResponder ()
specifier|private
name|void
name|closeResponder
parameter_list|()
block|{
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|response
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
DECL|method|closeStream ()
specifier|private
name|void
name|closeStream
parameter_list|()
block|{
if|if
condition|(
name|blockStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|blockReplyStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockReplyStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|s
condition|)
block|{
try|try
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|s
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|// The following synchronized methods are used whenever
comment|// errorIndex or restartingNodeIndex is set. This is because
comment|// check& set needs to be atomic. Simply reading variables
comment|// does not require a synchronization. When responder is
comment|// not running (e.g. during pipeline recovery), there is no
comment|// need to use these methods.
comment|/** Set the error node index. Called by responder */
DECL|method|setErrorIndex (int idx)
specifier|synchronized
name|void
name|setErrorIndex
parameter_list|(
name|int
name|idx
parameter_list|)
block|{
name|errorIndex
operator|=
name|idx
expr_stmt|;
block|}
comment|/** Set the restarting node index. Called by responder */
DECL|method|setRestartingNodeIndex (int idx)
specifier|synchronized
name|void
name|setRestartingNodeIndex
parameter_list|(
name|int
name|idx
parameter_list|)
block|{
name|restartingNodeIndex
operator|.
name|set
argument_list|(
name|idx
argument_list|)
expr_stmt|;
comment|// If the data streamer has already set the primary node
comment|// bad, clear it. It is likely that the write failed due to
comment|// the DN shutdown. Even if it was a real failure, the pipeline
comment|// recovery will take care of it.
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|/**      * This method is used when no explicit error report was received,      * but something failed. When the primary node is a suspect or      * unsure about the cause, the primary node is marked as failed.      */
DECL|method|tryMarkPrimaryDatanodeFailed ()
specifier|synchronized
name|void
name|tryMarkPrimaryDatanodeFailed
parameter_list|()
block|{
comment|// There should be no existing error and no ongoing restart.
if|if
condition|(
operator|(
name|errorIndex
operator|==
operator|-
literal|1
operator|)
operator|&&
operator|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
operator|)
condition|)
block|{
name|errorIndex
operator|=
literal|0
expr_stmt|;
block|}
block|}
comment|/**      * Examine whether it is worth waiting for a node to restart.      * @param index the node index      */
DECL|method|shouldWaitForRestart (int index)
name|boolean
name|shouldWaitForRestart
parameter_list|(
name|int
name|index
parameter_list|)
block|{
comment|// Only one node in the pipeline.
if|if
condition|(
name|nodes
operator|.
name|length
operator|==
literal|1
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Is it a local node?
name|InetAddress
name|addr
init|=
literal|null
decl_stmt|;
try|try
block|{
name|addr
operator|=
name|InetAddress
operator|.
name|getByName
argument_list|(
name|nodes
index|[
name|index
index|]
operator|.
name|getIpAddr
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|java
operator|.
name|net
operator|.
name|UnknownHostException
name|e
parameter_list|)
block|{
comment|// we are passing an ip address. this should not happen.
assert|assert
literal|false
assert|;
block|}
if|if
condition|(
name|addr
operator|!=
literal|null
operator|&&
name|NetUtils
operator|.
name|isLocalAddress
argument_list|(
name|addr
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|//
comment|// Processes responses from the datanodes.  A packet is removed
comment|// from the ackQueue when its response arrives.
comment|//
DECL|class|ResponseProcessor
specifier|private
class|class
name|ResponseProcessor
extends|extends
name|Daemon
block|{
DECL|field|responderClosed
specifier|private
specifier|volatile
name|boolean
name|responderClosed
init|=
literal|false
decl_stmt|;
DECL|field|targets
specifier|private
name|DatanodeInfo
index|[]
name|targets
init|=
literal|null
decl_stmt|;
DECL|field|isLastPacketInBlock
specifier|private
name|boolean
name|isLastPacketInBlock
init|=
literal|false
decl_stmt|;
DECL|method|ResponseProcessor (DatanodeInfo[] targets)
name|ResponseProcessor
parameter_list|(
name|DatanodeInfo
index|[]
name|targets
parameter_list|)
block|{
name|this
operator|.
name|targets
operator|=
name|targets
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|setName
argument_list|(
literal|"ResponseProcessor for block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|PipelineAck
name|ack
init|=
operator|new
name|PipelineAck
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|responderClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
operator|&&
operator|!
name|isLastPacketInBlock
condition|)
block|{
comment|// process responses from datanodes.
try|try
block|{
comment|// read an ack from the pipeline
name|long
name|begin
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|ack
operator|.
name|readFields
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
name|long
name|duration
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|-
name|begin
decl_stmt|;
if|if
condition|(
name|duration
operator|>
name|dfsclientSlowLogThresholdMs
operator|&&
name|ack
operator|.
name|getSeqno
argument_list|()
operator|!=
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Slow ReadProcessor read fields took "
operator|+
name|duration
operator|+
literal|"ms (threshold="
operator|+
name|dfsclientSlowLogThresholdMs
operator|+
literal|"ms); ack: "
operator|+
name|ack
operator|+
literal|", targets: "
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|targets
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient "
operator|+
name|ack
argument_list|)
expr_stmt|;
block|}
name|long
name|seqno
init|=
name|ack
operator|.
name|getSeqno
argument_list|()
decl_stmt|;
comment|// processes response status from datanodes.
for|for
control|(
name|int
name|i
init|=
name|ack
operator|.
name|getNumOfReplies
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|;
name|i
operator|--
control|)
block|{
specifier|final
name|Status
name|reply
init|=
name|PipelineAck
operator|.
name|getStatusFromHeader
argument_list|(
name|ack
operator|.
name|getReply
argument_list|(
name|i
argument_list|)
argument_list|)
decl_stmt|;
comment|// Restart will not be treated differently unless it is
comment|// the local node or the only one in the pipeline.
if|if
condition|(
name|PipelineAck
operator|.
name|isRestartOOBStatus
argument_list|(
name|reply
argument_list|)
operator|&&
name|shouldWaitForRestart
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|restartDeadline
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|datanodeRestartTimeout
operator|+
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
name|setRestartingNodeIndex
argument_list|(
name|i
argument_list|)
expr_stmt|;
name|String
name|message
init|=
literal|"A datanode is restarting: "
operator|+
name|targets
index|[
name|i
index|]
decl_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
name|message
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|message
argument_list|)
throw|;
block|}
comment|// node error
if|if
condition|(
name|reply
operator|!=
name|SUCCESS
condition|)
block|{
name|setErrorIndex
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|// first bad datanode
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Bad response "
operator|+
name|reply
operator|+
literal|" for block "
operator|+
name|block
operator|+
literal|" from datanode "
operator|+
name|targets
index|[
name|i
index|]
argument_list|)
throw|;
block|}
block|}
assert|assert
name|seqno
operator|!=
name|PipelineAck
operator|.
name|UNKOWN_SEQNO
operator|:
literal|"Ack for unknown seqno should be a failed ack: "
operator|+
name|ack
assert|;
if|if
condition|(
name|seqno
operator|==
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
condition|)
block|{
comment|// a heartbeat ack
continue|continue;
block|}
comment|// a success ack for a data packet
name|DFSPacket
name|one
decl_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|one
operator|=
name|ackQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|one
operator|.
name|getSeqno
argument_list|()
operator|!=
name|seqno
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"ResponseProcessor: Expecting seqno "
operator|+
literal|" for block "
operator|+
name|block
operator|+
name|one
operator|.
name|getSeqno
argument_list|()
operator|+
literal|" but received "
operator|+
name|seqno
argument_list|)
throw|;
block|}
name|isLastPacketInBlock
operator|=
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
expr_stmt|;
comment|// Fail the packet write for testing in order to force a
comment|// pipeline recovery.
if|if
condition|(
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|failPacket
argument_list|()
operator|&&
name|isLastPacketInBlock
condition|)
block|{
name|failPacket
operator|=
literal|true
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failing the last packet for testing."
argument_list|)
throw|;
block|}
comment|// update bytesAcked
name|block
operator|.
name|setNumBytes
argument_list|(
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|lastAckedSeqno
operator|=
name|seqno
expr_stmt|;
name|ackQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
name|one
operator|.
name|releaseBuffer
argument_list|(
name|byteArrayManager
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|responderClosed
condition|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|setLastException
argument_list|(
operator|(
name|IOException
operator|)
name|e
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
comment|// If no explicit error report was received, mark the primary
comment|// node as failed.
name|tryMarkPrimaryDatanodeFailed
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DFSOutputStream ResponseProcessor exception "
operator|+
literal|" for block "
operator|+
name|block
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|responderClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|close ()
name|void
name|close
parameter_list|()
block|{
name|responderClosed
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
comment|// If this stream has encountered any errors so far, shutdown
comment|// threads and mark stream as closed. Returns true if we should
comment|// sleep for a while after returning from this call.
comment|//
DECL|method|processDatanodeError ()
specifier|private
name|boolean
name|processDatanodeError
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Error Recovery for "
operator|+
name|block
operator|+
literal|" waiting for responder to exit. "
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|closeStream
argument_list|()
expr_stmt|;
comment|// move packets from ack queue to front of the data queue
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|addAll
argument_list|(
literal|0
argument_list|,
name|ackQueue
argument_list|)
expr_stmt|;
name|ackQueue
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|// Record the new pipeline failure recovery.
if|if
condition|(
name|lastAckedSeqnoBeforeFailure
operator|!=
name|lastAckedSeqno
condition|)
block|{
name|lastAckedSeqnoBeforeFailure
operator|=
name|lastAckedSeqno
expr_stmt|;
name|pipelineRecoveryCount
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|// If we had to recover the pipeline five times in a row for the
comment|// same packet, this client likely has corrupt data or corrupting
comment|// during transmission.
if|if
condition|(
operator|++
name|pipelineRecoveryCount
operator|>
literal|5
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error recovering pipeline for writing "
operator|+
name|block
operator|+
literal|". Already retried 5 times for the same packet."
argument_list|)
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Failing write. Tried pipeline "
operator|+
literal|"recovery 5 times without success."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|doSleep
init|=
name|setupPipelineForAppendOrRecovery
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
condition|)
block|{
comment|// If we had an error while closing the pipeline, we go through a fast-path
comment|// where the BlockReceiver does not run. Instead, the DataNode just finalizes
comment|// the block immediately during the 'connect ack' process. So, we want to pull
comment|// the end-of-block packet from the dataQueue, since we don't actually have
comment|// a true pipeline to send it over.
comment|//
comment|// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that
comment|// a client waiting on close() will be aware that the flush finished.
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|DFSPacket
name|endOfBlockPacket
init|=
name|dataQueue
operator|.
name|remove
argument_list|()
decl_stmt|;
comment|// remove the end of block packet
assert|assert
name|endOfBlockPacket
operator|.
name|isLastPacketInBlock
argument_list|()
assert|;
assert|assert
name|lastAckedSeqno
operator|==
name|endOfBlockPacket
operator|.
name|getSeqno
argument_list|()
operator|-
literal|1
assert|;
name|lastAckedSeqno
operator|=
name|endOfBlockPacket
operator|.
name|getSeqno
argument_list|()
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|doSleep
return|;
block|}
DECL|method|setHflush ()
specifier|private
name|void
name|setHflush
parameter_list|()
block|{
name|isHflushed
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|findNewDatanode (final DatanodeInfo[] original )
specifier|private
name|int
name|findNewDatanode
parameter_list|(
specifier|final
name|DatanodeInfo
index|[]
name|original
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|!=
name|original
operator|.
name|length
operator|+
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
literal|"Failed to replace a bad datanode on the existing pipeline "
argument_list|)
operator|.
name|append
argument_list|(
literal|"due to no more good datanodes being available to try. "
argument_list|)
operator|.
name|append
argument_list|(
literal|"(Nodes: current="
argument_list|)
operator|.
name|append
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", original="
argument_list|)
operator|.
name|append
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"). "
argument_list|)
operator|.
name|append
argument_list|(
literal|"The current failed datanode replacement policy is "
argument_list|)
operator|.
name|append
argument_list|(
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
argument_list|)
operator|.
name|append
argument_list|(
literal|", and "
argument_list|)
operator|.
name|append
argument_list|(
literal|"a client may configure this via '"
argument_list|)
operator|.
name|append
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_POLICY_KEY
argument_list|)
operator|.
name|append
argument_list|(
literal|"' in its configuration."
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|int
name|j
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
name|j
operator|<
name|original
operator|.
name|length
operator|&&
operator|!
name|nodes
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
name|original
index|[
name|j
index|]
argument_list|)
condition|;
name|j
operator|++
control|)
empty_stmt|;
if|if
condition|(
name|j
operator|==
name|original
operator|.
name|length
condition|)
block|{
return|return
name|i
return|;
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed: new datanode not found: nodes="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
operator|+
literal|", original="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
argument_list|)
throw|;
block|}
DECL|method|addDatanode2ExistingPipeline ()
specifier|private
name|void
name|addDatanode2ExistingPipeline
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"lastAckedSeqno = "
operator|+
name|lastAckedSeqno
argument_list|)
expr_stmt|;
block|}
comment|/*        * Is data transfer necessary?  We have the following cases.        *         * Case 1: Failure in Pipeline Setup        * - Append        *    + Transfer the stored replica, which may be a RBW or a finalized.        * - Create        *    + If no data, then no transfer is required.        *    + If there are data written, transfer RBW. This case may happens         *      when there are streaming failure earlier in this pipeline.        *        * Case 2: Failure in Streaming        * - Append/Create:        *    + transfer RBW        *         * Case 3: Failure in Close        * - Append/Create:        *    + no transfer, let NameNode replicates the block.        */
if|if
condition|(
operator|!
name|isAppend
operator|&&
name|lastAckedSeqno
operator|<
literal|0
operator|&&
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
comment|//no data have been written
return|return;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE_RECOVERY
condition|)
block|{
comment|//pipeline is closing
return|return;
block|}
comment|//get a new datanode
specifier|final
name|DatanodeInfo
index|[]
name|original
init|=
name|nodes
decl_stmt|;
specifier|final
name|LocatedBlock
name|lb
init|=
name|dfsClient
operator|.
name|namenode
operator|.
name|getAdditionalDatanode
argument_list|(
name|src
argument_list|,
name|fileId
argument_list|,
name|block
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|,
name|failed
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
name|failed
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
literal|1
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
decl_stmt|;
name|setPipeline
argument_list|(
name|lb
argument_list|)
expr_stmt|;
comment|//find the new datanode
specifier|final
name|int
name|d
init|=
name|findNewDatanode
argument_list|(
name|original
argument_list|)
decl_stmt|;
comment|//transfer replica
specifier|final
name|DatanodeInfo
name|src
init|=
name|d
operator|==
literal|0
condition|?
name|nodes
index|[
literal|1
index|]
else|:
name|nodes
index|[
name|d
operator|-
literal|1
index|]
decl_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|targets
init|=
block|{
name|nodes
index|[
name|d
index|]
block|}
decl_stmt|;
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
init|=
block|{
name|storageTypes
index|[
name|d
index|]
block|}
decl_stmt|;
name|transfer
argument_list|(
name|src
argument_list|,
name|targets
argument_list|,
name|targetStorageTypes
argument_list|,
name|lb
operator|.
name|getBlockToken
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|transfer (final DatanodeInfo src, final DatanodeInfo[] targets, final StorageType[] targetStorageTypes, final Token<BlockTokenIdentifier> blockToken)
specifier|private
name|void
name|transfer
parameter_list|(
specifier|final
name|DatanodeInfo
name|src
parameter_list|,
specifier|final
name|DatanodeInfo
index|[]
name|targets
parameter_list|,
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
parameter_list|,
specifier|final
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|)
throws|throws
name|IOException
block|{
comment|//transfer replica to the new datanode
name|Socket
name|sock
init|=
literal|null
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
name|DataInputStream
name|in
init|=
literal|null
decl_stmt|;
try|try
block|{
name|sock
operator|=
name|createSocketForPipeline
argument_list|(
name|src
argument_list|,
literal|2
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
specifier|final
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|sock
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|sock
argument_list|)
decl_stmt|;
name|IOStreamPair
name|saslStreams
init|=
name|dfsClient
operator|.
name|saslClient
operator|.
name|socketSend
argument_list|(
name|sock
argument_list|,
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
argument_list|,
name|blockToken
argument_list|,
name|src
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|saslStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|saslStreams
operator|.
name|in
expr_stmt|;
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|HdfsConstants
operator|.
name|SMALL_BUFFER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//send the TRANSFER_BLOCK request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|transferBlock
argument_list|(
name|block
argument_list|,
name|blockToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|targets
argument_list|,
name|targetStorageTypes
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
comment|//ack
name|BlockOpResponseProto
name|response
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelper
operator|.
name|vintPrefixed
argument_list|(
name|in
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|SUCCESS
operator|!=
name|response
operator|.
name|getStatus
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to add a datanode"
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Open a DataOutputStream to a DataNode pipeline so that       * it can be written to.      * This happens when a file is appended or data streaming fails      * It keeps on trying until a pipeline is setup      */
DECL|method|setupPipelineForAppendOrRecovery ()
specifier|private
name|boolean
name|setupPipelineForAppendOrRecovery
parameter_list|()
throws|throws
name|IOException
block|{
comment|// check number of datanodes
if|if
condition|(
name|nodes
operator|==
literal|null
operator|||
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|String
name|msg
init|=
literal|"Could not get block locations. "
operator|+
literal|"Source file \""
operator|+
name|src
operator|+
literal|"\" - Aborting..."
decl_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|setLastException
argument_list|(
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|long
name|newGS
init|=
literal|0L
decl_stmt|;
while|while
condition|(
operator|!
name|success
operator|&&
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
comment|// Sleep before reconnect if a dn is restarting.
comment|// This process will be repeated until the deadline or the datanode
comment|// starts back up.
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|>=
literal|0
condition|)
block|{
comment|// 4 seconds or the configured deadline period, whichever is shorter.
comment|// This is the retry interval and recovery will be retried in this
comment|// interval until timeout or success.
name|long
name|delay
init|=
name|Math
operator|.
name|min
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|datanodeRestartTimeout
argument_list|,
literal|4000L
argument_list|)
decl_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Interrupted while waiting for "
operator|+
literal|"datanode to restart. "
operator|+
name|nodes
index|[
name|restartingNodeIndex
operator|.
name|get
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|isRecovery
init|=
name|hasError
decl_stmt|;
comment|// remove bad datanode from list of datanodes.
comment|// If errorIndex was not set (i.e. appends), then do not remove
comment|// any datanodes
comment|//
if|if
condition|(
name|errorIndex
operator|>=
literal|0
condition|)
block|{
name|StringBuilder
name|pipelineMsg
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|nodes
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|pipelineMsg
operator|.
name|append
argument_list|(
name|nodes
index|[
name|j
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|j
operator|<
name|nodes
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|pipelineMsg
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|nodes
operator|.
name|length
operator|<=
literal|1
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"All datanodes "
operator|+
name|pipelineMsg
operator|+
literal|" are bad. Aborting..."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error Recovery for block "
operator|+
name|block
operator|+
literal|" in pipeline "
operator|+
name|pipelineMsg
operator|+
literal|": bad datanode "
operator|+
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|failed
operator|.
name|add
argument_list|(
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|DatanodeInfo
index|[]
name|newnodes
init|=
operator|new
name|DatanodeInfo
index|[
name|nodes
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|nodes
argument_list|,
name|newnodes
argument_list|,
name|errorIndex
argument_list|)
expr_stmt|;
specifier|final
name|StorageType
index|[]
name|newStorageTypes
init|=
operator|new
name|StorageType
index|[
name|newnodes
operator|.
name|length
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|storageTypes
argument_list|,
name|newStorageTypes
argument_list|,
name|errorIndex
argument_list|)
expr_stmt|;
specifier|final
name|String
index|[]
name|newStorageIDs
init|=
operator|new
name|String
index|[
name|newnodes
operator|.
name|length
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|storageIDs
argument_list|,
name|newStorageIDs
argument_list|,
name|errorIndex
argument_list|)
expr_stmt|;
name|setPipeline
argument_list|(
name|newnodes
argument_list|,
name|newStorageTypes
argument_list|,
name|newStorageIDs
argument_list|)
expr_stmt|;
comment|// Just took care of a node error while waiting for a node restart
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|>=
literal|0
condition|)
block|{
comment|// If the error came from a node further away than the restarting
comment|// node, the restart must have been complete.
if|if
condition|(
name|errorIndex
operator|>
name|restartingNodeIndex
operator|.
name|get
argument_list|()
condition|)
block|{
name|restartingNodeIndex
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|errorIndex
operator|<
name|restartingNodeIndex
operator|.
name|get
argument_list|()
condition|)
block|{
comment|// the node index has shifted.
name|restartingNodeIndex
operator|.
name|decrementAndGet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// this shouldn't happen...
assert|assert
literal|false
assert|;
block|}
block|}
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
name|lastException
operator|.
name|set
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// Check if replace-datanode policy is satisfied.
if|if
condition|(
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|.
name|satisfy
argument_list|(
name|blockReplication
argument_list|,
name|nodes
argument_list|,
name|isAppend
argument_list|,
name|isHflushed
argument_list|)
condition|)
block|{
try|try
block|{
name|addDatanode2ExistingPipeline
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
operator|!
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|.
name|isBestEffort
argument_list|()
condition|)
block|{
throw|throw
name|ioe
throw|;
block|}
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to replace datanode."
operator|+
literal|" Continue with the remaining datanodes since "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_BEST_EFFORT_KEY
operator|+
literal|" is set to true."
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
comment|// get a new generation stamp and an access token
name|LocatedBlock
name|lb
init|=
name|dfsClient
operator|.
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|block
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
decl_stmt|;
name|newGS
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
comment|// set up the pipeline again with the remaining nodes
if|if
condition|(
name|failPacket
condition|)
block|{
comment|// for testing
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|,
name|newGS
argument_list|,
name|isRecovery
argument_list|)
expr_stmt|;
name|failPacket
operator|=
literal|false
expr_stmt|;
try|try
block|{
comment|// Give DNs time to send in bad reports. In real situations,
comment|// good reports should follow bad ones, if client committed
comment|// with those nodes.
name|Thread
operator|.
name|sleep
argument_list|(
literal|2000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{}
block|}
else|else
block|{
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|,
name|newGS
argument_list|,
name|isRecovery
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|>=
literal|0
condition|)
block|{
assert|assert
name|hasError
operator|==
literal|true
assert|;
comment|// check errorIndex set above
if|if
condition|(
name|errorIndex
operator|==
name|restartingNodeIndex
operator|.
name|get
argument_list|()
condition|)
block|{
comment|// ignore, if came from the restarting node
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// still within the deadline
if|if
condition|(
name|Time
operator|.
name|now
argument_list|()
operator|<
name|restartDeadline
condition|)
block|{
continue|continue;
comment|// with in the deadline
block|}
comment|// expired. declare the restarting node dead
name|restartDeadline
operator|=
literal|0
expr_stmt|;
name|int
name|expiredNodeIndex
init|=
name|restartingNodeIndex
operator|.
name|get
argument_list|()
decl_stmt|;
name|restartingNodeIndex
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Datanode did not restart in time: "
operator|+
name|nodes
index|[
name|expiredNodeIndex
index|]
argument_list|)
expr_stmt|;
comment|// Mark the restarting node as failed. If there is any other failed
comment|// node during the last pipeline construction attempt, it will not be
comment|// overwritten/dropped. In this case, the restarting node will get
comment|// excluded in the following attempt, if it still does not come up.
if|if
condition|(
name|errorIndex
operator|==
operator|-
literal|1
condition|)
block|{
name|errorIndex
operator|=
name|expiredNodeIndex
expr_stmt|;
block|}
comment|// From this point on, normal pipeline recovery applies.
block|}
block|}
comment|// while
if|if
condition|(
name|success
condition|)
block|{
comment|// update pipeline at the namenode
name|ExtendedBlock
name|newBlock
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|block
operator|.
name|getBlockId
argument_list|()
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|newGS
argument_list|)
decl_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|updatePipeline
argument_list|(
name|dfsClient
operator|.
name|clientName
argument_list|,
name|block
argument_list|,
name|newBlock
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|)
expr_stmt|;
comment|// update client side generation stamp
name|block
operator|=
name|newBlock
expr_stmt|;
block|}
return|return
literal|false
return|;
comment|// do not sleep, continue processing
block|}
comment|/**      * Open a DataOutputStream to a DataNode so that it can be written to.      * This happens when a file is created and each time a new block is allocated.      * Must get block ID and the IDs of the destinations from the namenode.      * Returns the list of target datanodes.      */
DECL|method|nextBlockOutputStream ()
specifier|private
name|LocatedBlock
name|nextBlockOutputStream
parameter_list|()
throws|throws
name|IOException
block|{
name|LocatedBlock
name|lb
init|=
literal|null
decl_stmt|;
name|DatanodeInfo
index|[]
name|nodes
init|=
literal|null
decl_stmt|;
name|StorageType
index|[]
name|storageTypes
init|=
literal|null
decl_stmt|;
name|int
name|count
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nBlockWriteRetry
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|ExtendedBlock
name|oldBlock
init|=
name|block
decl_stmt|;
do|do
block|{
name|hasError
operator|=
literal|false
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|success
operator|=
literal|false
expr_stmt|;
name|long
name|startTime
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
name|DatanodeInfo
index|[]
name|excluded
init|=
name|excludedNodes
operator|.
name|getAllPresent
argument_list|(
name|excludedNodes
operator|.
name|asMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
operator|.
name|keySet
argument_list|()
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|block
operator|=
name|oldBlock
expr_stmt|;
name|lb
operator|=
name|locateFollowingBlock
argument_list|(
name|startTime
argument_list|,
name|excluded
operator|.
name|length
operator|>
literal|0
condition|?
name|excluded
else|:
literal|null
argument_list|)
expr_stmt|;
name|block
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
expr_stmt|;
name|block
operator|.
name|setNumBytes
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|bytesSent
operator|=
literal|0
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
name|nodes
operator|=
name|lb
operator|.
name|getLocations
argument_list|()
expr_stmt|;
name|storageTypes
operator|=
name|lb
operator|.
name|getStorageTypes
argument_list|()
expr_stmt|;
comment|//
comment|// Connect to first DataNode in the list.
comment|//
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|,
literal|0L
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Abandoning "
operator|+
name|block
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|abandonBlock
argument_list|(
name|block
argument_list|,
name|fileId
argument_list|,
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
name|block
operator|=
literal|null
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Excluding datanode "
operator|+
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|excludedNodes
operator|.
name|put
argument_list|(
name|nodes
index|[
name|errorIndex
index|]
argument_list|,
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|!
name|success
operator|&&
operator|--
name|count
operator|>=
literal|0
condition|)
do|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to create new block."
argument_list|)
throw|;
block|}
return|return
name|lb
return|;
block|}
comment|// connects to the first datanode in the pipeline
comment|// Returns true if success, otherwise return failure.
comment|//
DECL|method|createBlockOutputStream (DatanodeInfo[] nodes, StorageType[] nodeStorageTypes, long newGS, boolean recoveryFlag)
specifier|private
name|boolean
name|createBlockOutputStream
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|StorageType
index|[]
name|nodeStorageTypes
parameter_list|,
name|long
name|newGS
parameter_list|,
name|boolean
name|recoveryFlag
parameter_list|)
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"nodes are empty for write pipeline of block "
operator|+
name|block
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|Status
name|pipelineStatus
init|=
name|SUCCESS
decl_stmt|;
name|String
name|firstBadLink
init|=
literal|""
decl_stmt|;
name|boolean
name|checkRestart
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"pipeline = "
operator|+
name|nodes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|// persist blocks on namenode on next flush
name|persistBlocks
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|int
name|refetchEncryptionKey
init|=
literal|1
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
try|try
block|{
assert|assert
literal|null
operator|==
name|s
operator|:
literal|"Previous socket unclosed"
assert|;
assert|assert
literal|null
operator|==
name|blockReplyStream
operator|:
literal|"Previous blockReplyStream unclosed"
assert|;
name|s
operator|=
name|createSocketForPipeline
argument_list|(
name|nodes
index|[
literal|0
index|]
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
name|nodes
operator|.
name|length
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|s
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|s
argument_list|)
decl_stmt|;
name|IOStreamPair
name|saslStreams
init|=
name|dfsClient
operator|.
name|saslClient
operator|.
name|socketSend
argument_list|(
name|s
argument_list|,
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
argument_list|,
name|accessToken
argument_list|,
name|nodes
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|saslStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|saslStreams
operator|.
name|in
expr_stmt|;
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|HdfsConstants
operator|.
name|SMALL_BUFFER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//
comment|// Xmit header info to datanode
comment|//
name|BlockConstructionStage
name|bcs
init|=
name|recoveryFlag
condition|?
name|stage
operator|.
name|getRecoveryStage
argument_list|()
else|:
name|stage
decl_stmt|;
comment|// We cannot change the block length in 'block' as it counts the number
comment|// of bytes ack'ed.
name|ExtendedBlock
name|blockCopy
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|blockCopy
operator|.
name|setNumBytes
argument_list|(
name|blockSize
argument_list|)
expr_stmt|;
name|boolean
index|[]
name|targetPinnings
init|=
name|getPinnings
argument_list|(
name|nodes
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// send the request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|writeBlock
argument_list|(
name|blockCopy
argument_list|,
name|nodeStorageTypes
index|[
literal|0
index|]
argument_list|,
name|accessToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|nodes
argument_list|,
name|nodeStorageTypes
argument_list|,
literal|null
argument_list|,
name|bcs
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|bytesSent
argument_list|,
name|newGS
argument_list|,
name|checksum4WriteBlock
argument_list|,
name|cachingStrategy
operator|.
name|get
argument_list|()
argument_list|,
name|isLazyPersistFile
argument_list|,
operator|(
name|targetPinnings
operator|==
literal|null
condition|?
literal|false
else|:
name|targetPinnings
index|[
literal|0
index|]
operator|)
argument_list|,
name|targetPinnings
argument_list|)
expr_stmt|;
comment|// receive ack for connect
name|BlockOpResponseProto
name|resp
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelper
operator|.
name|vintPrefixed
argument_list|(
name|blockReplyStream
argument_list|)
argument_list|)
decl_stmt|;
name|pipelineStatus
operator|=
name|resp
operator|.
name|getStatus
argument_list|()
expr_stmt|;
name|firstBadLink
operator|=
name|resp
operator|.
name|getFirstBadLink
argument_list|()
expr_stmt|;
comment|// Got an restart OOB ack.
comment|// If a node is already restarting, this status is not likely from
comment|// the same node. If it is from a different node, it is not
comment|// from the local datanode. Thus it is safe to treat this as a
comment|// regular node error.
if|if
condition|(
name|PipelineAck
operator|.
name|isRestartOOBStatus
argument_list|(
name|pipelineStatus
argument_list|)
operator|&&
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
name|checkRestart
operator|=
literal|true
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"A datanode is restarting."
argument_list|)
throw|;
block|}
name|String
name|logInfo
init|=
literal|"ack with firstBadLink as "
operator|+
name|firstBadLink
decl_stmt|;
name|DataTransferProtoUtil
operator|.
name|checkBlockOpStatus
argument_list|(
name|resp
argument_list|,
name|logInfo
argument_list|)
expr_stmt|;
assert|assert
literal|null
operator|==
name|blockStream
operator|:
literal|"Previous blockStream unclosed"
assert|;
name|blockStream
operator|=
name|out
expr_stmt|;
name|result
operator|=
literal|true
expr_stmt|;
comment|// success
name|restartingNodeIndex
operator|.
name|set
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
name|hasError
operator|=
literal|false
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
if|if
condition|(
name|restartingNodeIndex
operator|.
name|get
argument_list|()
operator|==
operator|-
literal|1
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception in createBlockOutputStream"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|ie
operator|instanceof
name|InvalidEncryptionKeyException
operator|&&
name|refetchEncryptionKey
operator|>
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Will fetch a new encryption key and retry, "
operator|+
literal|"encryption key was invalid when connecting to "
operator|+
name|nodes
index|[
literal|0
index|]
operator|+
literal|" : "
operator|+
name|ie
argument_list|)
expr_stmt|;
comment|// The encryption key used is invalid.
name|refetchEncryptionKey
operator|--
expr_stmt|;
name|dfsClient
operator|.
name|clearDataEncryptionKey
argument_list|()
expr_stmt|;
comment|// Don't close the socket/exclude this node just yet. Try again with
comment|// a new encryption key.
continue|continue;
block|}
comment|// find the datanode that matches
if|if
condition|(
name|firstBadLink
operator|.
name|length
argument_list|()
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// NB: Unconditionally using the xfer addr w/o hostname
if|if
condition|(
name|firstBadLink
operator|.
name|equals
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
name|errorIndex
operator|=
name|i
expr_stmt|;
break|break;
block|}
block|}
block|}
else|else
block|{
assert|assert
name|checkRestart
operator|==
literal|false
assert|;
name|errorIndex
operator|=
literal|0
expr_stmt|;
block|}
comment|// Check whether there is a restart worth waiting for.
if|if
condition|(
name|checkRestart
operator|&&
name|shouldWaitForRestart
argument_list|(
name|errorIndex
argument_list|)
condition|)
block|{
name|restartDeadline
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|datanodeRestartTimeout
operator|+
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
name|restartingNodeIndex
operator|.
name|set
argument_list|(
name|errorIndex
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for the datanode to be restarted: "
operator|+
name|nodes
index|[
name|restartingNodeIndex
operator|.
name|get
argument_list|()
index|]
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
name|setLastException
argument_list|(
name|ie
argument_list|)
expr_stmt|;
name|result
operator|=
literal|false
expr_stmt|;
comment|// error
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|result
condition|)
block|{
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|out
operator|=
literal|null
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
block|}
DECL|method|getPinnings (DatanodeInfo[] nodes, boolean shouldLog)
specifier|private
name|boolean
index|[]
name|getPinnings
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|boolean
name|shouldLog
parameter_list|)
block|{
if|if
condition|(
name|favoredNodes
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|boolean
index|[]
name|pinnings
init|=
operator|new
name|boolean
index|[
name|nodes
operator|.
name|length
index|]
decl_stmt|;
name|HashSet
argument_list|<
name|String
argument_list|>
name|favoredSet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|favoredNodes
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|pinnings
index|[
name|i
index|]
operator|=
name|favoredSet
operator|.
name|remove
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddrWithHostname
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddrWithHostname
argument_list|()
operator|+
literal|" was chosen by name node (favored="
operator|+
name|pinnings
index|[
name|i
index|]
operator|+
literal|")."
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|shouldLog
operator|&&
operator|!
name|favoredSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// There is one or more favored nodes that were not allocated.
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"These favored nodes were specified but not chosen: "
operator|+
name|favoredSet
operator|+
literal|" Specified favored nodes: "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|favoredNodes
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|pinnings
return|;
block|}
block|}
DECL|method|locateFollowingBlock (long start, DatanodeInfo[] excludedNodes)
specifier|private
name|LocatedBlock
name|locateFollowingBlock
parameter_list|(
name|long
name|start
parameter_list|,
name|DatanodeInfo
index|[]
name|excludedNodes
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|retries
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nBlockWriteLocateFollowingRetry
decl_stmt|;
name|long
name|sleeptime
init|=
literal|400
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|long
name|localstart
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
return|return
name|dfsClient
operator|.
name|namenode
operator|.
name|addBlock
argument_list|(
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|block
argument_list|,
name|excludedNodes
argument_list|,
name|fileId
argument_list|,
name|favoredNodes
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|RemoteException
name|e
parameter_list|)
block|{
name|IOException
name|ue
init|=
name|e
operator|.
name|unwrapRemoteException
argument_list|(
name|FileNotFoundException
operator|.
name|class
argument_list|,
name|AccessControlException
operator|.
name|class
argument_list|,
name|NSQuotaExceededException
operator|.
name|class
argument_list|,
name|DSQuotaExceededException
operator|.
name|class
argument_list|,
name|UnresolvedPathException
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|ue
operator|!=
name|e
condition|)
block|{
throw|throw
name|ue
throw|;
comment|// no need to retry these exceptions
block|}
if|if
condition|(
name|NotReplicatedYetException
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|e
operator|.
name|getClassName
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|retries
operator|==
literal|0
condition|)
block|{
throw|throw
name|e
throw|;
block|}
else|else
block|{
operator|--
name|retries
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception while adding a block"
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|>
literal|5000
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for replication for "
operator|+
operator|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|)
operator|/
literal|1000
operator|+
literal|" seconds"
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"NotReplicatedYetException sleeping "
operator|+
name|src
operator|+
literal|" retries left "
operator|+
name|retries
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|sleeptime
argument_list|)
expr_stmt|;
name|sleeptime
operator|*=
literal|2
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
block|}
block|}
DECL|method|getBlock ()
name|ExtendedBlock
name|getBlock
parameter_list|()
block|{
return|return
name|block
return|;
block|}
DECL|method|getNodes ()
name|DatanodeInfo
index|[]
name|getNodes
parameter_list|()
block|{
return|return
name|nodes
return|;
block|}
DECL|method|getBlockToken ()
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockToken
parameter_list|()
block|{
return|return
name|accessToken
return|;
block|}
DECL|method|setLastException (IOException e)
specifier|private
name|void
name|setLastException
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|lastException
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a socket for a write pipeline    * @param first the first datanode     * @param length the pipeline length    * @param client client    * @return the socket connected to the first datanode    */
DECL|method|createSocketForPipeline (final DatanodeInfo first, final int length, final DFSClient client)
specifier|static
name|Socket
name|createSocketForPipeline
parameter_list|(
specifier|final
name|DatanodeInfo
name|first
parameter_list|,
specifier|final
name|int
name|length
parameter_list|,
specifier|final
name|DFSClient
name|client
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|dnAddr
init|=
name|first
operator|.
name|getXferAddr
argument_list|(
name|client
operator|.
name|getConf
argument_list|()
operator|.
name|connectToDnViaHostname
argument_list|)
decl_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connecting to datanode "
operator|+
name|dnAddr
argument_list|)
expr_stmt|;
block|}
specifier|final
name|InetSocketAddress
name|isa
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
specifier|final
name|Socket
name|sock
init|=
name|client
operator|.
name|socketFactory
operator|.
name|createSocket
argument_list|()
decl_stmt|;
specifier|final
name|int
name|timeout
init|=
name|client
operator|.
name|getDatanodeReadTimeout
argument_list|(
name|length
argument_list|)
decl_stmt|;
name|NetUtils
operator|.
name|connect
argument_list|(
name|sock
argument_list|,
name|isa
argument_list|,
name|client
operator|.
name|getRandomLocalInterfaceAddr
argument_list|()
argument_list|,
name|client
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSendBufferSize
argument_list|(
name|HdfsConstants
operator|.
name|DEFAULT_DATA_SOCKET_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Send buf size "
operator|+
name|sock
operator|.
name|getSendBufferSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sock
return|;
block|}
annotation|@
name|Override
DECL|method|checkClosed ()
specifier|protected
name|void
name|checkClosed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|IOException
name|e
init|=
name|lastException
operator|.
name|get
argument_list|()
decl_stmt|;
throw|throw
name|e
operator|!=
literal|null
condition|?
name|e
else|:
operator|new
name|ClosedChannelException
argument_list|()
throw|;
block|}
block|}
comment|//
comment|// returns the list of targets, if any, that is being currently used.
comment|//
annotation|@
name|VisibleForTesting
DECL|method|getPipeline ()
specifier|public
specifier|synchronized
name|DatanodeInfo
index|[]
name|getPipeline
parameter_list|()
block|{
if|if
condition|(
name|streamer
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|DatanodeInfo
index|[]
name|currentNodes
init|=
name|streamer
operator|.
name|getNodes
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentNodes
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|DatanodeInfo
index|[]
name|value
init|=
operator|new
name|DatanodeInfo
index|[
name|currentNodes
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|currentNodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|value
index|[
name|i
index|]
operator|=
name|currentNodes
index|[
name|i
index|]
expr_stmt|;
block|}
return|return
name|value
return|;
block|}
comment|/**     * @return the object for computing checksum.    *         The type is NULL if checksum is not computed.    */
DECL|method|getChecksum4Compute (DataChecksum checksum, HdfsFileStatus stat)
specifier|private
specifier|static
name|DataChecksum
name|getChecksum4Compute
parameter_list|(
name|DataChecksum
name|checksum
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|)
block|{
if|if
condition|(
name|isLazyPersist
argument_list|(
name|stat
argument_list|)
operator|&&
name|stat
operator|.
name|getReplication
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// do not compute checksum for writing to single replica to memory
return|return
name|DataChecksum
operator|.
name|newDataChecksum
argument_list|(
name|Type
operator|.
name|NULL
argument_list|,
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
return|;
block|}
return|return
name|checksum
return|;
block|}
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, Progressable progress, HdfsFileStatus stat, DataChecksum checksum)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|getChecksum4Compute
argument_list|(
name|checksum
argument_list|,
name|stat
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|dfsClient
operator|=
name|dfsClient
expr_stmt|;
name|this
operator|.
name|src
operator|=
name|src
expr_stmt|;
name|this
operator|.
name|fileId
operator|=
name|stat
operator|.
name|getFileId
argument_list|()
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|stat
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|this
operator|.
name|blockReplication
operator|=
name|stat
operator|.
name|getReplication
argument_list|()
expr_stmt|;
name|this
operator|.
name|fileEncryptionInfo
operator|=
name|stat
operator|.
name|getFileEncryptionInfo
argument_list|()
expr_stmt|;
name|this
operator|.
name|progress
operator|=
name|progress
expr_stmt|;
name|this
operator|.
name|cachingStrategy
operator|=
operator|new
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
argument_list|(
name|dfsClient
operator|.
name|getDefaultWriteCachingStrategy
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|progress
operator|!=
literal|null
operator|)
operator|&&
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Set non-null progress callback on DFSOutputStream "
operator|+
name|src
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|bytesPerChecksum
operator|=
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytesPerChecksum
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|HadoopIllegalArgumentException
argument_list|(
literal|"Invalid value: bytesPerChecksum = "
operator|+
name|bytesPerChecksum
operator|+
literal|"<= 0"
argument_list|)
throw|;
block|}
if|if
condition|(
name|blockSize
operator|%
name|bytesPerChecksum
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|HadoopIllegalArgumentException
argument_list|(
literal|"Invalid values: "
operator|+
name|DFSConfigKeys
operator|.
name|DFS_BYTES_PER_CHECKSUM_KEY
operator|+
literal|" (="
operator|+
name|bytesPerChecksum
operator|+
literal|") must divide block size (="
operator|+
name|blockSize
operator|+
literal|")."
argument_list|)
throw|;
block|}
name|this
operator|.
name|checksum4WriteBlock
operator|=
name|checksum
expr_stmt|;
name|this
operator|.
name|dfsclientSlowLogThresholdMs
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|dfsclientSlowIoWarningThresholdMs
expr_stmt|;
name|this
operator|.
name|byteArrayManager
operator|=
name|dfsClient
operator|.
name|getClientContext
argument_list|()
operator|.
name|getByteArrayManager
argument_list|()
expr_stmt|;
block|}
comment|/** Construct a new output stream for creating a file. */
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, HdfsFileStatus stat, EnumSet<CreateFlag> flag, Progressable progress, DataChecksum checksum, String[] favoredNodes)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
expr_stmt|;
name|this
operator|.
name|shouldSyncBlock
operator|=
name|flag
operator|.
name|contains
argument_list|(
name|CreateFlag
operator|.
name|SYNC_BLOCK
argument_list|)
expr_stmt|;
name|computePacketChunkSize
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
name|Span
name|traceSpan
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|Trace
operator|.
name|isTracing
argument_list|()
condition|)
block|{
name|traceSpan
operator|=
name|Trace
operator|.
name|startSpan
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
operator|.
name|detach
argument_list|()
expr_stmt|;
block|}
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|(
name|stat
argument_list|,
literal|null
argument_list|,
name|traceSpan
argument_list|)
expr_stmt|;
if|if
condition|(
name|favoredNodes
operator|!=
literal|null
operator|&&
name|favoredNodes
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
name|streamer
operator|.
name|setFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|newStreamForCreate (DFSClient dfsClient, String src, FsPermission masked, EnumSet<CreateFlag> flag, boolean createParent, short replication, long blockSize, Progressable progress, int buffersize, DataChecksum checksum, String[] favoredNodes)
specifier|static
name|DFSOutputStream
name|newStreamForCreate
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|FsPermission
name|masked
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|boolean
name|createParent
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|int
name|buffersize
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
throws|throws
name|IOException
block|{
name|HdfsFileStatus
name|stat
init|=
literal|null
decl_stmt|;
comment|// Retry the create if we get a RetryStartFileException up to a maximum
comment|// number of times
name|boolean
name|shouldRetry
init|=
literal|true
decl_stmt|;
name|int
name|retryCount
init|=
name|CREATE_RETRY_COUNT
decl_stmt|;
while|while
condition|(
name|shouldRetry
condition|)
block|{
name|shouldRetry
operator|=
literal|false
expr_stmt|;
try|try
block|{
name|stat
operator|=
name|dfsClient
operator|.
name|namenode
operator|.
name|create
argument_list|(
name|src
argument_list|,
name|masked
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
operator|new
name|EnumSetWritable
argument_list|<
name|CreateFlag
argument_list|>
argument_list|(
name|flag
argument_list|)
argument_list|,
name|createParent
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|,
name|SUPPORTED_CRYPTO_VERSIONS
argument_list|)
expr_stmt|;
break|break;
block|}
catch|catch
parameter_list|(
name|RemoteException
name|re
parameter_list|)
block|{
name|IOException
name|e
init|=
name|re
operator|.
name|unwrapRemoteException
argument_list|(
name|AccessControlException
operator|.
name|class
argument_list|,
name|DSQuotaExceededException
operator|.
name|class
argument_list|,
name|FileAlreadyExistsException
operator|.
name|class
argument_list|,
name|FileNotFoundException
operator|.
name|class
argument_list|,
name|ParentNotDirectoryException
operator|.
name|class
argument_list|,
name|NSQuotaExceededException
operator|.
name|class
argument_list|,
name|RetryStartFileException
operator|.
name|class
argument_list|,
name|SafeModeException
operator|.
name|class
argument_list|,
name|UnresolvedPathException
operator|.
name|class
argument_list|,
name|SnapshotAccessControlException
operator|.
name|class
argument_list|,
name|UnknownCryptoProtocolVersionException
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|RetryStartFileException
condition|)
block|{
if|if
condition|(
name|retryCount
operator|>
literal|0
condition|)
block|{
name|shouldRetry
operator|=
literal|true
expr_stmt|;
name|retryCount
operator|--
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Too many retries because of encryption"
operator|+
literal|" zone operations"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|stat
argument_list|,
literal|"HdfsFileStatus should not be null!"
argument_list|)
expr_stmt|;
specifier|final
name|DFSOutputStream
name|out
init|=
operator|new
name|DFSOutputStream
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|stat
argument_list|,
name|flag
argument_list|,
name|progress
argument_list|,
name|checksum
argument_list|,
name|favoredNodes
argument_list|)
decl_stmt|;
name|out
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|out
return|;
block|}
comment|/** Construct a new output stream for append. */
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, boolean toNewBlock, Progressable progress, LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|boolean
name|toNewBlock
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
expr_stmt|;
name|initialFileSize
operator|=
name|stat
operator|.
name|getLen
argument_list|()
expr_stmt|;
comment|// length of file when opened
name|Span
name|traceSpan
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|Trace
operator|.
name|isTracing
argument_list|()
condition|)
block|{
name|traceSpan
operator|=
name|Trace
operator|.
name|startSpan
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
operator|.
name|detach
argument_list|()
expr_stmt|;
block|}
comment|// The last partial block of the file has to be filled.
if|if
condition|(
operator|!
name|toNewBlock
operator|&&
name|lastBlock
operator|!=
literal|null
condition|)
block|{
comment|// indicate that we are appending to an existing block
name|bytesCurBlock
operator|=
name|lastBlock
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|(
name|lastBlock
argument_list|,
name|stat
argument_list|,
name|bytesPerChecksum
argument_list|,
name|traceSpan
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|computePacketChunkSize
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|(
name|stat
argument_list|,
name|lastBlock
operator|!=
literal|null
condition|?
name|lastBlock
operator|.
name|getBlock
argument_list|()
else|:
literal|null
argument_list|,
name|traceSpan
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|fileEncryptionInfo
operator|=
name|stat
operator|.
name|getFileEncryptionInfo
argument_list|()
expr_stmt|;
block|}
DECL|method|newStreamForAppend (DFSClient dfsClient, String src, boolean toNewBlock, int bufferSize, Progressable progress, LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum, String[] favoredNodes)
specifier|static
name|DFSOutputStream
name|newStreamForAppend
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|boolean
name|toNewBlock
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|DFSOutputStream
name|out
init|=
operator|new
name|DFSOutputStream
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|toNewBlock
argument_list|,
name|progress
argument_list|,
name|lastBlock
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
decl_stmt|;
if|if
condition|(
name|favoredNodes
operator|!=
literal|null
operator|&&
name|favoredNodes
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
name|out
operator|.
name|streamer
operator|.
name|setFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
expr_stmt|;
block|}
name|out
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|out
return|;
block|}
DECL|method|isLazyPersist (HdfsFileStatus stat)
specifier|private
specifier|static
name|boolean
name|isLazyPersist
parameter_list|(
name|HdfsFileStatus
name|stat
parameter_list|)
block|{
specifier|final
name|BlockStoragePolicy
name|p
init|=
name|blockStoragePolicySuite
operator|.
name|getPolicy
argument_list|(
name|HdfsConstants
operator|.
name|MEMORY_STORAGE_POLICY_NAME
argument_list|)
decl_stmt|;
return|return
name|p
operator|!=
literal|null
operator|&&
name|stat
operator|.
name|getStoragePolicy
argument_list|()
operator|==
name|p
operator|.
name|getId
argument_list|()
return|;
block|}
DECL|method|computePacketChunkSize (int psize, int csize)
specifier|private
name|void
name|computePacketChunkSize
parameter_list|(
name|int
name|psize
parameter_list|,
name|int
name|csize
parameter_list|)
block|{
specifier|final
name|int
name|bodySize
init|=
name|psize
operator|-
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
decl_stmt|;
specifier|final
name|int
name|chunkSize
init|=
name|csize
operator|+
name|getChecksumSize
argument_list|()
decl_stmt|;
name|chunksPerPacket
operator|=
name|Math
operator|.
name|max
argument_list|(
name|bodySize
operator|/
name|chunkSize
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|packetSize
operator|=
name|chunkSize
operator|*
name|chunksPerPacket
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"computePacketChunkSize: src="
operator|+
name|src
operator|+
literal|", chunkSize="
operator|+
name|chunkSize
operator|+
literal|", chunksPerPacket="
operator|+
name|chunksPerPacket
operator|+
literal|", packetSize="
operator|+
name|packetSize
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|queueCurrentPacket ()
specifier|private
name|void
name|queueCurrentPacket
parameter_list|()
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
if|if
condition|(
name|currentPacket
operator|==
literal|null
condition|)
return|return;
name|dataQueue
operator|.
name|addLast
argument_list|(
name|currentPacket
argument_list|)
expr_stmt|;
name|lastQueuedSeqno
operator|=
name|currentPacket
operator|.
name|getSeqno
argument_list|()
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Queued packet "
operator|+
name|currentPacket
operator|.
name|getSeqno
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|currentPacket
operator|=
literal|null
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|waitAndQueueCurrentPacket ()
specifier|private
name|void
name|waitAndQueueCurrentPacket
parameter_list|()
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
try|try
block|{
comment|// If queue is full, then wait till we have enough space
while|while
condition|(
operator|!
name|isClosed
argument_list|()
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|+
name|ackQueue
operator|.
name|size
argument_list|()
operator|>
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writeMaxPackets
condition|)
block|{
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// If we get interrupted while waiting to queue data, we still need to get rid
comment|// of the current packet. This is because we have an invariant that if
comment|// currentPacket gets full, it will get queued before the next writeChunk.
comment|//
comment|// Rather than wait around for space in the queue, we should instead try to
comment|// return to the caller as soon as possible, even though we slightly overrun
comment|// the MAX_PACKETS length.
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
name|queueCurrentPacket
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{       }
block|}
block|}
comment|// @see FSOutputSummer#writeChunk()
annotation|@
name|Override
DECL|method|writeChunk (byte[] b, int offset, int len, byte[] checksum, int ckoff, int cklen)
specifier|protected
specifier|synchronized
name|void
name|writeChunk
parameter_list|(
name|byte
index|[]
name|b
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|len
parameter_list|,
name|byte
index|[]
name|checksum
parameter_list|,
name|int
name|ckoff
parameter_list|,
name|int
name|cklen
parameter_list|)
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|len
operator|>
name|bytesPerChecksum
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"writeChunk() buffer size is "
operator|+
name|len
operator|+
literal|" is larger than supported  bytesPerChecksum "
operator|+
name|bytesPerChecksum
argument_list|)
throw|;
block|}
if|if
condition|(
name|cklen
operator|!=
literal|0
operator|&&
name|cklen
operator|!=
name|getChecksumSize
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"writeChunk() checksum size is supposed to be "
operator|+
name|getChecksumSize
argument_list|()
operator|+
literal|" but found to be "
operator|+
name|cklen
argument_list|)
throw|;
block|}
if|if
condition|(
name|currentPacket
operator|==
literal|null
condition|)
block|{
name|currentPacket
operator|=
name|createPacket
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient writeChunk allocating new packet seqno="
operator|+
name|currentPacket
operator|.
name|getSeqno
argument_list|()
operator|+
literal|", src="
operator|+
name|src
operator|+
literal|", packetSize="
operator|+
name|packetSize
operator|+
literal|", chunksPerPacket="
operator|+
name|chunksPerPacket
operator|+
literal|", bytesCurBlock="
operator|+
name|bytesCurBlock
argument_list|)
expr_stmt|;
block|}
block|}
name|currentPacket
operator|.
name|writeChecksum
argument_list|(
name|checksum
argument_list|,
name|ckoff
argument_list|,
name|cklen
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|writeData
argument_list|(
name|b
argument_list|,
name|offset
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|incNumChunks
argument_list|()
expr_stmt|;
name|bytesCurBlock
operator|+=
name|len
expr_stmt|;
comment|// If packet is full, enqueue it for transmission
comment|//
if|if
condition|(
name|currentPacket
operator|.
name|getNumChunks
argument_list|()
operator|==
name|currentPacket
operator|.
name|getMaxChunks
argument_list|()
operator|||
name|bytesCurBlock
operator|==
name|blockSize
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient writeChunk packet full seqno="
operator|+
name|currentPacket
operator|.
name|getSeqno
argument_list|()
operator|+
literal|", src="
operator|+
name|src
operator|+
literal|", bytesCurBlock="
operator|+
name|bytesCurBlock
operator|+
literal|", blockSize="
operator|+
name|blockSize
operator|+
literal|", appendChunk="
operator|+
name|appendChunk
argument_list|)
expr_stmt|;
block|}
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
comment|// If the reopened file did not end at chunk boundary and the above
comment|// write filled up its partial chunk. Tell the summer to generate full
comment|// crc chunks from now on.
if|if
condition|(
name|appendChunk
operator|&&
name|bytesCurBlock
operator|%
name|bytesPerChecksum
operator|==
literal|0
condition|)
block|{
name|appendChunk
operator|=
literal|false
expr_stmt|;
name|resetChecksumBufSize
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|appendChunk
condition|)
block|{
name|int
name|psize
init|=
name|Math
operator|.
name|min
argument_list|(
call|(
name|int
call|)
argument_list|(
name|blockSize
operator|-
name|bytesCurBlock
argument_list|)
argument_list|,
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|)
decl_stmt|;
name|computePacketChunkSize
argument_list|(
name|psize
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
comment|//
comment|// if encountering a block boundary, send an empty packet to
comment|// indicate the end of block and reset bytesCurBlock.
comment|//
if|if
condition|(
name|bytesCurBlock
operator|==
name|blockSize
condition|)
block|{
name|currentPacket
operator|=
name|createPacket
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|setSyncBlock
argument_list|(
name|shouldSyncBlock
argument_list|)
expr_stmt|;
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
name|bytesCurBlock
operator|=
literal|0
expr_stmt|;
name|lastFlushOffset
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flushes out to all replicas of the block. The data is in the buffers    * of the DNs but not necessarily in the DN's OS buffers.    *    * It is a synchronous operation. When it returns,    * it guarantees that flushed data become visible to new readers.     * It is not guaranteed that data has been flushed to     * persistent store on the datanode.     * Block allocations are persisted on namenode.    */
annotation|@
name|Override
DECL|method|hflush ()
specifier|public
name|void
name|hflush
parameter_list|()
throws|throws
name|IOException
block|{
name|flushOrSync
argument_list|(
literal|false
argument_list|,
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|SyncFlag
operator|.
name|class
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|hsync ()
specifier|public
name|void
name|hsync
parameter_list|()
throws|throws
name|IOException
block|{
name|hsync
argument_list|(
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|SyncFlag
operator|.
name|class
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * The expected semantics is all data have flushed out to all replicas     * and all replicas have done posix fsync equivalent - ie the OS has     * flushed it to the disk device (but the disk may have it in its cache).    *     * Note that only the current block is flushed to the disk device.    * To guarantee durable sync across block boundaries the stream should    * be created with {@link CreateFlag#SYNC_BLOCK}.    *     * @param syncFlags    *          Indicate the semantic of the sync. Currently used to specify    *          whether or not to update the block length in NameNode.    */
DECL|method|hsync (EnumSet<SyncFlag> syncFlags)
specifier|public
name|void
name|hsync
parameter_list|(
name|EnumSet
argument_list|<
name|SyncFlag
argument_list|>
name|syncFlags
parameter_list|)
throws|throws
name|IOException
block|{
name|flushOrSync
argument_list|(
literal|true
argument_list|,
name|syncFlags
argument_list|)
expr_stmt|;
block|}
comment|/**    * Flush/Sync buffered data to DataNodes.    *     * @param isSync    *          Whether or not to require all replicas to flush data to the disk    *          device    * @param syncFlags    *          Indicate extra detailed semantic of the flush/sync. Currently    *          mainly used to specify whether or not to update the file length in    *          the NameNode    * @throws IOException    */
DECL|method|flushOrSync (boolean isSync, EnumSet<SyncFlag> syncFlags)
specifier|private
name|void
name|flushOrSync
parameter_list|(
name|boolean
name|isSync
parameter_list|,
name|EnumSet
argument_list|<
name|SyncFlag
argument_list|>
name|syncFlags
parameter_list|)
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|toWaitFor
decl_stmt|;
name|long
name|lastBlockLength
init|=
operator|-
literal|1L
decl_stmt|;
name|boolean
name|updateLength
init|=
name|syncFlags
operator|.
name|contains
argument_list|(
name|SyncFlag
operator|.
name|UPDATE_LENGTH
argument_list|)
decl_stmt|;
name|boolean
name|endBlock
init|=
name|syncFlags
operator|.
name|contains
argument_list|(
name|SyncFlag
operator|.
name|END_BLOCK
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
comment|// flush checksum buffer, but keep checksum buffer intact if we do not
comment|// need to end the current block
name|int
name|numKept
init|=
name|flushBuffer
argument_list|(
operator|!
name|endBlock
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// bytesCurBlock potentially incremented if there was buffered data
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient flush(): "
operator|+
literal|" bytesCurBlock="
operator|+
name|bytesCurBlock
operator|+
literal|" lastFlushOffset="
operator|+
name|lastFlushOffset
operator|+
literal|" createNewBlock="
operator|+
name|endBlock
argument_list|)
expr_stmt|;
block|}
comment|// Flush only if we haven't already flushed till this offset.
if|if
condition|(
name|lastFlushOffset
operator|!=
name|bytesCurBlock
condition|)
block|{
assert|assert
name|bytesCurBlock
operator|>
name|lastFlushOffset
assert|;
comment|// record the valid offset of this flush
name|lastFlushOffset
operator|=
name|bytesCurBlock
expr_stmt|;
if|if
condition|(
name|isSync
operator|&&
name|currentPacket
operator|==
literal|null
operator|&&
operator|!
name|endBlock
condition|)
block|{
comment|// Nothing to send right now,
comment|// but sync was requested.
comment|// Send an empty packet if we do not end the block right now
name|currentPacket
operator|=
name|createPacket
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|isSync
operator|&&
name|bytesCurBlock
operator|>
literal|0
operator|&&
operator|!
name|endBlock
condition|)
block|{
comment|// Nothing to send right now,
comment|// and the block was partially written,
comment|// and sync was requested.
comment|// So send an empty sync packet if we do not end the block right now
name|currentPacket
operator|=
name|createPacket
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|currentPacket
operator|!=
literal|null
condition|)
block|{
comment|// just discard the current packet since it is already been sent.
name|currentPacket
operator|.
name|releaseBuffer
argument_list|(
name|byteArrayManager
argument_list|)
expr_stmt|;
name|currentPacket
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|currentPacket
operator|!=
literal|null
condition|)
block|{
name|currentPacket
operator|.
name|setSyncBlock
argument_list|(
name|isSync
argument_list|)
expr_stmt|;
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|endBlock
operator|&&
name|bytesCurBlock
operator|>
literal|0
condition|)
block|{
comment|// Need to end the current block, thus send an empty packet to
comment|// indicate this is the end of the block and reset bytesCurBlock
name|currentPacket
operator|=
name|createPacket
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|setSyncBlock
argument_list|(
name|shouldSyncBlock
operator|||
name|isSync
argument_list|)
expr_stmt|;
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
name|bytesCurBlock
operator|=
literal|0
expr_stmt|;
name|lastFlushOffset
operator|=
literal|0
expr_stmt|;
block|}
else|else
block|{
comment|// Restore state of stream. Record the last flush offset
comment|// of the last full chunk that was flushed.
name|bytesCurBlock
operator|-=
name|numKept
expr_stmt|;
block|}
name|toWaitFor
operator|=
name|lastQueuedSeqno
expr_stmt|;
block|}
comment|// end synchronized
name|waitForAckedSeqno
argument_list|(
name|toWaitFor
argument_list|)
expr_stmt|;
comment|// update the block length first time irrespective of flag
if|if
condition|(
name|updateLength
operator|||
name|persistBlocks
operator|.
name|get
argument_list|()
condition|)
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|streamer
operator|!=
literal|null
operator|&&
name|streamer
operator|.
name|block
operator|!=
literal|null
condition|)
block|{
name|lastBlockLength
operator|=
name|streamer
operator|.
name|block
operator|.
name|getNumBytes
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// If 1) any new blocks were allocated since the last flush, or 2) to
comment|// update length in NN is required, then persist block locations on
comment|// namenode.
if|if
condition|(
name|persistBlocks
operator|.
name|getAndSet
argument_list|(
literal|false
argument_list|)
operator|||
name|updateLength
condition|)
block|{
try|try
block|{
name|dfsClient
operator|.
name|namenode
operator|.
name|fsync
argument_list|(
name|src
argument_list|,
name|fileId
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|lastBlockLength
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to persist blocks in hflush for "
operator|+
name|src
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|// If we got an error here, it might be because some other thread called
comment|// close before our hflush completed. In that case, we should throw an
comment|// exception that the stream is closed.
name|checkClosed
argument_list|()
expr_stmt|;
comment|// If we aren't closed but failed to sync, we should expose that to the
comment|// caller.
throw|throw
name|ioe
throw|;
block|}
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|streamer
operator|!=
literal|null
condition|)
block|{
name|streamer
operator|.
name|setHflush
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedIOException
name|interrupt
parameter_list|)
block|{
comment|// This kind of error doesn't mean that the stream itself is broken - just the
comment|// flushing thread got interrupted. So, we shouldn't close down the writer,
comment|// but instead just propagate the error
throw|throw
name|interrupt
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error while syncing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
operator|!
name|isClosed
argument_list|()
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"IOException flush: "
operator|+
name|e
argument_list|)
argument_list|)
expr_stmt|;
name|closeThreads
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * @deprecated use {@link HdfsDataOutputStream#getCurrentBlockReplication()}.    */
annotation|@
name|Deprecated
DECL|method|getNumCurrentReplicas ()
specifier|public
specifier|synchronized
name|int
name|getNumCurrentReplicas
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getCurrentBlockReplication
argument_list|()
return|;
block|}
comment|/**    * Note that this is not a public API;    * use {@link HdfsDataOutputStream#getCurrentBlockReplication()} instead.    *     * @return the number of valid replicas of the current block    */
DECL|method|getCurrentBlockReplication ()
specifier|public
specifier|synchronized
name|int
name|getCurrentBlockReplication
parameter_list|()
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|streamer
operator|==
literal|null
condition|)
block|{
return|return
name|blockReplication
return|;
comment|// no pipeline, return repl factor of file
block|}
name|DatanodeInfo
index|[]
name|currentNodes
init|=
name|streamer
operator|.
name|getNodes
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentNodes
operator|==
literal|null
condition|)
block|{
return|return
name|blockReplication
return|;
comment|// no pipeline, return repl factor of file
block|}
return|return
name|currentNodes
operator|.
name|length
return|;
block|}
comment|/**    * Waits till all existing data is flushed and confirmations     * received from datanodes.     */
DECL|method|flushInternal ()
specifier|private
name|void
name|flushInternal
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|toWaitFor
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
comment|//
comment|// If there is data in the current buffer, send it across
comment|//
name|queueCurrentPacket
argument_list|()
expr_stmt|;
name|toWaitFor
operator|=
name|lastQueuedSeqno
expr_stmt|;
block|}
name|waitForAckedSeqno
argument_list|(
name|toWaitFor
argument_list|)
expr_stmt|;
block|}
DECL|method|waitForAckedSeqno (long seqno)
specifier|private
name|void
name|waitForAckedSeqno
parameter_list|(
name|long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Waiting for ack for: "
operator|+
name|seqno
argument_list|)
expr_stmt|;
block|}
name|long
name|begin
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|isClosed
argument_list|()
condition|)
block|{
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|lastAckedSeqno
operator|>=
name|seqno
condition|)
block|{
break|break;
block|}
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// when we receive an ack, we notify on
comment|// dataQueue
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted while waiting for data to be acknowledged by pipeline"
argument_list|)
throw|;
block|}
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{     }
name|long
name|duration
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|-
name|begin
decl_stmt|;
if|if
condition|(
name|duration
operator|>
name|dfsclientSlowLogThresholdMs
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Slow waitForAckedSeqno took "
operator|+
name|duration
operator|+
literal|"ms (threshold="
operator|+
name|dfsclientSlowLogThresholdMs
operator|+
literal|"ms)"
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|start ()
specifier|private
specifier|synchronized
name|void
name|start
parameter_list|()
block|{
name|streamer
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/**    * Aborts this output stream and releases any system     * resources associated with this stream.    */
DECL|method|abort ()
specifier|synchronized
name|void
name|abort
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
return|return;
block|}
name|streamer
operator|.
name|setLastException
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Lease timeout of "
operator|+
operator|(
name|dfsClient
operator|.
name|getHdfsTimeout
argument_list|()
operator|/
literal|1000
operator|)
operator|+
literal|" seconds expired."
argument_list|)
argument_list|)
expr_stmt|;
name|closeThreads
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|endFileLease
argument_list|(
name|fileId
argument_list|)
expr_stmt|;
block|}
DECL|method|isClosed ()
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|closed
return|;
block|}
DECL|method|setClosed ()
name|void
name|setClosed
parameter_list|()
block|{
name|closed
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|releaseBuffer
argument_list|(
name|dataQueue
argument_list|,
name|byteArrayManager
argument_list|)
expr_stmt|;
name|releaseBuffer
argument_list|(
name|ackQueue
argument_list|,
name|byteArrayManager
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|releaseBuffer (List<DFSPacket> packets, ByteArrayManager bam)
specifier|private
specifier|static
name|void
name|releaseBuffer
parameter_list|(
name|List
argument_list|<
name|DFSPacket
argument_list|>
name|packets
parameter_list|,
name|ByteArrayManager
name|bam
parameter_list|)
block|{
for|for
control|(
name|DFSPacket
name|p
range|:
name|packets
control|)
block|{
name|p
operator|.
name|releaseBuffer
argument_list|(
name|bam
argument_list|)
expr_stmt|;
block|}
name|packets
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|// shutdown datastreamer and responseprocessor threads.
comment|// interrupt datastreamer if force is true
DECL|method|closeThreads (boolean force)
specifier|private
name|void
name|closeThreads
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|streamer
operator|.
name|close
argument_list|(
name|force
argument_list|)
expr_stmt|;
name|streamer
operator|.
name|join
argument_list|()
expr_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to shutdown streamer"
argument_list|)
throw|;
block|}
finally|finally
block|{
name|streamer
operator|=
literal|null
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
name|setClosed
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Closes this output stream and releases any system     * resources associated with this stream.    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|IOException
name|e
init|=
name|lastException
operator|.
name|getAndSet
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|==
literal|null
condition|)
return|return;
else|else
throw|throw
name|e
throw|;
block|}
try|try
block|{
name|flushBuffer
argument_list|()
expr_stmt|;
comment|// flush from all upper layers
if|if
condition|(
name|currentPacket
operator|!=
literal|null
condition|)
block|{
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|bytesCurBlock
operator|!=
literal|0
condition|)
block|{
comment|// send an empty packet to mark the end of the block
name|currentPacket
operator|=
name|createPacket
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|setSyncBlock
argument_list|(
name|shouldSyncBlock
argument_list|)
expr_stmt|;
block|}
name|flushInternal
argument_list|()
expr_stmt|;
comment|// flush all data to Datanodes
comment|// get last block before destroying the streamer
name|ExtendedBlock
name|lastBlock
init|=
name|streamer
operator|.
name|getBlock
argument_list|()
decl_stmt|;
name|closeThreads
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|completeFile
argument_list|(
name|lastBlock
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|endFileLease
argument_list|(
name|fileId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{     }
finally|finally
block|{
name|setClosed
argument_list|()
expr_stmt|;
block|}
block|}
comment|// should be called holding (this) lock since setTestFilename() may
comment|// be called during unit tests
DECL|method|completeFile (ExtendedBlock last)
specifier|private
name|void
name|completeFile
parameter_list|(
name|ExtendedBlock
name|last
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|localstart
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
name|long
name|localTimeout
init|=
literal|400
decl_stmt|;
name|boolean
name|fileComplete
init|=
literal|false
decl_stmt|;
name|int
name|retries
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nBlockWriteLocateFollowingRetry
decl_stmt|;
while|while
condition|(
operator|!
name|fileComplete
condition|)
block|{
name|fileComplete
operator|=
name|dfsClient
operator|.
name|namenode
operator|.
name|complete
argument_list|(
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|last
argument_list|,
name|fileId
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fileComplete
condition|)
block|{
specifier|final
name|int
name|hdfsTimeout
init|=
name|dfsClient
operator|.
name|getHdfsTimeout
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|dfsClient
operator|.
name|clientRunning
operator|||
operator|(
name|hdfsTimeout
operator|>
literal|0
operator|&&
name|localstart
operator|+
name|hdfsTimeout
operator|<
name|Time
operator|.
name|now
argument_list|()
operator|)
condition|)
block|{
name|String
name|msg
init|=
literal|"Unable to close file because dfsclient "
operator|+
literal|" was unable to contact the HDFS servers."
operator|+
literal|" clientRunning "
operator|+
name|dfsClient
operator|.
name|clientRunning
operator|+
literal|" hdfsTimeout "
operator|+
name|hdfsTimeout
decl_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
try|try
block|{
if|if
condition|(
name|retries
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to close file because the last block"
operator|+
literal|" does not have enough number of replicas."
argument_list|)
throw|;
block|}
name|retries
operator|--
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|localTimeout
argument_list|)
expr_stmt|;
name|localTimeout
operator|*=
literal|2
expr_stmt|;
if|if
condition|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|>
literal|5000
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Could not complete "
operator|+
name|src
operator|+
literal|" retrying..."
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|setArtificialSlowdown (long period)
specifier|public
name|void
name|setArtificialSlowdown
parameter_list|(
name|long
name|period
parameter_list|)
block|{
name|artificialSlowdown
operator|=
name|period
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setChunksPerPacket (int value)
specifier|public
specifier|synchronized
name|void
name|setChunksPerPacket
parameter_list|(
name|int
name|value
parameter_list|)
block|{
name|chunksPerPacket
operator|=
name|Math
operator|.
name|min
argument_list|(
name|chunksPerPacket
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|packetSize
operator|=
operator|(
name|bytesPerChecksum
operator|+
name|getChecksumSize
argument_list|()
operator|)
operator|*
name|chunksPerPacket
expr_stmt|;
block|}
DECL|method|setTestFilename (String newname)
specifier|synchronized
name|void
name|setTestFilename
parameter_list|(
name|String
name|newname
parameter_list|)
block|{
name|src
operator|=
name|newname
expr_stmt|;
block|}
comment|/**    * Returns the size of a file as it was when this stream was opened    */
DECL|method|getInitialLen ()
specifier|public
name|long
name|getInitialLen
parameter_list|()
block|{
return|return
name|initialFileSize
return|;
block|}
comment|/**    * @return the FileEncryptionInfo for this stream, or null if not encrypted.    */
DECL|method|getFileEncryptionInfo ()
specifier|public
name|FileEncryptionInfo
name|getFileEncryptionInfo
parameter_list|()
block|{
return|return
name|fileEncryptionInfo
return|;
block|}
comment|/**    * Returns the access token currently used by streamer, for testing only    */
DECL|method|getBlockToken ()
specifier|synchronized
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockToken
parameter_list|()
block|{
return|return
name|streamer
operator|.
name|getBlockToken
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|setDropBehind (Boolean dropBehind)
specifier|public
name|void
name|setDropBehind
parameter_list|(
name|Boolean
name|dropBehind
parameter_list|)
throws|throws
name|IOException
block|{
name|CachingStrategy
name|prevStrategy
decl_stmt|,
name|nextStrategy
decl_stmt|;
comment|// CachingStrategy is immutable.  So build a new CachingStrategy with the
comment|// modifications we want, and compare-and-swap it in.
do|do
block|{
name|prevStrategy
operator|=
name|this
operator|.
name|cachingStrategy
operator|.
name|get
argument_list|()
expr_stmt|;
name|nextStrategy
operator|=
operator|new
name|CachingStrategy
operator|.
name|Builder
argument_list|(
name|prevStrategy
argument_list|)
operator|.
name|setDropBehind
argument_list|(
name|dropBehind
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
block|}
do|while
condition|(
operator|!
name|this
operator|.
name|cachingStrategy
operator|.
name|compareAndSet
argument_list|(
name|prevStrategy
argument_list|,
name|nextStrategy
argument_list|)
condition|)
do|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getBlock ()
name|ExtendedBlock
name|getBlock
parameter_list|()
block|{
return|return
name|streamer
operator|.
name|getBlock
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getFileId ()
specifier|public
name|long
name|getFileId
parameter_list|()
block|{
return|return
name|fileId
return|;
block|}
DECL|method|arraycopy (T[] srcs, T[] dsts, int skipIndex)
specifier|private
specifier|static
parameter_list|<
name|T
parameter_list|>
name|void
name|arraycopy
parameter_list|(
name|T
index|[]
name|srcs
parameter_list|,
name|T
index|[]
name|dsts
parameter_list|,
name|int
name|skipIndex
parameter_list|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|srcs
argument_list|,
literal|0
argument_list|,
name|dsts
argument_list|,
literal|0
argument_list|,
name|skipIndex
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|srcs
argument_list|,
name|skipIndex
operator|+
literal|1
argument_list|,
name|dsts
argument_list|,
name|skipIndex
argument_list|,
name|dsts
operator|.
name|length
operator|-
name|skipIndex
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

