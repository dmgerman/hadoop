begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
operator|.
name|SUCCESS
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|BufferOverflowException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|ClosedChannelException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CanSetDropBehind
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSOutputSummer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ParentNotDirectoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Syncable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsDataOutputStream
operator|.
name|SyncFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|NSQuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|SnapshotAccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|UnresolvedPathException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|BlockConstructionStage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferEncryptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|IOStreamPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|InvalidEncryptionKeyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PacketHeader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PipelineAck
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|Sender
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|BlockOpResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|PBHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|InvalidBlockTokenException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|CachingStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NotReplicatedYetException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|SafeModeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|EnumSetWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|AccessControlException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|LoadingCache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalNotification
import|;
end_import

begin_comment
comment|/****************************************************************  * DFSOutputStream creates files from a stream of bytes.  *  * The client application writes data that is cached internally by  * this stream. Data is broken up into packets, each packet is  * typically 64K in size. A packet comprises of chunks. Each chunk  * is typically 512 bytes and has an associated checksum with it.  *  * When a client application fills up the currentPacket, it is  * enqueued into dataQueue.  The DataStreamer thread picks up  * packets from the dataQueue, sends it to the first datanode in  * the pipeline and moves it from the dataQueue to the ackQueue.  * The ResponseProcessor receives acks from the datanodes. When an  * successful ack for a packet is received from all datanodes, the  * ResponseProcessor removes the corresponding packet from the  * ackQueue.  *  * In case of error, all outstanding packets and moved from  * ackQueue. A new pipeline is setup by eliminating the bad  * datanode from the original pipeline. The DataStreamer now  * starts sending packets from the dataQueue. ****************************************************************/
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DFSOutputStream
specifier|public
class|class
name|DFSOutputStream
extends|extends
name|FSOutputSummer
implements|implements
name|Syncable
implements|,
name|CanSetDropBehind
block|{
DECL|field|MAX_PACKETS
specifier|private
specifier|static
specifier|final
name|int
name|MAX_PACKETS
init|=
literal|80
decl_stmt|;
comment|// each packet 64K, total 5MB
DECL|field|dfsClient
specifier|private
specifier|final
name|DFSClient
name|dfsClient
decl_stmt|;
DECL|field|s
specifier|private
name|Socket
name|s
decl_stmt|;
comment|// closed is accessed by different threads under different locks.
DECL|field|closed
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
DECL|field|src
specifier|private
name|String
name|src
decl_stmt|;
DECL|field|fileId
specifier|private
specifier|final
name|long
name|fileId
decl_stmt|;
DECL|field|blockSize
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
DECL|field|checksum
specifier|private
specifier|final
name|DataChecksum
name|checksum
decl_stmt|;
comment|// both dataQueue and ackQueue are protected by dataQueue lock
DECL|field|dataQueue
specifier|private
specifier|final
name|LinkedList
argument_list|<
name|Packet
argument_list|>
name|dataQueue
init|=
operator|new
name|LinkedList
argument_list|<
name|Packet
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|ackQueue
specifier|private
specifier|final
name|LinkedList
argument_list|<
name|Packet
argument_list|>
name|ackQueue
init|=
operator|new
name|LinkedList
argument_list|<
name|Packet
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|currentPacket
specifier|private
name|Packet
name|currentPacket
init|=
literal|null
decl_stmt|;
DECL|field|streamer
specifier|private
name|DataStreamer
name|streamer
decl_stmt|;
DECL|field|currentSeqno
specifier|private
name|long
name|currentSeqno
init|=
literal|0
decl_stmt|;
DECL|field|lastQueuedSeqno
specifier|private
name|long
name|lastQueuedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|lastAckedSeqno
specifier|private
name|long
name|lastAckedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|bytesCurBlock
specifier|private
name|long
name|bytesCurBlock
init|=
literal|0
decl_stmt|;
comment|// bytes written in current block
DECL|field|packetSize
specifier|private
name|int
name|packetSize
init|=
literal|0
decl_stmt|;
comment|// write packet size, not including the header.
DECL|field|chunksPerPacket
specifier|private
name|int
name|chunksPerPacket
init|=
literal|0
decl_stmt|;
DECL|field|lastException
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|IOException
argument_list|>
name|lastException
init|=
operator|new
name|AtomicReference
argument_list|<
name|IOException
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|artificialSlowdown
specifier|private
name|long
name|artificialSlowdown
init|=
literal|0
decl_stmt|;
DECL|field|lastFlushOffset
specifier|private
name|long
name|lastFlushOffset
init|=
literal|0
decl_stmt|;
comment|// offset when flush was invoked
comment|//persist blocks on namenode
DECL|field|persistBlocks
specifier|private
specifier|final
name|AtomicBoolean
name|persistBlocks
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|appendChunk
specifier|private
specifier|volatile
name|boolean
name|appendChunk
init|=
literal|false
decl_stmt|;
comment|// appending to existing partial block
DECL|field|initialFileSize
specifier|private
name|long
name|initialFileSize
init|=
literal|0
decl_stmt|;
comment|// at time of file open
DECL|field|progress
specifier|private
name|Progressable
name|progress
decl_stmt|;
DECL|field|blockReplication
specifier|private
specifier|final
name|short
name|blockReplication
decl_stmt|;
comment|// replication factor of file
DECL|field|shouldSyncBlock
specifier|private
name|boolean
name|shouldSyncBlock
init|=
literal|false
decl_stmt|;
comment|// force blocks to disk upon close
DECL|field|cachingStrategy
specifier|private
name|CachingStrategy
name|cachingStrategy
decl_stmt|;
DECL|class|Packet
specifier|private
specifier|static
class|class
name|Packet
block|{
DECL|field|HEART_BEAT_SEQNO
specifier|private
specifier|static
specifier|final
name|long
name|HEART_BEAT_SEQNO
init|=
operator|-
literal|1L
decl_stmt|;
DECL|field|seqno
name|long
name|seqno
decl_stmt|;
comment|// sequencenumber of buffer in block
DECL|field|offsetInBlock
specifier|final
name|long
name|offsetInBlock
decl_stmt|;
comment|// offset in block
DECL|field|syncBlock
name|boolean
name|syncBlock
decl_stmt|;
comment|// this packet forces the current block to disk
DECL|field|numChunks
name|int
name|numChunks
decl_stmt|;
comment|// number of chunks currently in packet
DECL|field|maxChunks
specifier|final
name|int
name|maxChunks
decl_stmt|;
comment|// max chunks in packet
DECL|field|buf
name|byte
index|[]
name|buf
decl_stmt|;
DECL|field|lastPacketInBlock
specifier|private
name|boolean
name|lastPacketInBlock
decl_stmt|;
comment|// is this the last packet in block?
comment|/**      * buf is pointed into like follows:      *  (C is checksum data, D is payload data)      *      * [_________CCCCCCCCC________________DDDDDDDDDDDDDDDD___]      *           ^        ^               ^               ^      *           |        checksumPos     dataStart       dataPos      *           checksumStart      *       * Right before sending, we move the checksum data to immediately precede      * the actual data, and then insert the header into the buffer immediately      * preceding the checksum data, so we make sure to keep enough space in      * front of the checksum data to support the largest conceivable header.       */
DECL|field|checksumStart
name|int
name|checksumStart
decl_stmt|;
DECL|field|checksumPos
name|int
name|checksumPos
decl_stmt|;
DECL|field|dataStart
specifier|final
name|int
name|dataStart
decl_stmt|;
DECL|field|dataPos
name|int
name|dataPos
decl_stmt|;
comment|/**      * Create a heartbeat packet.      */
DECL|method|Packet (int checksumSize)
name|Packet
parameter_list|(
name|int
name|checksumSize
parameter_list|)
block|{
name|this
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|HEART_BEAT_SEQNO
argument_list|,
name|checksumSize
argument_list|)
expr_stmt|;
block|}
comment|/**      * Create a new packet.      *       * @param pktSize maximum size of the packet,       *                including checksum data and actual data.      * @param chunksPerPkt maximum number of chunks per packet.      * @param offsetInBlock offset in bytes into the HDFS block.      */
DECL|method|Packet (int pktSize, int chunksPerPkt, long offsetInBlock, long seqno, int checksumSize)
name|Packet
parameter_list|(
name|int
name|pktSize
parameter_list|,
name|int
name|chunksPerPkt
parameter_list|,
name|long
name|offsetInBlock
parameter_list|,
name|long
name|seqno
parameter_list|,
name|int
name|checksumSize
parameter_list|)
block|{
name|this
operator|.
name|lastPacketInBlock
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|numChunks
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|offsetInBlock
operator|=
name|offsetInBlock
expr_stmt|;
name|this
operator|.
name|seqno
operator|=
name|seqno
expr_stmt|;
name|buf
operator|=
operator|new
name|byte
index|[
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
operator|+
name|pktSize
index|]
expr_stmt|;
name|checksumStart
operator|=
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
expr_stmt|;
name|checksumPos
operator|=
name|checksumStart
expr_stmt|;
name|dataStart
operator|=
name|checksumStart
operator|+
operator|(
name|chunksPerPkt
operator|*
name|checksumSize
operator|)
expr_stmt|;
name|dataPos
operator|=
name|dataStart
expr_stmt|;
name|maxChunks
operator|=
name|chunksPerPkt
expr_stmt|;
block|}
DECL|method|writeData (byte[] inarray, int off, int len)
name|void
name|writeData
parameter_list|(
name|byte
index|[]
name|inarray
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
block|{
if|if
condition|(
name|dataPos
operator|+
name|len
operator|>
name|buf
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|BufferOverflowException
argument_list|()
throw|;
block|}
name|System
operator|.
name|arraycopy
argument_list|(
name|inarray
argument_list|,
name|off
argument_list|,
name|buf
argument_list|,
name|dataPos
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|dataPos
operator|+=
name|len
expr_stmt|;
block|}
DECL|method|writeChecksum (byte[] inarray, int off, int len)
name|void
name|writeChecksum
parameter_list|(
name|byte
index|[]
name|inarray
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
block|{
if|if
condition|(
name|checksumPos
operator|+
name|len
operator|>
name|dataStart
condition|)
block|{
throw|throw
operator|new
name|BufferOverflowException
argument_list|()
throw|;
block|}
name|System
operator|.
name|arraycopy
argument_list|(
name|inarray
argument_list|,
name|off
argument_list|,
name|buf
argument_list|,
name|checksumPos
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|checksumPos
operator|+=
name|len
expr_stmt|;
block|}
comment|/**      * Write the full packet, including the header, to the given output stream.      */
DECL|method|writeTo (DataOutputStream stm)
name|void
name|writeTo
parameter_list|(
name|DataOutputStream
name|stm
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|int
name|dataLen
init|=
name|dataPos
operator|-
name|dataStart
decl_stmt|;
specifier|final
name|int
name|checksumLen
init|=
name|checksumPos
operator|-
name|checksumStart
decl_stmt|;
specifier|final
name|int
name|pktLen
init|=
name|HdfsConstants
operator|.
name|BYTES_IN_INTEGER
operator|+
name|dataLen
operator|+
name|checksumLen
decl_stmt|;
name|PacketHeader
name|header
init|=
operator|new
name|PacketHeader
argument_list|(
name|pktLen
argument_list|,
name|offsetInBlock
argument_list|,
name|seqno
argument_list|,
name|lastPacketInBlock
argument_list|,
name|dataLen
argument_list|,
name|syncBlock
argument_list|)
decl_stmt|;
if|if
condition|(
name|checksumPos
operator|!=
name|dataStart
condition|)
block|{
comment|// Move the checksum to cover the gap. This can happen for the last
comment|// packet or during an hflush/hsync call.
name|System
operator|.
name|arraycopy
argument_list|(
name|buf
argument_list|,
name|checksumStart
argument_list|,
name|buf
argument_list|,
name|dataStart
operator|-
name|checksumLen
argument_list|,
name|checksumLen
argument_list|)
expr_stmt|;
name|checksumPos
operator|=
name|dataStart
expr_stmt|;
name|checksumStart
operator|=
name|checksumPos
operator|-
name|checksumLen
expr_stmt|;
block|}
specifier|final
name|int
name|headerStart
init|=
name|checksumStart
operator|-
name|header
operator|.
name|getSerializedSize
argument_list|()
decl_stmt|;
assert|assert
name|checksumStart
operator|+
literal|1
operator|>=
name|header
operator|.
name|getSerializedSize
argument_list|()
assert|;
assert|assert
name|checksumPos
operator|==
name|dataStart
assert|;
assert|assert
name|headerStart
operator|>=
literal|0
assert|;
assert|assert
name|headerStart
operator|+
name|header
operator|.
name|getSerializedSize
argument_list|()
operator|==
name|checksumStart
assert|;
comment|// Copy the header data into the buffer immediately preceding the checksum
comment|// data.
name|System
operator|.
name|arraycopy
argument_list|(
name|header
operator|.
name|getBytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|buf
argument_list|,
name|headerStart
argument_list|,
name|header
operator|.
name|getSerializedSize
argument_list|()
argument_list|)
expr_stmt|;
comment|// corrupt the data for testing.
if|if
condition|(
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|corruptPacket
argument_list|()
condition|)
block|{
name|buf
index|[
name|headerStart
operator|+
name|header
operator|.
name|getSerializedSize
argument_list|()
operator|+
name|checksumLen
operator|+
name|dataLen
operator|-
literal|1
index|]
operator|^=
literal|0xff
expr_stmt|;
block|}
comment|// Write the now contiguous full packet to the output stream.
name|stm
operator|.
name|write
argument_list|(
name|buf
argument_list|,
name|headerStart
argument_list|,
name|header
operator|.
name|getSerializedSize
argument_list|()
operator|+
name|checksumLen
operator|+
name|dataLen
argument_list|)
expr_stmt|;
comment|// undo corruption.
if|if
condition|(
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|uncorruptPacket
argument_list|()
condition|)
block|{
name|buf
index|[
name|headerStart
operator|+
name|header
operator|.
name|getSerializedSize
argument_list|()
operator|+
name|checksumLen
operator|+
name|dataLen
operator|-
literal|1
index|]
operator|^=
literal|0xff
expr_stmt|;
block|}
block|}
comment|// get the packet's last byte's offset in the block
DECL|method|getLastByteOffsetBlock ()
name|long
name|getLastByteOffsetBlock
parameter_list|()
block|{
return|return
name|offsetInBlock
operator|+
name|dataPos
operator|-
name|dataStart
return|;
block|}
comment|/**      * Check if this packet is a heart beat packet      * @return true if the sequence number is HEART_BEAT_SEQNO      */
DECL|method|isHeartbeatPacket ()
specifier|private
name|boolean
name|isHeartbeatPacket
parameter_list|()
block|{
return|return
name|seqno
operator|==
name|HEART_BEAT_SEQNO
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"packet seqno:"
operator|+
name|this
operator|.
name|seqno
operator|+
literal|" offsetInBlock:"
operator|+
name|this
operator|.
name|offsetInBlock
operator|+
literal|" lastPacketInBlock:"
operator|+
name|this
operator|.
name|lastPacketInBlock
operator|+
literal|" lastByteOffsetInBlock: "
operator|+
name|this
operator|.
name|getLastByteOffsetBlock
argument_list|()
return|;
block|}
block|}
comment|//
comment|// The DataStreamer class is responsible for sending data packets to the
comment|// datanodes in the pipeline. It retrieves a new blockid and block locations
comment|// from the namenode, and starts streaming packets to the pipeline of
comment|// Datanodes. Every packet has a sequence number associated with
comment|// it. When all the packets for a block are sent out and acks for each
comment|// if them are received, the DataStreamer closes the current block.
comment|//
DECL|class|DataStreamer
class|class
name|DataStreamer
extends|extends
name|Daemon
block|{
DECL|field|streamerClosed
specifier|private
specifier|volatile
name|boolean
name|streamerClosed
init|=
literal|false
decl_stmt|;
DECL|field|block
specifier|private
name|ExtendedBlock
name|block
decl_stmt|;
comment|// its length is number of bytes acked
DECL|field|accessToken
specifier|private
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
decl_stmt|;
DECL|field|blockStream
specifier|private
name|DataOutputStream
name|blockStream
decl_stmt|;
DECL|field|blockReplyStream
specifier|private
name|DataInputStream
name|blockReplyStream
decl_stmt|;
DECL|field|response
specifier|private
name|ResponseProcessor
name|response
init|=
literal|null
decl_stmt|;
DECL|field|nodes
specifier|private
specifier|volatile
name|DatanodeInfo
index|[]
name|nodes
init|=
literal|null
decl_stmt|;
comment|// list of targets for current block
comment|//TODO: update storage IDs
DECL|field|storageIDs
specifier|private
specifier|volatile
name|String
index|[]
name|storageIDs
init|=
literal|null
decl_stmt|;
DECL|field|excludedNodes
specifier|private
name|LoadingCache
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|excludedNodes
init|=
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|expireAfterWrite
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|excludedNodesCacheExpiry
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
operator|.
name|removalListener
argument_list|(
operator|new
name|RemovalListener
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|onRemoval
parameter_list|(
name|RemovalNotification
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|notification
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Removing node "
operator|+
name|notification
operator|.
name|getKey
argument_list|()
operator|+
literal|" from the excluded nodes list"
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
operator|.
name|build
argument_list|(
operator|new
name|CacheLoader
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DatanodeInfo
name|load
parameter_list|(
name|DatanodeInfo
name|key
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|key
return|;
block|}
block|}
argument_list|)
decl_stmt|;
DECL|field|favoredNodes
specifier|private
name|String
index|[]
name|favoredNodes
decl_stmt|;
DECL|field|hasError
specifier|volatile
name|boolean
name|hasError
init|=
literal|false
decl_stmt|;
DECL|field|errorIndex
specifier|volatile
name|int
name|errorIndex
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|stage
specifier|private
name|BlockConstructionStage
name|stage
decl_stmt|;
comment|// block construction stage
DECL|field|bytesSent
specifier|private
name|long
name|bytesSent
init|=
literal|0
decl_stmt|;
comment|// number of bytes that've been sent
comment|/** Nodes have been used in the pipeline before and have failed. */
DECL|field|failed
specifier|private
specifier|final
name|List
argument_list|<
name|DatanodeInfo
argument_list|>
name|failed
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|()
decl_stmt|;
comment|/** The last ack sequence number before pipeline failure. */
DECL|field|lastAckedSeqnoBeforeFailure
specifier|private
name|long
name|lastAckedSeqnoBeforeFailure
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|pipelineRecoveryCount
specifier|private
name|int
name|pipelineRecoveryCount
init|=
literal|0
decl_stmt|;
comment|/** Has the current block been hflushed? */
DECL|field|isHflushed
specifier|private
name|boolean
name|isHflushed
init|=
literal|false
decl_stmt|;
comment|/** Append on an existing block? */
DECL|field|isAppend
specifier|private
specifier|final
name|boolean
name|isAppend
decl_stmt|;
comment|/**      * Default construction for file create      */
DECL|method|DataStreamer ()
specifier|private
name|DataStreamer
parameter_list|()
block|{
name|isAppend
operator|=
literal|false
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
block|}
comment|/**      * Construct a data streamer for append      * @param lastBlock last block of the file to be appended      * @param stat status of the file to be appended      * @param bytesPerChecksum number of bytes per checksum      * @throws IOException if error occurs      */
DECL|method|DataStreamer (LocatedBlock lastBlock, HdfsFileStatus stat, int bytesPerChecksum)
specifier|private
name|DataStreamer
parameter_list|(
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|int
name|bytesPerChecksum
parameter_list|)
throws|throws
name|IOException
block|{
name|isAppend
operator|=
literal|true
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
expr_stmt|;
name|block
operator|=
name|lastBlock
operator|.
name|getBlock
argument_list|()
expr_stmt|;
name|bytesSent
operator|=
name|block
operator|.
name|getNumBytes
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lastBlock
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
name|long
name|usedInLastBlock
init|=
name|stat
operator|.
name|getLen
argument_list|()
operator|%
name|blockSize
decl_stmt|;
name|int
name|freeInLastBlock
init|=
call|(
name|int
call|)
argument_list|(
name|blockSize
operator|-
name|usedInLastBlock
argument_list|)
decl_stmt|;
comment|// calculate the amount of free space in the pre-existing
comment|// last crc chunk
name|int
name|usedInCksum
init|=
call|(
name|int
call|)
argument_list|(
name|stat
operator|.
name|getLen
argument_list|()
operator|%
name|bytesPerChecksum
argument_list|)
decl_stmt|;
name|int
name|freeInCksum
init|=
name|bytesPerChecksum
operator|-
name|usedInCksum
decl_stmt|;
comment|// if there is space in the last block, then we have to
comment|// append to that block
if|if
condition|(
name|freeInLastBlock
operator|==
name|blockSize
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The last block for file "
operator|+
name|src
operator|+
literal|" is full."
argument_list|)
throw|;
block|}
if|if
condition|(
name|usedInCksum
operator|>
literal|0
operator|&&
name|freeInCksum
operator|>
literal|0
condition|)
block|{
comment|// if there is space in the last partial chunk, then
comment|// setup in such a way that the next packet will have only
comment|// one chunk that fills up the partial chunk.
comment|//
name|computePacketChunkSize
argument_list|(
literal|0
argument_list|,
name|freeInCksum
argument_list|)
expr_stmt|;
name|resetChecksumChunk
argument_list|(
name|freeInCksum
argument_list|)
expr_stmt|;
name|appendChunk
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
comment|// if the remaining space in the block is smaller than
comment|// that expected size of of a packet, then create
comment|// smaller size packet.
comment|//
name|computePacketChunkSize
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|freeInLastBlock
argument_list|)
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
comment|// setup pipeline to append to the last block XXX retries??
name|nodes
operator|=
name|lastBlock
operator|.
name|getLocations
argument_list|()
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
comment|// no errors yet.
if|if
condition|(
name|nodes
operator|.
name|length
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to retrieve blocks locations "
operator|+
literal|" for last block "
operator|+
name|block
operator|+
literal|"of file "
operator|+
name|src
argument_list|)
throw|;
block|}
block|}
DECL|method|setFavoredNodes (String[] favoredNodes)
specifier|private
name|void
name|setFavoredNodes
parameter_list|(
name|String
index|[]
name|favoredNodes
parameter_list|)
block|{
name|this
operator|.
name|favoredNodes
operator|=
name|favoredNodes
expr_stmt|;
block|}
comment|/**      * Initialize for data streaming      */
DECL|method|initDataStreaming ()
specifier|private
name|void
name|initDataStreaming
parameter_list|()
block|{
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
operator|+
literal|" block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|response
operator|=
operator|new
name|ResponseProcessor
argument_list|(
name|nodes
argument_list|)
expr_stmt|;
name|response
operator|.
name|start
argument_list|()
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
expr_stmt|;
block|}
DECL|method|endBlock ()
specifier|private
name|void
name|endBlock
parameter_list|()
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing old block "
operator|+
name|block
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
argument_list|)
expr_stmt|;
name|closeResponder
argument_list|()
expr_stmt|;
name|closeStream
argument_list|()
expr_stmt|;
name|nodes
operator|=
literal|null
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
block|}
comment|/*      * streamer thread is the only thread that opens streams to datanode,       * and closes them. Any error recovery is also done by this thread.      */
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|long
name|lastPacket
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
comment|// if the Responder encountered an error, shutdown Responder
if|if
condition|(
name|hasError
operator|&&
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
name|response
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|Packet
name|one
decl_stmt|;
try|try
block|{
comment|// process datanode IO errors if any
name|boolean
name|doSleep
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|hasError
operator|&&
name|errorIndex
operator|>=
literal|0
condition|)
block|{
name|doSleep
operator|=
name|processDatanodeError
argument_list|()
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// wait for a packet to be sent.
name|long
name|now
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
while|while
condition|(
operator|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|dfsClient
operator|.
name|clientRunning
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
operator|(
name|stage
operator|!=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|&&
name|now
operator|-
name|lastPacket
operator|<
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
operator|/
literal|2
operator|)
operator|)
operator|||
name|doSleep
condition|)
block|{
name|long
name|timeout
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
operator|/
literal|2
operator|-
operator|(
name|now
operator|-
name|lastPacket
operator|)
decl_stmt|;
name|timeout
operator|=
name|timeout
operator|<=
literal|0
condition|?
literal|1000
else|:
name|timeout
expr_stmt|;
name|timeout
operator|=
operator|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|)
condition|?
name|timeout
else|:
literal|1000
expr_stmt|;
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|doSleep
operator|=
literal|false
expr_stmt|;
name|now
operator|=
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
comment|// get packet to be sent.
if|if
condition|(
name|dataQueue
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|one
operator|=
operator|new
name|Packet
argument_list|(
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
comment|// heartbeat packet
block|}
else|else
block|{
name|one
operator|=
name|dataQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
comment|// regular data packet
block|}
block|}
assert|assert
name|one
operator|!=
literal|null
assert|;
comment|// get new block from namenode.
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Allocating new block"
argument_list|)
expr_stmt|;
block|}
name|nodes
operator|=
name|nextBlockOutputStream
argument_list|()
expr_stmt|;
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Append to block "
operator|+
name|block
argument_list|)
expr_stmt|;
block|}
name|setupPipelineForAppendOrRecovery
argument_list|()
expr_stmt|;
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
name|long
name|lastByteOffsetInBlock
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastByteOffsetInBlock
operator|>
name|blockSize
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlockSize "
operator|+
name|blockSize
operator|+
literal|" is smaller than data size. "
operator|+
literal|" Offset of packet in block "
operator|+
name|lastByteOffsetInBlock
operator|+
literal|" Aborting file "
operator|+
name|src
argument_list|)
throw|;
block|}
if|if
condition|(
name|one
operator|.
name|lastPacketInBlock
condition|)
block|{
comment|// wait for all data packets have been successfully acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
try|try
block|{
comment|// wait for acks to arrive from datanodes
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
expr_stmt|;
block|}
comment|// send the packet
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// move packet from dataQueue to ackQueue
if|if
condition|(
operator|!
name|one
operator|.
name|isHeartbeatPacket
argument_list|()
condition|)
block|{
name|dataQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|ackQueue
operator|.
name|addLast
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataStreamer block "
operator|+
name|block
operator|+
literal|" sending packet "
operator|+
name|one
argument_list|)
expr_stmt|;
block|}
comment|// write out data to remote datanode
try|try
block|{
name|one
operator|.
name|writeTo
argument_list|(
name|blockStream
argument_list|)
expr_stmt|;
name|blockStream
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// HDFS-3398 treat primary DN is down since client is unable to
comment|// write to primary DN
name|errorIndex
operator|=
literal|0
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|lastPacket
operator|=
name|Time
operator|.
name|now
argument_list|()
expr_stmt|;
comment|// update bytesSent
name|long
name|tmpBytesSent
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|bytesSent
operator|<
name|tmpBytesSent
condition|)
block|{
name|bytesSent
operator|=
name|tmpBytesSent
expr_stmt|;
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
comment|// Is this block full?
if|if
condition|(
name|one
operator|.
name|lastPacketInBlock
condition|)
block|{
comment|// wait for the close packet has been acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
operator|!
name|hasError
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// wait for acks to arrive from datanodes
block|}
block|}
if|if
condition|(
name|streamerClosed
operator|||
name|hasError
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
continue|continue;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|progress
operator|!=
literal|null
condition|)
block|{
name|progress
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
comment|// This is used by unit test to trigger race conditions.
if|if
condition|(
name|artificialSlowdown
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|artificialSlowdown
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DataStreamer Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|setLastException
argument_list|(
operator|(
name|IOException
operator|)
name|e
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|errorIndex
operator|==
operator|-
literal|1
condition|)
block|{
comment|// not a datanode error
name|streamerClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
name|closeInternal
argument_list|()
expr_stmt|;
block|}
DECL|method|closeInternal ()
specifier|private
name|void
name|closeInternal
parameter_list|()
block|{
name|closeResponder
argument_list|()
expr_stmt|;
comment|// close and join
name|closeStream
argument_list|()
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
name|closed
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*      * close both streamer and DFSOutputStream, should be called only       * by an external thread and only after all data to be sent has       * been flushed to datanode.      *       * Interrupt this data streamer if force is true      *       * @param force if this data stream is forced to be closed       */
DECL|method|close (boolean force)
name|void
name|close
parameter_list|(
name|boolean
name|force
parameter_list|)
block|{
name|streamerClosed
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|force
condition|)
block|{
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|closeResponder ()
specifier|private
name|void
name|closeResponder
parameter_list|()
block|{
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|response
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
DECL|method|closeStream ()
specifier|private
name|void
name|closeStream
parameter_list|()
block|{
if|if
condition|(
name|blockStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|blockReplyStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockReplyStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|s
condition|)
block|{
try|try
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|setLastException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|s
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|//
comment|// Processes responses from the datanodes.  A packet is removed
comment|// from the ackQueue when its response arrives.
comment|//
DECL|class|ResponseProcessor
specifier|private
class|class
name|ResponseProcessor
extends|extends
name|Daemon
block|{
DECL|field|responderClosed
specifier|private
specifier|volatile
name|boolean
name|responderClosed
init|=
literal|false
decl_stmt|;
DECL|field|targets
specifier|private
name|DatanodeInfo
index|[]
name|targets
init|=
literal|null
decl_stmt|;
DECL|field|isLastPacketInBlock
specifier|private
name|boolean
name|isLastPacketInBlock
init|=
literal|false
decl_stmt|;
DECL|method|ResponseProcessor (DatanodeInfo[] targets)
name|ResponseProcessor
parameter_list|(
name|DatanodeInfo
index|[]
name|targets
parameter_list|)
block|{
name|this
operator|.
name|targets
operator|=
name|targets
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|setName
argument_list|(
literal|"ResponseProcessor for block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|PipelineAck
name|ack
init|=
operator|new
name|PipelineAck
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|responderClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
operator|&&
operator|!
name|isLastPacketInBlock
condition|)
block|{
comment|// process responses from datanodes.
try|try
block|{
comment|// read an ack from the pipeline
name|ack
operator|.
name|readFields
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient "
operator|+
name|ack
argument_list|)
expr_stmt|;
block|}
name|long
name|seqno
init|=
name|ack
operator|.
name|getSeqno
argument_list|()
decl_stmt|;
comment|// processes response status from datanodes.
for|for
control|(
name|int
name|i
init|=
name|ack
operator|.
name|getNumOfReplies
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|;
name|i
operator|--
control|)
block|{
specifier|final
name|Status
name|reply
init|=
name|ack
operator|.
name|getReply
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|reply
operator|!=
name|SUCCESS
condition|)
block|{
name|errorIndex
operator|=
name|i
expr_stmt|;
comment|// first bad datanode
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Bad response "
operator|+
name|reply
operator|+
literal|" for block "
operator|+
name|block
operator|+
literal|" from datanode "
operator|+
name|targets
index|[
name|i
index|]
argument_list|)
throw|;
block|}
block|}
assert|assert
name|seqno
operator|!=
name|PipelineAck
operator|.
name|UNKOWN_SEQNO
operator|:
literal|"Ack for unknown seqno should be a failed ack: "
operator|+
name|ack
assert|;
if|if
condition|(
name|seqno
operator|==
name|Packet
operator|.
name|HEART_BEAT_SEQNO
condition|)
block|{
comment|// a heartbeat ack
continue|continue;
block|}
comment|// a success ack for a data packet
name|Packet
name|one
decl_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|one
operator|=
name|ackQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|one
operator|.
name|seqno
operator|!=
name|seqno
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"ResponseProcessor: Expecting seqno "
operator|+
literal|" for block "
operator|+
name|block
operator|+
name|one
operator|.
name|seqno
operator|+
literal|" but received "
operator|+
name|seqno
argument_list|)
throw|;
block|}
name|isLastPacketInBlock
operator|=
name|one
operator|.
name|lastPacketInBlock
expr_stmt|;
comment|// update bytesAcked
name|block
operator|.
name|setNumBytes
argument_list|(
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|lastAckedSeqno
operator|=
name|seqno
expr_stmt|;
name|ackQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|responderClosed
condition|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|setLastException
argument_list|(
operator|(
name|IOException
operator|)
name|e
argument_list|)
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
name|errorIndex
operator|=
name|errorIndex
operator|==
operator|-
literal|1
condition|?
literal|0
else|:
name|errorIndex
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DFSOutputStream ResponseProcessor exception "
operator|+
literal|" for block "
operator|+
name|block
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|responderClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|close ()
name|void
name|close
parameter_list|()
block|{
name|responderClosed
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
comment|// If this stream has encountered any errors so far, shutdown
comment|// threads and mark stream as closed. Returns true if we should
comment|// sleep for a while after returning from this call.
comment|//
DECL|method|processDatanodeError ()
specifier|private
name|boolean
name|processDatanodeError
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Error Recovery for "
operator|+
name|block
operator|+
literal|" waiting for responder to exit. "
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|closeStream
argument_list|()
expr_stmt|;
comment|// move packets from ack queue to front of the data queue
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|addAll
argument_list|(
literal|0
argument_list|,
name|ackQueue
argument_list|)
expr_stmt|;
name|ackQueue
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|// Record the new pipeline failure recovery.
if|if
condition|(
name|lastAckedSeqnoBeforeFailure
operator|!=
name|lastAckedSeqno
condition|)
block|{
name|lastAckedSeqnoBeforeFailure
operator|=
name|lastAckedSeqno
expr_stmt|;
name|pipelineRecoveryCount
operator|=
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|// If we had to recover the pipeline five times in a row for the
comment|// same packet, this client likely has corrupt data or corrupting
comment|// during transmission.
if|if
condition|(
operator|++
name|pipelineRecoveryCount
operator|>
literal|5
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error recovering pipeline for writing "
operator|+
name|block
operator|+
literal|". Already retried 5 times for the same packet."
argument_list|)
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Failing write. Tried pipeline "
operator|+
literal|"recovery 5 times without success."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|doSleep
init|=
name|setupPipelineForAppendOrRecovery
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
condition|)
block|{
comment|// If we had an error while closing the pipeline, we go through a fast-path
comment|// where the BlockReceiver does not run. Instead, the DataNode just finalizes
comment|// the block immediately during the 'connect ack' process. So, we want to pull
comment|// the end-of-block packet from the dataQueue, since we don't actually have
comment|// a true pipeline to send it over.
comment|//
comment|// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that
comment|// a client waiting on close() will be aware that the flush finished.
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
assert|assert
name|dataQueue
operator|.
name|size
argument_list|()
operator|==
literal|1
assert|;
name|Packet
name|endOfBlockPacket
init|=
name|dataQueue
operator|.
name|remove
argument_list|()
decl_stmt|;
comment|// remove the end of block packet
assert|assert
name|endOfBlockPacket
operator|.
name|lastPacketInBlock
assert|;
assert|assert
name|lastAckedSeqno
operator|==
name|endOfBlockPacket
operator|.
name|seqno
operator|-
literal|1
assert|;
name|lastAckedSeqno
operator|=
name|endOfBlockPacket
operator|.
name|seqno
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|doSleep
return|;
block|}
DECL|method|setHflush ()
specifier|private
name|void
name|setHflush
parameter_list|()
block|{
name|isHflushed
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|findNewDatanode (final DatanodeInfo[] original )
specifier|private
name|int
name|findNewDatanode
parameter_list|(
specifier|final
name|DatanodeInfo
index|[]
name|original
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|!=
name|original
operator|.
name|length
operator|+
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
literal|"Failed to replace a bad datanode on the existing pipeline "
argument_list|)
operator|.
name|append
argument_list|(
literal|"due to no more good datanodes being available to try. "
argument_list|)
operator|.
name|append
argument_list|(
literal|"(Nodes: current="
argument_list|)
operator|.
name|append
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", original="
argument_list|)
operator|.
name|append
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"). "
argument_list|)
operator|.
name|append
argument_list|(
literal|"The current failed datanode replacement policy is "
argument_list|)
operator|.
name|append
argument_list|(
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
argument_list|)
operator|.
name|append
argument_list|(
literal|", and "
argument_list|)
operator|.
name|append
argument_list|(
literal|"a client may configure this via '"
argument_list|)
operator|.
name|append
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_POLICY_KEY
argument_list|)
operator|.
name|append
argument_list|(
literal|"' in its configuration."
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|int
name|j
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
name|j
operator|<
name|original
operator|.
name|length
operator|&&
operator|!
name|nodes
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
name|original
index|[
name|j
index|]
argument_list|)
condition|;
name|j
operator|++
control|)
empty_stmt|;
if|if
condition|(
name|j
operator|==
name|original
operator|.
name|length
condition|)
block|{
return|return
name|i
return|;
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed: new datanode not found: nodes="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
operator|+
literal|", original="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
argument_list|)
throw|;
block|}
DECL|method|addDatanode2ExistingPipeline ()
specifier|private
name|void
name|addDatanode2ExistingPipeline
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"lastAckedSeqno = "
operator|+
name|lastAckedSeqno
argument_list|)
expr_stmt|;
block|}
comment|/*        * Is data transfer necessary?  We have the following cases.        *         * Case 1: Failure in Pipeline Setup        * - Append        *    + Transfer the stored replica, which may be a RBW or a finalized.        * - Create        *    + If no data, then no transfer is required.        *    + If there are data written, transfer RBW. This case may happens         *      when there are streaming failure earlier in this pipeline.        *        * Case 2: Failure in Streaming        * - Append/Create:        *    + transfer RBW        *         * Case 3: Failure in Close        * - Append/Create:        *    + no transfer, let NameNode replicates the block.        */
if|if
condition|(
operator|!
name|isAppend
operator|&&
name|lastAckedSeqno
operator|<
literal|0
operator|&&
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
comment|//no data have been written
return|return;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE_RECOVERY
condition|)
block|{
comment|//pipeline is closing
return|return;
block|}
comment|//get a new datanode
specifier|final
name|DatanodeInfo
index|[]
name|original
init|=
name|nodes
decl_stmt|;
specifier|final
name|LocatedBlock
name|lb
init|=
name|dfsClient
operator|.
name|namenode
operator|.
name|getAdditionalDatanode
argument_list|(
name|src
argument_list|,
name|block
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|,
name|failed
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
name|failed
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
literal|1
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
decl_stmt|;
name|nodes
operator|=
name|lb
operator|.
name|getLocations
argument_list|()
expr_stmt|;
comment|//find the new datanode
specifier|final
name|int
name|d
init|=
name|findNewDatanode
argument_list|(
name|original
argument_list|)
decl_stmt|;
comment|//transfer replica
specifier|final
name|DatanodeInfo
name|src
init|=
name|d
operator|==
literal|0
condition|?
name|nodes
index|[
literal|1
index|]
else|:
name|nodes
index|[
name|d
operator|-
literal|1
index|]
decl_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|targets
init|=
block|{
name|nodes
index|[
name|d
index|]
block|}
decl_stmt|;
name|transfer
argument_list|(
name|src
argument_list|,
name|targets
argument_list|,
name|lb
operator|.
name|getBlockToken
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|transfer (final DatanodeInfo src, final DatanodeInfo[] targets, final Token<BlockTokenIdentifier> blockToken)
specifier|private
name|void
name|transfer
parameter_list|(
specifier|final
name|DatanodeInfo
name|src
parameter_list|,
specifier|final
name|DatanodeInfo
index|[]
name|targets
parameter_list|,
specifier|final
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|)
throws|throws
name|IOException
block|{
comment|//transfer replica to the new datanode
name|Socket
name|sock
init|=
literal|null
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
name|DataInputStream
name|in
init|=
literal|null
decl_stmt|;
try|try
block|{
name|sock
operator|=
name|createSocketForPipeline
argument_list|(
name|src
argument_list|,
literal|2
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
specifier|final
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|sock
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|sock
argument_list|)
decl_stmt|;
if|if
condition|(
name|dfsClient
operator|.
name|shouldEncryptData
argument_list|()
condition|)
block|{
name|IOStreamPair
name|encryptedStreams
init|=
name|DataTransferEncryptor
operator|.
name|getEncryptedStreams
argument_list|(
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
operator|.
name|getDataEncryptionKey
argument_list|()
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|encryptedStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|encryptedStreams
operator|.
name|in
expr_stmt|;
block|}
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|HdfsConstants
operator|.
name|SMALL_BUFFER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//send the TRANSFER_BLOCK request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|transferBlock
argument_list|(
name|block
argument_list|,
name|blockToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|targets
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
comment|//ack
name|BlockOpResponseProto
name|response
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelper
operator|.
name|vintPrefixed
argument_list|(
name|in
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|SUCCESS
operator|!=
name|response
operator|.
name|getStatus
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to add a datanode"
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Open a DataOutputStream to a DataNode pipeline so that       * it can be written to.      * This happens when a file is appended or data streaming fails      * It keeps on trying until a pipeline is setup      */
DECL|method|setupPipelineForAppendOrRecovery ()
specifier|private
name|boolean
name|setupPipelineForAppendOrRecovery
parameter_list|()
throws|throws
name|IOException
block|{
comment|// check number of datanodes
if|if
condition|(
name|nodes
operator|==
literal|null
operator|||
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|String
name|msg
init|=
literal|"Could not get block locations. "
operator|+
literal|"Source file \""
operator|+
name|src
operator|+
literal|"\" - Aborting..."
decl_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|setLastException
argument_list|(
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|long
name|newGS
init|=
literal|0L
decl_stmt|;
while|while
condition|(
operator|!
name|success
operator|&&
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|boolean
name|isRecovery
init|=
name|hasError
decl_stmt|;
comment|// remove bad datanode from list of datanodes.
comment|// If errorIndex was not set (i.e. appends), then do not remove
comment|// any datanodes
comment|//
if|if
condition|(
name|errorIndex
operator|>=
literal|0
condition|)
block|{
name|StringBuilder
name|pipelineMsg
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|nodes
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
name|pipelineMsg
operator|.
name|append
argument_list|(
name|nodes
index|[
name|j
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|j
operator|<
name|nodes
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|pipelineMsg
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|nodes
operator|.
name|length
operator|<=
literal|1
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"All datanodes "
operator|+
name|pipelineMsg
operator|+
literal|" are bad. Aborting..."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error Recovery for block "
operator|+
name|block
operator|+
literal|" in pipeline "
operator|+
name|pipelineMsg
operator|+
literal|": bad datanode "
operator|+
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|failed
operator|.
name|add
argument_list|(
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|DatanodeInfo
index|[]
name|newnodes
init|=
operator|new
name|DatanodeInfo
index|[
name|nodes
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|nodes
argument_list|,
literal|0
argument_list|,
name|newnodes
argument_list|,
literal|0
argument_list|,
name|errorIndex
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|nodes
argument_list|,
name|errorIndex
operator|+
literal|1
argument_list|,
name|newnodes
argument_list|,
name|errorIndex
argument_list|,
name|newnodes
operator|.
name|length
operator|-
name|errorIndex
argument_list|)
expr_stmt|;
name|nodes
operator|=
name|newnodes
expr_stmt|;
name|hasError
operator|=
literal|false
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// Check if replace-datanode policy is satisfied.
if|if
condition|(
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|.
name|satisfy
argument_list|(
name|blockReplication
argument_list|,
name|nodes
argument_list|,
name|isAppend
argument_list|,
name|isHflushed
argument_list|)
condition|)
block|{
name|addDatanode2ExistingPipeline
argument_list|()
expr_stmt|;
block|}
comment|// get a new generation stamp and an access token
name|LocatedBlock
name|lb
init|=
name|dfsClient
operator|.
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|block
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
decl_stmt|;
name|newGS
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
comment|// set up the pipeline again with the remaining nodes
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|newGS
argument_list|,
name|isRecovery
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|success
condition|)
block|{
comment|// update pipeline at the namenode
name|ExtendedBlock
name|newBlock
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|block
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|block
operator|.
name|getBlockId
argument_list|()
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|newGS
argument_list|)
decl_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|updatePipeline
argument_list|(
name|dfsClient
operator|.
name|clientName
argument_list|,
name|block
argument_list|,
name|newBlock
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|)
expr_stmt|;
comment|// update client side generation stamp
name|block
operator|=
name|newBlock
expr_stmt|;
block|}
return|return
literal|false
return|;
comment|// do not sleep, continue processing
block|}
comment|/**      * Open a DataOutputStream to a DataNode so that it can be written to.      * This happens when a file is created and each time a new block is allocated.      * Must get block ID and the IDs of the destinations from the namenode.      * Returns the list of target datanodes.      */
DECL|method|nextBlockOutputStream ()
specifier|private
name|DatanodeInfo
index|[]
name|nextBlockOutputStream
parameter_list|()
throws|throws
name|IOException
block|{
name|LocatedBlock
name|lb
init|=
literal|null
decl_stmt|;
name|DatanodeInfo
index|[]
name|nodes
init|=
literal|null
decl_stmt|;
name|int
name|count
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nBlockWriteRetry
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|ExtendedBlock
name|oldBlock
init|=
name|block
decl_stmt|;
do|do
block|{
name|hasError
operator|=
literal|false
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|errorIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|success
operator|=
literal|false
expr_stmt|;
name|long
name|startTime
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
name|DatanodeInfo
index|[]
name|excluded
init|=
name|excludedNodes
operator|.
name|getAllPresent
argument_list|(
name|excludedNodes
operator|.
name|asMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
operator|.
name|keySet
argument_list|()
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|block
operator|=
name|oldBlock
expr_stmt|;
name|lb
operator|=
name|locateFollowingBlock
argument_list|(
name|startTime
argument_list|,
name|excluded
operator|.
name|length
operator|>
literal|0
condition|?
name|excluded
else|:
literal|null
argument_list|)
expr_stmt|;
name|block
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
expr_stmt|;
name|block
operator|.
name|setNumBytes
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
name|nodes
operator|=
name|lb
operator|.
name|getLocations
argument_list|()
expr_stmt|;
comment|//
comment|// Connect to first DataNode in the list.
comment|//
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
literal|0L
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Abandoning "
operator|+
name|block
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|abandonBlock
argument_list|(
name|block
argument_list|,
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
name|block
operator|=
literal|null
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Excluding datanode "
operator|+
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
name|excludedNodes
operator|.
name|put
argument_list|(
name|nodes
index|[
name|errorIndex
index|]
argument_list|,
name|nodes
index|[
name|errorIndex
index|]
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|!
name|success
operator|&&
operator|--
name|count
operator|>=
literal|0
condition|)
do|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to create new block."
argument_list|)
throw|;
block|}
return|return
name|nodes
return|;
block|}
comment|// connects to the first datanode in the pipeline
comment|// Returns true if success, otherwise return failure.
comment|//
DECL|method|createBlockOutputStream (DatanodeInfo[] nodes, long newGS, boolean recoveryFlag)
specifier|private
name|boolean
name|createBlockOutputStream
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|long
name|newGS
parameter_list|,
name|boolean
name|recoveryFlag
parameter_list|)
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"nodes are empty for write pipeline of block "
operator|+
name|block
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|Status
name|pipelineStatus
init|=
name|SUCCESS
decl_stmt|;
name|String
name|firstBadLink
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"pipeline = "
operator|+
name|nodes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|// persist blocks on namenode on next flush
name|persistBlocks
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|int
name|refetchEncryptionKey
init|=
literal|1
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
try|try
block|{
assert|assert
literal|null
operator|==
name|s
operator|:
literal|"Previous socket unclosed"
assert|;
assert|assert
literal|null
operator|==
name|blockReplyStream
operator|:
literal|"Previous blockReplyStream unclosed"
assert|;
name|s
operator|=
name|createSocketForPipeline
argument_list|(
name|nodes
index|[
literal|0
index|]
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
name|nodes
operator|.
name|length
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|s
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|s
argument_list|)
decl_stmt|;
if|if
condition|(
name|dfsClient
operator|.
name|shouldEncryptData
argument_list|()
condition|)
block|{
name|IOStreamPair
name|encryptedStreams
init|=
name|DataTransferEncryptor
operator|.
name|getEncryptedStreams
argument_list|(
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
operator|.
name|getDataEncryptionKey
argument_list|()
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|encryptedStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|encryptedStreams
operator|.
name|in
expr_stmt|;
block|}
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|HdfsConstants
operator|.
name|SMALL_BUFFER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//
comment|// Xmit header info to datanode
comment|//
comment|// send the request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|writeBlock
argument_list|(
name|block
argument_list|,
name|accessToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|nodes
argument_list|,
literal|null
argument_list|,
name|recoveryFlag
condition|?
name|stage
operator|.
name|getRecoveryStage
argument_list|()
else|:
name|stage
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|bytesSent
argument_list|,
name|newGS
argument_list|,
name|checksum
argument_list|,
name|cachingStrategy
argument_list|)
expr_stmt|;
comment|// receive ack for connect
name|BlockOpResponseProto
name|resp
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelper
operator|.
name|vintPrefixed
argument_list|(
name|blockReplyStream
argument_list|)
argument_list|)
decl_stmt|;
name|pipelineStatus
operator|=
name|resp
operator|.
name|getStatus
argument_list|()
expr_stmt|;
name|firstBadLink
operator|=
name|resp
operator|.
name|getFirstBadLink
argument_list|()
expr_stmt|;
if|if
condition|(
name|pipelineStatus
operator|!=
name|SUCCESS
condition|)
block|{
if|if
condition|(
name|pipelineStatus
operator|==
name|Status
operator|.
name|ERROR_ACCESS_TOKEN
condition|)
block|{
throw|throw
operator|new
name|InvalidBlockTokenException
argument_list|(
literal|"Got access token error for connect ack with firstBadLink as "
operator|+
name|firstBadLink
argument_list|)
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Bad connect ack with firstBadLink as "
operator|+
name|firstBadLink
argument_list|)
throw|;
block|}
block|}
assert|assert
literal|null
operator|==
name|blockStream
operator|:
literal|"Previous blockStream unclosed"
assert|;
name|blockStream
operator|=
name|out
expr_stmt|;
name|result
operator|=
literal|true
expr_stmt|;
comment|// success
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception in createBlockOutputStream"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
if|if
condition|(
name|ie
operator|instanceof
name|InvalidEncryptionKeyException
operator|&&
name|refetchEncryptionKey
operator|>
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Will fetch a new encryption key and retry, "
operator|+
literal|"encryption key was invalid when connecting to "
operator|+
name|nodes
index|[
literal|0
index|]
operator|+
literal|" : "
operator|+
name|ie
argument_list|)
expr_stmt|;
comment|// The encryption key used is invalid.
name|refetchEncryptionKey
operator|--
expr_stmt|;
name|dfsClient
operator|.
name|clearDataEncryptionKey
argument_list|()
expr_stmt|;
comment|// Don't close the socket/exclude this node just yet. Try again with
comment|// a new encryption key.
continue|continue;
block|}
comment|// find the datanode that matches
if|if
condition|(
name|firstBadLink
operator|.
name|length
argument_list|()
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// NB: Unconditionally using the xfer addr w/o hostname
if|if
condition|(
name|firstBadLink
operator|.
name|equals
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
name|errorIndex
operator|=
name|i
expr_stmt|;
break|break;
block|}
block|}
block|}
else|else
block|{
name|errorIndex
operator|=
literal|0
expr_stmt|;
block|}
name|hasError
operator|=
literal|true
expr_stmt|;
name|setLastException
argument_list|(
name|ie
argument_list|)
expr_stmt|;
name|result
operator|=
literal|false
expr_stmt|;
comment|// error
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|result
condition|)
block|{
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|out
operator|=
literal|null
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
block|}
DECL|method|locateFollowingBlock (long start, DatanodeInfo[] excludedNodes)
specifier|private
name|LocatedBlock
name|locateFollowingBlock
parameter_list|(
name|long
name|start
parameter_list|,
name|DatanodeInfo
index|[]
name|excludedNodes
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|retries
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nBlockWriteLocateFollowingRetry
decl_stmt|;
name|long
name|sleeptime
init|=
literal|400
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|long
name|localstart
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
return|return
name|dfsClient
operator|.
name|namenode
operator|.
name|addBlock
argument_list|(
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|block
argument_list|,
name|excludedNodes
argument_list|,
name|fileId
argument_list|,
name|favoredNodes
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|RemoteException
name|e
parameter_list|)
block|{
name|IOException
name|ue
init|=
name|e
operator|.
name|unwrapRemoteException
argument_list|(
name|FileNotFoundException
operator|.
name|class
argument_list|,
name|AccessControlException
operator|.
name|class
argument_list|,
name|NSQuotaExceededException
operator|.
name|class
argument_list|,
name|DSQuotaExceededException
operator|.
name|class
argument_list|,
name|UnresolvedPathException
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|ue
operator|!=
name|e
condition|)
block|{
throw|throw
name|ue
throw|;
comment|// no need to retry these exceptions
block|}
if|if
condition|(
name|NotReplicatedYetException
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|e
operator|.
name|getClassName
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|retries
operator|==
literal|0
condition|)
block|{
throw|throw
name|e
throw|;
block|}
else|else
block|{
operator|--
name|retries
expr_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception while adding a block"
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|>
literal|5000
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for replication for "
operator|+
operator|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|)
operator|/
literal|1000
operator|+
literal|" seconds"
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"NotReplicatedYetException sleeping "
operator|+
name|src
operator|+
literal|" retries left "
operator|+
name|retries
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|sleeptime
argument_list|)
expr_stmt|;
name|sleeptime
operator|*=
literal|2
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
block|}
block|}
DECL|method|getBlock ()
name|ExtendedBlock
name|getBlock
parameter_list|()
block|{
return|return
name|block
return|;
block|}
DECL|method|getNodes ()
name|DatanodeInfo
index|[]
name|getNodes
parameter_list|()
block|{
return|return
name|nodes
return|;
block|}
DECL|method|getBlockToken ()
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockToken
parameter_list|()
block|{
return|return
name|accessToken
return|;
block|}
DECL|method|setLastException (IOException e)
specifier|private
name|void
name|setLastException
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|lastException
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a socket for a write pipeline    * @param first the first datanode     * @param length the pipeline length    * @param client client    * @return the socket connected to the first datanode    */
DECL|method|createSocketForPipeline (final DatanodeInfo first, final int length, final DFSClient client)
specifier|static
name|Socket
name|createSocketForPipeline
parameter_list|(
specifier|final
name|DatanodeInfo
name|first
parameter_list|,
specifier|final
name|int
name|length
parameter_list|,
specifier|final
name|DFSClient
name|client
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|dnAddr
init|=
name|first
operator|.
name|getXferAddr
argument_list|(
name|client
operator|.
name|getConf
argument_list|()
operator|.
name|connectToDnViaHostname
argument_list|)
decl_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connecting to datanode "
operator|+
name|dnAddr
argument_list|)
expr_stmt|;
block|}
specifier|final
name|InetSocketAddress
name|isa
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
specifier|final
name|Socket
name|sock
init|=
name|client
operator|.
name|socketFactory
operator|.
name|createSocket
argument_list|()
decl_stmt|;
specifier|final
name|int
name|timeout
init|=
name|client
operator|.
name|getDatanodeReadTimeout
argument_list|(
name|length
argument_list|)
decl_stmt|;
name|NetUtils
operator|.
name|connect
argument_list|(
name|sock
argument_list|,
name|isa
argument_list|,
name|client
operator|.
name|getRandomLocalInterfaceAddr
argument_list|()
argument_list|,
name|client
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSendBufferSize
argument_list|(
name|HdfsConstants
operator|.
name|DEFAULT_DATA_SOCKET_SIZE
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Send buf size "
operator|+
name|sock
operator|.
name|getSendBufferSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|sock
return|;
block|}
DECL|method|checkClosed ()
specifier|protected
name|void
name|checkClosed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
name|IOException
name|e
init|=
name|lastException
operator|.
name|get
argument_list|()
decl_stmt|;
throw|throw
name|e
operator|!=
literal|null
condition|?
name|e
else|:
operator|new
name|ClosedChannelException
argument_list|()
throw|;
block|}
block|}
comment|//
comment|// returns the list of targets, if any, that is being currently used.
comment|//
annotation|@
name|VisibleForTesting
DECL|method|getPipeline ()
specifier|public
specifier|synchronized
name|DatanodeInfo
index|[]
name|getPipeline
parameter_list|()
block|{
if|if
condition|(
name|streamer
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|DatanodeInfo
index|[]
name|currentNodes
init|=
name|streamer
operator|.
name|getNodes
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentNodes
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|DatanodeInfo
index|[]
name|value
init|=
operator|new
name|DatanodeInfo
index|[
name|currentNodes
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|currentNodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|value
index|[
name|i
index|]
operator|=
name|currentNodes
index|[
name|i
index|]
expr_stmt|;
block|}
return|return
name|value
return|;
block|}
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, Progressable progress, HdfsFileStatus stat, DataChecksum checksum)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|checksum
argument_list|,
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|,
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|dfsClient
operator|=
name|dfsClient
expr_stmt|;
name|this
operator|.
name|src
operator|=
name|src
expr_stmt|;
name|this
operator|.
name|fileId
operator|=
name|stat
operator|.
name|getFileId
argument_list|()
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|stat
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|this
operator|.
name|blockReplication
operator|=
name|stat
operator|.
name|getReplication
argument_list|()
expr_stmt|;
name|this
operator|.
name|progress
operator|=
name|progress
expr_stmt|;
name|this
operator|.
name|cachingStrategy
operator|=
name|dfsClient
operator|.
name|getDefaultWriteCachingStrategy
argument_list|()
operator|.
name|duplicate
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|progress
operator|!=
literal|null
operator|)
operator|&&
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Set non-null progress callback on DFSOutputStream "
operator|+
name|src
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|bytesPerChecksum
init|=
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
decl_stmt|;
if|if
condition|(
name|bytesPerChecksum
operator|<
literal|1
operator|||
name|blockSize
operator|%
name|bytesPerChecksum
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"io.bytes.per.checksum("
operator|+
name|bytesPerChecksum
operator|+
literal|") and blockSize("
operator|+
name|blockSize
operator|+
literal|") do not match. "
operator|+
literal|"blockSize should be a "
operator|+
literal|"multiple of io.bytes.per.checksum"
argument_list|)
throw|;
block|}
name|this
operator|.
name|checksum
operator|=
name|checksum
expr_stmt|;
block|}
comment|/** Construct a new output stream for creating a file. */
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, HdfsFileStatus stat, EnumSet<CreateFlag> flag, Progressable progress, DataChecksum checksum, String[] favoredNodes)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
expr_stmt|;
name|this
operator|.
name|shouldSyncBlock
operator|=
name|flag
operator|.
name|contains
argument_list|(
name|CreateFlag
operator|.
name|SYNC_BLOCK
argument_list|)
expr_stmt|;
name|computePacketChunkSize
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|()
expr_stmt|;
if|if
condition|(
name|favoredNodes
operator|!=
literal|null
operator|&&
name|favoredNodes
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
name|streamer
operator|.
name|setFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|newStreamForCreate (DFSClient dfsClient, String src, FsPermission masked, EnumSet<CreateFlag> flag, boolean createParent, short replication, long blockSize, Progressable progress, int buffersize, DataChecksum checksum, String[] favoredNodes)
specifier|static
name|DFSOutputStream
name|newStreamForCreate
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|FsPermission
name|masked
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|boolean
name|createParent
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|int
name|buffersize
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|HdfsFileStatus
name|stat
decl_stmt|;
try|try
block|{
name|stat
operator|=
name|dfsClient
operator|.
name|namenode
operator|.
name|create
argument_list|(
name|src
argument_list|,
name|masked
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
operator|new
name|EnumSetWritable
argument_list|<
name|CreateFlag
argument_list|>
argument_list|(
name|flag
argument_list|)
argument_list|,
name|createParent
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RemoteException
name|re
parameter_list|)
block|{
throw|throw
name|re
operator|.
name|unwrapRemoteException
argument_list|(
name|AccessControlException
operator|.
name|class
argument_list|,
name|DSQuotaExceededException
operator|.
name|class
argument_list|,
name|FileAlreadyExistsException
operator|.
name|class
argument_list|,
name|FileNotFoundException
operator|.
name|class
argument_list|,
name|ParentNotDirectoryException
operator|.
name|class
argument_list|,
name|NSQuotaExceededException
operator|.
name|class
argument_list|,
name|SafeModeException
operator|.
name|class
argument_list|,
name|UnresolvedPathException
operator|.
name|class
argument_list|,
name|SnapshotAccessControlException
operator|.
name|class
argument_list|)
throw|;
block|}
specifier|final
name|DFSOutputStream
name|out
init|=
operator|new
name|DFSOutputStream
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|stat
argument_list|,
name|flag
argument_list|,
name|progress
argument_list|,
name|checksum
argument_list|,
name|favoredNodes
argument_list|)
decl_stmt|;
name|out
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|out
return|;
block|}
DECL|method|newStreamForCreate (DFSClient dfsClient, String src, FsPermission masked, EnumSet<CreateFlag> flag, boolean createParent, short replication, long blockSize, Progressable progress, int buffersize, DataChecksum checksum)
specifier|static
name|DFSOutputStream
name|newStreamForCreate
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|FsPermission
name|masked
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flag
parameter_list|,
name|boolean
name|createParent
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|int
name|buffersize
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|newStreamForCreate
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|masked
argument_list|,
name|flag
argument_list|,
name|createParent
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|,
name|progress
argument_list|,
name|buffersize
argument_list|,
name|checksum
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/** Construct a new output stream for append. */
DECL|method|DFSOutputStream (DFSClient dfsClient, String src, Progressable progress, LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)
specifier|private
name|DFSOutputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
expr_stmt|;
name|initialFileSize
operator|=
name|stat
operator|.
name|getLen
argument_list|()
expr_stmt|;
comment|// length of file when opened
comment|// The last partial block of the file has to be filled.
if|if
condition|(
name|lastBlock
operator|!=
literal|null
condition|)
block|{
comment|// indicate that we are appending to an existing block
name|bytesCurBlock
operator|=
name|lastBlock
operator|.
name|getBlockSize
argument_list|()
expr_stmt|;
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|(
name|lastBlock
argument_list|,
name|stat
argument_list|,
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|computePacketChunkSize
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|,
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|streamer
operator|=
operator|new
name|DataStreamer
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|newStreamForAppend (DFSClient dfsClient, String src, int buffersize, Progressable progress, LocatedBlock lastBlock, HdfsFileStatus stat, DataChecksum checksum)
specifier|static
name|DFSOutputStream
name|newStreamForAppend
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|int
name|buffersize
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|DFSOutputStream
name|out
init|=
operator|new
name|DFSOutputStream
argument_list|(
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|lastBlock
argument_list|,
name|stat
argument_list|,
name|checksum
argument_list|)
decl_stmt|;
name|out
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|out
return|;
block|}
DECL|method|computePacketChunkSize (int psize, int csize)
specifier|private
name|void
name|computePacketChunkSize
parameter_list|(
name|int
name|psize
parameter_list|,
name|int
name|csize
parameter_list|)
block|{
name|int
name|chunkSize
init|=
name|csize
operator|+
name|checksum
operator|.
name|getChecksumSize
argument_list|()
decl_stmt|;
name|chunksPerPacket
operator|=
name|Math
operator|.
name|max
argument_list|(
name|psize
operator|/
name|chunkSize
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|packetSize
operator|=
name|chunkSize
operator|*
name|chunksPerPacket
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"computePacketChunkSize: src="
operator|+
name|src
operator|+
literal|", chunkSize="
operator|+
name|chunkSize
operator|+
literal|", chunksPerPacket="
operator|+
name|chunksPerPacket
operator|+
literal|", packetSize="
operator|+
name|packetSize
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|queueCurrentPacket ()
specifier|private
name|void
name|queueCurrentPacket
parameter_list|()
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
if|if
condition|(
name|currentPacket
operator|==
literal|null
condition|)
return|return;
name|dataQueue
operator|.
name|addLast
argument_list|(
name|currentPacket
argument_list|)
expr_stmt|;
name|lastQueuedSeqno
operator|=
name|currentPacket
operator|.
name|seqno
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Queued packet "
operator|+
name|currentPacket
operator|.
name|seqno
argument_list|)
expr_stmt|;
block|}
name|currentPacket
operator|=
literal|null
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|waitAndQueueCurrentPacket ()
specifier|private
name|void
name|waitAndQueueCurrentPacket
parameter_list|()
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
try|try
block|{
comment|// If queue is full, then wait till we have enough space
while|while
condition|(
operator|!
name|closed
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|+
name|ackQueue
operator|.
name|size
argument_list|()
operator|>
name|MAX_PACKETS
condition|)
block|{
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// If we get interrupted while waiting to queue data, we still need to get rid
comment|// of the current packet. This is because we have an invariant that if
comment|// currentPacket gets full, it will get queued before the next writeChunk.
comment|//
comment|// Rather than wait around for space in the queue, we should instead try to
comment|// return to the caller as soon as possible, even though we slightly overrun
comment|// the MAX_PACKETS length.
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
name|queueCurrentPacket
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{       }
block|}
block|}
comment|// @see FSOutputSummer#writeChunk()
annotation|@
name|Override
DECL|method|writeChunk (byte[] b, int offset, int len, byte[] checksum)
specifier|protected
specifier|synchronized
name|void
name|writeChunk
parameter_list|(
name|byte
index|[]
name|b
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|len
parameter_list|,
name|byte
index|[]
name|checksum
parameter_list|)
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
name|int
name|cklen
init|=
name|checksum
operator|.
name|length
decl_stmt|;
name|int
name|bytesPerChecksum
init|=
name|this
operator|.
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
decl_stmt|;
if|if
condition|(
name|len
operator|>
name|bytesPerChecksum
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"writeChunk() buffer size is "
operator|+
name|len
operator|+
literal|" is larger than supported  bytesPerChecksum "
operator|+
name|bytesPerChecksum
argument_list|)
throw|;
block|}
if|if
condition|(
name|checksum
operator|.
name|length
operator|!=
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"writeChunk() checksum size is supposed to be "
operator|+
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
operator|+
literal|" but found to be "
operator|+
name|checksum
operator|.
name|length
argument_list|)
throw|;
block|}
if|if
condition|(
name|currentPacket
operator|==
literal|null
condition|)
block|{
name|currentPacket
operator|=
operator|new
name|Packet
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient writeChunk allocating new packet seqno="
operator|+
name|currentPacket
operator|.
name|seqno
operator|+
literal|", src="
operator|+
name|src
operator|+
literal|", packetSize="
operator|+
name|packetSize
operator|+
literal|", chunksPerPacket="
operator|+
name|chunksPerPacket
operator|+
literal|", bytesCurBlock="
operator|+
name|bytesCurBlock
argument_list|)
expr_stmt|;
block|}
block|}
name|currentPacket
operator|.
name|writeChecksum
argument_list|(
name|checksum
argument_list|,
literal|0
argument_list|,
name|cklen
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|writeData
argument_list|(
name|b
argument_list|,
name|offset
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|numChunks
operator|++
expr_stmt|;
name|bytesCurBlock
operator|+=
name|len
expr_stmt|;
comment|// If packet is full, enqueue it for transmission
comment|//
if|if
condition|(
name|currentPacket
operator|.
name|numChunks
operator|==
name|currentPacket
operator|.
name|maxChunks
operator|||
name|bytesCurBlock
operator|==
name|blockSize
condition|)
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient writeChunk packet full seqno="
operator|+
name|currentPacket
operator|.
name|seqno
operator|+
literal|", src="
operator|+
name|src
operator|+
literal|", bytesCurBlock="
operator|+
name|bytesCurBlock
operator|+
literal|", blockSize="
operator|+
name|blockSize
operator|+
literal|", appendChunk="
operator|+
name|appendChunk
argument_list|)
expr_stmt|;
block|}
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
comment|// If the reopened file did not end at chunk boundary and the above
comment|// write filled up its partial chunk. Tell the summer to generate full
comment|// crc chunks from now on.
if|if
condition|(
name|appendChunk
operator|&&
name|bytesCurBlock
operator|%
name|bytesPerChecksum
operator|==
literal|0
condition|)
block|{
name|appendChunk
operator|=
literal|false
expr_stmt|;
name|resetChecksumChunk
argument_list|(
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|appendChunk
condition|)
block|{
name|int
name|psize
init|=
name|Math
operator|.
name|min
argument_list|(
call|(
name|int
call|)
argument_list|(
name|blockSize
operator|-
name|bytesCurBlock
argument_list|)
argument_list|,
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|writePacketSize
argument_list|)
decl_stmt|;
name|computePacketChunkSize
argument_list|(
name|psize
argument_list|,
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
comment|//
comment|// if encountering a block boundary, send an empty packet to
comment|// indicate the end of block and reset bytesCurBlock.
comment|//
if|if
condition|(
name|bytesCurBlock
operator|==
name|blockSize
condition|)
block|{
name|currentPacket
operator|=
operator|new
name|Packet
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|lastPacketInBlock
operator|=
literal|true
expr_stmt|;
name|currentPacket
operator|.
name|syncBlock
operator|=
name|shouldSyncBlock
expr_stmt|;
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
name|bytesCurBlock
operator|=
literal|0
expr_stmt|;
name|lastFlushOffset
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flushes out to all replicas of the block. The data is in the buffers    * of the DNs but not necessarily in the DN's OS buffers.    *    * It is a synchronous operation. When it returns,    * it guarantees that flushed data become visible to new readers.     * It is not guaranteed that data has been flushed to     * persistent store on the datanode.     * Block allocations are persisted on namenode.    */
annotation|@
name|Override
DECL|method|hflush ()
specifier|public
name|void
name|hflush
parameter_list|()
throws|throws
name|IOException
block|{
name|flushOrSync
argument_list|(
literal|false
argument_list|,
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|SyncFlag
operator|.
name|class
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|hsync ()
specifier|public
name|void
name|hsync
parameter_list|()
throws|throws
name|IOException
block|{
name|hsync
argument_list|(
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|SyncFlag
operator|.
name|class
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * The expected semantics is all data have flushed out to all replicas     * and all replicas have done posix fsync equivalent - ie the OS has     * flushed it to the disk device (but the disk may have it in its cache).    *     * Note that only the current block is flushed to the disk device.    * To guarantee durable sync across block boundaries the stream should    * be created with {@link CreateFlag#SYNC_BLOCK}.    *     * @param syncFlags    *          Indicate the semantic of the sync. Currently used to specify    *          whether or not to update the block length in NameNode.    */
DECL|method|hsync (EnumSet<SyncFlag> syncFlags)
specifier|public
name|void
name|hsync
parameter_list|(
name|EnumSet
argument_list|<
name|SyncFlag
argument_list|>
name|syncFlags
parameter_list|)
throws|throws
name|IOException
block|{
name|flushOrSync
argument_list|(
literal|true
argument_list|,
name|syncFlags
argument_list|)
expr_stmt|;
block|}
comment|/**    * Flush/Sync buffered data to DataNodes.    *     * @param isSync    *          Whether or not to require all replicas to flush data to the disk    *          device    * @param syncFlags    *          Indicate extra detailed semantic of the flush/sync. Currently    *          mainly used to specify whether or not to update the file length in    *          the NameNode    * @throws IOException    */
DECL|method|flushOrSync (boolean isSync, EnumSet<SyncFlag> syncFlags)
specifier|private
name|void
name|flushOrSync
parameter_list|(
name|boolean
name|isSync
parameter_list|,
name|EnumSet
argument_list|<
name|SyncFlag
argument_list|>
name|syncFlags
parameter_list|)
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|toWaitFor
decl_stmt|;
name|long
name|lastBlockLength
init|=
operator|-
literal|1L
decl_stmt|;
name|boolean
name|updateLength
init|=
name|syncFlags
operator|.
name|contains
argument_list|(
name|SyncFlag
operator|.
name|UPDATE_LENGTH
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
comment|/* Record current blockOffset. This might be changed inside          * flushBuffer() where a partial checksum chunk might be flushed.          * After the flush, reset the bytesCurBlock back to its previous value,          * any partial checksum chunk will be sent now and in next packet.          */
name|long
name|saveOffset
init|=
name|bytesCurBlock
decl_stmt|;
name|Packet
name|oldCurrentPacket
init|=
name|currentPacket
decl_stmt|;
comment|// flush checksum buffer, but keep checksum buffer intact
name|flushBuffer
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// bytesCurBlock potentially incremented if there was buffered data
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient flush() : saveOffset "
operator|+
name|saveOffset
operator|+
literal|" bytesCurBlock "
operator|+
name|bytesCurBlock
operator|+
literal|" lastFlushOffset "
operator|+
name|lastFlushOffset
argument_list|)
expr_stmt|;
block|}
comment|// Flush only if we haven't already flushed till this offset.
if|if
condition|(
name|lastFlushOffset
operator|!=
name|bytesCurBlock
condition|)
block|{
assert|assert
name|bytesCurBlock
operator|>
name|lastFlushOffset
assert|;
comment|// record the valid offset of this flush
name|lastFlushOffset
operator|=
name|bytesCurBlock
expr_stmt|;
if|if
condition|(
name|isSync
operator|&&
name|currentPacket
operator|==
literal|null
condition|)
block|{
comment|// Nothing to send right now,
comment|// but sync was requested.
comment|// Send an empty packet
name|currentPacket
operator|=
operator|new
name|Packet
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// We already flushed up to this offset.
comment|// This means that we haven't written anything since the last flush
comment|// (or the beginning of the file). Hence, we should not have any
comment|// packet queued prior to this call, since the last flush set
comment|// currentPacket = null.
assert|assert
name|oldCurrentPacket
operator|==
literal|null
operator|:
literal|"Empty flush should not occur with a currentPacket"
assert|;
if|if
condition|(
name|isSync
operator|&&
name|bytesCurBlock
operator|>
literal|0
condition|)
block|{
comment|// Nothing to send right now,
comment|// and the block was partially written,
comment|// and sync was requested.
comment|// So send an empty sync packet.
name|currentPacket
operator|=
operator|new
name|Packet
argument_list|(
name|packetSize
argument_list|,
name|chunksPerPacket
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// just discard the current packet since it is already been sent.
name|currentPacket
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|currentPacket
operator|!=
literal|null
condition|)
block|{
name|currentPacket
operator|.
name|syncBlock
operator|=
name|isSync
expr_stmt|;
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
block|}
comment|// Restore state of stream. Record the last flush offset
comment|// of the last full chunk that was flushed.
comment|//
name|bytesCurBlock
operator|=
name|saveOffset
expr_stmt|;
name|toWaitFor
operator|=
name|lastQueuedSeqno
expr_stmt|;
block|}
comment|// end synchronized
name|waitForAckedSeqno
argument_list|(
name|toWaitFor
argument_list|)
expr_stmt|;
if|if
condition|(
name|updateLength
condition|)
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|streamer
operator|!=
literal|null
operator|&&
name|streamer
operator|.
name|block
operator|!=
literal|null
condition|)
block|{
name|lastBlockLength
operator|=
name|streamer
operator|.
name|block
operator|.
name|getNumBytes
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// If 1) any new blocks were allocated since the last flush, or 2) to
comment|// update length in NN is required, then persist block locations on
comment|// namenode.
if|if
condition|(
name|persistBlocks
operator|.
name|getAndSet
argument_list|(
literal|false
argument_list|)
operator|||
name|updateLength
condition|)
block|{
try|try
block|{
name|dfsClient
operator|.
name|namenode
operator|.
name|fsync
argument_list|(
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|lastBlockLength
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to persist blocks in hflush for "
operator|+
name|src
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|// If we got an error here, it might be because some other thread called
comment|// close before our hflush completed. In that case, we should throw an
comment|// exception that the stream is closed.
name|checkClosed
argument_list|()
expr_stmt|;
comment|// If we aren't closed but failed to sync, we should expose that to the
comment|// caller.
throw|throw
name|ioe
throw|;
block|}
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|streamer
operator|!=
literal|null
condition|)
block|{
name|streamer
operator|.
name|setHflush
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedIOException
name|interrupt
parameter_list|)
block|{
comment|// This kind of error doesn't mean that the stream itself is broken - just the
comment|// flushing thread got interrupted. So, we shouldn't close down the writer,
comment|// but instead just propagate the error
throw|throw
name|interrupt
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error while syncing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
operator|!
name|closed
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"IOException flush:"
operator|+
name|e
argument_list|)
argument_list|)
expr_stmt|;
name|closeThreads
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * @deprecated use {@link HdfsDataOutputStream#getCurrentBlockReplication()}.    */
annotation|@
name|Deprecated
DECL|method|getNumCurrentReplicas ()
specifier|public
specifier|synchronized
name|int
name|getNumCurrentReplicas
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getCurrentBlockReplication
argument_list|()
return|;
block|}
comment|/**    * Note that this is not a public API;    * use {@link HdfsDataOutputStream#getCurrentBlockReplication()} instead.    *     * @return the number of valid replicas of the current block    */
DECL|method|getCurrentBlockReplication ()
specifier|public
specifier|synchronized
name|int
name|getCurrentBlockReplication
parameter_list|()
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|streamer
operator|==
literal|null
condition|)
block|{
return|return
name|blockReplication
return|;
comment|// no pipeline, return repl factor of file
block|}
name|DatanodeInfo
index|[]
name|currentNodes
init|=
name|streamer
operator|.
name|getNodes
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentNodes
operator|==
literal|null
condition|)
block|{
return|return
name|blockReplication
return|;
comment|// no pipeline, return repl factor of file
block|}
return|return
name|currentNodes
operator|.
name|length
return|;
block|}
comment|/**    * Waits till all existing data is flushed and confirmations     * received from datanodes.     */
DECL|method|flushInternal ()
specifier|private
name|void
name|flushInternal
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|toWaitFor
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
name|checkClosed
argument_list|()
expr_stmt|;
comment|//
comment|// If there is data in the current buffer, send it across
comment|//
name|queueCurrentPacket
argument_list|()
expr_stmt|;
name|toWaitFor
operator|=
name|lastQueuedSeqno
expr_stmt|;
block|}
name|waitForAckedSeqno
argument_list|(
name|toWaitFor
argument_list|)
expr_stmt|;
block|}
DECL|method|waitForAckedSeqno (long seqno)
specifier|private
name|void
name|waitForAckedSeqno
parameter_list|(
name|long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Waiting for ack for: "
operator|+
name|seqno
argument_list|)
expr_stmt|;
block|}
try|try
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|closed
condition|)
block|{
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|lastAckedSeqno
operator|>=
name|seqno
condition|)
block|{
break|break;
block|}
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// when we receive an ack, we notify on
comment|// dataQueue
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted while waiting for data to be acknowledged by pipeline"
argument_list|)
throw|;
block|}
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{     }
block|}
DECL|method|start ()
specifier|private
specifier|synchronized
name|void
name|start
parameter_list|()
block|{
name|streamer
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/**    * Aborts this output stream and releases any system     * resources associated with this stream.    */
DECL|method|abort ()
specifier|synchronized
name|void
name|abort
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
return|return;
block|}
name|streamer
operator|.
name|setLastException
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Lease timeout of "
operator|+
operator|(
name|dfsClient
operator|.
name|getHdfsTimeout
argument_list|()
operator|/
literal|1000
operator|)
operator|+
literal|" seconds expired."
argument_list|)
argument_list|)
expr_stmt|;
name|closeThreads
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|endFileLease
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
comment|// shutdown datastreamer and responseprocessor threads.
comment|// interrupt datastreamer if force is true
DECL|method|closeThreads (boolean force)
specifier|private
name|void
name|closeThreads
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|streamer
operator|.
name|close
argument_list|(
name|force
argument_list|)
expr_stmt|;
name|streamer
operator|.
name|join
argument_list|()
expr_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to shutdown streamer"
argument_list|)
throw|;
block|}
finally|finally
block|{
name|streamer
operator|=
literal|null
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
name|closed
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|/**    * Closes this output stream and releases any system     * resources associated with this stream.    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
name|IOException
name|e
init|=
name|lastException
operator|.
name|getAndSet
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|e
operator|==
literal|null
condition|)
return|return;
else|else
throw|throw
name|e
throw|;
block|}
try|try
block|{
name|flushBuffer
argument_list|()
expr_stmt|;
comment|// flush from all upper layers
if|if
condition|(
name|currentPacket
operator|!=
literal|null
condition|)
block|{
name|waitAndQueueCurrentPacket
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|bytesCurBlock
operator|!=
literal|0
condition|)
block|{
comment|// send an empty packet to mark the end of the block
name|currentPacket
operator|=
operator|new
name|Packet
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|bytesCurBlock
argument_list|,
name|currentSeqno
operator|++
argument_list|,
name|this
operator|.
name|checksum
operator|.
name|getChecksumSize
argument_list|()
argument_list|)
expr_stmt|;
name|currentPacket
operator|.
name|lastPacketInBlock
operator|=
literal|true
expr_stmt|;
name|currentPacket
operator|.
name|syncBlock
operator|=
name|shouldSyncBlock
expr_stmt|;
block|}
name|flushInternal
argument_list|()
expr_stmt|;
comment|// flush all data to Datanodes
comment|// get last block before destroying the streamer
name|ExtendedBlock
name|lastBlock
init|=
name|streamer
operator|.
name|getBlock
argument_list|()
decl_stmt|;
name|closeThreads
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|completeFile
argument_list|(
name|lastBlock
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|endFileLease
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|e
parameter_list|)
block|{     }
finally|finally
block|{
name|closed
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// should be called holding (this) lock since setTestFilename() may
comment|// be called during unit tests
DECL|method|completeFile (ExtendedBlock last)
specifier|private
name|void
name|completeFile
parameter_list|(
name|ExtendedBlock
name|last
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|localstart
init|=
name|Time
operator|.
name|now
argument_list|()
decl_stmt|;
name|boolean
name|fileComplete
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|fileComplete
condition|)
block|{
name|fileComplete
operator|=
name|dfsClient
operator|.
name|namenode
operator|.
name|complete
argument_list|(
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|last
argument_list|,
name|fileId
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fileComplete
condition|)
block|{
specifier|final
name|int
name|hdfsTimeout
init|=
name|dfsClient
operator|.
name|getHdfsTimeout
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|dfsClient
operator|.
name|clientRunning
operator|||
operator|(
name|hdfsTimeout
operator|>
literal|0
operator|&&
name|localstart
operator|+
name|hdfsTimeout
operator|<
name|Time
operator|.
name|now
argument_list|()
operator|)
condition|)
block|{
name|String
name|msg
init|=
literal|"Unable to close file because dfsclient "
operator|+
literal|" was unable to contact the HDFS servers."
operator|+
literal|" clientRunning "
operator|+
name|dfsClient
operator|.
name|clientRunning
operator|+
literal|" hdfsTimeout "
operator|+
name|hdfsTimeout
decl_stmt|;
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|400
argument_list|)
expr_stmt|;
if|if
condition|(
name|Time
operator|.
name|now
argument_list|()
operator|-
name|localstart
operator|>
literal|5000
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Could not complete "
operator|+
name|src
operator|+
literal|" retrying..."
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception "
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|setArtificialSlowdown (long period)
specifier|public
name|void
name|setArtificialSlowdown
parameter_list|(
name|long
name|period
parameter_list|)
block|{
name|artificialSlowdown
operator|=
name|period
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setChunksPerPacket (int value)
specifier|public
specifier|synchronized
name|void
name|setChunksPerPacket
parameter_list|(
name|int
name|value
parameter_list|)
block|{
name|chunksPerPacket
operator|=
name|Math
operator|.
name|min
argument_list|(
name|chunksPerPacket
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|packetSize
operator|=
operator|(
name|checksum
operator|.
name|getBytesPerChecksum
argument_list|()
operator|+
name|checksum
operator|.
name|getChecksumSize
argument_list|()
operator|)
operator|*
name|chunksPerPacket
expr_stmt|;
block|}
DECL|method|setTestFilename (String newname)
specifier|synchronized
name|void
name|setTestFilename
parameter_list|(
name|String
name|newname
parameter_list|)
block|{
name|src
operator|=
name|newname
expr_stmt|;
block|}
comment|/**    * Returns the size of a file as it was when this stream was opened    */
DECL|method|getInitialLen ()
name|long
name|getInitialLen
parameter_list|()
block|{
return|return
name|initialFileSize
return|;
block|}
comment|/**    * Returns the access token currently used by streamer, for testing only    */
DECL|method|getBlockToken ()
specifier|synchronized
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockToken
parameter_list|()
block|{
return|return
name|streamer
operator|.
name|getBlockToken
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|setDropBehind (Boolean dropBehind)
specifier|public
name|void
name|setDropBehind
parameter_list|(
name|Boolean
name|dropBehind
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|cachingStrategy
operator|.
name|setDropBehind
argument_list|(
name|dropBehind
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

