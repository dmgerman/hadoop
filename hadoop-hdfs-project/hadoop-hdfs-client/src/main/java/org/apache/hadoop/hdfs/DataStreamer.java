begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
operator|.
name|SUCCESS
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|ClosedChannelException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StorageType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|HdfsClientConfigKeys
operator|.
name|BlockWrite
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|client
operator|.
name|impl
operator|.
name|DfsClientConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|HdfsFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|QuotaExceededException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|BlockConstructionStage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtoUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|DataTransferProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|IOStreamPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|InvalidEncryptionKeyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PacketHeader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|PipelineAck
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|datatransfer
operator|.
name|Sender
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|BlockOpResponseProto
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|proto
operator|.
name|DataTransferProtos
operator|.
name|Status
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocolPB
operator|.
name|PBHelperClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|CachingStrategy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|util
operator|.
name|ByteArrayManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MultipleIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Daemon
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|Span
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|SpanId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|TraceScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|Tracer
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheBuilder
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|CacheLoader
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|LoadingCache
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|cache
operator|.
name|RemovalNotification
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nonnull
import|;
end_import

begin_comment
comment|/*********************************************************************  *  * The DataStreamer class is responsible for sending data packets to the  * datanodes in the pipeline. It retrieves a new blockid and block locations  * from the namenode, and starts streaming packets to the pipeline of  * Datanodes. Every packet has a sequence number associated with  * it. When all the packets for a block are sent out and acks for each  * if them are received, the DataStreamer closes the current block.  *  * The DataStreamer thread picks up packets from the dataQueue, sends it to  * the first datanode in the pipeline and moves it from the dataQueue to the  * ackQueue. The ResponseProcessor receives acks from the datanodes. When an  * successful ack for a packet is received from all datanodes, the  * ResponseProcessor removes the corresponding packet from the ackQueue.  *  * In case of error, all outstanding packets are moved from ackQueue. A new  * pipeline is setup by eliminating the bad datanode from the original  * pipeline. The DataStreamer now starts sending packets from the dataQueue.  *  *********************************************************************/
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DataStreamer
class|class
name|DataStreamer
extends|extends
name|Daemon
block|{
DECL|field|LOG
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DataStreamer
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**    * Create a socket for a write pipeline    *    * @param first the first datanode    * @param length the pipeline length    * @param client client    * @return the socket connected to the first datanode    */
DECL|method|createSocketForPipeline (final DatanodeInfo first, final int length, final DFSClient client)
specifier|static
name|Socket
name|createSocketForPipeline
parameter_list|(
specifier|final
name|DatanodeInfo
name|first
parameter_list|,
specifier|final
name|int
name|length
parameter_list|,
specifier|final
name|DFSClient
name|client
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|DfsClientConf
name|conf
init|=
name|client
operator|.
name|getConf
argument_list|()
decl_stmt|;
specifier|final
name|String
name|dnAddr
init|=
name|first
operator|.
name|getXferAddr
argument_list|(
name|conf
operator|.
name|isConnectToDnViaHostname
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connecting to datanode {}"
argument_list|,
name|dnAddr
argument_list|)
expr_stmt|;
specifier|final
name|InetSocketAddress
name|isa
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
specifier|final
name|Socket
name|sock
init|=
name|client
operator|.
name|socketFactory
operator|.
name|createSocket
argument_list|()
decl_stmt|;
specifier|final
name|int
name|timeout
init|=
name|client
operator|.
name|getDatanodeReadTimeout
argument_list|(
name|length
argument_list|)
decl_stmt|;
name|NetUtils
operator|.
name|connect
argument_list|(
name|sock
argument_list|,
name|isa
argument_list|,
name|client
operator|.
name|getRandomLocalInterfaceAddr
argument_list|()
argument_list|,
name|conf
operator|.
name|getSocketTimeout
argument_list|()
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setKeepAlive
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getSocketSendBufferSize
argument_list|()
operator|>
literal|0
condition|)
block|{
name|sock
operator|.
name|setSendBufferSize
argument_list|(
name|conf
operator|.
name|getSocketSendBufferSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Send buf size {}"
argument_list|,
name|sock
operator|.
name|getSendBufferSize
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sock
return|;
block|}
comment|/**    * if this file is lazy persist    *    * @param stat the HdfsFileStatus of a file    * @return if this file is lazy persist    */
DECL|method|isLazyPersist (HdfsFileStatus stat)
specifier|static
name|boolean
name|isLazyPersist
parameter_list|(
name|HdfsFileStatus
name|stat
parameter_list|)
block|{
return|return
name|stat
operator|.
name|getStoragePolicy
argument_list|()
operator|==
name|HdfsConstants
operator|.
name|MEMORY_STORAGE_POLICY_ID
return|;
block|}
comment|/**    * release a list of packets to ByteArrayManager    *    * @param packets packets to be release    * @param bam ByteArrayManager    */
DECL|method|releaseBuffer (List<DFSPacket> packets, ByteArrayManager bam)
specifier|private
specifier|static
name|void
name|releaseBuffer
parameter_list|(
name|List
argument_list|<
name|DFSPacket
argument_list|>
name|packets
parameter_list|,
name|ByteArrayManager
name|bam
parameter_list|)
block|{
for|for
control|(
name|DFSPacket
name|p
range|:
name|packets
control|)
block|{
name|p
operator|.
name|releaseBuffer
argument_list|(
name|bam
argument_list|)
expr_stmt|;
block|}
name|packets
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
DECL|class|LastExceptionInStreamer
class|class
name|LastExceptionInStreamer
block|{
DECL|field|thrown
specifier|private
name|IOException
name|thrown
decl_stmt|;
DECL|method|set (Throwable t)
specifier|synchronized
name|void
name|set
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
assert|assert
name|t
operator|!=
literal|null
assert|;
name|this
operator|.
name|thrown
operator|=
name|t
operator|instanceof
name|IOException
condition|?
operator|(
name|IOException
operator|)
name|t
else|:
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
DECL|method|clear ()
specifier|synchronized
name|void
name|clear
parameter_list|()
block|{
name|thrown
operator|=
literal|null
expr_stmt|;
block|}
comment|/** Check if there already is an exception. */
DECL|method|check (boolean resetToNull)
specifier|synchronized
name|void
name|check
parameter_list|(
name|boolean
name|resetToNull
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|thrown
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
comment|// wrap and print the exception to know when the check is called
name|LOG
operator|.
name|trace
argument_list|(
literal|"Got Exception while checking, "
operator|+
name|DataStreamer
operator|.
name|this
argument_list|,
operator|new
name|Throwable
argument_list|(
name|thrown
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|final
name|IOException
name|e
init|=
name|thrown
decl_stmt|;
if|if
condition|(
name|resetToNull
condition|)
block|{
name|thrown
operator|=
literal|null
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
block|}
DECL|method|throwException4Close ()
specifier|synchronized
name|void
name|throwException4Close
parameter_list|()
throws|throws
name|IOException
block|{
name|check
argument_list|(
literal|false
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|ClosedChannelException
argument_list|()
throw|;
block|}
block|}
DECL|enum|ErrorType
enum|enum
name|ErrorType
block|{
DECL|enumConstant|NONE
DECL|enumConstant|INTERNAL
DECL|enumConstant|EXTERNAL
name|NONE
block|,
name|INTERNAL
block|,
name|EXTERNAL
block|}
DECL|class|ErrorState
specifier|static
class|class
name|ErrorState
block|{
DECL|field|error
name|ErrorType
name|error
init|=
name|ErrorType
operator|.
name|NONE
decl_stmt|;
DECL|field|badNodeIndex
specifier|private
name|int
name|badNodeIndex
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|restartingNodeIndex
specifier|private
name|int
name|restartingNodeIndex
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|restartingNodeDeadline
specifier|private
name|long
name|restartingNodeDeadline
init|=
literal|0
decl_stmt|;
DECL|field|datanodeRestartTimeout
specifier|private
specifier|final
name|long
name|datanodeRestartTimeout
decl_stmt|;
DECL|method|ErrorState (long datanodeRestartTimeout)
name|ErrorState
parameter_list|(
name|long
name|datanodeRestartTimeout
parameter_list|)
block|{
name|this
operator|.
name|datanodeRestartTimeout
operator|=
name|datanodeRestartTimeout
expr_stmt|;
block|}
DECL|method|resetInternalError ()
specifier|synchronized
name|void
name|resetInternalError
parameter_list|()
block|{
if|if
condition|(
name|hasInternalError
argument_list|()
condition|)
block|{
name|error
operator|=
name|ErrorType
operator|.
name|NONE
expr_stmt|;
block|}
name|badNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|restartingNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|restartingNodeDeadline
operator|=
literal|0
expr_stmt|;
block|}
DECL|method|reset ()
specifier|synchronized
name|void
name|reset
parameter_list|()
block|{
name|error
operator|=
name|ErrorType
operator|.
name|NONE
expr_stmt|;
name|badNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|restartingNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|restartingNodeDeadline
operator|=
literal|0
expr_stmt|;
block|}
DECL|method|hasInternalError ()
specifier|synchronized
name|boolean
name|hasInternalError
parameter_list|()
block|{
return|return
name|error
operator|==
name|ErrorType
operator|.
name|INTERNAL
return|;
block|}
DECL|method|hasExternalError ()
specifier|synchronized
name|boolean
name|hasExternalError
parameter_list|()
block|{
return|return
name|error
operator|==
name|ErrorType
operator|.
name|EXTERNAL
return|;
block|}
DECL|method|hasError ()
specifier|synchronized
name|boolean
name|hasError
parameter_list|()
block|{
return|return
name|error
operator|!=
name|ErrorType
operator|.
name|NONE
return|;
block|}
DECL|method|hasDatanodeError ()
specifier|synchronized
name|boolean
name|hasDatanodeError
parameter_list|()
block|{
return|return
name|error
operator|==
name|ErrorType
operator|.
name|INTERNAL
operator|&&
name|isNodeMarked
argument_list|()
return|;
block|}
DECL|method|setInternalError ()
specifier|synchronized
name|void
name|setInternalError
parameter_list|()
block|{
name|this
operator|.
name|error
operator|=
name|ErrorType
operator|.
name|INTERNAL
expr_stmt|;
block|}
DECL|method|setExternalError ()
specifier|synchronized
name|void
name|setExternalError
parameter_list|()
block|{
if|if
condition|(
operator|!
name|hasInternalError
argument_list|()
condition|)
block|{
name|this
operator|.
name|error
operator|=
name|ErrorType
operator|.
name|EXTERNAL
expr_stmt|;
block|}
block|}
DECL|method|setBadNodeIndex (int index)
specifier|synchronized
name|void
name|setBadNodeIndex
parameter_list|(
name|int
name|index
parameter_list|)
block|{
name|this
operator|.
name|badNodeIndex
operator|=
name|index
expr_stmt|;
block|}
DECL|method|getBadNodeIndex ()
specifier|synchronized
name|int
name|getBadNodeIndex
parameter_list|()
block|{
return|return
name|badNodeIndex
return|;
block|}
DECL|method|getRestartingNodeIndex ()
specifier|synchronized
name|int
name|getRestartingNodeIndex
parameter_list|()
block|{
return|return
name|restartingNodeIndex
return|;
block|}
DECL|method|initRestartingNode (int i, String message)
specifier|synchronized
name|void
name|initRestartingNode
parameter_list|(
name|int
name|i
parameter_list|,
name|String
name|message
parameter_list|)
block|{
name|restartingNodeIndex
operator|=
name|i
expr_stmt|;
name|restartingNodeDeadline
operator|=
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|+
name|datanodeRestartTimeout
expr_stmt|;
comment|// If the data streamer has already set the primary node
comment|// bad, clear it. It is likely that the write failed due to
comment|// the DN shutdown. Even if it was a real failure, the pipeline
comment|// recovery will take care of it.
name|badNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
DECL|method|isRestartingNode ()
specifier|synchronized
name|boolean
name|isRestartingNode
parameter_list|()
block|{
return|return
name|restartingNodeIndex
operator|>=
literal|0
return|;
block|}
DECL|method|isNodeMarked ()
specifier|synchronized
name|boolean
name|isNodeMarked
parameter_list|()
block|{
return|return
name|badNodeIndex
operator|>=
literal|0
operator|||
name|isRestartingNode
argument_list|()
return|;
block|}
comment|/**      * This method is used when no explicit error report was received, but      * something failed. The first node is a suspect or unsure about the cause      * so that it is marked as failed.      */
DECL|method|markFirstNodeIfNotMarked ()
specifier|synchronized
name|void
name|markFirstNodeIfNotMarked
parameter_list|()
block|{
comment|// There should be no existing error and no ongoing restart.
if|if
condition|(
operator|!
name|isNodeMarked
argument_list|()
condition|)
block|{
name|badNodeIndex
operator|=
literal|0
expr_stmt|;
block|}
block|}
DECL|method|adjustState4RestartingNode ()
specifier|synchronized
name|void
name|adjustState4RestartingNode
parameter_list|()
block|{
comment|// Just took care of a node error while waiting for a node restart
if|if
condition|(
name|restartingNodeIndex
operator|>=
literal|0
condition|)
block|{
comment|// If the error came from a node further away than the restarting
comment|// node, the restart must have been complete.
if|if
condition|(
name|badNodeIndex
operator|>
name|restartingNodeIndex
condition|)
block|{
name|restartingNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|badNodeIndex
operator|<
name|restartingNodeIndex
condition|)
block|{
comment|// the node index has shifted.
name|restartingNodeIndex
operator|--
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"badNodeIndex = "
operator|+
name|badNodeIndex
operator|+
literal|" = restartingNodeIndex = "
operator|+
name|restartingNodeIndex
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|isRestartingNode
argument_list|()
condition|)
block|{
name|error
operator|=
name|ErrorType
operator|.
name|NONE
expr_stmt|;
block|}
name|badNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
DECL|method|checkRestartingNodeDeadline (DatanodeInfo[] nodes)
specifier|synchronized
name|void
name|checkRestartingNodeDeadline
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|)
block|{
if|if
condition|(
name|restartingNodeIndex
operator|>=
literal|0
condition|)
block|{
if|if
condition|(
name|error
operator|==
name|ErrorType
operator|.
name|NONE
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"error=false while checking"
operator|+
literal|" restarting node deadline"
argument_list|)
throw|;
block|}
comment|// check badNodeIndex
if|if
condition|(
name|badNodeIndex
operator|==
name|restartingNodeIndex
condition|)
block|{
comment|// ignore, if came from the restarting node
name|badNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|// not within the deadline
if|if
condition|(
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|>=
name|restartingNodeDeadline
condition|)
block|{
comment|// expired. declare the restarting node dead
name|restartingNodeDeadline
operator|=
literal|0
expr_stmt|;
specifier|final
name|int
name|i
init|=
name|restartingNodeIndex
decl_stmt|;
name|restartingNodeIndex
operator|=
operator|-
literal|1
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Datanode "
operator|+
name|i
operator|+
literal|" did not restart within "
operator|+
name|datanodeRestartTimeout
operator|+
literal|"ms: "
operator|+
name|nodes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
comment|// Mark the restarting node as failed. If there is any other failed
comment|// node during the last pipeline construction attempt, it will not be
comment|// overwritten/dropped. In this case, the restarting node will get
comment|// excluded in the following attempt, if it still does not come up.
if|if
condition|(
name|badNodeIndex
operator|==
operator|-
literal|1
condition|)
block|{
name|badNodeIndex
operator|=
name|i
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
DECL|field|streamerClosed
specifier|private
specifier|volatile
name|boolean
name|streamerClosed
init|=
literal|false
decl_stmt|;
DECL|field|block
specifier|protected
specifier|volatile
name|ExtendedBlock
name|block
decl_stmt|;
comment|// its length is number of bytes acked
DECL|field|accessToken
specifier|protected
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
decl_stmt|;
DECL|field|blockStream
specifier|private
name|DataOutputStream
name|blockStream
decl_stmt|;
DECL|field|blockReplyStream
specifier|private
name|DataInputStream
name|blockReplyStream
decl_stmt|;
DECL|field|response
specifier|private
name|ResponseProcessor
name|response
init|=
literal|null
decl_stmt|;
DECL|field|nodes
specifier|private
specifier|volatile
name|DatanodeInfo
index|[]
name|nodes
init|=
literal|null
decl_stmt|;
comment|// list of targets for current block
DECL|field|storageTypes
specifier|private
specifier|volatile
name|StorageType
index|[]
name|storageTypes
init|=
literal|null
decl_stmt|;
DECL|field|storageIDs
specifier|private
specifier|volatile
name|String
index|[]
name|storageIDs
init|=
literal|null
decl_stmt|;
DECL|field|errorState
specifier|private
specifier|final
name|ErrorState
name|errorState
decl_stmt|;
DECL|field|stage
specifier|private
specifier|volatile
name|BlockConstructionStage
name|stage
decl_stmt|;
comment|// block construction stage
DECL|field|bytesSent
specifier|protected
name|long
name|bytesSent
init|=
literal|0
decl_stmt|;
comment|// number of bytes that've been sent
DECL|field|isLazyPersistFile
specifier|private
specifier|final
name|boolean
name|isLazyPersistFile
decl_stmt|;
comment|/** Nodes have been used in the pipeline before and have failed. */
DECL|field|failed
specifier|private
specifier|final
name|List
argument_list|<
name|DatanodeInfo
argument_list|>
name|failed
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/** The times have retried to recover pipeline, for the same packet. */
DECL|field|pipelineRecoveryCount
specifier|private
specifier|volatile
name|int
name|pipelineRecoveryCount
init|=
literal|0
decl_stmt|;
comment|/** Has the current block been hflushed? */
DECL|field|isHflushed
specifier|private
name|boolean
name|isHflushed
init|=
literal|false
decl_stmt|;
comment|/** Append on an existing block? */
DECL|field|isAppend
specifier|private
specifier|final
name|boolean
name|isAppend
decl_stmt|;
DECL|field|currentSeqno
specifier|private
name|long
name|currentSeqno
init|=
literal|0
decl_stmt|;
DECL|field|lastQueuedSeqno
specifier|private
name|long
name|lastQueuedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|lastAckedSeqno
specifier|private
name|long
name|lastAckedSeqno
init|=
operator|-
literal|1
decl_stmt|;
DECL|field|bytesCurBlock
specifier|private
name|long
name|bytesCurBlock
init|=
literal|0
decl_stmt|;
comment|// bytes written in current block
DECL|field|lastException
specifier|private
specifier|final
name|LastExceptionInStreamer
name|lastException
init|=
operator|new
name|LastExceptionInStreamer
argument_list|()
decl_stmt|;
DECL|field|s
specifier|private
name|Socket
name|s
decl_stmt|;
DECL|field|dfsClient
specifier|protected
specifier|final
name|DFSClient
name|dfsClient
decl_stmt|;
DECL|field|src
specifier|protected
specifier|final
name|String
name|src
decl_stmt|;
comment|/** Only for DataTransferProtocol.writeBlock(..) */
DECL|field|checksum4WriteBlock
specifier|final
name|DataChecksum
name|checksum4WriteBlock
decl_stmt|;
DECL|field|progress
specifier|final
name|Progressable
name|progress
decl_stmt|;
DECL|field|stat
specifier|protected
specifier|final
name|HdfsFileStatus
name|stat
decl_stmt|;
comment|// appending to existing partial block
DECL|field|appendChunk
specifier|private
specifier|volatile
name|boolean
name|appendChunk
init|=
literal|false
decl_stmt|;
comment|// both dataQueue and ackQueue are protected by dataQueue lock
DECL|field|dataQueue
specifier|protected
specifier|final
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
name|dataQueue
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|ackQueue
specifier|private
specifier|final
name|LinkedList
argument_list|<
name|DFSPacket
argument_list|>
name|ackQueue
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|cachingStrategy
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
name|cachingStrategy
decl_stmt|;
DECL|field|byteArrayManager
specifier|private
specifier|final
name|ByteArrayManager
name|byteArrayManager
decl_stmt|;
comment|//persist blocks on namenode
DECL|field|persistBlocks
specifier|private
specifier|final
name|AtomicBoolean
name|persistBlocks
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|failPacket
specifier|private
name|boolean
name|failPacket
init|=
literal|false
decl_stmt|;
DECL|field|dfsclientSlowLogThresholdMs
specifier|private
specifier|final
name|long
name|dfsclientSlowLogThresholdMs
decl_stmt|;
DECL|field|artificialSlowdown
specifier|private
name|long
name|artificialSlowdown
init|=
literal|0
decl_stmt|;
comment|// List of congested data nodes. The stream will back off if the DataNodes
comment|// are congested
DECL|field|congestedNodes
specifier|private
specifier|final
name|List
argument_list|<
name|DatanodeInfo
argument_list|>
name|congestedNodes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
DECL|field|CONGESTION_BACKOFF_MEAN_TIME_IN_MS
specifier|private
specifier|static
specifier|final
name|int
name|CONGESTION_BACKOFF_MEAN_TIME_IN_MS
init|=
literal|5000
decl_stmt|;
DECL|field|CONGESTION_BACK_OFF_MAX_TIME_IN_MS
specifier|private
specifier|static
specifier|final
name|int
name|CONGESTION_BACK_OFF_MAX_TIME_IN_MS
init|=
name|CONGESTION_BACKOFF_MEAN_TIME_IN_MS
operator|*
literal|10
decl_stmt|;
DECL|field|lastCongestionBackoffTime
specifier|private
name|int
name|lastCongestionBackoffTime
decl_stmt|;
DECL|field|excludedNodes
specifier|protected
specifier|final
name|LoadingCache
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|excludedNodes
decl_stmt|;
DECL|field|favoredNodes
specifier|private
specifier|final
name|String
index|[]
name|favoredNodes
decl_stmt|;
DECL|method|DataStreamer (HdfsFileStatus stat, ExtendedBlock block, DFSClient dfsClient, String src, Progressable progress, DataChecksum checksum, AtomicReference<CachingStrategy> cachingStrategy, ByteArrayManager byteArrayManage, boolean isAppend, String[] favoredNodes)
specifier|private
name|DataStreamer
parameter_list|(
name|HdfsFileStatus
name|stat
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|,
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
name|cachingStrategy
parameter_list|,
name|ByteArrayManager
name|byteArrayManage
parameter_list|,
name|boolean
name|isAppend
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
block|{
name|this
operator|.
name|block
operator|=
name|block
expr_stmt|;
name|this
operator|.
name|dfsClient
operator|=
name|dfsClient
expr_stmt|;
name|this
operator|.
name|src
operator|=
name|src
expr_stmt|;
name|this
operator|.
name|progress
operator|=
name|progress
expr_stmt|;
name|this
operator|.
name|stat
operator|=
name|stat
expr_stmt|;
name|this
operator|.
name|checksum4WriteBlock
operator|=
name|checksum
expr_stmt|;
name|this
operator|.
name|cachingStrategy
operator|=
name|cachingStrategy
expr_stmt|;
name|this
operator|.
name|byteArrayManager
operator|=
name|byteArrayManage
expr_stmt|;
name|this
operator|.
name|isLazyPersistFile
operator|=
name|isLazyPersist
argument_list|(
name|stat
argument_list|)
expr_stmt|;
name|this
operator|.
name|isAppend
operator|=
name|isAppend
expr_stmt|;
name|this
operator|.
name|favoredNodes
operator|=
name|favoredNodes
expr_stmt|;
specifier|final
name|DfsClientConf
name|conf
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|this
operator|.
name|dfsclientSlowLogThresholdMs
operator|=
name|conf
operator|.
name|getSlowIoWarningThresholdMs
argument_list|()
expr_stmt|;
name|this
operator|.
name|excludedNodes
operator|=
name|initExcludedNodes
argument_list|(
name|conf
operator|.
name|getExcludedNodesCacheExpiry
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|errorState
operator|=
operator|new
name|ErrorState
argument_list|(
name|conf
operator|.
name|getDatanodeRestartTimeout
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * construction with tracing info    */
DECL|method|DataStreamer (HdfsFileStatus stat, ExtendedBlock block, DFSClient dfsClient, String src, Progressable progress, DataChecksum checksum, AtomicReference<CachingStrategy> cachingStrategy, ByteArrayManager byteArrayManage, String[] favoredNodes)
name|DataStreamer
parameter_list|(
name|HdfsFileStatus
name|stat
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|,
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
name|cachingStrategy
parameter_list|,
name|ByteArrayManager
name|byteArrayManage
parameter_list|,
name|String
index|[]
name|favoredNodes
parameter_list|)
block|{
name|this
argument_list|(
name|stat
argument_list|,
name|block
argument_list|,
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|checksum
argument_list|,
name|cachingStrategy
argument_list|,
name|byteArrayManage
argument_list|,
literal|false
argument_list|,
name|favoredNodes
argument_list|)
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
block|}
comment|/**    * Construct a data streamer for appending to the last partial block    * @param lastBlock last block of the file to be appended    * @param stat status of the file to be appended    */
DECL|method|DataStreamer (LocatedBlock lastBlock, HdfsFileStatus stat, DFSClient dfsClient, String src, Progressable progress, DataChecksum checksum, AtomicReference<CachingStrategy> cachingStrategy, ByteArrayManager byteArrayManage)
name|DataStreamer
parameter_list|(
name|LocatedBlock
name|lastBlock
parameter_list|,
name|HdfsFileStatus
name|stat
parameter_list|,
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|DataChecksum
name|checksum
parameter_list|,
name|AtomicReference
argument_list|<
name|CachingStrategy
argument_list|>
name|cachingStrategy
parameter_list|,
name|ByteArrayManager
name|byteArrayManage
parameter_list|)
block|{
name|this
argument_list|(
name|stat
argument_list|,
name|lastBlock
operator|.
name|getBlock
argument_list|()
argument_list|,
name|dfsClient
argument_list|,
name|src
argument_list|,
name|progress
argument_list|,
name|checksum
argument_list|,
name|cachingStrategy
argument_list|,
name|byteArrayManage
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
expr_stmt|;
name|bytesSent
operator|=
name|block
operator|.
name|getNumBytes
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lastBlock
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
block|}
comment|/**    * Set pipeline in construction    *    * @param lastBlock the last block of a file    * @throws IOException    */
DECL|method|setPipelineInConstruction (LocatedBlock lastBlock)
name|void
name|setPipelineInConstruction
parameter_list|(
name|LocatedBlock
name|lastBlock
parameter_list|)
throws|throws
name|IOException
block|{
comment|// setup pipeline to append to the last block XXX retries??
name|setPipeline
argument_list|(
name|lastBlock
argument_list|)
expr_stmt|;
if|if
condition|(
name|nodes
operator|.
name|length
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to retrieve blocks locations "
operator|+
literal|" for last block "
operator|+
name|block
operator|+
literal|" of file "
operator|+
name|src
argument_list|)
throw|;
block|}
block|}
DECL|method|setAccessToken (Token<BlockTokenIdentifier> t)
name|void
name|setAccessToken
parameter_list|(
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|t
parameter_list|)
block|{
name|this
operator|.
name|accessToken
operator|=
name|t
expr_stmt|;
block|}
DECL|method|setPipeline (LocatedBlock lb)
specifier|private
name|void
name|setPipeline
parameter_list|(
name|LocatedBlock
name|lb
parameter_list|)
block|{
name|setPipeline
argument_list|(
name|lb
operator|.
name|getLocations
argument_list|()
argument_list|,
name|lb
operator|.
name|getStorageTypes
argument_list|()
argument_list|,
name|lb
operator|.
name|getStorageIDs
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|setPipeline (DatanodeInfo[] nodes, StorageType[] storageTypes, String[] storageIDs)
specifier|private
name|void
name|setPipeline
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|StorageType
index|[]
name|storageTypes
parameter_list|,
name|String
index|[]
name|storageIDs
parameter_list|)
block|{
name|this
operator|.
name|nodes
operator|=
name|nodes
expr_stmt|;
name|this
operator|.
name|storageTypes
operator|=
name|storageTypes
expr_stmt|;
name|this
operator|.
name|storageIDs
operator|=
name|storageIDs
expr_stmt|;
block|}
comment|/**    * Initialize for data streaming    */
DECL|method|initDataStreaming ()
specifier|private
name|void
name|initDataStreaming
parameter_list|()
block|{
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
operator|+
literal|" block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|response
operator|=
operator|new
name|ResponseProcessor
argument_list|(
name|nodes
argument_list|)
expr_stmt|;
name|response
operator|.
name|start
argument_list|()
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
expr_stmt|;
block|}
DECL|method|endBlock ()
specifier|protected
name|void
name|endBlock
parameter_list|()
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing old block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|this
operator|.
name|setName
argument_list|(
literal|"DataStreamer for file "
operator|+
name|src
argument_list|)
expr_stmt|;
name|closeResponder
argument_list|()
expr_stmt|;
name|closeStream
argument_list|()
expr_stmt|;
name|setPipeline
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
expr_stmt|;
block|}
DECL|method|shouldStop ()
specifier|private
name|boolean
name|shouldStop
parameter_list|()
block|{
return|return
name|streamerClosed
operator|||
name|errorState
operator|.
name|hasError
argument_list|()
operator|||
operator|!
name|dfsClient
operator|.
name|clientRunning
return|;
block|}
comment|/*    * streamer thread is the only thread that opens streams to datanode,    * and closes them. Any error recovery is also done by this thread.    */
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|long
name|lastPacket
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|TraceScope
name|scope
init|=
literal|null
decl_stmt|;
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
comment|// if the Responder encountered an error, shutdown Responder
if|if
condition|(
name|errorState
operator|.
name|hasError
argument_list|()
operator|&&
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
name|response
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|DFSPacket
name|one
decl_stmt|;
try|try
block|{
comment|// process datanode IO errors if any
name|boolean
name|doSleep
init|=
name|processDatanodeOrExternalError
argument_list|()
decl_stmt|;
specifier|final
name|int
name|halfSocketTimeout
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|getSocketTimeout
argument_list|()
operator|/
literal|2
decl_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// wait for a packet to be sent.
name|long
name|now
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
while|while
condition|(
operator|(
operator|!
name|shouldStop
argument_list|()
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
operator|(
name|stage
operator|!=
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|&&
name|now
operator|-
name|lastPacket
operator|<
name|halfSocketTimeout
operator|)
operator|)
operator|||
name|doSleep
condition|)
block|{
name|long
name|timeout
init|=
name|halfSocketTimeout
operator|-
operator|(
name|now
operator|-
name|lastPacket
operator|)
decl_stmt|;
name|timeout
operator|=
name|timeout
operator|<=
literal|0
condition|?
literal|1000
else|:
name|timeout
expr_stmt|;
name|timeout
operator|=
operator|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|DATA_STREAMING
operator|)
condition|?
name|timeout
else|:
literal|1000
expr_stmt|;
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
name|timeout
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|doSleep
operator|=
literal|false
expr_stmt|;
name|now
operator|=
name|Time
operator|.
name|monotonicNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|shouldStop
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// get packet to be sent.
if|if
condition|(
name|dataQueue
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|one
operator|=
name|createHeartbeatPacket
argument_list|()
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|backOffIfNecessary
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|one
operator|=
name|dataQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
comment|// regular data packet
name|SpanId
index|[]
name|parents
init|=
name|one
operator|.
name|getTraceParents
argument_list|()
decl_stmt|;
if|if
condition|(
name|parents
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|scope
operator|=
name|dfsClient
operator|.
name|getTracer
argument_list|()
operator|.
name|newScope
argument_list|(
literal|"dataStreamer"
argument_list|,
name|parents
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|scope
operator|.
name|getSpan
argument_list|()
operator|.
name|setParents
argument_list|(
name|parents
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// get new block from namenode.
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"stage="
operator|+
name|stage
operator|+
literal|", "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Allocating new block: "
operator|+
name|this
argument_list|)
expr_stmt|;
name|setPipeline
argument_list|(
name|nextBlockOutputStream
argument_list|()
argument_list|)
expr_stmt|;
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_APPEND
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Append to block {}"
argument_list|,
name|block
argument_list|)
expr_stmt|;
name|setupPipelineForAppendOrRecovery
argument_list|()
expr_stmt|;
if|if
condition|(
name|streamerClosed
condition|)
block|{
continue|continue;
block|}
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
name|long
name|lastByteOffsetInBlock
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastByteOffsetInBlock
operator|>
name|stat
operator|.
name|getBlockSize
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlockSize "
operator|+
name|stat
operator|.
name|getBlockSize
argument_list|()
operator|+
literal|"< lastByteOffsetInBlock, "
operator|+
name|this
operator|+
literal|", "
operator|+
name|one
argument_list|)
throw|;
block|}
if|if
condition|(
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
condition|)
block|{
comment|// wait for all data packets have been successfully acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|shouldStop
argument_list|()
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
try|try
block|{
comment|// wait for acks to arrive from datanodes
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|shouldStop
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|stage
operator|=
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
expr_stmt|;
block|}
comment|// send the packet
name|SpanId
name|spanId
init|=
name|SpanId
operator|.
name|INVALID
decl_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
comment|// move packet from dataQueue to ackQueue
if|if
condition|(
operator|!
name|one
operator|.
name|isHeartbeatPacket
argument_list|()
condition|)
block|{
if|if
condition|(
name|scope
operator|!=
literal|null
condition|)
block|{
name|spanId
operator|=
name|scope
operator|.
name|getSpanId
argument_list|()
expr_stmt|;
name|scope
operator|.
name|detach
argument_list|()
expr_stmt|;
name|one
operator|.
name|setTraceScope
argument_list|(
name|scope
argument_list|)
expr_stmt|;
block|}
name|scope
operator|=
literal|null
expr_stmt|;
name|dataQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|ackQueue
operator|.
name|addLast
argument_list|(
name|one
argument_list|)
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
name|this
operator|+
literal|" sending "
operator|+
name|one
argument_list|)
expr_stmt|;
comment|// write out data to remote datanode
try|try
init|(
name|TraceScope
name|ignored
init|=
name|dfsClient
operator|.
name|getTracer
argument_list|()
operator|.
name|newScope
argument_list|(
literal|"DataStreamer#writeTo"
argument_list|,
name|spanId
argument_list|)
init|)
block|{
name|one
operator|.
name|writeTo
argument_list|(
name|blockStream
argument_list|)
expr_stmt|;
name|blockStream
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// HDFS-3398 treat primary DN is down since client is unable to
comment|// write to primary DN. If a failed or restarting node has already
comment|// been recorded by the responder, the following call will have no
comment|// effect. Pipeline recovery can handle only one node error at a
comment|// time. If the primary node fails again during the recovery, it
comment|// will be taken out then.
name|errorState
operator|.
name|markFirstNodeIfNotMarked
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|lastPacket
operator|=
name|Time
operator|.
name|monotonicNow
argument_list|()
expr_stmt|;
comment|// update bytesSent
name|long
name|tmpBytesSent
init|=
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|bytesSent
operator|<
name|tmpBytesSent
condition|)
block|{
name|bytesSent
operator|=
name|tmpBytesSent
expr_stmt|;
block|}
if|if
condition|(
name|shouldStop
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// Is this block full?
if|if
condition|(
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
condition|)
block|{
comment|// wait for the close packet has been acked
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|shouldStop
argument_list|()
operator|&&
name|ackQueue
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// wait for acks to arrive from datanodes
block|}
block|}
if|if
condition|(
name|shouldStop
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|progress
operator|!=
literal|null
condition|)
block|{
name|progress
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
comment|// This is used by unit test to trigger race conditions.
if|if
condition|(
name|artificialSlowdown
operator|!=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|artificialSlowdown
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
comment|// Log warning if there was a real error.
if|if
condition|(
operator|!
name|errorState
operator|.
name|isRestartingNode
argument_list|()
condition|)
block|{
comment|// Since their messages are descriptive enough, do not always
comment|// log a verbose stack-trace WARN for quota exceptions.
if|if
condition|(
name|e
operator|instanceof
name|QuotaExceededException
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DataStreamer Quota Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"DataStreamer Exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|lastException
operator|.
name|set
argument_list|(
name|e
argument_list|)
expr_stmt|;
assert|assert
operator|!
operator|(
name|e
operator|instanceof
name|NullPointerException
operator|)
assert|;
name|errorState
operator|.
name|setInternalError
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|errorState
operator|.
name|isNodeMarked
argument_list|()
condition|)
block|{
comment|// Not a datanode issue
name|streamerClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|scope
operator|!=
literal|null
condition|)
block|{
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
name|scope
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
name|closeInternal
argument_list|()
expr_stmt|;
block|}
DECL|method|closeInternal ()
specifier|private
name|void
name|closeInternal
parameter_list|()
block|{
name|closeResponder
argument_list|()
expr_stmt|;
comment|// close and join
name|closeStream
argument_list|()
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
name|release
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * release the DFSPackets in the two queues    *    */
DECL|method|release ()
name|void
name|release
parameter_list|()
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|releaseBuffer
argument_list|(
name|dataQueue
argument_list|,
name|byteArrayManager
argument_list|)
expr_stmt|;
name|releaseBuffer
argument_list|(
name|ackQueue
argument_list|,
name|byteArrayManager
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * wait for the ack of seqno    *    * @param seqno the sequence number to be acked    * @throws IOException    */
DECL|method|waitForAckedSeqno (long seqno)
name|void
name|waitForAckedSeqno
parameter_list|(
name|long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|TraceScope
name|ignored
init|=
name|dfsClient
operator|.
name|getTracer
argument_list|()
operator|.
name|newScope
argument_list|(
literal|"waitForAckedSeqno"
argument_list|)
init|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} waiting for ack for: {}"
argument_list|,
name|this
argument_list|,
name|seqno
argument_list|)
expr_stmt|;
name|long
name|begin
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
while|while
condition|(
operator|!
name|streamerClosed
condition|)
block|{
name|checkClosed
argument_list|()
expr_stmt|;
if|if
condition|(
name|lastAckedSeqno
operator|>=
name|seqno
condition|)
block|{
break|break;
block|}
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// when we receive an ack, we notify on
comment|// dataQueue
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted while waiting for data to be acknowledged by pipeline"
argument_list|)
throw|;
block|}
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|cce
parameter_list|)
block|{       }
name|long
name|duration
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|-
name|begin
decl_stmt|;
if|if
condition|(
name|duration
operator|>
name|dfsclientSlowLogThresholdMs
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Slow waitForAckedSeqno took "
operator|+
name|duration
operator|+
literal|"ms (threshold="
operator|+
name|dfsclientSlowLogThresholdMs
operator|+
literal|"ms)"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * wait for space of dataQueue and queue the packet    *    * @param packet  the DFSPacket to be queued    * @throws IOException    */
DECL|method|waitAndQueuePacket (DFSPacket packet)
name|void
name|waitAndQueuePacket
parameter_list|(
name|DFSPacket
name|packet
parameter_list|)
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
try|try
block|{
comment|// If queue is full, then wait till we have enough space
name|boolean
name|firstWait
init|=
literal|true
decl_stmt|;
try|try
block|{
while|while
condition|(
operator|!
name|streamerClosed
operator|&&
name|dataQueue
operator|.
name|size
argument_list|()
operator|+
name|ackQueue
operator|.
name|size
argument_list|()
operator|>
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|getWriteMaxPackets
argument_list|()
condition|)
block|{
if|if
condition|(
name|firstWait
condition|)
block|{
name|Span
name|span
init|=
name|Tracer
operator|.
name|getCurrentSpan
argument_list|()
decl_stmt|;
if|if
condition|(
name|span
operator|!=
literal|null
condition|)
block|{
name|span
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"dataQueue.wait"
argument_list|)
expr_stmt|;
block|}
name|firstWait
operator|=
literal|false
expr_stmt|;
block|}
try|try
block|{
name|dataQueue
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// If we get interrupted while waiting to queue data, we still need to get rid
comment|// of the current packet. This is because we have an invariant that if
comment|// currentPacket gets full, it will get queued before the next writeChunk.
comment|//
comment|// Rather than wait around for space in the queue, we should instead try to
comment|// return to the caller as soon as possible, even though we slightly overrun
comment|// the MAX_PACKETS length.
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
block|}
finally|finally
block|{
name|Span
name|span
init|=
name|Tracer
operator|.
name|getCurrentSpan
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|span
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|!
name|firstWait
operator|)
condition|)
block|{
name|span
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"end.wait"
argument_list|)
expr_stmt|;
block|}
block|}
name|checkClosed
argument_list|()
expr_stmt|;
name|queuePacket
argument_list|(
name|packet
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClosedChannelException
name|ignored
parameter_list|)
block|{       }
block|}
block|}
comment|/*    * close the streamer, should be called only by an external thread    * and only after all data to be sent has been flushed to datanode.    *    * Interrupt this data streamer if force is true    *    * @param force if this data stream is forced to be closed    */
DECL|method|close (boolean force)
name|void
name|close
parameter_list|(
name|boolean
name|force
parameter_list|)
block|{
name|streamerClosed
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|force
condition|)
block|{
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|setStreamerAsClosed ()
name|void
name|setStreamerAsClosed
parameter_list|()
block|{
name|streamerClosed
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|checkClosed ()
specifier|private
name|void
name|checkClosed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|streamerClosed
condition|)
block|{
name|lastException
operator|.
name|throwException4Close
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|closeResponder ()
specifier|private
name|void
name|closeResponder
parameter_list|()
block|{
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|response
operator|.
name|close
argument_list|()
expr_stmt|;
name|response
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Caught exception"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|response
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
DECL|method|closeStream ()
name|void
name|closeStream
parameter_list|()
block|{
specifier|final
name|MultipleIOException
operator|.
name|Builder
name|b
init|=
operator|new
name|MultipleIOException
operator|.
name|Builder
argument_list|()
decl_stmt|;
if|if
condition|(
name|blockStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|b
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|blockReplyStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|blockReplyStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|b
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
literal|null
operator|!=
name|s
condition|)
block|{
try|try
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|b
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|s
operator|=
literal|null
expr_stmt|;
block|}
block|}
specifier|final
name|IOException
name|ioe
init|=
name|b
operator|.
name|build
argument_list|()
decl_stmt|;
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Examine whether it is worth waiting for a node to restart.    * @param index the node index    */
DECL|method|shouldWaitForRestart (int index)
name|boolean
name|shouldWaitForRestart
parameter_list|(
name|int
name|index
parameter_list|)
block|{
comment|// Only one node in the pipeline.
if|if
condition|(
name|nodes
operator|.
name|length
operator|==
literal|1
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Is it a local node?
name|InetAddress
name|addr
init|=
literal|null
decl_stmt|;
try|try
block|{
name|addr
operator|=
name|InetAddress
operator|.
name|getByName
argument_list|(
name|nodes
index|[
name|index
index|]
operator|.
name|getIpAddr
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|java
operator|.
name|net
operator|.
name|UnknownHostException
name|e
parameter_list|)
block|{
comment|// we are passing an ip address. this should not happen.
assert|assert
literal|false
assert|;
block|}
return|return
name|addr
operator|!=
literal|null
operator|&&
name|NetUtils
operator|.
name|isLocalAddress
argument_list|(
name|addr
argument_list|)
return|;
block|}
comment|//
comment|// Processes responses from the datanodes.  A packet is removed
comment|// from the ackQueue when its response arrives.
comment|//
DECL|class|ResponseProcessor
specifier|private
class|class
name|ResponseProcessor
extends|extends
name|Daemon
block|{
DECL|field|responderClosed
specifier|private
specifier|volatile
name|boolean
name|responderClosed
init|=
literal|false
decl_stmt|;
DECL|field|targets
specifier|private
name|DatanodeInfo
index|[]
name|targets
init|=
literal|null
decl_stmt|;
DECL|field|isLastPacketInBlock
specifier|private
name|boolean
name|isLastPacketInBlock
init|=
literal|false
decl_stmt|;
DECL|method|ResponseProcessor (DatanodeInfo[] targets)
name|ResponseProcessor
parameter_list|(
name|DatanodeInfo
index|[]
name|targets
parameter_list|)
block|{
name|this
operator|.
name|targets
operator|=
name|targets
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|setName
argument_list|(
literal|"ResponseProcessor for block "
operator|+
name|block
argument_list|)
expr_stmt|;
name|PipelineAck
name|ack
init|=
operator|new
name|PipelineAck
argument_list|()
decl_stmt|;
name|TraceScope
name|scope
init|=
literal|null
decl_stmt|;
while|while
condition|(
operator|!
name|responderClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
operator|&&
operator|!
name|isLastPacketInBlock
condition|)
block|{
comment|// process responses from datanodes.
try|try
block|{
comment|// read an ack from the pipeline
name|long
name|begin
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|ack
operator|.
name|readFields
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
name|long
name|duration
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
operator|-
name|begin
decl_stmt|;
if|if
condition|(
name|duration
operator|>
name|dfsclientSlowLogThresholdMs
operator|&&
name|ack
operator|.
name|getSeqno
argument_list|()
operator|!=
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Slow ReadProcessor read fields took "
operator|+
name|duration
operator|+
literal|"ms (threshold="
operator|+
name|dfsclientSlowLogThresholdMs
operator|+
literal|"ms); ack: "
operator|+
name|ack
operator|+
literal|", targets: "
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|targets
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DFSClient {}"
argument_list|,
name|ack
argument_list|)
expr_stmt|;
block|}
name|long
name|seqno
init|=
name|ack
operator|.
name|getSeqno
argument_list|()
decl_stmt|;
comment|// processes response status from datanodes.
name|ArrayList
argument_list|<
name|DatanodeInfo
argument_list|>
name|congestedNodesFromAck
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|ack
operator|.
name|getNumOfReplies
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|;
name|i
operator|--
control|)
block|{
specifier|final
name|Status
name|reply
init|=
name|PipelineAck
operator|.
name|getStatusFromHeader
argument_list|(
name|ack
operator|.
name|getHeaderFlag
argument_list|(
name|i
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|PipelineAck
operator|.
name|getECNFromHeader
argument_list|(
name|ack
operator|.
name|getHeaderFlag
argument_list|(
name|i
argument_list|)
argument_list|)
operator|==
name|PipelineAck
operator|.
name|ECN
operator|.
name|CONGESTED
condition|)
block|{
name|congestedNodesFromAck
operator|.
name|add
argument_list|(
name|targets
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// Restart will not be treated differently unless it is
comment|// the local node or the only one in the pipeline.
if|if
condition|(
name|PipelineAck
operator|.
name|isRestartOOBStatus
argument_list|(
name|reply
argument_list|)
operator|&&
name|shouldWaitForRestart
argument_list|(
name|i
argument_list|)
condition|)
block|{
specifier|final
name|String
name|message
init|=
literal|"Datanode "
operator|+
name|i
operator|+
literal|" is restarting: "
operator|+
name|targets
index|[
name|i
index|]
decl_stmt|;
name|errorState
operator|.
name|initRestartingNode
argument_list|(
name|i
argument_list|,
name|message
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|message
argument_list|)
throw|;
block|}
comment|// node error
if|if
condition|(
name|reply
operator|!=
name|SUCCESS
condition|)
block|{
name|errorState
operator|.
name|setBadNodeIndex
argument_list|(
name|i
argument_list|)
expr_stmt|;
comment|// mark bad datanode
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Bad response "
operator|+
name|reply
operator|+
literal|" for "
operator|+
name|block
operator|+
literal|" from datanode "
operator|+
name|targets
index|[
name|i
index|]
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|congestedNodesFromAck
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
synchronized|synchronized
init|(
name|congestedNodes
init|)
block|{
name|congestedNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
name|congestedNodes
operator|.
name|addAll
argument_list|(
name|congestedNodesFromAck
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
synchronized|synchronized
init|(
name|congestedNodes
init|)
block|{
name|congestedNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
name|lastCongestionBackoffTime
operator|=
literal|0
expr_stmt|;
block|}
block|}
assert|assert
name|seqno
operator|!=
name|PipelineAck
operator|.
name|UNKOWN_SEQNO
operator|:
literal|"Ack for unknown seqno should be a failed ack: "
operator|+
name|ack
assert|;
if|if
condition|(
name|seqno
operator|==
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
condition|)
block|{
comment|// a heartbeat ack
continue|continue;
block|}
comment|// a success ack for a data packet
name|DFSPacket
name|one
decl_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|one
operator|=
name|ackQueue
operator|.
name|getFirst
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|one
operator|.
name|getSeqno
argument_list|()
operator|!=
name|seqno
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"ResponseProcessor: Expecting seqno "
operator|+
literal|" for block "
operator|+
name|block
operator|+
name|one
operator|.
name|getSeqno
argument_list|()
operator|+
literal|" but received "
operator|+
name|seqno
argument_list|)
throw|;
block|}
name|isLastPacketInBlock
operator|=
name|one
operator|.
name|isLastPacketInBlock
argument_list|()
expr_stmt|;
comment|// Fail the packet write for testing in order to force a
comment|// pipeline recovery.
if|if
condition|(
name|DFSClientFaultInjector
operator|.
name|get
argument_list|()
operator|.
name|failPacket
argument_list|()
operator|&&
name|isLastPacketInBlock
condition|)
block|{
name|failPacket
operator|=
literal|true
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failing the last packet for testing."
argument_list|)
throw|;
block|}
comment|// update bytesAcked
name|block
operator|.
name|setNumBytes
argument_list|(
name|one
operator|.
name|getLastByteOffsetBlock
argument_list|()
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|scope
operator|=
name|one
operator|.
name|getTraceScope
argument_list|()
expr_stmt|;
if|if
condition|(
name|scope
operator|!=
literal|null
condition|)
block|{
name|scope
operator|.
name|reattach
argument_list|()
expr_stmt|;
name|one
operator|.
name|setTraceScope
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|lastAckedSeqno
operator|=
name|seqno
expr_stmt|;
name|pipelineRecoveryCount
operator|=
literal|0
expr_stmt|;
name|ackQueue
operator|.
name|removeFirst
argument_list|()
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
name|one
operator|.
name|releaseBuffer
argument_list|(
name|byteArrayManager
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|responderClosed
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|errorState
operator|.
name|setInternalError
argument_list|()
expr_stmt|;
name|errorState
operator|.
name|markFirstNodeIfNotMarked
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|errorState
operator|.
name|isRestartingNode
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception for "
operator|+
name|block
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|responderClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|scope
operator|!=
literal|null
condition|)
block|{
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|scope
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
DECL|method|close ()
name|void
name|close
parameter_list|()
block|{
name|responderClosed
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|shouldHandleExternalError ()
specifier|private
name|boolean
name|shouldHandleExternalError
parameter_list|()
block|{
return|return
name|errorState
operator|.
name|hasExternalError
argument_list|()
operator|&&
name|blockStream
operator|!=
literal|null
return|;
block|}
comment|/**    * If this stream has encountered any errors, shutdown threads    * and mark the stream as closed.    *    * @return true if it should sleep for a while after returning.    */
DECL|method|processDatanodeOrExternalError ()
specifier|private
name|boolean
name|processDatanodeOrExternalError
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|errorState
operator|.
name|hasDatanodeError
argument_list|()
operator|&&
operator|!
name|shouldHandleExternalError
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"start process datanode/external error, {}"
argument_list|,
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|response
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Error Recovery for "
operator|+
name|block
operator|+
literal|" waiting for responder to exit. "
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|closeStream
argument_list|()
expr_stmt|;
comment|// move packets from ack queue to front of the data queue
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|dataQueue
operator|.
name|addAll
argument_list|(
literal|0
argument_list|,
name|ackQueue
argument_list|)
expr_stmt|;
name|ackQueue
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|// If we had to recover the pipeline five times in a row for the
comment|// same packet, this client likely has corrupt data or corrupting
comment|// during transmission.
if|if
condition|(
operator|!
name|errorState
operator|.
name|isRestartingNode
argument_list|()
operator|&&
operator|++
name|pipelineRecoveryCount
operator|>
literal|5
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error recovering pipeline for writing "
operator|+
name|block
operator|+
literal|". Already retried 5 times for the same packet."
argument_list|)
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Failing write. Tried pipeline "
operator|+
literal|"recovery 5 times without success."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|setupPipelineForAppendOrRecovery
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
condition|)
block|{
comment|// If we had an error while closing the pipeline, we go through a fast-path
comment|// where the BlockReceiver does not run. Instead, the DataNode just finalizes
comment|// the block immediately during the 'connect ack' process. So, we want to pull
comment|// the end-of-block packet from the dataQueue, since we don't actually have
comment|// a true pipeline to send it over.
comment|//
comment|// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that
comment|// a client waiting on close() will be aware that the flush finished.
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
name|DFSPacket
name|endOfBlockPacket
init|=
name|dataQueue
operator|.
name|remove
argument_list|()
decl_stmt|;
comment|// remove the end of block packet
comment|// Close any trace span associated with this Packet
name|TraceScope
name|scope
init|=
name|endOfBlockPacket
operator|.
name|getTraceScope
argument_list|()
decl_stmt|;
if|if
condition|(
name|scope
operator|!=
literal|null
condition|)
block|{
name|scope
operator|.
name|reattach
argument_list|()
expr_stmt|;
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
name|endOfBlockPacket
operator|.
name|setTraceScope
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
assert|assert
name|endOfBlockPacket
operator|.
name|isLastPacketInBlock
argument_list|()
assert|;
assert|assert
name|lastAckedSeqno
operator|==
name|endOfBlockPacket
operator|.
name|getSeqno
argument_list|()
operator|-
literal|1
assert|;
name|lastAckedSeqno
operator|=
name|endOfBlockPacket
operator|.
name|getSeqno
argument_list|()
expr_stmt|;
name|pipelineRecoveryCount
operator|=
literal|0
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
name|endBlock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|initDataStreaming
argument_list|()
expr_stmt|;
block|}
block|}
return|return
literal|false
return|;
block|}
DECL|method|setHflush ()
name|void
name|setHflush
parameter_list|()
block|{
name|isHflushed
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|findNewDatanode (final DatanodeInfo[] original )
specifier|private
name|int
name|findNewDatanode
parameter_list|(
specifier|final
name|DatanodeInfo
index|[]
name|original
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|!=
name|original
operator|.
name|length
operator|+
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to replace a bad datanode on the existing pipeline "
operator|+
literal|"due to no more good datanodes being available to try. "
operator|+
literal|"(Nodes: current="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
operator|+
literal|", original="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
operator|+
literal|"). "
operator|+
literal|"The current failed datanode replacement policy is "
operator|+
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|+
literal|", and a client may configure this via '"
operator|+
name|BlockWrite
operator|.
name|ReplaceDatanodeOnFailure
operator|.
name|POLICY_KEY
operator|+
literal|"' in its configuration."
argument_list|)
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|int
name|j
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
name|j
operator|<
name|original
operator|.
name|length
operator|&&
operator|!
name|nodes
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
name|original
index|[
name|j
index|]
argument_list|)
condition|;
name|j
operator|++
control|)
empty_stmt|;
if|if
condition|(
name|j
operator|==
name|original
operator|.
name|length
condition|)
block|{
return|return
name|i
return|;
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed: new datanode not found: nodes="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|nodes
argument_list|)
operator|+
literal|", original="
operator|+
name|Arrays
operator|.
name|asList
argument_list|(
name|original
argument_list|)
argument_list|)
throw|;
block|}
DECL|method|addDatanode2ExistingPipeline ()
specifier|private
name|void
name|addDatanode2ExistingPipeline
parameter_list|()
throws|throws
name|IOException
block|{
name|DataTransferProtocol
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"lastAckedSeqno = {}"
argument_list|,
name|lastAckedSeqno
argument_list|)
expr_stmt|;
comment|/*        * Is data transfer necessary?  We have the following cases.        *        * Case 1: Failure in Pipeline Setup        * - Append        *    + Transfer the stored replica, which may be a RBW or a finalized.        * - Create        *    + If no data, then no transfer is required.        *    + If there are data written, transfer RBW. This case may happens        *      when there are streaming failure earlier in this pipeline.        *        * Case 2: Failure in Streaming        * - Append/Create:        *    + transfer RBW        *        * Case 3: Failure in Close        * - Append/Create:        *    + no transfer, let NameNode replicates the block.        */
if|if
condition|(
operator|!
name|isAppend
operator|&&
name|lastAckedSeqno
operator|<
literal|0
operator|&&
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_SETUP_CREATE
condition|)
block|{
comment|//no data have been written
return|return;
block|}
elseif|else
if|if
condition|(
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE
operator|||
name|stage
operator|==
name|BlockConstructionStage
operator|.
name|PIPELINE_CLOSE_RECOVERY
condition|)
block|{
comment|//pipeline is closing
return|return;
block|}
name|int
name|tried
init|=
literal|0
decl_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|original
init|=
name|nodes
decl_stmt|;
specifier|final
name|StorageType
index|[]
name|originalTypes
init|=
name|storageTypes
decl_stmt|;
specifier|final
name|String
index|[]
name|originalIDs
init|=
name|storageIDs
decl_stmt|;
name|IOException
name|caughtException
init|=
literal|null
decl_stmt|;
name|ArrayList
argument_list|<
name|DatanodeInfo
argument_list|>
name|exclude
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|failed
argument_list|)
decl_stmt|;
while|while
condition|(
name|tried
operator|<
literal|3
condition|)
block|{
name|LocatedBlock
name|lb
decl_stmt|;
comment|//get a new datanode
name|lb
operator|=
name|dfsClient
operator|.
name|namenode
operator|.
name|getAdditionalDatanode
argument_list|(
name|src
argument_list|,
name|stat
operator|.
name|getFileId
argument_list|()
argument_list|,
name|block
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|,
name|exclude
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
name|exclude
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
literal|1
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
comment|// a new node was allocated by the namenode. Update nodes.
name|setPipeline
argument_list|(
name|lb
argument_list|)
expr_stmt|;
comment|//find the new datanode
specifier|final
name|int
name|d
init|=
name|findNewDatanode
argument_list|(
name|original
argument_list|)
decl_stmt|;
comment|//transfer replica. pick a source from the original nodes
specifier|final
name|DatanodeInfo
name|src
init|=
name|original
index|[
name|tried
operator|%
name|original
operator|.
name|length
index|]
decl_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|targets
init|=
block|{
name|nodes
index|[
name|d
index|]
block|}
decl_stmt|;
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
init|=
block|{
name|storageTypes
index|[
name|d
index|]
block|}
decl_stmt|;
try|try
block|{
name|transfer
argument_list|(
name|src
argument_list|,
name|targets
argument_list|,
name|targetStorageTypes
argument_list|,
name|lb
operator|.
name|getBlockToken
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error transferring data from "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|nodes
index|[
name|d
index|]
operator|+
literal|": "
operator|+
name|ioe
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|caughtException
operator|=
name|ioe
expr_stmt|;
comment|// add the allocated node to the exclude list.
name|exclude
operator|.
name|add
argument_list|(
name|nodes
index|[
name|d
index|]
argument_list|)
expr_stmt|;
name|setPipeline
argument_list|(
name|original
argument_list|,
name|originalTypes
argument_list|,
name|originalIDs
argument_list|)
expr_stmt|;
name|tried
operator|++
expr_stmt|;
continue|continue;
block|}
return|return;
comment|// finished successfully
block|}
comment|// All retries failed
throw|throw
operator|(
name|caughtException
operator|!=
literal|null
operator|)
condition|?
name|caughtException
else|:
operator|new
name|IOException
argument_list|(
literal|"Failed to add a node"
argument_list|)
throw|;
block|}
DECL|method|transfer (final DatanodeInfo src, final DatanodeInfo[] targets, final StorageType[] targetStorageTypes, final Token<BlockTokenIdentifier> blockToken)
specifier|private
name|void
name|transfer
parameter_list|(
specifier|final
name|DatanodeInfo
name|src
parameter_list|,
specifier|final
name|DatanodeInfo
index|[]
name|targets
parameter_list|,
specifier|final
name|StorageType
index|[]
name|targetStorageTypes
parameter_list|,
specifier|final
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|)
throws|throws
name|IOException
block|{
comment|//transfer replica to the new datanode
name|Socket
name|sock
init|=
literal|null
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
name|DataInputStream
name|in
init|=
literal|null
decl_stmt|;
try|try
block|{
name|sock
operator|=
name|createSocketForPipeline
argument_list|(
name|src
argument_list|,
literal|2
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
specifier|final
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
literal|2
argument_list|)
decl_stmt|;
comment|// transfer timeout multiplier based on the transfer size
comment|// One per 200 packets = 12.8MB. Minimum is 2.
name|int
name|multi
init|=
literal|2
operator|+
call|(
name|int
call|)
argument_list|(
name|bytesSent
operator|/
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|getWritePacketSize
argument_list|()
argument_list|)
operator|/
literal|200
decl_stmt|;
specifier|final
name|long
name|readTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeReadTimeout
argument_list|(
name|multi
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|sock
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|sock
argument_list|,
name|readTimeout
argument_list|)
decl_stmt|;
name|IOStreamPair
name|saslStreams
init|=
name|dfsClient
operator|.
name|saslClient
operator|.
name|socketSend
argument_list|(
name|sock
argument_list|,
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
argument_list|,
name|blockToken
argument_list|,
name|src
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|saslStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|saslStreams
operator|.
name|in
expr_stmt|;
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|DFSUtilClient
operator|.
name|getSmallBufferSize
argument_list|(
name|dfsClient
operator|.
name|getConfiguration
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//send the TRANSFER_BLOCK request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|transferBlock
argument_list|(
name|block
argument_list|,
name|blockToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|targets
argument_list|,
name|targetStorageTypes
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
comment|//ack
name|BlockOpResponseProto
name|response
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelperClient
operator|.
name|vintPrefixed
argument_list|(
name|in
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|SUCCESS
operator|!=
name|response
operator|.
name|getStatus
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to add a datanode"
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|sock
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Open a DataStreamer to a DataNode pipeline so that    * it can be written to.    * This happens when a file is appended or data streaming fails    * It keeps on trying until a pipeline is setup    */
DECL|method|setupPipelineForAppendOrRecovery ()
specifier|private
name|void
name|setupPipelineForAppendOrRecovery
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Check number of datanodes. Note that if there is no healthy datanode,
comment|// this must be internal error because we mark external error in striped
comment|// outputstream only when all the streamers are in the DATA_STREAMING stage
if|if
condition|(
name|nodes
operator|==
literal|null
operator|||
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|String
name|msg
init|=
literal|"Could not get block locations. "
operator|+
literal|"Source file \""
operator|+
name|src
operator|+
literal|"\" - Aborting..."
operator|+
name|this
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return;
block|}
name|setupPipelineInternal
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|)
expr_stmt|;
block|}
DECL|method|setupPipelineInternal (DatanodeInfo[] datanodes, StorageType[] nodeStorageTypes)
specifier|protected
name|void
name|setupPipelineInternal
parameter_list|(
name|DatanodeInfo
index|[]
name|datanodes
parameter_list|,
name|StorageType
index|[]
name|nodeStorageTypes
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|long
name|newGS
init|=
literal|0L
decl_stmt|;
while|while
condition|(
operator|!
name|success
operator|&&
operator|!
name|streamerClosed
operator|&&
name|dfsClient
operator|.
name|clientRunning
condition|)
block|{
if|if
condition|(
operator|!
name|handleRestartingDatanode
argument_list|()
condition|)
block|{
return|return;
block|}
specifier|final
name|boolean
name|isRecovery
init|=
name|errorState
operator|.
name|hasInternalError
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|handleBadDatanode
argument_list|()
condition|)
block|{
return|return;
block|}
name|handleDatanodeReplacement
argument_list|()
expr_stmt|;
comment|// get a new generation stamp and an access token
specifier|final
name|LocatedBlock
name|lb
init|=
name|updateBlockForPipeline
argument_list|()
decl_stmt|;
name|newGS
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
operator|.
name|getGenerationStamp
argument_list|()
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
comment|// set up the pipeline again with the remaining nodes
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|,
name|newGS
argument_list|,
name|isRecovery
argument_list|)
expr_stmt|;
name|failPacket4Testing
argument_list|()
expr_stmt|;
name|errorState
operator|.
name|checkRestartingNodeDeadline
argument_list|(
name|nodes
argument_list|)
expr_stmt|;
block|}
comment|// while
if|if
condition|(
name|success
condition|)
block|{
name|block
operator|=
name|updatePipeline
argument_list|(
name|newGS
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Sleep if a node is restarting.    * This process is repeated until the deadline or the node starts back up.    * @return true if it should continue.    */
DECL|method|handleRestartingDatanode ()
name|boolean
name|handleRestartingDatanode
parameter_list|()
block|{
if|if
condition|(
name|errorState
operator|.
name|isRestartingNode
argument_list|()
condition|)
block|{
comment|// 4 seconds or the configured deadline period, whichever is shorter.
comment|// This is the retry interval and recovery will be retried in this
comment|// interval until timeout or success.
specifier|final
name|long
name|delay
init|=
name|Math
operator|.
name|min
argument_list|(
name|errorState
operator|.
name|datanodeRestartTimeout
argument_list|,
literal|4000L
argument_list|)
decl_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|delay
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Interrupted while waiting for restarting "
operator|+
name|nodes
index|[
name|errorState
operator|.
name|getRestartingNodeIndex
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Remove bad node from list of nodes if badNodeIndex was set.    * @return true if it should continue.    */
DECL|method|handleBadDatanode ()
name|boolean
name|handleBadDatanode
parameter_list|()
block|{
specifier|final
name|int
name|badNodeIndex
init|=
name|errorState
operator|.
name|getBadNodeIndex
argument_list|()
decl_stmt|;
if|if
condition|(
name|badNodeIndex
operator|>=
literal|0
condition|)
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|<=
literal|1
condition|)
block|{
name|lastException
operator|.
name|set
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"All datanodes "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|nodes
argument_list|)
operator|+
literal|" are bad. Aborting..."
argument_list|)
argument_list|)
expr_stmt|;
name|streamerClosed
operator|=
literal|true
expr_stmt|;
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error Recovery for "
operator|+
name|block
operator|+
literal|" in pipeline "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|nodes
argument_list|)
operator|+
literal|": datanode "
operator|+
name|badNodeIndex
operator|+
literal|"("
operator|+
name|nodes
index|[
name|badNodeIndex
index|]
operator|+
literal|") is bad."
argument_list|)
expr_stmt|;
name|failed
operator|.
name|add
argument_list|(
name|nodes
index|[
name|badNodeIndex
index|]
argument_list|)
expr_stmt|;
name|DatanodeInfo
index|[]
name|newnodes
init|=
operator|new
name|DatanodeInfo
index|[
name|nodes
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|nodes
argument_list|,
name|newnodes
argument_list|,
name|badNodeIndex
argument_list|)
expr_stmt|;
specifier|final
name|StorageType
index|[]
name|newStorageTypes
init|=
operator|new
name|StorageType
index|[
name|newnodes
operator|.
name|length
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|storageTypes
argument_list|,
name|newStorageTypes
argument_list|,
name|badNodeIndex
argument_list|)
expr_stmt|;
specifier|final
name|String
index|[]
name|newStorageIDs
init|=
operator|new
name|String
index|[
name|newnodes
operator|.
name|length
index|]
decl_stmt|;
name|arraycopy
argument_list|(
name|storageIDs
argument_list|,
name|newStorageIDs
argument_list|,
name|badNodeIndex
argument_list|)
expr_stmt|;
name|setPipeline
argument_list|(
name|newnodes
argument_list|,
name|newStorageTypes
argument_list|,
name|newStorageIDs
argument_list|)
expr_stmt|;
name|errorState
operator|.
name|adjustState4RestartingNode
argument_list|()
expr_stmt|;
name|lastException
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/** Add a datanode if replace-datanode policy is satisfied. */
DECL|method|handleDatanodeReplacement ()
specifier|private
name|void
name|handleDatanodeReplacement
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|.
name|satisfy
argument_list|(
name|stat
operator|.
name|getReplication
argument_list|()
argument_list|,
name|nodes
argument_list|,
name|isAppend
argument_list|,
name|isHflushed
argument_list|)
condition|)
block|{
try|try
block|{
name|addDatanode2ExistingPipeline
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
operator|!
name|dfsClient
operator|.
name|dtpReplaceDatanodeOnFailure
operator|.
name|isBestEffort
argument_list|()
condition|)
block|{
throw|throw
name|ioe
throw|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to replace datanode."
operator|+
literal|" Continue with the remaining datanodes since "
operator|+
name|BlockWrite
operator|.
name|ReplaceDatanodeOnFailure
operator|.
name|BEST_EFFORT_KEY
operator|+
literal|" is set to true."
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|failPacket4Testing ()
name|void
name|failPacket4Testing
parameter_list|()
block|{
if|if
condition|(
name|failPacket
condition|)
block|{
comment|// for testing
name|failPacket
operator|=
literal|false
expr_stmt|;
try|try
block|{
comment|// Give DNs time to send in bad reports. In real situations,
comment|// good reports should follow bad ones, if client committed
comment|// with those nodes.
name|Thread
operator|.
name|sleep
argument_list|(
literal|2000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ignored
parameter_list|)
block|{       }
block|}
block|}
DECL|method|updateBlockForPipeline ()
specifier|private
name|LocatedBlock
name|updateBlockForPipeline
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|dfsClient
operator|.
name|namenode
operator|.
name|updateBlockForPipeline
argument_list|(
name|block
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
return|;
block|}
DECL|method|newBlock (ExtendedBlock b, final long newGS)
specifier|static
name|ExtendedBlock
name|newBlock
parameter_list|(
name|ExtendedBlock
name|b
parameter_list|,
specifier|final
name|long
name|newGS
parameter_list|)
block|{
return|return
operator|new
name|ExtendedBlock
argument_list|(
name|b
operator|.
name|getBlockPoolId
argument_list|()
argument_list|,
name|b
operator|.
name|getBlockId
argument_list|()
argument_list|,
name|b
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|newGS
argument_list|)
return|;
block|}
comment|/** update pipeline at the namenode */
DECL|method|updatePipeline (long newGS)
name|ExtendedBlock
name|updatePipeline
parameter_list|(
name|long
name|newGS
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ExtendedBlock
name|newBlock
init|=
name|newBlock
argument_list|(
name|block
argument_list|,
name|newGS
argument_list|)
decl_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|updatePipeline
argument_list|(
name|dfsClient
operator|.
name|clientName
argument_list|,
name|block
argument_list|,
name|newBlock
argument_list|,
name|nodes
argument_list|,
name|storageIDs
argument_list|)
expr_stmt|;
return|return
name|newBlock
return|;
block|}
DECL|method|getExcludedNodes ()
name|DatanodeInfo
index|[]
name|getExcludedNodes
parameter_list|()
block|{
return|return
name|excludedNodes
operator|.
name|getAllPresent
argument_list|(
name|excludedNodes
operator|.
name|asMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
operator|.
name|keySet
argument_list|()
operator|.
name|toArray
argument_list|(
operator|new
name|DatanodeInfo
index|[
literal|0
index|]
argument_list|)
return|;
block|}
comment|/**    * Open a DataStreamer to a DataNode so that it can be written to.    * This happens when a file is created and each time a new block is allocated.    * Must get block ID and the IDs of the destinations from the namenode.    * Returns the list of target datanodes.    */
DECL|method|nextBlockOutputStream ()
specifier|protected
name|LocatedBlock
name|nextBlockOutputStream
parameter_list|()
throws|throws
name|IOException
block|{
name|LocatedBlock
name|lb
decl_stmt|;
name|DatanodeInfo
index|[]
name|nodes
decl_stmt|;
name|StorageType
index|[]
name|storageTypes
decl_stmt|;
name|int
name|count
init|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|getNumBlockWriteRetry
argument_list|()
decl_stmt|;
name|boolean
name|success
decl_stmt|;
name|ExtendedBlock
name|oldBlock
init|=
name|block
decl_stmt|;
do|do
block|{
name|errorState
operator|.
name|resetInternalError
argument_list|()
expr_stmt|;
name|lastException
operator|.
name|clear
argument_list|()
expr_stmt|;
name|DatanodeInfo
index|[]
name|excluded
init|=
name|getExcludedNodes
argument_list|()
decl_stmt|;
name|block
operator|=
name|oldBlock
expr_stmt|;
name|lb
operator|=
name|locateFollowingBlock
argument_list|(
name|excluded
operator|.
name|length
operator|>
literal|0
condition|?
name|excluded
else|:
literal|null
argument_list|)
expr_stmt|;
name|block
operator|=
name|lb
operator|.
name|getBlock
argument_list|()
expr_stmt|;
name|block
operator|.
name|setNumBytes
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|bytesSent
operator|=
literal|0
expr_stmt|;
name|accessToken
operator|=
name|lb
operator|.
name|getBlockToken
argument_list|()
expr_stmt|;
name|nodes
operator|=
name|lb
operator|.
name|getLocations
argument_list|()
expr_stmt|;
name|storageTypes
operator|=
name|lb
operator|.
name|getStorageTypes
argument_list|()
expr_stmt|;
comment|//
comment|// Connect to first DataNode in the list.
comment|//
name|success
operator|=
name|createBlockOutputStream
argument_list|(
name|nodes
argument_list|,
name|storageTypes
argument_list|,
literal|0L
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Abandoning "
operator|+
name|block
argument_list|)
expr_stmt|;
name|dfsClient
operator|.
name|namenode
operator|.
name|abandonBlock
argument_list|(
name|block
argument_list|,
name|stat
operator|.
name|getFileId
argument_list|()
argument_list|,
name|src
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
name|block
operator|=
literal|null
expr_stmt|;
specifier|final
name|DatanodeInfo
name|badNode
init|=
name|nodes
index|[
name|errorState
operator|.
name|getBadNodeIndex
argument_list|()
index|]
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Excluding datanode "
operator|+
name|badNode
argument_list|)
expr_stmt|;
name|excludedNodes
operator|.
name|put
argument_list|(
name|badNode
argument_list|,
name|badNode
argument_list|)
expr_stmt|;
block|}
block|}
do|while
condition|(
operator|!
name|success
operator|&&
operator|--
name|count
operator|>=
literal|0
condition|)
do|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to create new block."
argument_list|)
throw|;
block|}
return|return
name|lb
return|;
block|}
comment|// connects to the first datanode in the pipeline
comment|// Returns true if success, otherwise return failure.
comment|//
DECL|method|createBlockOutputStream (DatanodeInfo[] nodes, StorageType[] nodeStorageTypes, long newGS, boolean recoveryFlag)
name|boolean
name|createBlockOutputStream
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|,
name|StorageType
index|[]
name|nodeStorageTypes
parameter_list|,
name|long
name|newGS
parameter_list|,
name|boolean
name|recoveryFlag
parameter_list|)
block|{
if|if
condition|(
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"nodes are empty for write pipeline of "
operator|+
name|block
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|String
name|firstBadLink
init|=
literal|""
decl_stmt|;
name|boolean
name|checkRestart
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"pipeline = "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|nodes
argument_list|)
operator|+
literal|", "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
comment|// persist blocks on namenode on next flush
name|persistBlocks
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|int
name|refetchEncryptionKey
init|=
literal|1
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|DataOutputStream
name|out
init|=
literal|null
decl_stmt|;
try|try
block|{
assert|assert
literal|null
operator|==
name|s
operator|:
literal|"Previous socket unclosed"
assert|;
assert|assert
literal|null
operator|==
name|blockReplyStream
operator|:
literal|"Previous blockReplyStream unclosed"
assert|;
name|s
operator|=
name|createSocketForPipeline
argument_list|(
name|nodes
index|[
literal|0
index|]
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|dfsClient
argument_list|)
expr_stmt|;
name|long
name|writeTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeWriteTimeout
argument_list|(
name|nodes
operator|.
name|length
argument_list|)
decl_stmt|;
name|long
name|readTimeout
init|=
name|dfsClient
operator|.
name|getDatanodeReadTimeout
argument_list|(
name|nodes
operator|.
name|length
argument_list|)
decl_stmt|;
name|OutputStream
name|unbufOut
init|=
name|NetUtils
operator|.
name|getOutputStream
argument_list|(
name|s
argument_list|,
name|writeTimeout
argument_list|)
decl_stmt|;
name|InputStream
name|unbufIn
init|=
name|NetUtils
operator|.
name|getInputStream
argument_list|(
name|s
argument_list|,
name|readTimeout
argument_list|)
decl_stmt|;
name|IOStreamPair
name|saslStreams
init|=
name|dfsClient
operator|.
name|saslClient
operator|.
name|socketSend
argument_list|(
name|s
argument_list|,
name|unbufOut
argument_list|,
name|unbufIn
argument_list|,
name|dfsClient
argument_list|,
name|accessToken
argument_list|,
name|nodes
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|unbufOut
operator|=
name|saslStreams
operator|.
name|out
expr_stmt|;
name|unbufIn
operator|=
name|saslStreams
operator|.
name|in
expr_stmt|;
name|out
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|BufferedOutputStream
argument_list|(
name|unbufOut
argument_list|,
name|DFSUtilClient
operator|.
name|getSmallBufferSize
argument_list|(
name|dfsClient
operator|.
name|getConfiguration
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
operator|new
name|DataInputStream
argument_list|(
name|unbufIn
argument_list|)
expr_stmt|;
comment|//
comment|// Xmit header info to datanode
comment|//
name|BlockConstructionStage
name|bcs
init|=
name|recoveryFlag
condition|?
name|stage
operator|.
name|getRecoveryStage
argument_list|()
else|:
name|stage
decl_stmt|;
comment|// We cannot change the block length in 'block' as it counts the number
comment|// of bytes ack'ed.
name|ExtendedBlock
name|blockCopy
init|=
operator|new
name|ExtendedBlock
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|blockCopy
operator|.
name|setNumBytes
argument_list|(
name|stat
operator|.
name|getBlockSize
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
index|[]
name|targetPinnings
init|=
name|getPinnings
argument_list|(
name|nodes
argument_list|)
decl_stmt|;
comment|// send the request
operator|new
name|Sender
argument_list|(
name|out
argument_list|)
operator|.
name|writeBlock
argument_list|(
name|blockCopy
argument_list|,
name|nodeStorageTypes
index|[
literal|0
index|]
argument_list|,
name|accessToken
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|,
name|nodes
argument_list|,
name|nodeStorageTypes
argument_list|,
literal|null
argument_list|,
name|bcs
argument_list|,
name|nodes
operator|.
name|length
argument_list|,
name|block
operator|.
name|getNumBytes
argument_list|()
argument_list|,
name|bytesSent
argument_list|,
name|newGS
argument_list|,
name|checksum4WriteBlock
argument_list|,
name|cachingStrategy
operator|.
name|get
argument_list|()
argument_list|,
name|isLazyPersistFile
argument_list|,
operator|(
name|targetPinnings
operator|!=
literal|null
operator|&&
name|targetPinnings
index|[
literal|0
index|]
operator|)
argument_list|,
name|targetPinnings
argument_list|)
expr_stmt|;
comment|// receive ack for connect
name|BlockOpResponseProto
name|resp
init|=
name|BlockOpResponseProto
operator|.
name|parseFrom
argument_list|(
name|PBHelperClient
operator|.
name|vintPrefixed
argument_list|(
name|blockReplyStream
argument_list|)
argument_list|)
decl_stmt|;
name|Status
name|pipelineStatus
init|=
name|resp
operator|.
name|getStatus
argument_list|()
decl_stmt|;
name|firstBadLink
operator|=
name|resp
operator|.
name|getFirstBadLink
argument_list|()
expr_stmt|;
comment|// Got an restart OOB ack.
comment|// If a node is already restarting, this status is not likely from
comment|// the same node. If it is from a different node, it is not
comment|// from the local datanode. Thus it is safe to treat this as a
comment|// regular node error.
if|if
condition|(
name|PipelineAck
operator|.
name|isRestartOOBStatus
argument_list|(
name|pipelineStatus
argument_list|)
operator|&&
operator|!
name|errorState
operator|.
name|isRestartingNode
argument_list|()
condition|)
block|{
name|checkRestart
operator|=
literal|true
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"A datanode is restarting."
argument_list|)
throw|;
block|}
name|String
name|logInfo
init|=
literal|"ack with firstBadLink as "
operator|+
name|firstBadLink
decl_stmt|;
name|DataTransferProtoUtil
operator|.
name|checkBlockOpStatus
argument_list|(
name|resp
argument_list|,
name|logInfo
argument_list|)
expr_stmt|;
assert|assert
literal|null
operator|==
name|blockStream
operator|:
literal|"Previous blockStream unclosed"
assert|;
name|blockStream
operator|=
name|out
expr_stmt|;
name|result
operator|=
literal|true
expr_stmt|;
comment|// success
name|errorState
operator|.
name|resetInternalError
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
if|if
condition|(
operator|!
name|errorState
operator|.
name|isRestartingNode
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception in createBlockOutputStream "
operator|+
name|this
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|ie
operator|instanceof
name|InvalidEncryptionKeyException
operator|&&
name|refetchEncryptionKey
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Will fetch a new encryption key and retry, "
operator|+
literal|"encryption key was invalid when connecting to "
operator|+
name|nodes
index|[
literal|0
index|]
operator|+
literal|" : "
operator|+
name|ie
argument_list|)
expr_stmt|;
comment|// The encryption key used is invalid.
name|refetchEncryptionKey
operator|--
expr_stmt|;
name|dfsClient
operator|.
name|clearDataEncryptionKey
argument_list|()
expr_stmt|;
comment|// Don't close the socket/exclude this node just yet. Try again with
comment|// a new encryption key.
continue|continue;
block|}
comment|// find the datanode that matches
if|if
condition|(
name|firstBadLink
operator|.
name|length
argument_list|()
operator|!=
literal|0
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// NB: Unconditionally using the xfer addr w/o hostname
if|if
condition|(
name|firstBadLink
operator|.
name|equals
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddr
argument_list|()
argument_list|)
condition|)
block|{
name|errorState
operator|.
name|setBadNodeIndex
argument_list|(
name|i
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
else|else
block|{
assert|assert
operator|!
name|checkRestart
assert|;
name|errorState
operator|.
name|setBadNodeIndex
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|i
init|=
name|errorState
operator|.
name|getBadNodeIndex
argument_list|()
decl_stmt|;
comment|// Check whether there is a restart worth waiting for.
if|if
condition|(
name|checkRestart
operator|&&
name|shouldWaitForRestart
argument_list|(
name|i
argument_list|)
condition|)
block|{
name|errorState
operator|.
name|initRestartingNode
argument_list|(
name|i
argument_list|,
literal|"Datanode "
operator|+
name|i
operator|+
literal|" is restarting: "
operator|+
name|nodes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|errorState
operator|.
name|setInternalError
argument_list|()
expr_stmt|;
name|lastException
operator|.
name|set
argument_list|(
name|ie
argument_list|)
expr_stmt|;
name|result
operator|=
literal|false
expr_stmt|;
comment|// error
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|result
condition|)
block|{
name|IOUtils
operator|.
name|closeSocket
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|blockReplyStream
argument_list|)
expr_stmt|;
name|blockReplyStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
block|}
DECL|method|getPinnings (DatanodeInfo[] nodes)
specifier|private
name|boolean
index|[]
name|getPinnings
parameter_list|(
name|DatanodeInfo
index|[]
name|nodes
parameter_list|)
block|{
if|if
condition|(
name|favoredNodes
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
name|boolean
index|[]
name|pinnings
init|=
operator|new
name|boolean
index|[
name|nodes
operator|.
name|length
index|]
decl_stmt|;
name|HashSet
argument_list|<
name|String
argument_list|>
name|favoredSet
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|favoredNodes
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|pinnings
index|[
name|i
index|]
operator|=
name|favoredSet
operator|.
name|remove
argument_list|(
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddrWithHostname
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} was chosen by name node (favored={})."
argument_list|,
name|nodes
index|[
name|i
index|]
operator|.
name|getXferAddrWithHostname
argument_list|()
argument_list|,
name|pinnings
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|favoredSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// There is one or more favored nodes that were not allocated.
name|LOG
operator|.
name|warn
argument_list|(
literal|"These favored nodes were specified but not chosen: "
operator|+
name|favoredSet
operator|+
literal|" Specified favored nodes: "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|favoredNodes
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|pinnings
return|;
block|}
block|}
DECL|method|locateFollowingBlock (DatanodeInfo[] excludedNodes)
specifier|private
name|LocatedBlock
name|locateFollowingBlock
parameter_list|(
name|DatanodeInfo
index|[]
name|excludedNodes
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|DFSOutputStream
operator|.
name|addBlock
argument_list|(
name|excludedNodes
argument_list|,
name|dfsClient
argument_list|,
name|src
argument_list|,
name|block
argument_list|,
name|stat
operator|.
name|getFileId
argument_list|()
argument_list|,
name|favoredNodes
argument_list|)
return|;
block|}
comment|/**    * This function sleeps for a certain amount of time when the writing    * pipeline is congested. The function calculates the time based on a    * decorrelated filter.    *    * @see    *<a href="http://www.awsarchitectureblog.com/2015/03/backoff.html">    *   http://www.awsarchitectureblog.com/2015/03/backoff.html</a>    */
DECL|method|backOffIfNecessary ()
specifier|private
name|void
name|backOffIfNecessary
parameter_list|()
throws|throws
name|InterruptedException
block|{
name|int
name|t
init|=
literal|0
decl_stmt|;
synchronized|synchronized
init|(
name|congestedNodes
init|)
block|{
if|if
condition|(
operator|!
name|congestedNodes
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"DataNode"
argument_list|)
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|i
range|:
name|congestedNodes
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|' '
argument_list|)
operator|.
name|append
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
name|int
name|range
init|=
name|Math
operator|.
name|abs
argument_list|(
name|lastCongestionBackoffTime
operator|*
literal|3
operator|-
name|CONGESTION_BACKOFF_MEAN_TIME_IN_MS
argument_list|)
decl_stmt|;
name|int
name|base
init|=
name|Math
operator|.
name|min
argument_list|(
name|lastCongestionBackoffTime
operator|*
literal|3
argument_list|,
name|CONGESTION_BACKOFF_MEAN_TIME_IN_MS
argument_list|)
decl_stmt|;
name|t
operator|=
name|Math
operator|.
name|min
argument_list|(
name|CONGESTION_BACK_OFF_MAX_TIME_IN_MS
argument_list|,
call|(
name|int
call|)
argument_list|(
name|base
operator|+
name|Math
operator|.
name|random
argument_list|()
operator|*
name|range
argument_list|)
argument_list|)
expr_stmt|;
name|lastCongestionBackoffTime
operator|=
name|t
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" are congested. Backing off for "
argument_list|)
operator|.
name|append
argument_list|(
name|t
argument_list|)
operator|.
name|append
argument_list|(
literal|" ms"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|congestedNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|t
operator|!=
literal|0
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * get the block this streamer is writing to    *    * @return the block this streamer is writing to    */
DECL|method|getBlock ()
name|ExtendedBlock
name|getBlock
parameter_list|()
block|{
return|return
name|block
return|;
block|}
comment|/**    * return the target datanodes in the pipeline    *    * @return the target datanodes in the pipeline    */
DECL|method|getNodes ()
name|DatanodeInfo
index|[]
name|getNodes
parameter_list|()
block|{
return|return
name|nodes
return|;
block|}
DECL|method|getStorageIDs ()
name|String
index|[]
name|getStorageIDs
parameter_list|()
block|{
return|return
name|storageIDs
return|;
block|}
DECL|method|getStage ()
name|BlockConstructionStage
name|getStage
parameter_list|()
block|{
return|return
name|stage
return|;
block|}
comment|/**    * return the token of the block    *    * @return the token of the block    */
DECL|method|getBlockToken ()
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|getBlockToken
parameter_list|()
block|{
return|return
name|accessToken
return|;
block|}
DECL|method|getErrorState ()
name|ErrorState
name|getErrorState
parameter_list|()
block|{
return|return
name|errorState
return|;
block|}
comment|/**    * Put a packet to the data queue    *    * @param packet the packet to be put into the data queued    */
DECL|method|queuePacket (DFSPacket packet)
name|void
name|queuePacket
parameter_list|(
name|DFSPacket
name|packet
parameter_list|)
block|{
synchronized|synchronized
init|(
name|dataQueue
init|)
block|{
if|if
condition|(
name|packet
operator|==
literal|null
condition|)
return|return;
name|packet
operator|.
name|addTraceParent
argument_list|(
name|Tracer
operator|.
name|getCurrentSpanId
argument_list|()
argument_list|)
expr_stmt|;
name|dataQueue
operator|.
name|addLast
argument_list|(
name|packet
argument_list|)
expr_stmt|;
name|lastQueuedSeqno
operator|=
name|packet
operator|.
name|getSeqno
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Queued "
operator|+
name|packet
operator|+
literal|", "
operator|+
name|this
argument_list|)
expr_stmt|;
name|dataQueue
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * For heartbeat packets, create buffer directly by new byte[]    * since heartbeats should not be blocked.    */
DECL|method|createHeartbeatPacket ()
specifier|private
name|DFSPacket
name|createHeartbeatPacket
parameter_list|()
block|{
specifier|final
name|byte
index|[]
name|buf
init|=
operator|new
name|byte
index|[
name|PacketHeader
operator|.
name|PKT_MAX_HEADER_LEN
index|]
decl_stmt|;
return|return
operator|new
name|DFSPacket
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|DFSPacket
operator|.
name|HEART_BEAT_SEQNO
argument_list|,
literal|0
argument_list|,
literal|false
argument_list|)
return|;
block|}
DECL|method|initExcludedNodes ( long excludedNodesCacheExpiry)
specifier|private
specifier|static
name|LoadingCache
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|initExcludedNodes
parameter_list|(
name|long
name|excludedNodesCacheExpiry
parameter_list|)
block|{
return|return
name|CacheBuilder
operator|.
name|newBuilder
argument_list|()
operator|.
name|expireAfterWrite
argument_list|(
name|excludedNodesCacheExpiry
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
operator|.
name|removalListener
argument_list|(
operator|new
name|RemovalListener
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|onRemoval
parameter_list|(
annotation|@
name|Nonnull
name|RemovalNotification
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|notification
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Removing node "
operator|+
name|notification
operator|.
name|getKey
argument_list|()
operator|+
literal|" from the excluded nodes list"
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
operator|.
name|build
argument_list|(
operator|new
name|CacheLoader
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|DatanodeInfo
name|load
parameter_list|(
name|DatanodeInfo
name|key
parameter_list|)
throws|throws
name|Exception
block|{
return|return
name|key
return|;
block|}
block|}
argument_list|)
return|;
block|}
DECL|method|arraycopy (T[] srcs, T[] dsts, int skipIndex)
specifier|private
specifier|static
parameter_list|<
name|T
parameter_list|>
name|void
name|arraycopy
parameter_list|(
name|T
index|[]
name|srcs
parameter_list|,
name|T
index|[]
name|dsts
parameter_list|,
name|int
name|skipIndex
parameter_list|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|srcs
argument_list|,
literal|0
argument_list|,
name|dsts
argument_list|,
literal|0
argument_list|,
name|skipIndex
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|srcs
argument_list|,
name|skipIndex
operator|+
literal|1
argument_list|,
name|dsts
argument_list|,
name|skipIndex
argument_list|,
name|dsts
operator|.
name|length
operator|-
name|skipIndex
argument_list|)
expr_stmt|;
block|}
comment|/**    * check if to persist blocks on namenode    *    * @return if to persist blocks on namenode    */
DECL|method|getPersistBlocks ()
name|AtomicBoolean
name|getPersistBlocks
parameter_list|()
block|{
return|return
name|persistBlocks
return|;
block|}
comment|/**    * check if to append a chunk    *    * @param appendChunk if to append a chunk    */
DECL|method|setAppendChunk (boolean appendChunk)
name|void
name|setAppendChunk
parameter_list|(
name|boolean
name|appendChunk
parameter_list|)
block|{
name|this
operator|.
name|appendChunk
operator|=
name|appendChunk
expr_stmt|;
block|}
comment|/**    * get if to append a chunk    *    * @return if to append a chunk    */
DECL|method|getAppendChunk ()
name|boolean
name|getAppendChunk
parameter_list|()
block|{
return|return
name|appendChunk
return|;
block|}
comment|/**    * @return the last exception    */
DECL|method|getLastException ()
name|LastExceptionInStreamer
name|getLastException
parameter_list|()
block|{
return|return
name|lastException
return|;
block|}
comment|/**    * set socket to null    */
DECL|method|setSocketToNull ()
name|void
name|setSocketToNull
parameter_list|()
block|{
name|this
operator|.
name|s
operator|=
literal|null
expr_stmt|;
block|}
comment|/**    * return current sequence number and then increase it by 1    *    * @return current sequence number before increasing    */
DECL|method|getAndIncCurrentSeqno ()
name|long
name|getAndIncCurrentSeqno
parameter_list|()
block|{
name|long
name|old
init|=
name|this
operator|.
name|currentSeqno
decl_stmt|;
name|this
operator|.
name|currentSeqno
operator|++
expr_stmt|;
return|return
name|old
return|;
block|}
comment|/**    * get last queued sequence number    *    * @return last queued sequence number    */
DECL|method|getLastQueuedSeqno ()
name|long
name|getLastQueuedSeqno
parameter_list|()
block|{
return|return
name|lastQueuedSeqno
return|;
block|}
comment|/**    * get the number of bytes of current block    *    * @return the number of bytes of current block    */
DECL|method|getBytesCurBlock ()
name|long
name|getBytesCurBlock
parameter_list|()
block|{
return|return
name|bytesCurBlock
return|;
block|}
comment|/**    * set the bytes of current block that have been written    *    * @param bytesCurBlock bytes of current block that have been written    */
DECL|method|setBytesCurBlock (long bytesCurBlock)
name|void
name|setBytesCurBlock
parameter_list|(
name|long
name|bytesCurBlock
parameter_list|)
block|{
name|this
operator|.
name|bytesCurBlock
operator|=
name|bytesCurBlock
expr_stmt|;
block|}
comment|/**    * increase bytes of current block by len.    *    * @param len how many bytes to increase to current block    */
DECL|method|incBytesCurBlock (long len)
name|void
name|incBytesCurBlock
parameter_list|(
name|long
name|len
parameter_list|)
block|{
name|this
operator|.
name|bytesCurBlock
operator|+=
name|len
expr_stmt|;
block|}
comment|/**    * set artificial slow down for unit test    *    * @param period artificial slow down    */
DECL|method|setArtificialSlowdown (long period)
name|void
name|setArtificialSlowdown
parameter_list|(
name|long
name|period
parameter_list|)
block|{
name|this
operator|.
name|artificialSlowdown
operator|=
name|period
expr_stmt|;
block|}
comment|/**    * if this streamer is to terminate    *    * @return if this streamer is to terminate    */
DECL|method|streamerClosed ()
name|boolean
name|streamerClosed
parameter_list|()
block|{
return|return
name|streamerClosed
return|;
block|}
comment|/**    * @return The times have retried to recover pipeline, for the same packet.    */
annotation|@
name|VisibleForTesting
DECL|method|getPipelineRecoveryCount ()
name|int
name|getPipelineRecoveryCount
parameter_list|()
block|{
return|return
name|pipelineRecoveryCount
return|;
block|}
DECL|method|closeSocket ()
name|void
name|closeSocket
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|block
operator|==
literal|null
condition|?
literal|"block==null"
else|:
literal|""
operator|+
name|block
operator|.
name|getLocalBlock
argument_list|()
return|;
block|}
block|}
end_class

end_unit

