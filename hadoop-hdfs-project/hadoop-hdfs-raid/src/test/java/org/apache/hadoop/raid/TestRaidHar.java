begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.raid
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|raid
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|impl
operator|.
name|Log4JLogger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|MiniMRCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|log4j
operator|.
name|Level
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_comment
comment|/**  * If a file gets deleted, then verify that the parity file gets deleted too.  */
end_comment

begin_class
DECL|class|TestRaidHar
specifier|public
class|class
name|TestRaidHar
block|{
DECL|field|TEST_DIR
specifier|final
specifier|static
name|String
name|TEST_DIR
init|=
operator|new
name|File
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
literal|"target/test-data"
argument_list|)
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
decl_stmt|;
DECL|field|CONFIG_FILE
specifier|final
specifier|static
name|String
name|CONFIG_FILE
init|=
operator|new
name|File
argument_list|(
name|TEST_DIR
argument_list|,
literal|"test-raid.xml"
argument_list|)
operator|.
name|getAbsolutePath
argument_list|()
decl_stmt|;
DECL|field|RELOAD_INTERVAL
specifier|final
specifier|static
name|long
name|RELOAD_INTERVAL
init|=
literal|1000
decl_stmt|;
DECL|field|LOG
specifier|final
specifier|static
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
literal|"org.apache.hadoop.raid.TestRaidNode"
argument_list|)
decl_stmt|;
DECL|field|rand
specifier|final
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
block|{
operator|(
operator|(
name|Log4JLogger
operator|)
name|RaidNode
operator|.
name|LOG
operator|)
operator|.
name|getLogger
argument_list|()
operator|.
name|setLevel
argument_list|(
name|Level
operator|.
name|ALL
argument_list|)
expr_stmt|;
block|}
DECL|field|conf
name|Configuration
name|conf
decl_stmt|;
DECL|field|namenode
name|String
name|namenode
init|=
literal|null
decl_stmt|;
DECL|field|hftp
name|String
name|hftp
init|=
literal|null
decl_stmt|;
DECL|field|dfs
name|MiniDFSCluster
name|dfs
init|=
literal|null
decl_stmt|;
DECL|field|mr
name|MiniMRCluster
name|mr
init|=
literal|null
decl_stmt|;
DECL|field|fileSys
name|FileSystem
name|fileSys
init|=
literal|null
decl_stmt|;
DECL|field|jobTrackerName
name|String
name|jobTrackerName
init|=
literal|null
decl_stmt|;
comment|/**    * create mapreduce and dfs clusters    */
DECL|method|createClusters (boolean local)
specifier|private
name|void
name|createClusters
parameter_list|(
name|boolean
name|local
parameter_list|)
throws|throws
name|Exception
block|{
operator|new
name|File
argument_list|(
name|TEST_DIR
argument_list|)
operator|.
name|mkdirs
argument_list|()
expr_stmt|;
comment|// Make sure data directory exists
name|conf
operator|=
operator|new
name|Configuration
argument_list|()
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"raid.config.file"
argument_list|,
name|CONFIG_FILE
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"raid.config.reload"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setLong
argument_list|(
literal|"raid.config.reload.interval"
argument_list|,
name|RELOAD_INTERVAL
argument_list|)
expr_stmt|;
comment|// scan all policies once every 5 second
name|conf
operator|.
name|setLong
argument_list|(
literal|"raid.policy.rescan.interval"
argument_list|,
literal|5000
argument_list|)
expr_stmt|;
comment|// make all deletions not go through Trash
name|conf
operator|.
name|set
argument_list|(
literal|"fs.shell.delete.classname"
argument_list|,
literal|"org.apache.hadoop.hdfs.DFSClient"
argument_list|)
expr_stmt|;
comment|// the RaidNode does the raiding inline (instead of submitting to map/reduce)
if|if
condition|(
name|local
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"raid.classname"
argument_list|,
literal|"org.apache.hadoop.raid.LocalRaidNode"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"raid.classname"
argument_list|,
literal|"org.apache.hadoop.raid.DistRaidNode"
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
literal|"raid.server.address"
argument_list|,
literal|"localhost:0"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|RaidNode
operator|.
name|RAID_LOCATION_KEY
argument_list|,
literal|"/destraid"
argument_list|)
expr_stmt|;
comment|// create a dfs and map-reduce cluster
specifier|final
name|int
name|taskTrackers
init|=
literal|4
decl_stmt|;
name|dfs
operator|=
operator|new
name|MiniDFSCluster
argument_list|(
name|conf
argument_list|,
literal|3
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|dfs
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|fileSys
operator|=
name|dfs
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
name|namenode
operator|=
name|fileSys
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
expr_stmt|;
name|mr
operator|=
operator|new
name|MiniMRCluster
argument_list|(
name|taskTrackers
argument_list|,
name|namenode
argument_list|,
literal|3
argument_list|)
expr_stmt|;
name|JobConf
name|jobConf
init|=
name|mr
operator|.
name|createJobConf
argument_list|()
decl_stmt|;
name|jobTrackerName
operator|=
literal|"localhost:"
operator|+
name|jobConf
operator|.
name|get
argument_list|(
name|JTConfig
operator|.
name|JT_IPC_ADDRESS
argument_list|)
expr_stmt|;
name|hftp
operator|=
literal|"hftp://localhost.localdomain:"
operator|+
name|dfs
operator|.
name|getNameNodePort
argument_list|()
expr_stmt|;
name|FileSystem
operator|.
name|setDefaultUri
argument_list|(
name|conf
argument_list|,
name|namenode
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.job.tracker"
argument_list|,
name|jobTrackerName
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"mapreduce.framework.name"
argument_list|,
literal|"yarn"
argument_list|)
expr_stmt|;
name|String
name|rmAdress
init|=
name|jobConf
operator|.
name|get
argument_list|(
literal|"yarn.resourcemanager.address"
argument_list|)
decl_stmt|;
if|if
condition|(
name|rmAdress
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"yarn.resourcemanager.address"
argument_list|,
name|rmAdress
argument_list|)
expr_stmt|;
block|}
name|String
name|schedulerAdress
init|=
name|jobConf
operator|.
name|get
argument_list|(
literal|"yarn.resourcemanager.scheduler.address"
argument_list|)
decl_stmt|;
if|if
condition|(
name|schedulerAdress
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"yarn.resourcemanager.scheduler.address"
argument_list|,
name|schedulerAdress
argument_list|)
expr_stmt|;
block|}
name|String
name|jobHistoryAddress
init|=
name|jobConf
operator|.
name|get
argument_list|(
literal|"mapreduce.jobhistory.address"
argument_list|)
decl_stmt|;
if|if
condition|(
name|jobHistoryAddress
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"mapreduce.jobhistory.address"
argument_list|,
name|jobHistoryAddress
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * create raid.xml file for RaidNode    */
DECL|method|mySetup (long targetReplication, long metaReplication, long stripeLength)
specifier|private
name|void
name|mySetup
parameter_list|(
name|long
name|targetReplication
parameter_list|,
name|long
name|metaReplication
parameter_list|,
name|long
name|stripeLength
parameter_list|)
throws|throws
name|Exception
block|{
name|FileWriter
name|fileWriter
init|=
operator|new
name|FileWriter
argument_list|(
name|CONFIG_FILE
argument_list|)
decl_stmt|;
name|fileWriter
operator|.
name|write
argument_list|(
literal|"<?xml version=\"1.0\"?>\n"
argument_list|)
expr_stmt|;
name|String
name|str
init|=
literal|"<configuration> "
operator|+
literal|"<srcPath prefix=\"/user/test/raidtest\"> "
operator|+
literal|"<policy name = \"RaidTest1\"> "
operator|+
literal|"<erasureCode>xor</erasureCode> "
operator|+
literal|"<property> "
operator|+
literal|"<name>targetReplication</name> "
operator|+
literal|"<value>"
operator|+
name|targetReplication
operator|+
literal|"</value> "
operator|+
literal|"<description>after RAIDing, decrease the replication factor of a file to this value."
operator|+
literal|"</description> "
operator|+
literal|"</property> "
operator|+
literal|"<property> "
operator|+
literal|"<name>metaReplication</name> "
operator|+
literal|"<value>"
operator|+
name|metaReplication
operator|+
literal|"</value> "
operator|+
literal|"<description> replication factor of parity file"
operator|+
literal|"</description> "
operator|+
literal|"</property> "
operator|+
literal|"<property> "
operator|+
literal|"<name>stripeLength</name> "
operator|+
literal|"<value>"
operator|+
name|stripeLength
operator|+
literal|"</value> "
operator|+
literal|"<description> the max number of blocks in a file to RAID together "
operator|+
literal|"</description> "
operator|+
literal|"</property> "
operator|+
literal|"<property> "
operator|+
literal|"<name>time_before_har</name> "
operator|+
literal|"<value>0</value> "
operator|+
literal|"<description> amount of time waited before har'ing parity files"
operator|+
literal|"</description> "
operator|+
literal|"</property> "
operator|+
literal|"<property> "
operator|+
literal|"<name>modTimePeriod</name> "
operator|+
literal|"<value>2000</value> "
operator|+
literal|"<description> time (milliseconds) after a file is modified to make it "
operator|+
literal|"a candidate for RAIDing "
operator|+
literal|"</description> "
operator|+
literal|"</property> "
operator|+
literal|"</policy>"
operator|+
literal|"</srcPath>"
operator|+
literal|"</configuration>"
decl_stmt|;
name|fileWriter
operator|.
name|write
argument_list|(
name|str
argument_list|)
expr_stmt|;
name|fileWriter
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * stop clusters created earlier    */
DECL|method|stopClusters ()
specifier|private
name|void
name|stopClusters
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|mr
operator|!=
literal|null
condition|)
block|{
name|mr
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|dfs
operator|!=
literal|null
condition|)
block|{
name|dfs
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Test that parity files that do not have an associated master file    * get deleted.    */
annotation|@
name|Test
DECL|method|testRaidHar ()
specifier|public
name|void
name|testRaidHar
parameter_list|()
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Test testRaidHar  started."
argument_list|)
expr_stmt|;
name|long
name|blockSizes
index|[]
init|=
block|{
literal|1024L
block|}
decl_stmt|;
name|long
name|stripeLengths
index|[]
init|=
block|{
literal|5
block|}
decl_stmt|;
name|long
name|targetReplication
init|=
literal|1
decl_stmt|;
name|long
name|metaReplication
init|=
literal|1
decl_stmt|;
name|int
name|numBlock
init|=
literal|9
decl_stmt|;
name|int
name|iter
init|=
literal|0
decl_stmt|;
name|createClusters
argument_list|(
literal|true
argument_list|)
expr_stmt|;
try|try
block|{
for|for
control|(
name|long
name|blockSize
range|:
name|blockSizes
control|)
block|{
for|for
control|(
name|long
name|stripeLength
range|:
name|stripeLengths
control|)
block|{
name|doTestHar
argument_list|(
name|iter
argument_list|,
name|targetReplication
argument_list|,
name|metaReplication
argument_list|,
name|stripeLength
argument_list|,
name|blockSize
argument_list|,
name|numBlock
argument_list|)
expr_stmt|;
name|iter
operator|++
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|stopClusters
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Test testRaidHar completed."
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create parity file, delete original file and then validate that    * parity file is automatically deleted.    */
DECL|method|doTestHar (int iter, long targetReplication, long metaReplication, long stripeLength, long blockSize, int numBlock)
specifier|private
name|void
name|doTestHar
parameter_list|(
name|int
name|iter
parameter_list|,
name|long
name|targetReplication
parameter_list|,
name|long
name|metaReplication
parameter_list|,
name|long
name|stripeLength
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|int
name|numBlock
parameter_list|)
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar started---------------------------:"
operator|+
literal|" iter "
operator|+
name|iter
operator|+
literal|" blockSize="
operator|+
name|blockSize
operator|+
literal|" stripeLength="
operator|+
name|stripeLength
argument_list|)
expr_stmt|;
name|mySetup
argument_list|(
name|targetReplication
argument_list|,
name|metaReplication
argument_list|,
name|stripeLength
argument_list|)
expr_stmt|;
name|Path
name|dir
init|=
operator|new
name|Path
argument_list|(
literal|"/user/test/raidtest/subdir/"
argument_list|)
decl_stmt|;
name|Path
name|file1
init|=
operator|new
name|Path
argument_list|(
name|dir
operator|+
literal|"/file"
operator|+
name|iter
argument_list|)
decl_stmt|;
name|RaidNode
name|cnode
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Path
name|destPath
init|=
operator|new
name|Path
argument_list|(
literal|"/destraid/user/test/raidtest/subdir"
argument_list|)
decl_stmt|;
name|fileSys
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|fileSys
operator|.
name|delete
argument_list|(
name|destPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
literal|10
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|file
init|=
operator|new
name|Path
argument_list|(
name|dir
operator|+
literal|"/file"
operator|+
name|i
argument_list|)
decl_stmt|;
name|TestRaidNode
operator|.
name|createOldFile
argument_list|(
name|fileSys
argument_list|,
name|file
argument_list|,
literal|1
argument_list|,
name|numBlock
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar created test files for iteration "
operator|+
name|iter
argument_list|)
expr_stmt|;
comment|// create an instance of the RaidNode
name|Configuration
name|localConf
init|=
operator|new
name|Configuration
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|localConf
operator|.
name|set
argument_list|(
name|RaidNode
operator|.
name|RAID_LOCATION_KEY
argument_list|,
literal|"/destraid"
argument_list|)
expr_stmt|;
name|cnode
operator|=
name|RaidNode
operator|.
name|createRaidNode
argument_list|(
literal|null
argument_list|,
name|localConf
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|listPaths
init|=
literal|null
decl_stmt|;
name|int
name|maxFilesFound
init|=
literal|0
decl_stmt|;
comment|// wait till file is raided
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
name|listPaths
operator|=
name|fileSys
operator|.
name|listStatus
argument_list|(
name|destPath
argument_list|)
expr_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
name|Path
name|harPath
init|=
literal|null
decl_stmt|;
name|int
name|filesFound
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|listPaths
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|s
range|:
name|listPaths
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar found path "
operator|+
name|s
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|s
operator|.
name|isDir
argument_list|()
condition|)
name|filesFound
operator|++
expr_stmt|;
if|if
condition|(
name|filesFound
operator|>
name|maxFilesFound
condition|)
name|maxFilesFound
operator|=
name|filesFound
expr_stmt|;
if|if
condition|(
name|s
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
literal|".har"
argument_list|)
condition|)
block|{
comment|// If a HAR directory is found, ensure that we have seen
comment|// 10 parity files. We have to keep track of the max # of
comment|// files since some parity files might get deleted by the
comment|// purge thread.
name|assertEquals
argument_list|(
literal|10
argument_list|,
name|maxFilesFound
argument_list|)
expr_stmt|;
name|harPath
operator|=
name|s
operator|.
name|getPath
argument_list|()
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|count
operator|==
literal|1
operator|&&
name|listPaths
operator|.
name|length
operator|==
literal|1
condition|)
block|{
name|Path
name|partfile
init|=
operator|new
name|Path
argument_list|(
name|harPath
argument_list|,
literal|"part-0"
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|fileSys
operator|.
name|getFileStatus
argument_list|(
name|partfile
argument_list|)
operator|.
name|getReplication
argument_list|()
argument_list|,
name|targetReplication
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|//ignore
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar waiting for files to be raided and parity files to be har'ed and deleted. Found "
operator|+
operator|(
name|listPaths
operator|==
literal|null
condition|?
literal|"none"
else|:
name|listPaths
operator|.
name|length
operator|)
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
comment|// keep waiting
block|}
name|fileSys
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// wait till raid file is deleted
name|int
name|count
init|=
literal|1
decl_stmt|;
while|while
condition|(
name|count
operator|>
literal|0
condition|)
block|{
name|count
operator|=
literal|0
expr_stmt|;
try|try
block|{
name|listPaths
operator|=
name|fileSys
operator|.
name|listStatus
argument_list|(
name|destPath
argument_list|)
expr_stmt|;
if|if
condition|(
name|listPaths
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|s
range|:
name|listPaths
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar found path "
operator|+
name|s
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|s
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
literal|".har"
argument_list|)
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{ }
comment|//ignoring
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar waiting for har file to be deleted. Found "
operator|+
operator|(
name|listPaths
operator|==
literal|null
condition|?
literal|"none"
else|:
name|listPaths
operator|.
name|length
operator|)
operator|+
literal|" files"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar Exception "
operator|+
name|e
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
if|if
condition|(
name|cnode
operator|!=
literal|null
condition|)
block|{
name|cnode
operator|.
name|stop
argument_list|()
expr_stmt|;
name|cnode
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"doTestHar completed:"
operator|+
literal|" blockSize="
operator|+
name|blockSize
operator|+
literal|" stripeLength="
operator|+
name|stripeLength
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

