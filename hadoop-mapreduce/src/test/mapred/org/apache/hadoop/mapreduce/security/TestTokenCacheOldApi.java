begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/** Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce.security
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|fail
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|NoSuchAlgorithmException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|KeyGenerator
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|spec
operator|.
name|SecretKeySpec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|codec
operator|.
name|binary
operator|.
name|Base64
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NameNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NameNodeAdapter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IntWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|EmptyInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Mapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|MiniMRCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|OutputCollector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Partitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|NullOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|map
operator|.
name|ObjectMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_class
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|class|TestTokenCacheOldApi
specifier|public
class|class
name|TestTokenCacheOldApi
block|{
DECL|field|NUM_OF_KEYS
specifier|private
specifier|static
specifier|final
name|int
name|NUM_OF_KEYS
init|=
literal|10
decl_stmt|;
comment|// my sleep class - adds check for tokenCache
DECL|class|MyDummyJob
specifier|static
class|class
name|MyDummyJob
extends|extends
name|Configured
implements|implements
name|Tool
implements|,
name|Mapper
argument_list|<
name|IntWritable
argument_list|,
name|IntWritable
argument_list|,
name|IntWritable
argument_list|,
name|NullWritable
argument_list|>
implements|,
name|Reducer
argument_list|<
name|IntWritable
argument_list|,
name|NullWritable
argument_list|,
name|NullWritable
argument_list|,
name|NullWritable
argument_list|>
implements|,
name|Partitioner
argument_list|<
name|IntWritable
argument_list|,
name|NullWritable
argument_list|>
block|{
DECL|field|ts
name|Credentials
name|ts
decl_stmt|;
DECL|method|configure (JobConf job)
specifier|public
name|void
name|configure
parameter_list|(
name|JobConf
name|job
parameter_list|)
block|{     }
comment|/**      * attempts to access tokenCache as from client      */
DECL|method|map (IntWritable key, IntWritable value, OutputCollector<IntWritable, NullWritable> output, Reporter reporter)
specifier|public
name|void
name|map
parameter_list|(
name|IntWritable
name|key
parameter_list|,
name|IntWritable
name|value
parameter_list|,
name|OutputCollector
argument_list|<
name|IntWritable
argument_list|,
name|NullWritable
argument_list|>
name|output
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
comment|// get token storage and a key
name|byte
index|[]
name|key1
init|=
name|ts
operator|.
name|getSecretKey
argument_list|(
operator|new
name|Text
argument_list|(
literal|"alias1"
argument_list|)
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
argument_list|>
name|dts
init|=
name|ts
operator|.
name|getAllTokens
argument_list|()
decl_stmt|;
name|int
name|dts_size
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|dts
operator|!=
literal|null
condition|)
name|dts_size
operator|=
name|dts
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|dts
operator|.
name|size
argument_list|()
operator|!=
literal|2
condition|)
block|{
comment|// one job token and one delegation token
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"tokens are not available"
argument_list|)
throw|;
comment|// fail the test
block|}
if|if
condition|(
name|key1
operator|==
literal|null
operator|||
name|ts
operator|==
literal|null
operator|||
name|ts
operator|.
name|numberOfSecretKeys
argument_list|()
operator|!=
name|NUM_OF_KEYS
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"secret keys are not available"
argument_list|)
throw|;
comment|// fail the test
block|}
name|output
operator|.
name|collect
argument_list|(
operator|new
name|IntWritable
argument_list|(
literal|1
argument_list|)
argument_list|,
name|NullWritable
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|setupJobConf ()
specifier|public
name|JobConf
name|setupJobConf
parameter_list|()
block|{
name|JobConf
name|job
init|=
operator|new
name|JobConf
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|MyDummyJob
operator|.
name|class
argument_list|)
decl_stmt|;
name|job
operator|.
name|setNumMapTasks
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|MyDummyJob
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputKeyClass
argument_list|(
name|IntWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputValueClass
argument_list|(
name|NullWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|MyDummyJob
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormat
argument_list|(
name|NullOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormat
argument_list|(
name|EmptyInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setPartitionerClass
argument_list|(
name|MyDummyJob
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setSpeculativeExecution
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJobName
argument_list|(
literal|"Sleep job"
argument_list|)
expr_stmt|;
name|populateTokens
argument_list|(
name|job
argument_list|)
expr_stmt|;
return|return
name|job
return|;
block|}
DECL|method|populateTokens (JobConf job)
specifier|private
name|void
name|populateTokens
parameter_list|(
name|JobConf
name|job
parameter_list|)
block|{
comment|// Credentials in the job will not have delegation tokens
comment|// because security is disabled. Fetch delegation tokens
comment|// and populate the credential in the job.
try|try
block|{
name|Credentials
name|ts
init|=
name|job
operator|.
name|getCredentials
argument_list|()
decl_stmt|;
name|Path
name|p1
init|=
operator|new
name|Path
argument_list|(
literal|"file1"
argument_list|)
decl_stmt|;
name|p1
operator|=
name|p1
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|p1
argument_list|)
expr_stmt|;
name|Credentials
name|cred
init|=
operator|new
name|Credentials
argument_list|()
decl_stmt|;
name|TokenCache
operator|.
name|obtainTokensForNamenodesInternal
argument_list|(
name|cred
argument_list|,
operator|new
name|Path
index|[]
block|{
name|p1
block|}
argument_list|,
name|job
argument_list|)
expr_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|t
range|:
name|cred
operator|.
name|getAllTokens
argument_list|()
control|)
block|{
name|ts
operator|.
name|addToken
argument_list|(
operator|new
name|Text
argument_list|(
literal|"Hdfs"
argument_list|)
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|fail
argument_list|(
literal|"Exception "
operator|+
name|e
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{     }
DECL|method|reduce (IntWritable key, Iterator<NullWritable> values, OutputCollector<NullWritable, NullWritable> output, Reporter reporter)
specifier|public
name|void
name|reduce
parameter_list|(
name|IntWritable
name|key
parameter_list|,
name|Iterator
argument_list|<
name|NullWritable
argument_list|>
name|values
parameter_list|,
name|OutputCollector
argument_list|<
name|NullWritable
argument_list|,
name|NullWritable
argument_list|>
name|output
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return;
block|}
DECL|method|getPartition (IntWritable key, NullWritable value, int numPartitions)
specifier|public
name|int
name|getPartition
parameter_list|(
name|IntWritable
name|key
parameter_list|,
name|NullWritable
name|value
parameter_list|,
name|int
name|numPartitions
parameter_list|)
block|{
return|return
name|key
operator|.
name|get
argument_list|()
operator|%
name|numPartitions
return|;
block|}
DECL|method|run (String[] args)
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|JobConf
name|job
init|=
name|setupJobConf
argument_list|()
decl_stmt|;
name|JobClient
operator|.
name|runJob
argument_list|(
name|job
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
block|}
DECL|field|mrCluster
specifier|private
specifier|static
name|MiniMRCluster
name|mrCluster
decl_stmt|;
DECL|field|dfsCluster
specifier|private
specifier|static
name|MiniDFSCluster
name|dfsCluster
decl_stmt|;
DECL|field|TEST_DIR
specifier|private
specifier|static
specifier|final
name|Path
name|TEST_DIR
init|=
operator|new
name|Path
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
literal|"/tmp"
argument_list|)
argument_list|,
literal|"sleepTest"
argument_list|)
decl_stmt|;
DECL|field|tokenFileName
specifier|private
specifier|static
specifier|final
name|Path
name|tokenFileName
init|=
operator|new
name|Path
argument_list|(
name|TEST_DIR
argument_list|,
literal|"tokenFile.json"
argument_list|)
decl_stmt|;
DECL|field|numSlaves
specifier|private
specifier|static
name|int
name|numSlaves
init|=
literal|1
decl_stmt|;
DECL|field|jConf
specifier|private
specifier|static
name|JobConf
name|jConf
decl_stmt|;
DECL|field|mapper
specifier|private
specifier|static
name|ObjectMapper
name|mapper
init|=
operator|new
name|ObjectMapper
argument_list|()
decl_stmt|;
DECL|field|p1
specifier|private
specifier|static
name|Path
name|p1
decl_stmt|;
DECL|field|p2
specifier|private
specifier|static
name|Path
name|p2
decl_stmt|;
annotation|@
name|BeforeClass
DECL|method|setUp ()
specifier|public
specifier|static
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
name|dfsCluster
operator|=
operator|new
name|MiniDFSCluster
argument_list|(
name|conf
argument_list|,
name|numSlaves
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|jConf
operator|=
operator|new
name|JobConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|mrCluster
operator|=
operator|new
name|MiniMRCluster
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|numSlaves
argument_list|,
name|dfsCluster
operator|.
name|getFileSystem
argument_list|()
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
literal|1
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|jConf
argument_list|)
expr_stmt|;
name|createTokenFileJson
argument_list|()
expr_stmt|;
name|verifySecretKeysInJSONFile
argument_list|()
expr_stmt|;
name|NameNodeAdapter
operator|.
name|getDtSecretManager
argument_list|(
name|dfsCluster
operator|.
name|getNamesystem
argument_list|()
argument_list|)
operator|.
name|startThreads
argument_list|()
expr_stmt|;
name|FileSystem
name|fs
init|=
name|dfsCluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|p1
operator|=
operator|new
name|Path
argument_list|(
literal|"file1"
argument_list|)
expr_stmt|;
name|p2
operator|=
operator|new
name|Path
argument_list|(
literal|"file2"
argument_list|)
expr_stmt|;
name|p1
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
name|p1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|AfterClass
DECL|method|tearDown ()
specifier|public
specifier|static
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|mrCluster
operator|!=
literal|null
condition|)
name|mrCluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|mrCluster
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|dfsCluster
operator|!=
literal|null
condition|)
name|dfsCluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|dfsCluster
operator|=
literal|null
expr_stmt|;
block|}
comment|// create jason file and put some keys into it..
DECL|method|createTokenFileJson ()
specifier|private
specifier|static
name|void
name|createTokenFileJson
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|KeyGenerator
name|kg
init|=
name|KeyGenerator
operator|.
name|getInstance
argument_list|(
literal|"HmacSHA1"
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|NUM_OF_KEYS
condition|;
name|i
operator|++
control|)
block|{
name|SecretKeySpec
name|key
init|=
operator|(
name|SecretKeySpec
operator|)
name|kg
operator|.
name|generateKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|enc_key
init|=
name|key
operator|.
name|getEncoded
argument_list|()
decl_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"alias"
operator|+
name|i
argument_list|,
operator|new
name|String
argument_list|(
name|Base64
operator|.
name|encodeBase64
argument_list|(
name|enc_key
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchAlgorithmException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
try|try
block|{
name|File
name|p
init|=
operator|new
name|File
argument_list|(
name|tokenFileName
operator|.
name|getParent
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|p
operator|.
name|mkdirs
argument_list|()
expr_stmt|;
comment|// convert to JSON and save to the file
name|mapper
operator|.
name|writeValue
argument_list|(
operator|new
name|File
argument_list|(
name|tokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|map
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"failed with :"
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
DECL|method|verifySecretKeysInJSONFile ()
specifier|private
specifier|static
name|void
name|verifySecretKeysInJSONFile
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|map
decl_stmt|;
name|map
operator|=
name|mapper
operator|.
name|readValue
argument_list|(
operator|new
name|File
argument_list|(
name|tokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|Map
operator|.
name|class
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"didn't read JSON correctly"
argument_list|,
name|map
operator|.
name|size
argument_list|()
argument_list|,
name|NUM_OF_KEYS
argument_list|)
expr_stmt|;
block|}
comment|/**    * run a distributed job and verify that TokenCache is available    * @throws IOException    */
annotation|@
name|Test
DECL|method|testTokenCache ()
specifier|public
name|void
name|testTokenCache
parameter_list|()
throws|throws
name|IOException
block|{
comment|// make sure JT starts
name|jConf
operator|=
name|mrCluster
operator|.
name|createJobConf
argument_list|()
expr_stmt|;
comment|// provide namenodes names for the job to get the delegation tokens for
comment|//String nnUri = dfsCluster.getNameNode().getUri(namenode).toString();
name|NameNode
name|nn
init|=
name|dfsCluster
operator|.
name|getNameNode
argument_list|()
decl_stmt|;
name|URI
name|nnUri
init|=
name|NameNode
operator|.
name|getUri
argument_list|(
name|nn
operator|.
name|getNameNodeAddress
argument_list|()
argument_list|)
decl_stmt|;
name|jConf
operator|.
name|set
argument_list|(
name|JobContext
operator|.
name|JOB_NAMENODES
argument_list|,
name|nnUri
operator|+
literal|","
operator|+
name|nnUri
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// job tracker principle id..
name|jConf
operator|.
name|set
argument_list|(
name|JobTracker
operator|.
name|JT_USER_NAME
argument_list|,
literal|"jt_id"
argument_list|)
expr_stmt|;
comment|// using argument to pass the file name
name|String
index|[]
name|args
init|=
block|{
literal|"-tokenCacheFile"
block|,
name|tokenFileName
operator|.
name|toString
argument_list|()
block|,
literal|"-m"
block|,
literal|"1"
block|,
literal|"-r"
block|,
literal|"1"
block|,
literal|"-mt"
block|,
literal|"1"
block|,
literal|"-rt"
block|,
literal|"1"
block|}
decl_stmt|;
name|int
name|res
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|res
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|jConf
argument_list|,
operator|new
name|MyDummyJob
argument_list|()
argument_list|,
name|args
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Job failed with"
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
name|e
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|out
argument_list|)
expr_stmt|;
name|Assert
operator|.
name|fail
argument_list|(
literal|"Job failed"
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"dist job res is not 0"
argument_list|,
name|res
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/**    * run a local job and verify that TokenCache is available    * @throws NoSuchAlgorithmException    * @throws IOException    */
annotation|@
name|Test
DECL|method|testLocalJobTokenCache ()
specifier|public
name|void
name|testLocalJobTokenCache
parameter_list|()
throws|throws
name|NoSuchAlgorithmException
throws|,
name|IOException
block|{
comment|// this is local job
name|String
index|[]
name|args
init|=
block|{
literal|"-m"
block|,
literal|"1"
block|,
literal|"-r"
block|,
literal|"1"
block|,
literal|"-mt"
block|,
literal|"1"
block|,
literal|"-rt"
block|,
literal|"1"
block|}
decl_stmt|;
name|jConf
operator|.
name|set
argument_list|(
literal|"mapreduce.job.credentials.json"
argument_list|,
name|tokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|res
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|res
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|jConf
argument_list|,
operator|new
name|MyDummyJob
argument_list|()
argument_list|,
name|args
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Job failed with"
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
name|e
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|out
argument_list|)
expr_stmt|;
name|fail
argument_list|(
literal|"local Job failed"
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"local job res is not 0"
argument_list|,
name|res
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

