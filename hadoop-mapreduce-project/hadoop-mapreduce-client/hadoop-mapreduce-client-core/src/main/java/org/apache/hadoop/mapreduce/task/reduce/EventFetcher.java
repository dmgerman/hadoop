begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce.task.reduce
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|task
operator|.
name|reduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|MapTaskCompletionEventsUpdate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|TaskCompletionEvent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|TaskUmbilicalProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
import|;
end_import

begin_class
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|class|EventFetcher
class|class
name|EventFetcher
parameter_list|<
name|K
parameter_list|,
name|V
parameter_list|>
extends|extends
name|Thread
block|{
DECL|field|SLEEP_TIME
specifier|private
specifier|static
specifier|final
name|long
name|SLEEP_TIME
init|=
literal|1000
decl_stmt|;
DECL|field|MAX_EVENTS_TO_FETCH
specifier|private
specifier|static
specifier|final
name|int
name|MAX_EVENTS_TO_FETCH
init|=
literal|10000
decl_stmt|;
DECL|field|MAX_RETRIES
specifier|private
specifier|static
specifier|final
name|int
name|MAX_RETRIES
init|=
literal|10
decl_stmt|;
DECL|field|RETRY_PERIOD
specifier|private
specifier|static
specifier|final
name|int
name|RETRY_PERIOD
init|=
literal|5000
decl_stmt|;
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|EventFetcher
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|reduce
specifier|private
specifier|final
name|TaskAttemptID
name|reduce
decl_stmt|;
DECL|field|umbilical
specifier|private
specifier|final
name|TaskUmbilicalProtocol
name|umbilical
decl_stmt|;
DECL|field|scheduler
specifier|private
specifier|final
name|ShuffleScheduler
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|scheduler
decl_stmt|;
DECL|field|fromEventId
specifier|private
name|int
name|fromEventId
init|=
literal|0
decl_stmt|;
DECL|field|exceptionReporter
specifier|private
name|ExceptionReporter
name|exceptionReporter
init|=
literal|null
decl_stmt|;
DECL|field|maxMapRuntime
specifier|private
name|int
name|maxMapRuntime
init|=
literal|0
decl_stmt|;
DECL|field|stopped
specifier|private
specifier|volatile
name|boolean
name|stopped
init|=
literal|false
decl_stmt|;
DECL|method|EventFetcher (TaskAttemptID reduce, TaskUmbilicalProtocol umbilical, ShuffleScheduler<K,V> scheduler, ExceptionReporter reporter)
specifier|public
name|EventFetcher
parameter_list|(
name|TaskAttemptID
name|reduce
parameter_list|,
name|TaskUmbilicalProtocol
name|umbilical
parameter_list|,
name|ShuffleScheduler
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|scheduler
parameter_list|,
name|ExceptionReporter
name|reporter
parameter_list|)
block|{
name|setName
argument_list|(
literal|"EventFetcher for fetching Map Completion Events"
argument_list|)
expr_stmt|;
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|reduce
operator|=
name|reduce
expr_stmt|;
name|this
operator|.
name|umbilical
operator|=
name|umbilical
expr_stmt|;
name|this
operator|.
name|scheduler
operator|=
name|scheduler
expr_stmt|;
name|exceptionReporter
operator|=
name|reporter
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|int
name|failures
init|=
literal|0
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|reduce
operator|+
literal|" Thread started: "
operator|+
name|getName
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
while|while
condition|(
operator|!
name|stopped
operator|&&
operator|!
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
try|try
block|{
name|int
name|numNewMaps
init|=
name|getMapCompletionEvents
argument_list|()
decl_stmt|;
name|failures
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|numNewMaps
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|reduce
operator|+
literal|": "
operator|+
literal|"Got "
operator|+
name|numNewMaps
operator|+
literal|" new map-outputs"
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"GetMapEventsThread about to sleep for "
operator|+
name|SLEEP_TIME
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|SLEEP_TIME
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"EventFetcher is interrupted.. Returning"
argument_list|)
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Exception in getting events"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
comment|// check to see whether to abort
if|if
condition|(
operator|++
name|failures
operator|>=
name|MAX_RETRIES
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"too many failures downloading events"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
comment|// sleep for a bit
if|if
condition|(
operator|!
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|RETRY_PERIOD
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
return|return;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|exceptionReporter
operator|.
name|reportException
argument_list|(
name|t
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
DECL|method|shutDown ()
specifier|public
name|void
name|shutDown
parameter_list|()
block|{
name|this
operator|.
name|stopped
operator|=
literal|true
expr_stmt|;
name|interrupt
argument_list|()
expr_stmt|;
try|try
block|{
name|join
argument_list|(
literal|5000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got interrupted while joining "
operator|+
name|getName
argument_list|()
argument_list|,
name|ie
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**     * Queries the {@link TaskTracker} for a set of map-completion events     * from a given event ID.    * @throws IOException    */
DECL|method|getMapCompletionEvents ()
specifier|private
name|int
name|getMapCompletionEvents
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|numNewMaps
init|=
literal|0
decl_stmt|;
name|MapTaskCompletionEventsUpdate
name|update
init|=
name|umbilical
operator|.
name|getMapCompletionEvents
argument_list|(
operator|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobID
operator|)
name|reduce
operator|.
name|getJobID
argument_list|()
argument_list|,
name|fromEventId
argument_list|,
name|MAX_EVENTS_TO_FETCH
argument_list|,
operator|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|TaskAttemptID
operator|)
name|reduce
argument_list|)
decl_stmt|;
name|TaskCompletionEvent
name|events
index|[]
init|=
name|update
operator|.
name|getMapTaskCompletionEvents
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got "
operator|+
name|events
operator|.
name|length
operator|+
literal|" map completion events from "
operator|+
name|fromEventId
argument_list|)
expr_stmt|;
comment|// Check if the reset is required.
comment|// Since there is no ordering of the task completion events at the
comment|// reducer, the only option to sync with the new jobtracker is to reset
comment|// the events index
if|if
condition|(
name|update
operator|.
name|shouldReset
argument_list|()
condition|)
block|{
name|fromEventId
operator|=
literal|0
expr_stmt|;
name|scheduler
operator|.
name|resetKnownMaps
argument_list|()
expr_stmt|;
block|}
comment|// Update the last seen event ID
name|fromEventId
operator|+=
name|events
operator|.
name|length
expr_stmt|;
comment|// Process the TaskCompletionEvents:
comment|// 1. Save the SUCCEEDED maps in knownOutputs to fetch the outputs.
comment|// 2. Save the OBSOLETE/FAILED/KILLED maps in obsoleteOutputs to stop
comment|//    fetching from those maps.
comment|// 3. Remove TIPFAILED maps from neededOutputs since we don't need their
comment|//    outputs at all.
for|for
control|(
name|TaskCompletionEvent
name|event
range|:
name|events
control|)
block|{
switch|switch
condition|(
name|event
operator|.
name|getTaskStatus
argument_list|()
condition|)
block|{
case|case
name|SUCCEEDED
case|:
name|URI
name|u
init|=
name|getBaseURI
argument_list|(
name|event
operator|.
name|getTaskTrackerHttp
argument_list|()
argument_list|)
decl_stmt|;
name|scheduler
operator|.
name|addKnownMapOutput
argument_list|(
name|u
operator|.
name|getHost
argument_list|()
operator|+
literal|":"
operator|+
name|u
operator|.
name|getPort
argument_list|()
argument_list|,
name|u
operator|.
name|toString
argument_list|()
argument_list|,
name|event
operator|.
name|getTaskAttemptId
argument_list|()
argument_list|)
expr_stmt|;
name|numNewMaps
operator|++
expr_stmt|;
name|int
name|duration
init|=
name|event
operator|.
name|getTaskRunTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|duration
operator|>
name|maxMapRuntime
condition|)
block|{
name|maxMapRuntime
operator|=
name|duration
expr_stmt|;
name|scheduler
operator|.
name|informMaxMapRunTime
argument_list|(
name|maxMapRuntime
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|FAILED
case|:
case|case
name|KILLED
case|:
case|case
name|OBSOLETE
case|:
name|scheduler
operator|.
name|obsoleteMapOutput
argument_list|(
name|event
operator|.
name|getTaskAttemptId
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring obsolete output of "
operator|+
name|event
operator|.
name|getTaskStatus
argument_list|()
operator|+
literal|" map-task: '"
operator|+
name|event
operator|.
name|getTaskAttemptId
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
break|break;
case|case
name|TIPFAILED
case|:
name|scheduler
operator|.
name|tipFailed
argument_list|(
name|event
operator|.
name|getTaskAttemptId
argument_list|()
operator|.
name|getTaskID
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring output of failed map TIP: '"
operator|+
name|event
operator|.
name|getTaskAttemptId
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
return|return
name|numNewMaps
return|;
block|}
DECL|method|getBaseURI (String url)
specifier|private
name|URI
name|getBaseURI
parameter_list|(
name|String
name|url
parameter_list|)
block|{
name|StringBuffer
name|baseUrl
init|=
operator|new
name|StringBuffer
argument_list|(
name|url
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|url
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|baseUrl
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
block|}
name|baseUrl
operator|.
name|append
argument_list|(
literal|"mapOutput?job="
argument_list|)
expr_stmt|;
name|baseUrl
operator|.
name|append
argument_list|(
name|reduce
operator|.
name|getJobID
argument_list|()
argument_list|)
expr_stmt|;
name|baseUrl
operator|.
name|append
argument_list|(
literal|"&reduce="
argument_list|)
expr_stmt|;
name|baseUrl
operator|.
name|append
argument_list|(
name|reduce
operator|.
name|getTaskID
argument_list|()
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|baseUrl
operator|.
name|append
argument_list|(
literal|"&map="
argument_list|)
expr_stmt|;
name|URI
name|u
init|=
name|URI
operator|.
name|create
argument_list|(
name|baseUrl
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|u
return|;
block|}
block|}
end_class

end_unit

