begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|ClusterStatus
operator|.
name|BlackListInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Cluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|ClusterMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|QueueInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskTrackerInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|filecache
operator|.
name|DistributedCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|token
operator|.
name|delegation
operator|.
name|DelegationTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|tools
operator|.
name|CLI
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|util
operator|.
name|ConfigUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|SecretManager
operator|.
name|InvalidToken
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_comment
comment|/**  *<code>JobClient</code> is the primary interface for the user-job to interact  * with the cluster.  *   *<code>JobClient</code> provides facilities to submit jobs, track their   * progress, access component-tasks' reports/logs, get the Map-Reduce cluster  * status information etc.  *   *<p>The job submission process involves:  *<ol>  *<li>  *   Checking the input and output specifications of the job.  *</li>  *<li>  *   Computing the {@link InputSplit}s for the job.  *</li>  *<li>  *   Setup the requisite accounting information for the {@link DistributedCache}   *   of the job, if necessary.  *</li>  *<li>  *   Copying the job's jar and configuration to the map-reduce system directory   *   on the distributed file-system.   *</li>  *<li>  *   Submitting the job to the cluster and optionally monitoring  *   it's status.  *</li>  *</ol></p>  *    * Normally the user creates the application, describes various facets of the  * job via {@link JobConf} and then uses the<code>JobClient</code> to submit   * the job and monitor its progress.  *   *<p>Here is an example on how to use<code>JobClient</code>:</p>  *<p><blockquote><pre>  *     // Create a new JobConf  *     JobConf job = new JobConf(new Configuration(), MyJob.class);  *       *     // Specify various job-specific parameters       *     job.setJobName("myjob");  *       *     job.setInputPath(new Path("in"));  *     job.setOutputPath(new Path("out"));  *       *     job.setMapperClass(MyJob.MyMapper.class);  *     job.setReducerClass(MyJob.MyReducer.class);  *  *     // Submit the job, then poll for progress until the job is complete  *     JobClient.runJob(job);  *</pre></blockquote></p>  *   *<h4 id="JobControl">Job Control</h4>  *   *<p>At times clients would chain map-reduce jobs to accomplish complex tasks   * which cannot be done via a single map-reduce job. This is fairly easy since   * the output of the job, typically, goes to distributed file-system and that   * can be used as the input for the next job.</p>  *   *<p>However, this also means that the onus on ensuring jobs are complete   * (success/failure) lies squarely on the clients. In such situations the   * various job-control options are:  *<ol>  *<li>  *   {@link #runJob(JobConf)} : submits the job and returns only after   *   the job has completed.  *</li>  *<li>  *   {@link #submitJob(JobConf)} : only submits the job, then poll the   *   returned handle to the {@link RunningJob} to query status and make   *   scheduling decisions.  *</li>  *<li>  *   {@link JobConf#setJobEndNotificationURI(String)} : setup a notification  *   on job-completion, thus avoiding polling.  *</li>  *</ol></p>  *   * @see JobConf  * @see ClusterStatus  * @see Tool  * @see DistributedCache  * @deprecated Use {@link Job} and {@link Cluster} instead  */
end_comment

begin_class
annotation|@
name|Deprecated
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Stable
DECL|class|JobClient
specifier|public
class|class
name|JobClient
extends|extends
name|CLI
block|{
DECL|enum|TaskStatusFilter
DECL|enumConstant|NONE
DECL|enumConstant|KILLED
DECL|enumConstant|FAILED
DECL|enumConstant|SUCCEEDED
DECL|enumConstant|ALL
specifier|public
specifier|static
enum|enum
name|TaskStatusFilter
block|{
name|NONE
block|,
name|KILLED
block|,
name|FAILED
block|,
name|SUCCEEDED
block|,
name|ALL
block|}
DECL|field|taskOutputFilter
specifier|private
name|TaskStatusFilter
name|taskOutputFilter
init|=
name|TaskStatusFilter
operator|.
name|FAILED
decl_stmt|;
static|static
block|{
name|ConfigUtil
operator|.
name|loadResources
argument_list|()
expr_stmt|;
block|}
comment|/**    * A NetworkedJob is an implementation of RunningJob.  It holds    * a JobProfile object to provide some info, and interacts with the    * remote service to provide certain functionality.    */
DECL|class|NetworkedJob
specifier|static
class|class
name|NetworkedJob
implements|implements
name|RunningJob
block|{
DECL|field|job
name|Job
name|job
decl_stmt|;
comment|/**      * We store a JobProfile and a timestamp for when we last      * acquired the job profile.  If the job is null, then we cannot      * perform any of the tasks.  The job might be null if the cluster      * has completely forgotten about the job.  (eg, 24 hours after the      * job completes.)      */
DECL|method|NetworkedJob (JobStatus status, Cluster cluster)
specifier|public
name|NetworkedJob
parameter_list|(
name|JobStatus
name|status
parameter_list|,
name|Cluster
name|cluster
parameter_list|)
throws|throws
name|IOException
block|{
name|job
operator|=
name|Job
operator|.
name|getInstance
argument_list|(
name|cluster
argument_list|,
name|status
argument_list|,
operator|new
name|JobConf
argument_list|(
name|status
operator|.
name|getJobFile
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|NetworkedJob (Job job)
specifier|public
name|NetworkedJob
parameter_list|(
name|Job
name|job
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|job
operator|=
name|job
expr_stmt|;
block|}
DECL|method|getConfiguration ()
specifier|public
name|Configuration
name|getConfiguration
parameter_list|()
block|{
return|return
name|job
operator|.
name|getConfiguration
argument_list|()
return|;
block|}
comment|/**      * An identifier for the job      */
DECL|method|getID ()
specifier|public
name|JobID
name|getID
parameter_list|()
block|{
return|return
name|JobID
operator|.
name|downgrade
argument_list|(
name|job
operator|.
name|getJobID
argument_list|()
argument_list|)
return|;
block|}
comment|/** @deprecated This method is deprecated and will be removed. Applications should       * rather use {@link #getID()}.*/
annotation|@
name|Deprecated
DECL|method|getJobID ()
specifier|public
name|String
name|getJobID
parameter_list|()
block|{
return|return
name|getID
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**      * The user-specified job name      */
DECL|method|getJobName ()
specifier|public
name|String
name|getJobName
parameter_list|()
block|{
return|return
name|job
operator|.
name|getJobName
argument_list|()
return|;
block|}
comment|/**      * The name of the job file      */
DECL|method|getJobFile ()
specifier|public
name|String
name|getJobFile
parameter_list|()
block|{
return|return
name|job
operator|.
name|getJobFile
argument_list|()
return|;
block|}
comment|/**      * A URL where the job's status can be seen      */
DECL|method|getTrackingURL ()
specifier|public
name|String
name|getTrackingURL
parameter_list|()
block|{
return|return
name|job
operator|.
name|getTrackingURL
argument_list|()
return|;
block|}
comment|/**      * A float between 0.0 and 1.0, indicating the % of map work      * completed.      */
DECL|method|mapProgress ()
specifier|public
name|float
name|mapProgress
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|mapProgress
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * A float between 0.0 and 1.0, indicating the % of reduce work      * completed.      */
DECL|method|reduceProgress ()
specifier|public
name|float
name|reduceProgress
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|reduceProgress
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * A float between 0.0 and 1.0, indicating the % of cleanup work      * completed.      */
DECL|method|cleanupProgress ()
specifier|public
name|float
name|cleanupProgress
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|cleanupProgress
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * A float between 0.0 and 1.0, indicating the % of setup work      * completed.      */
DECL|method|setupProgress ()
specifier|public
name|float
name|setupProgress
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|setupProgress
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * Returns immediately whether the whole job is done yet or not.      */
DECL|method|isComplete ()
specifier|public
specifier|synchronized
name|boolean
name|isComplete
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|isComplete
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * True iff job completed successfully.      */
DECL|method|isSuccessful ()
specifier|public
specifier|synchronized
name|boolean
name|isSuccessful
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|isSuccessful
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * Blocks until the job is finished      */
DECL|method|waitForCompletion ()
specifier|public
name|void
name|waitForCompletion
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|ce
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ce
argument_list|)
throw|;
block|}
block|}
comment|/**      * Tells the service to get the state of the current job.      */
DECL|method|getJobState ()
specifier|public
specifier|synchronized
name|int
name|getJobState
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|getJobState
argument_list|()
operator|.
name|getValue
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * Tells the service to terminate the current job.      */
DECL|method|killJob ()
specifier|public
specifier|synchronized
name|void
name|killJob
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|job
operator|.
name|killJob
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/** Set the priority of the job.     * @param priority new priority of the job.      */
DECL|method|setJobPriority (String priority)
specifier|public
specifier|synchronized
name|void
name|setJobPriority
parameter_list|(
name|String
name|priority
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|job
operator|.
name|setPriority
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobPriority
operator|.
name|valueOf
argument_list|(
name|priority
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * Kill indicated task attempt.      * @param taskId the id of the task to kill.      * @param shouldFail if true the task is failed and added to failed tasks list, otherwise      * it is just killed, w/o affecting job failure status.      */
DECL|method|killTask (TaskAttemptID taskId, boolean shouldFail)
specifier|public
specifier|synchronized
name|void
name|killTask
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|boolean
name|shouldFail
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|shouldFail
condition|)
block|{
name|job
operator|.
name|failTask
argument_list|(
name|taskId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|job
operator|.
name|killTask
argument_list|(
name|taskId
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/** @deprecated Applications should rather use {@link #killTask(TaskAttemptID, boolean)}*/
annotation|@
name|Deprecated
DECL|method|killTask (String taskId, boolean shouldFail)
specifier|public
specifier|synchronized
name|void
name|killTask
parameter_list|(
name|String
name|taskId
parameter_list|,
name|boolean
name|shouldFail
parameter_list|)
throws|throws
name|IOException
block|{
name|killTask
argument_list|(
name|TaskAttemptID
operator|.
name|forName
argument_list|(
name|taskId
argument_list|)
argument_list|,
name|shouldFail
argument_list|)
expr_stmt|;
block|}
comment|/**      * Fetch task completion events from cluster for this job.       */
DECL|method|getTaskCompletionEvents ( int startFrom)
specifier|public
specifier|synchronized
name|TaskCompletionEvent
index|[]
name|getTaskCompletionEvents
parameter_list|(
name|int
name|startFrom
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskCompletionEvent
index|[]
name|acls
init|=
name|job
operator|.
name|getTaskCompletionEvents
argument_list|(
name|startFrom
argument_list|,
literal|10
argument_list|)
decl_stmt|;
name|TaskCompletionEvent
index|[]
name|ret
init|=
operator|new
name|TaskCompletionEvent
index|[
name|acls
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|acls
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ret
index|[
name|i
index|]
operator|=
name|TaskCompletionEvent
operator|.
name|downgrade
argument_list|(
name|acls
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**      * Dump stats to screen      */
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|job
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**      * Returns the counters for this job      */
DECL|method|getCounters ()
specifier|public
name|Counters
name|getCounters
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|Counters
name|result
init|=
literal|null
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Counters
name|temp
init|=
name|job
operator|.
name|getCounters
argument_list|()
decl_stmt|;
if|if
condition|(
name|temp
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
name|Counters
operator|.
name|downgrade
argument_list|(
name|temp
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|getTaskDiagnostics (TaskAttemptID id)
specifier|public
name|String
index|[]
name|getTaskDiagnostics
parameter_list|(
name|TaskAttemptID
name|id
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|getTaskDiagnostics
argument_list|(
name|id
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
DECL|method|getHistoryUrl ()
specifier|public
name|String
name|getHistoryUrl
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|getHistoryUrl
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
DECL|method|isRetired ()
specifier|public
name|boolean
name|isRetired
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|job
operator|.
name|isRetired
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
DECL|method|monitorAndPrintJob ()
name|boolean
name|monitorAndPrintJob
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
name|job
operator|.
name|monitorAndPrintJob
argument_list|()
return|;
block|}
block|}
DECL|field|cluster
name|Cluster
name|cluster
decl_stmt|;
comment|/**    * Create a job client.    */
DECL|method|JobClient ()
specifier|public
name|JobClient
parameter_list|()
block|{   }
comment|/**    * Build a job client with the given {@link JobConf}, and connect to the     * default cluster    *     * @param conf the job configuration.    * @throws IOException    */
DECL|method|JobClient (JobConf conf)
specifier|public
name|JobClient
parameter_list|(
name|JobConf
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Build a job client with the given {@link Configuration},     * and connect to the default cluster    *     * @param conf the configuration.    * @throws IOException    */
DECL|method|JobClient (Configuration conf)
specifier|public
name|JobClient
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|init
argument_list|(
operator|new
name|JobConf
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Connect to the default cluster    * @param conf the job configuration.    * @throws IOException    */
DECL|method|init (JobConf conf)
specifier|public
name|void
name|init
parameter_list|(
name|JobConf
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|cluster
operator|=
operator|new
name|Cluster
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Build a job client, connect to the indicated job tracker.    *     * @param jobTrackAddr the job tracker to connect to.    * @param conf configuration.    */
DECL|method|JobClient (InetSocketAddress jobTrackAddr, Configuration conf)
specifier|public
name|JobClient
parameter_list|(
name|InetSocketAddress
name|jobTrackAddr
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|cluster
operator|=
operator|new
name|Cluster
argument_list|(
name|jobTrackAddr
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Close the<code>JobClient</code>.    */
DECL|method|close ()
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|cluster
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Get a filesystem handle.  We need this to prepare jobs    * for submission to the MapReduce system.    *     * @return the filesystem handle.    */
DECL|method|getFs ()
specifier|public
specifier|synchronized
name|FileSystem
name|getFs
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|cluster
operator|.
name|getFileSystem
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get a handle to the Cluster    */
DECL|method|getClusterHandle ()
specifier|public
name|Cluster
name|getClusterHandle
parameter_list|()
block|{
return|return
name|cluster
return|;
block|}
comment|/**    * Submit a job to the MR system.    *     * This returns a handle to the {@link RunningJob} which can be used to track    * the running-job.    *     * @param jobFile the job configuration.    * @return a handle to the {@link RunningJob} which can be used to track the    *         running-job.    * @throws FileNotFoundException    * @throws InvalidJobConfException    * @throws IOException    */
DECL|method|submitJob (String jobFile)
specifier|public
name|RunningJob
name|submitJob
parameter_list|(
name|String
name|jobFile
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|InvalidJobConfException
throws|,
name|IOException
block|{
comment|// Load in the submitted job details
name|JobConf
name|job
init|=
operator|new
name|JobConf
argument_list|(
name|jobFile
argument_list|)
decl_stmt|;
return|return
name|submitJob
argument_list|(
name|job
argument_list|)
return|;
block|}
comment|/**    * Submit a job to the MR system.    * This returns a handle to the {@link RunningJob} which can be used to track    * the running-job.    *     * @param conf the job configuration.    * @return a handle to the {@link RunningJob} which can be used to track the    *         running-job.    * @throws FileNotFoundException    * @throws IOException    */
DECL|method|submitJob (JobConf conf)
specifier|public
name|RunningJob
name|submitJob
parameter_list|(
name|JobConf
name|conf
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
try|try
block|{
name|conf
operator|.
name|setBooleanIfUnset
argument_list|(
literal|"mapred.mapper.new-api"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBooleanIfUnset
argument_list|(
literal|"mapred.reducer.new-api"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|Job
name|job
init|=
name|Job
operator|.
name|getInstance
argument_list|(
name|cluster
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|job
operator|.
name|submit
argument_list|()
expr_stmt|;
return|return
operator|new
name|NetworkedJob
argument_list|(
name|job
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"interrupted"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|cnfe
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"class not found"
argument_list|,
name|cnfe
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get an {@link RunningJob} object to track an ongoing job.  Returns    * null if the id does not correspond to any known job.    *     * @param jobid the jobid of the job.    * @return the {@link RunningJob} handle to track the job, null if the     *<code>jobid</code> doesn't correspond to any known job.    * @throws IOException    */
DECL|method|getJob (JobID jobid)
specifier|public
name|RunningJob
name|getJob
parameter_list|(
name|JobID
name|jobid
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|Job
name|job
init|=
name|cluster
operator|.
name|getJob
argument_list|(
name|jobid
argument_list|)
decl_stmt|;
if|if
condition|(
name|job
operator|!=
literal|null
condition|)
block|{
name|JobStatus
name|status
init|=
name|JobStatus
operator|.
name|downgrade
argument_list|(
name|job
operator|.
name|getStatus
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|NetworkedJob
argument_list|(
name|status
argument_list|,
name|cluster
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
comment|/**@deprecated Applications should rather use {@link #getJob(JobID)}.     */
annotation|@
name|Deprecated
DECL|method|getJob (String jobid)
specifier|public
name|RunningJob
name|getJob
parameter_list|(
name|String
name|jobid
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getJob
argument_list|(
name|JobID
operator|.
name|forName
argument_list|(
name|jobid
argument_list|)
argument_list|)
return|;
block|}
DECL|field|EMPTY_TASK_REPORTS
specifier|private
specifier|static
specifier|final
name|TaskReport
index|[]
name|EMPTY_TASK_REPORTS
init|=
operator|new
name|TaskReport
index|[
literal|0
index|]
decl_stmt|;
comment|/**    * Get the information of the current state of the map tasks of a job.    *     * @param jobId the job to query.    * @return the list of all of the map tips.    * @throws IOException    */
DECL|method|getMapTaskReports (JobID jobId)
specifier|public
name|TaskReport
index|[]
name|getMapTaskReports
parameter_list|(
name|JobID
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTaskReports
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|MAP
argument_list|)
return|;
block|}
DECL|method|getTaskReports (JobID jobId, TaskType type)
specifier|private
name|TaskReport
index|[]
name|getTaskReports
parameter_list|(
name|JobID
name|jobId
parameter_list|,
name|TaskType
name|type
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|Job
name|j
init|=
name|cluster
operator|.
name|getJob
argument_list|(
name|jobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|j
operator|==
literal|null
condition|)
block|{
return|return
name|EMPTY_TASK_REPORTS
return|;
block|}
return|return
name|TaskReport
operator|.
name|downgradeArray
argument_list|(
name|j
operator|.
name|getTaskReports
argument_list|(
name|type
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**@deprecated Applications should rather use {@link #getMapTaskReports(JobID)}*/
annotation|@
name|Deprecated
DECL|method|getMapTaskReports (String jobId)
specifier|public
name|TaskReport
index|[]
name|getMapTaskReports
parameter_list|(
name|String
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getMapTaskReports
argument_list|(
name|JobID
operator|.
name|forName
argument_list|(
name|jobId
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Get the information of the current state of the reduce tasks of a job.    *     * @param jobId the job to query.    * @return the list of all of the reduce tips.    * @throws IOException    */
DECL|method|getReduceTaskReports (JobID jobId)
specifier|public
name|TaskReport
index|[]
name|getReduceTaskReports
parameter_list|(
name|JobID
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTaskReports
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|REDUCE
argument_list|)
return|;
block|}
comment|/**    * Get the information of the current state of the cleanup tasks of a job.    *     * @param jobId the job to query.    * @return the list of all of the cleanup tips.    * @throws IOException    */
DECL|method|getCleanupTaskReports (JobID jobId)
specifier|public
name|TaskReport
index|[]
name|getCleanupTaskReports
parameter_list|(
name|JobID
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTaskReports
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|JOB_CLEANUP
argument_list|)
return|;
block|}
comment|/**    * Get the information of the current state of the setup tasks of a job.    *     * @param jobId the job to query.    * @return the list of all of the setup tips.    * @throws IOException    */
DECL|method|getSetupTaskReports (JobID jobId)
specifier|public
name|TaskReport
index|[]
name|getSetupTaskReports
parameter_list|(
name|JobID
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTaskReports
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|JOB_SETUP
argument_list|)
return|;
block|}
comment|/**@deprecated Applications should rather use {@link #getReduceTaskReports(JobID)}*/
annotation|@
name|Deprecated
DECL|method|getReduceTaskReports (String jobId)
specifier|public
name|TaskReport
index|[]
name|getReduceTaskReports
parameter_list|(
name|String
name|jobId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getReduceTaskReports
argument_list|(
name|JobID
operator|.
name|forName
argument_list|(
name|jobId
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Display the information about a job's tasks, of a particular type and    * in a particular state    *     * @param jobId the ID of the job    * @param type the type of the task (map/reduce/setup/cleanup)    * @param state the state of the task     * (pending/running/completed/failed/killed)    */
DECL|method|displayTasks (JobID jobId, String type, String state)
specifier|public
name|void
name|displayTasks
parameter_list|(
name|JobID
name|jobId
parameter_list|,
name|String
name|type
parameter_list|,
name|String
name|state
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|super
operator|.
name|displayTasks
argument_list|(
name|cluster
operator|.
name|getJob
argument_list|(
name|jobId
argument_list|)
argument_list|,
name|type
argument_list|,
name|state
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get status information about the Map-Reduce cluster.    *      * @return the status information about the Map-Reduce cluster as an object    *         of {@link ClusterStatus}.    * @throws IOException    */
DECL|method|getClusterStatus ()
specifier|public
name|ClusterStatus
name|getClusterStatus
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|ClusterMetrics
name|metrics
init|=
name|cluster
operator|.
name|getClusterStatus
argument_list|()
decl_stmt|;
return|return
operator|new
name|ClusterStatus
argument_list|(
name|metrics
operator|.
name|getTaskTrackerCount
argument_list|()
argument_list|,
name|metrics
operator|.
name|getBlackListedTaskTrackerCount
argument_list|()
argument_list|,
name|cluster
operator|.
name|getTaskTrackerExpiryInterval
argument_list|()
argument_list|,
name|metrics
operator|.
name|getOccupiedMapSlots
argument_list|()
argument_list|,
name|metrics
operator|.
name|getOccupiedReduceSlots
argument_list|()
argument_list|,
name|metrics
operator|.
name|getMapSlotCapacity
argument_list|()
argument_list|,
name|metrics
operator|.
name|getReduceSlotCapacity
argument_list|()
argument_list|,
name|cluster
operator|.
name|getJobTrackerStatus
argument_list|()
argument_list|,
name|metrics
operator|.
name|getDecommissionedTaskTrackerCount
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
DECL|method|arrayToStringList (TaskTrackerInfo[] objs)
specifier|private
name|Collection
argument_list|<
name|String
argument_list|>
name|arrayToStringList
parameter_list|(
name|TaskTrackerInfo
index|[]
name|objs
parameter_list|)
block|{
name|Collection
argument_list|<
name|String
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|TaskTrackerInfo
name|info
range|:
name|objs
control|)
block|{
name|list
operator|.
name|add
argument_list|(
name|info
operator|.
name|getTaskTrackerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|list
return|;
block|}
DECL|method|arrayToBlackListInfo (TaskTrackerInfo[] objs)
specifier|private
name|Collection
argument_list|<
name|BlackListInfo
argument_list|>
name|arrayToBlackListInfo
parameter_list|(
name|TaskTrackerInfo
index|[]
name|objs
parameter_list|)
block|{
name|Collection
argument_list|<
name|BlackListInfo
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<
name|BlackListInfo
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|TaskTrackerInfo
name|info
range|:
name|objs
control|)
block|{
name|BlackListInfo
name|binfo
init|=
operator|new
name|BlackListInfo
argument_list|()
decl_stmt|;
name|binfo
operator|.
name|setTrackerName
argument_list|(
name|info
operator|.
name|getTaskTrackerName
argument_list|()
argument_list|)
expr_stmt|;
name|binfo
operator|.
name|setReasonForBlackListing
argument_list|(
name|info
operator|.
name|getReasonForBlacklist
argument_list|()
argument_list|)
expr_stmt|;
name|binfo
operator|.
name|setBlackListReport
argument_list|(
name|info
operator|.
name|getBlacklistReport
argument_list|()
argument_list|)
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|binfo
argument_list|)
expr_stmt|;
block|}
return|return
name|list
return|;
block|}
comment|/**    * Get status information about the Map-Reduce cluster.    *      * @param  detailed if true then get a detailed status including the    *         tracker names    * @return the status information about the Map-Reduce cluster as an object    *         of {@link ClusterStatus}.    * @throws IOException    */
DECL|method|getClusterStatus (boolean detailed)
specifier|public
name|ClusterStatus
name|getClusterStatus
parameter_list|(
name|boolean
name|detailed
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|ClusterMetrics
name|metrics
init|=
name|cluster
operator|.
name|getClusterStatus
argument_list|()
decl_stmt|;
return|return
operator|new
name|ClusterStatus
argument_list|(
name|arrayToStringList
argument_list|(
name|cluster
operator|.
name|getActiveTaskTrackers
argument_list|()
argument_list|)
argument_list|,
name|arrayToBlackListInfo
argument_list|(
name|cluster
operator|.
name|getBlackListedTaskTrackers
argument_list|()
argument_list|)
argument_list|,
name|cluster
operator|.
name|getTaskTrackerExpiryInterval
argument_list|()
argument_list|,
name|metrics
operator|.
name|getOccupiedMapSlots
argument_list|()
argument_list|,
name|metrics
operator|.
name|getOccupiedReduceSlots
argument_list|()
argument_list|,
name|metrics
operator|.
name|getMapSlotCapacity
argument_list|()
argument_list|,
name|metrics
operator|.
name|getReduceSlotCapacity
argument_list|()
argument_list|,
name|cluster
operator|.
name|getJobTrackerStatus
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**     * Get the jobs that are not completed and not failed.    *     * @return array of {@link JobStatus} for the running/to-be-run jobs.    * @throws IOException    */
DECL|method|jobsToComplete ()
specifier|public
name|JobStatus
index|[]
name|jobsToComplete
parameter_list|()
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|JobStatus
argument_list|>
name|stats
init|=
operator|new
name|ArrayList
argument_list|<
name|JobStatus
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|JobStatus
name|stat
range|:
name|getAllJobs
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|stat
operator|.
name|isJobComplete
argument_list|()
condition|)
block|{
name|stats
operator|.
name|add
argument_list|(
name|stat
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|stats
operator|.
name|toArray
argument_list|(
operator|new
name|JobStatus
index|[
literal|0
index|]
argument_list|)
return|;
block|}
comment|/**     * Get the jobs that are submitted.    *     * @return array of {@link JobStatus} for the submitted jobs.    * @throws IOException    */
DECL|method|getAllJobs ()
specifier|public
name|JobStatus
index|[]
name|getAllJobs
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
index|[]
name|jobs
init|=
name|cluster
operator|.
name|getAllJobStatuses
argument_list|()
decl_stmt|;
name|JobStatus
index|[]
name|stats
init|=
operator|new
name|JobStatus
index|[
name|jobs
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|jobs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|stats
index|[
name|i
index|]
operator|=
name|JobStatus
operator|.
name|downgrade
argument_list|(
name|jobs
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|stats
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**     * Utility that submits a job, then polls for progress until the job is    * complete.    *     * @param job the job configuration.    * @throws IOException if the job fails    */
DECL|method|runJob (JobConf job)
specifier|public
specifier|static
name|RunningJob
name|runJob
parameter_list|(
name|JobConf
name|job
parameter_list|)
throws|throws
name|IOException
block|{
name|JobClient
name|jc
init|=
operator|new
name|JobClient
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|RunningJob
name|rj
init|=
name|jc
operator|.
name|submitJob
argument_list|(
name|job
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|jc
operator|.
name|monitorAndPrintJob
argument_list|(
name|job
argument_list|,
name|rj
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Job failed!"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
return|return
name|rj
return|;
block|}
comment|/**    * Monitor a job and print status in real-time as progress is made and tasks     * fail.    * @param conf the job's configuration    * @param job the job to track    * @return true if the job succeeded    * @throws IOException if communication to the JobTracker fails    */
DECL|method|monitorAndPrintJob (JobConf conf, RunningJob job )
specifier|public
name|boolean
name|monitorAndPrintJob
parameter_list|(
name|JobConf
name|conf
parameter_list|,
name|RunningJob
name|job
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
operator|(
operator|(
name|NetworkedJob
operator|)
name|job
operator|)
operator|.
name|monitorAndPrintJob
argument_list|()
return|;
block|}
DECL|method|getTaskLogURL (TaskAttemptID taskId, String baseUrl)
specifier|static
name|String
name|getTaskLogURL
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|String
name|baseUrl
parameter_list|)
block|{
return|return
operator|(
name|baseUrl
operator|+
literal|"/tasklog?plaintext=true&attemptid="
operator|+
name|taskId
operator|)
return|;
block|}
DECL|method|getConfiguration (String jobTrackerSpec)
specifier|static
name|Configuration
name|getConfiguration
parameter_list|(
name|String
name|jobTrackerSpec
parameter_list|)
block|{
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
if|if
condition|(
name|jobTrackerSpec
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|jobTrackerSpec
operator|.
name|indexOf
argument_list|(
literal|":"
argument_list|)
operator|>=
literal|0
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"mapred.job.tracker"
argument_list|,
name|jobTrackerSpec
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|String
name|classpathFile
init|=
literal|"hadoop-"
operator|+
name|jobTrackerSpec
operator|+
literal|".xml"
decl_stmt|;
name|URL
name|validate
init|=
name|conf
operator|.
name|getResource
argument_list|(
name|classpathFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|validate
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|classpathFile
operator|+
literal|" not found on CLASSPATH"
argument_list|)
throw|;
block|}
name|conf
operator|.
name|addResource
argument_list|(
name|classpathFile
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|conf
return|;
block|}
comment|/**    * Sets the output filter for tasks. only those tasks are printed whose    * output matches the filter.     * @param newValue task filter.    */
annotation|@
name|Deprecated
DECL|method|setTaskOutputFilter (TaskStatusFilter newValue)
specifier|public
name|void
name|setTaskOutputFilter
parameter_list|(
name|TaskStatusFilter
name|newValue
parameter_list|)
block|{
name|this
operator|.
name|taskOutputFilter
operator|=
name|newValue
expr_stmt|;
block|}
comment|/**    * Get the task output filter out of the JobConf.    *     * @param job the JobConf to examine.    * @return the filter level.    */
DECL|method|getTaskOutputFilter (JobConf job)
specifier|public
specifier|static
name|TaskStatusFilter
name|getTaskOutputFilter
parameter_list|(
name|JobConf
name|job
parameter_list|)
block|{
return|return
name|TaskStatusFilter
operator|.
name|valueOf
argument_list|(
name|job
operator|.
name|get
argument_list|(
literal|"jobclient.output.filter"
argument_list|,
literal|"FAILED"
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Modify the JobConf to set the task output filter.    *     * @param job the JobConf to modify.    * @param newValue the value to set.    */
DECL|method|setTaskOutputFilter (JobConf job, TaskStatusFilter newValue)
specifier|public
specifier|static
name|void
name|setTaskOutputFilter
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|TaskStatusFilter
name|newValue
parameter_list|)
block|{
name|job
operator|.
name|set
argument_list|(
literal|"jobclient.output.filter"
argument_list|,
name|newValue
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Returns task output filter.    * @return task filter.     */
annotation|@
name|Deprecated
DECL|method|getTaskOutputFilter ()
specifier|public
name|TaskStatusFilter
name|getTaskOutputFilter
parameter_list|()
block|{
return|return
name|this
operator|.
name|taskOutputFilter
return|;
block|}
DECL|method|getCounter (org.apache.hadoop.mapreduce.Counters cntrs, String counterGroupName, String counterName)
specifier|protected
name|long
name|getCounter
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Counters
name|cntrs
parameter_list|,
name|String
name|counterGroupName
parameter_list|,
name|String
name|counterName
parameter_list|)
throws|throws
name|IOException
block|{
name|Counters
name|counters
init|=
name|Counters
operator|.
name|downgrade
argument_list|(
name|cntrs
argument_list|)
decl_stmt|;
return|return
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGroupName
argument_list|,
name|counterName
argument_list|)
operator|.
name|getValue
argument_list|()
return|;
block|}
comment|/**    * Get status information about the max available Maps in the cluster.    *      * @return the max available Maps in the cluster    * @throws IOException    */
DECL|method|getDefaultMaps ()
specifier|public
name|int
name|getDefaultMaps
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|cluster
operator|.
name|getClusterStatus
argument_list|()
operator|.
name|getMapSlotCapacity
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get status information about the max available Reduces in the cluster.    *      * @return the max available Reduces in the cluster    * @throws IOException    */
DECL|method|getDefaultReduces ()
specifier|public
name|int
name|getDefaultReduces
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|cluster
operator|.
name|getClusterStatus
argument_list|()
operator|.
name|getReduceSlotCapacity
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Grab the jobtracker system directory path where job-specific files are to be placed.    *     * @return the system directory where job-specific files are to be placed.    */
DECL|method|getSystemDir ()
specifier|public
name|Path
name|getSystemDir
parameter_list|()
block|{
try|try
block|{
return|return
name|cluster
operator|.
name|getSystemDir
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
block|}
DECL|method|getJobQueueInfoArray (QueueInfo[] queues)
specifier|private
name|JobQueueInfo
index|[]
name|getJobQueueInfoArray
parameter_list|(
name|QueueInfo
index|[]
name|queues
parameter_list|)
throws|throws
name|IOException
block|{
name|JobQueueInfo
index|[]
name|ret
init|=
operator|new
name|JobQueueInfo
index|[
name|queues
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|queues
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ret
index|[
name|i
index|]
operator|=
operator|new
name|JobQueueInfo
argument_list|(
name|queues
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * Returns an array of queue information objects about root level queues    * configured    *    * @return the array of root level JobQueueInfo objects    * @throws IOException    */
DECL|method|getRootQueues ()
specifier|public
name|JobQueueInfo
index|[]
name|getRootQueues
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|getJobQueueInfoArray
argument_list|(
name|cluster
operator|.
name|getRootQueues
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Returns an array of queue information objects about immediate children    * of queue queueName.    *     * @param queueName    * @return the array of immediate children JobQueueInfo objects    * @throws IOException    */
DECL|method|getChildQueues (String queueName)
specifier|public
name|JobQueueInfo
index|[]
name|getChildQueues
parameter_list|(
name|String
name|queueName
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|getJobQueueInfoArray
argument_list|(
name|cluster
operator|.
name|getChildQueues
argument_list|(
name|queueName
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Return an array of queue information objects about all the Job Queues    * configured.    *     * @return Array of JobQueueInfo objects    * @throws IOException    */
DECL|method|getQueues ()
specifier|public
name|JobQueueInfo
index|[]
name|getQueues
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|getJobQueueInfoArray
argument_list|(
name|cluster
operator|.
name|getQueues
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Gets all the jobs which were added to particular Job Queue    *     * @param queueName name of the Job Queue    * @return Array of jobs present in the job queue    * @throws IOException    */
DECL|method|getJobsFromQueue (String queueName)
specifier|public
name|JobStatus
index|[]
name|getJobsFromQueue
parameter_list|(
name|String
name|queueName
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|QueueInfo
name|queue
init|=
name|cluster
operator|.
name|getQueue
argument_list|(
name|queueName
argument_list|)
decl_stmt|;
if|if
condition|(
name|queue
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
index|[]
name|stats
init|=
name|queue
operator|.
name|getJobStatuses
argument_list|()
decl_stmt|;
name|JobStatus
index|[]
name|ret
init|=
operator|new
name|JobStatus
index|[
name|stats
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stats
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ret
index|[
name|i
index|]
operator|=
name|JobStatus
operator|.
name|downgrade
argument_list|(
name|stats
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Gets the queue information associated to a particular Job Queue    *     * @param queueName name of the job queue.    * @return Queue information associated to particular queue.    * @throws IOException    */
DECL|method|getQueueInfo (String queueName)
specifier|public
name|JobQueueInfo
name|getQueueInfo
parameter_list|(
name|String
name|queueName
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|QueueInfo
name|queueInfo
init|=
name|cluster
operator|.
name|getQueue
argument_list|(
name|queueName
argument_list|)
decl_stmt|;
if|if
condition|(
name|queueInfo
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|JobQueueInfo
argument_list|(
name|queueInfo
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Gets the Queue ACLs for current user    * @return array of QueueAclsInfo object for current user.    * @throws IOException    */
DECL|method|getQueueAclsForCurrentUser ()
specifier|public
name|QueueAclsInfo
index|[]
name|getQueueAclsForCurrentUser
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|QueueAclsInfo
index|[]
name|acls
init|=
name|cluster
operator|.
name|getQueueAclsForCurrentUser
argument_list|()
decl_stmt|;
name|QueueAclsInfo
index|[]
name|ret
init|=
operator|new
name|QueueAclsInfo
index|[
name|acls
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|acls
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ret
index|[
name|i
index|]
operator|=
name|QueueAclsInfo
operator|.
name|downgrade
argument_list|(
name|acls
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get a delegation token for the user from the JobTracker.    * @param renewer the user who can renew the token    * @return the new token    * @throws IOException    */
specifier|public
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
DECL|method|getDelegationToken (Text renewer)
name|getDelegationToken
parameter_list|(
name|Text
name|renewer
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
name|cluster
operator|.
name|getDelegationToken
argument_list|(
name|renewer
argument_list|)
return|;
block|}
comment|/**    * Renew a delegation token    * @param token the token to renew    * @return true if the renewal went well    * @throws InvalidToken    * @throws IOException    */
DECL|method|renewDelegationToken (Token<DelegationTokenIdentifier> token )
specifier|public
name|long
name|renewDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|InvalidToken
throws|,
name|IOException
throws|,
name|InterruptedException
block|{
return|return
name|cluster
operator|.
name|renewDelegationToken
argument_list|(
name|token
argument_list|)
return|;
block|}
comment|/**    * Cancel a delegation token from the JobTracker    * @param token the token to cancel    * @throws IOException    */
DECL|method|cancelDelegationToken (Token<DelegationTokenIdentifier> token )
specifier|public
name|void
name|cancelDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|InvalidToken
throws|,
name|IOException
throws|,
name|InterruptedException
block|{
name|cluster
operator|.
name|cancelDelegationToken
argument_list|(
name|token
argument_list|)
expr_stmt|;
block|}
comment|/**    */
DECL|method|main (String argv[])
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
name|argv
index|[]
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|res
init|=
name|ToolRunner
operator|.
name|run
argument_list|(
operator|new
name|JobClient
argument_list|()
argument_list|,
name|argv
argument_list|)
decl_stmt|;
name|System
operator|.
name|exit
argument_list|(
name|res
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

