begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|NoSuchAlgorithmException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|KeyGenerator
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|SecretKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|fasterxml
operator|.
name|jackson
operator|.
name|core
operator|.
name|JsonParseException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|fasterxml
operator|.
name|jackson
operator|.
name|databind
operator|.
name|JsonMappingException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|fasterxml
operator|.
name|jackson
operator|.
name|databind
operator|.
name|ObjectMapper
import|;
end_import

begin_import
import|import
name|com
operator|.
name|fasterxml
operator|.
name|jackson
operator|.
name|databind
operator|.
name|ObjectReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|QueueACL
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|QueueManager
operator|.
name|toFullPropertyName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|counters
operator|.
name|Limits
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|filecache
operator|.
name|DistributedCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|protocol
operator|.
name|ClientProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|TokenCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|split
operator|.
name|JobSplitWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|AccessControlList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|ReservationId
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Charsets
import|;
end_import

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|class|JobSubmitter
class|class
name|JobSubmitter
block|{
DECL|field|LOG
specifier|protected
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|JobSubmitter
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|READER
specifier|private
specifier|static
specifier|final
name|ObjectReader
name|READER
init|=
operator|new
name|ObjectMapper
argument_list|()
operator|.
name|readerFor
argument_list|(
name|Map
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|SHUFFLE_KEYGEN_ALGORITHM
specifier|private
specifier|static
specifier|final
name|String
name|SHUFFLE_KEYGEN_ALGORITHM
init|=
literal|"HmacSHA1"
decl_stmt|;
DECL|field|SHUFFLE_KEY_LENGTH
specifier|private
specifier|static
specifier|final
name|int
name|SHUFFLE_KEY_LENGTH
init|=
literal|64
decl_stmt|;
DECL|field|jtFs
specifier|private
name|FileSystem
name|jtFs
decl_stmt|;
DECL|field|submitClient
specifier|private
name|ClientProtocol
name|submitClient
decl_stmt|;
DECL|field|submitHostName
specifier|private
name|String
name|submitHostName
decl_stmt|;
DECL|field|submitHostAddress
specifier|private
name|String
name|submitHostAddress
decl_stmt|;
DECL|method|JobSubmitter (FileSystem submitFs, ClientProtocol submitClient)
name|JobSubmitter
parameter_list|(
name|FileSystem
name|submitFs
parameter_list|,
name|ClientProtocol
name|submitClient
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|submitClient
operator|=
name|submitClient
expr_stmt|;
name|this
operator|.
name|jtFs
operator|=
name|submitFs
expr_stmt|;
block|}
comment|/**    * configure the jobconf of the user with the command line options of     * -libjars, -files, -archives.    * @param job    * @throws IOException    */
DECL|method|copyAndConfigureFiles (Job job, Path jobSubmitDir)
specifier|private
name|void
name|copyAndConfigureFiles
parameter_list|(
name|Job
name|job
parameter_list|,
name|Path
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|boolean
name|useWildcards
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|Job
operator|.
name|USE_WILDCARD_FOR_LIBJARS
argument_list|,
name|Job
operator|.
name|DEFAULT_USE_WILDCARD_FOR_LIBJARS
argument_list|)
decl_stmt|;
name|JobResourceUploader
name|rUploader
init|=
operator|new
name|JobResourceUploader
argument_list|(
name|jtFs
argument_list|,
name|useWildcards
argument_list|)
decl_stmt|;
name|rUploader
operator|.
name|uploadResources
argument_list|(
name|job
argument_list|,
name|jobSubmitDir
argument_list|)
expr_stmt|;
comment|// Get the working directory. If not set, sets it to filesystem working dir
comment|// This code has been added so that working directory reset before running
comment|// the job. This is necessary for backward compatibility as other systems
comment|// might use the public API JobConf#setWorkingDirectory to reset the working
comment|// directory.
name|job
operator|.
name|getWorkingDirectory
argument_list|()
expr_stmt|;
block|}
comment|/**    * Internal method for submitting jobs to the system.    *     *<p>The job submission process involves:    *<ol>    *<li>    *   Checking the input and output specifications of the job.    *</li>    *<li>    *   Computing the {@link InputSplit}s for the job.    *</li>    *<li>    *   Setup the requisite accounting information for the     *   {@link DistributedCache} of the job, if necessary.    *</li>    *<li>    *   Copying the job's jar and configuration to the map-reduce system    *   directory on the distributed file-system.     *</li>    *<li>    *   Submitting the job to the<code>JobTracker</code> and optionally    *   monitoring it's status.    *</li>    *</ol></p>    * @param job the configuration to submit    * @param cluster the handle to the Cluster    * @throws ClassNotFoundException    * @throws InterruptedException    * @throws IOException    */
DECL|method|submitJobInternal (Job job, Cluster cluster)
name|JobStatus
name|submitJobInternal
parameter_list|(
name|Job
name|job
parameter_list|,
name|Cluster
name|cluster
parameter_list|)
throws|throws
name|ClassNotFoundException
throws|,
name|InterruptedException
throws|,
name|IOException
block|{
comment|//validate the jobs output specs
name|checkSpecs
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|addMRFrameworkToDistributedCache
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|Path
name|jobStagingArea
init|=
name|JobSubmissionFiles
operator|.
name|getStagingDir
argument_list|(
name|cluster
argument_list|,
name|conf
argument_list|)
decl_stmt|;
comment|//configure the command line options correctly on the submitting dfs
name|InetAddress
name|ip
init|=
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
decl_stmt|;
if|if
condition|(
name|ip
operator|!=
literal|null
condition|)
block|{
name|submitHostAddress
operator|=
name|ip
operator|.
name|getHostAddress
argument_list|()
expr_stmt|;
name|submitHostName
operator|=
name|ip
operator|.
name|getHostName
argument_list|()
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOST
argument_list|,
name|submitHostName
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOSTADDR
argument_list|,
name|submitHostAddress
argument_list|)
expr_stmt|;
block|}
name|JobID
name|jobId
init|=
name|submitClient
operator|.
name|getNewJobID
argument_list|()
decl_stmt|;
name|job
operator|.
name|setJobID
argument_list|(
name|jobId
argument_list|)
expr_stmt|;
name|Path
name|submitJobDir
init|=
operator|new
name|Path
argument_list|(
name|jobStagingArea
argument_list|,
name|jobId
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|JobStatus
name|status
init|=
literal|null
decl_stmt|;
try|try
block|{
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|USER_NAME
argument_list|,
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
literal|"hadoop.http.filter.initializers"
argument_list|,
literal|"org.apache.hadoop.yarn.server.webproxy.amfilter.AmFilterInitializer"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_DIR
argument_list|,
name|submitJobDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Configuring job "
operator|+
name|jobId
operator|+
literal|" with "
operator|+
name|submitJobDir
operator|+
literal|" as the submit dir"
argument_list|)
expr_stmt|;
comment|// get delegation token for the dir
name|TokenCache
operator|.
name|obtainTokensForNamenodes
argument_list|(
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|,
operator|new
name|Path
index|[]
block|{
name|submitJobDir
block|}
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|populateTokenCache
argument_list|(
name|conf
argument_list|,
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
expr_stmt|;
comment|// generate a secret to authenticate shuffle transfers
if|if
condition|(
name|TokenCache
operator|.
name|getShuffleSecretKey
argument_list|(
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
operator|==
literal|null
condition|)
block|{
name|KeyGenerator
name|keyGen
decl_stmt|;
try|try
block|{
name|keyGen
operator|=
name|KeyGenerator
operator|.
name|getInstance
argument_list|(
name|SHUFFLE_KEYGEN_ALGORITHM
argument_list|)
expr_stmt|;
name|keyGen
operator|.
name|init
argument_list|(
name|SHUFFLE_KEY_LENGTH
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchAlgorithmException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Error generating shuffle secret key"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|SecretKey
name|shuffleKey
init|=
name|keyGen
operator|.
name|generateKey
argument_list|()
decl_stmt|;
name|TokenCache
operator|.
name|setShuffleSecretKey
argument_list|(
name|shuffleKey
operator|.
name|getEncoded
argument_list|()
argument_list|,
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|CryptoUtils
operator|.
name|isEncryptedSpillEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|conf
operator|.
name|setInt
argument_list|(
name|MRJobConfig
operator|.
name|MR_AM_MAX_ATTEMPTS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Max job attempts set to 1 since encrypted intermediate"
operator|+
literal|"data spill is enabled"
argument_list|)
expr_stmt|;
block|}
name|copyAndConfigureFiles
argument_list|(
name|job
argument_list|,
name|submitJobDir
argument_list|)
expr_stmt|;
name|Path
name|submitJobFile
init|=
name|JobSubmissionFiles
operator|.
name|getJobConfPath
argument_list|(
name|submitJobDir
argument_list|)
decl_stmt|;
comment|// Create the splits for the job
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating splits at "
operator|+
name|jtFs
operator|.
name|makeQualified
argument_list|(
name|submitJobDir
argument_list|)
argument_list|)
expr_stmt|;
name|int
name|maps
init|=
name|writeSplits
argument_list|(
name|job
argument_list|,
name|submitJobDir
argument_list|)
decl_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|MRJobConfig
operator|.
name|NUM_MAPS
argument_list|,
name|maps
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"number of splits:"
operator|+
name|maps
argument_list|)
expr_stmt|;
name|int
name|maxMaps
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|JOB_MAX_MAP
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_JOB_MAX_MAP
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxMaps
operator|>=
literal|0
operator|&&
name|maxMaps
operator|<
name|maps
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The number of map tasks "
operator|+
name|maps
operator|+
literal|" exceeded limit "
operator|+
name|maxMaps
argument_list|)
throw|;
block|}
comment|// write "queue admins of the queue to which job is being submitted"
comment|// to job file.
name|String
name|queue
init|=
name|conf
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|QUEUE_NAME
argument_list|,
name|JobConf
operator|.
name|DEFAULT_QUEUE_NAME
argument_list|)
decl_stmt|;
name|AccessControlList
name|acl
init|=
name|submitClient
operator|.
name|getQueueAdmins
argument_list|(
name|queue
argument_list|)
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|toFullPropertyName
argument_list|(
name|queue
argument_list|,
name|QueueACL
operator|.
name|ADMINISTER_JOBS
operator|.
name|getAclName
argument_list|()
argument_list|)
argument_list|,
name|acl
operator|.
name|getAclString
argument_list|()
argument_list|)
expr_stmt|;
comment|// removing jobtoken referrals before copying the jobconf to HDFS
comment|// as the tasks don't need this setting, actually they may break
comment|// because of it if present as the referral will point to a
comment|// different job.
name|TokenCache
operator|.
name|cleanUpTokenReferral
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|MRJobConfig
operator|.
name|JOB_TOKEN_TRACKING_IDS_ENABLED
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED
argument_list|)
condition|)
block|{
comment|// Add HDFS tracking ids
name|ArrayList
argument_list|<
name|String
argument_list|>
name|trackingIds
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|t
range|:
name|job
operator|.
name|getCredentials
argument_list|()
operator|.
name|getAllTokens
argument_list|()
control|)
block|{
name|trackingIds
operator|.
name|add
argument_list|(
name|t
operator|.
name|decodeIdentifier
argument_list|()
operator|.
name|getTrackingId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setStrings
argument_list|(
name|MRJobConfig
operator|.
name|JOB_TOKEN_TRACKING_IDS
argument_list|,
name|trackingIds
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|trackingIds
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Set reservation info if it exists
name|ReservationId
name|reservationId
init|=
name|job
operator|.
name|getReservationId
argument_list|()
decl_stmt|;
if|if
condition|(
name|reservationId
operator|!=
literal|null
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|RESERVATION_ID
argument_list|,
name|reservationId
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Write job file to submit dir
name|writeConf
argument_list|(
name|conf
argument_list|,
name|submitJobFile
argument_list|)
expr_stmt|;
name|Limits
operator|.
name|reset
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|//
comment|// Now, actually submit the job (using the submit name)
comment|//
name|printTokens
argument_list|(
name|jobId
argument_list|,
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
expr_stmt|;
name|status
operator|=
name|submitClient
operator|.
name|submitJob
argument_list|(
name|jobId
argument_list|,
name|submitJobDir
operator|.
name|toString
argument_list|()
argument_list|,
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
block|{
return|return
name|status
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not launch job"
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|status
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleaning up the staging area "
operator|+
name|submitJobDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|jtFs
operator|!=
literal|null
operator|&&
name|submitJobDir
operator|!=
literal|null
condition|)
name|jtFs
operator|.
name|delete
argument_list|(
name|submitJobDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|checkSpecs (Job job)
specifier|private
name|void
name|checkSpecs
parameter_list|(
name|Job
name|job
parameter_list|)
throws|throws
name|ClassNotFoundException
throws|,
name|InterruptedException
throws|,
name|IOException
block|{
name|JobConf
name|jConf
init|=
operator|(
name|JobConf
operator|)
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
comment|// Check the output specification
if|if
condition|(
name|jConf
operator|.
name|getNumReduceTasks
argument_list|()
operator|==
literal|0
condition|?
name|jConf
operator|.
name|getUseNewMapper
argument_list|()
else|:
name|jConf
operator|.
name|getUseNewReducer
argument_list|()
condition|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|output
init|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|job
operator|.
name|getOutputFormatClass
argument_list|()
argument_list|,
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|output
operator|.
name|checkOutputSpecs
argument_list|(
name|job
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|jConf
operator|.
name|getOutputFormat
argument_list|()
operator|.
name|checkOutputSpecs
argument_list|(
name|jtFs
argument_list|,
name|jConf
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|writeConf (Configuration conf, Path jobFile)
specifier|private
name|void
name|writeConf
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Path
name|jobFile
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Write job file to JobTracker's fs
name|FSDataOutputStream
name|out
init|=
name|FileSystem
operator|.
name|create
argument_list|(
name|jtFs
argument_list|,
name|jobFile
argument_list|,
operator|new
name|FsPermission
argument_list|(
name|JobSubmissionFiles
operator|.
name|JOB_FILE_PERMISSION
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|conf
operator|.
name|writeXml
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|printTokens (JobID jobId, Credentials credentials)
specifier|private
name|void
name|printTokens
parameter_list|(
name|JobID
name|jobId
parameter_list|,
name|Credentials
name|credentials
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Submitting tokens for job: "
operator|+
name|jobId
argument_list|)
expr_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
argument_list|>
name|token
range|:
name|credentials
operator|.
name|getAllTokens
argument_list|()
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|token
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
parameter_list|<
name|T
extends|extends
name|InputSplit
parameter_list|>
DECL|method|writeNewSplits (JobContext job, Path jobSubmitDir)
name|int
name|writeNewSplits
parameter_list|(
name|JobContext
name|job
parameter_list|,
name|Path
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
throws|,
name|ClassNotFoundException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|InputFormat
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|input
init|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|job
operator|.
name|getInputFormatClass
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|InputSplit
argument_list|>
name|splits
init|=
name|input
operator|.
name|getSplits
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|T
index|[]
name|array
init|=
operator|(
name|T
index|[]
operator|)
name|splits
operator|.
name|toArray
argument_list|(
operator|new
name|InputSplit
index|[
name|splits
operator|.
name|size
argument_list|()
index|]
argument_list|)
decl_stmt|;
comment|// sort the splits into order based on size, so that the biggest
comment|// go first
name|Arrays
operator|.
name|sort
argument_list|(
name|array
argument_list|,
operator|new
name|SplitComparator
argument_list|()
argument_list|)
expr_stmt|;
name|JobSplitWriter
operator|.
name|createSplitFiles
argument_list|(
name|jobSubmitDir
argument_list|,
name|conf
argument_list|,
name|jobSubmitDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|array
argument_list|)
expr_stmt|;
return|return
name|array
operator|.
name|length
return|;
block|}
DECL|method|writeSplits (org.apache.hadoop.mapreduce.JobContext job, Path jobSubmitDir)
specifier|private
name|int
name|writeSplits
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
name|job
parameter_list|,
name|Path
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
throws|,
name|ClassNotFoundException
block|{
name|JobConf
name|jConf
init|=
operator|(
name|JobConf
operator|)
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|int
name|maps
decl_stmt|;
if|if
condition|(
name|jConf
operator|.
name|getUseNewMapper
argument_list|()
condition|)
block|{
name|maps
operator|=
name|writeNewSplits
argument_list|(
name|job
argument_list|,
name|jobSubmitDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|maps
operator|=
name|writeOldSplits
argument_list|(
name|jConf
argument_list|,
name|jobSubmitDir
argument_list|)
expr_stmt|;
block|}
return|return
name|maps
return|;
block|}
comment|//method to write splits for old api mapper.
DECL|method|writeOldSplits (JobConf job, Path jobSubmitDir)
specifier|private
name|int
name|writeOldSplits
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|Path
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
index|[]
name|splits
init|=
name|job
operator|.
name|getInputFormat
argument_list|()
operator|.
name|getSplits
argument_list|(
name|job
argument_list|,
name|job
operator|.
name|getNumMapTasks
argument_list|()
argument_list|)
decl_stmt|;
comment|// sort the splits into order based on size, so that the biggest
comment|// go first
name|Arrays
operator|.
name|sort
argument_list|(
name|splits
argument_list|,
operator|new
name|Comparator
argument_list|<
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
argument_list|>
argument_list|()
block|{
specifier|public
name|int
name|compare
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
name|a
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|InputSplit
name|b
parameter_list|)
block|{
try|try
block|{
name|long
name|left
init|=
name|a
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|long
name|right
init|=
name|b
operator|.
name|getLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|left
operator|==
name|right
condition|)
block|{
return|return
literal|0
return|;
block|}
elseif|else
if|if
condition|(
name|left
operator|<
name|right
condition|)
block|{
return|return
literal|1
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Problem getting input split size"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
name|JobSplitWriter
operator|.
name|createSplitFiles
argument_list|(
name|jobSubmitDir
argument_list|,
name|job
argument_list|,
name|jobSubmitDir
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
argument_list|,
name|splits
argument_list|)
expr_stmt|;
return|return
name|splits
operator|.
name|length
return|;
block|}
DECL|class|SplitComparator
specifier|private
specifier|static
class|class
name|SplitComparator
implements|implements
name|Comparator
argument_list|<
name|InputSplit
argument_list|>
block|{
annotation|@
name|Override
DECL|method|compare (InputSplit o1, InputSplit o2)
specifier|public
name|int
name|compare
parameter_list|(
name|InputSplit
name|o1
parameter_list|,
name|InputSplit
name|o2
parameter_list|)
block|{
try|try
block|{
name|long
name|len1
init|=
name|o1
operator|.
name|getLength
argument_list|()
decl_stmt|;
name|long
name|len2
init|=
name|o2
operator|.
name|getLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|len1
operator|<
name|len2
condition|)
block|{
return|return
literal|1
return|;
block|}
elseif|else
if|if
condition|(
name|len1
operator|==
name|len2
condition|)
block|{
return|return
literal|0
return|;
block|}
else|else
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"exception in compare"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"exception in compare"
argument_list|,
name|ie
argument_list|)
throw|;
block|}
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
DECL|method|readTokensFromFiles (Configuration conf, Credentials credentials)
specifier|private
name|void
name|readTokensFromFiles
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Credentials
name|credentials
parameter_list|)
throws|throws
name|IOException
block|{
comment|// add tokens and secrets coming from a token storage file
name|String
name|binaryTokenFilename
init|=
name|conf
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_CREDENTIALS_BINARY
argument_list|)
decl_stmt|;
if|if
condition|(
name|binaryTokenFilename
operator|!=
literal|null
condition|)
block|{
name|Credentials
name|binary
init|=
name|Credentials
operator|.
name|readTokenStorageFile
argument_list|(
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
name|binaryTokenFilename
argument_list|)
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|credentials
operator|.
name|addAll
argument_list|(
name|binary
argument_list|)
expr_stmt|;
block|}
comment|// add secret keys coming from a json file
name|String
name|tokensFileName
init|=
name|conf
operator|.
name|get
argument_list|(
literal|"mapreduce.job.credentials.json"
argument_list|)
decl_stmt|;
if|if
condition|(
name|tokensFileName
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"loading user's secret keys from "
operator|+
name|tokensFileName
argument_list|)
expr_stmt|;
name|String
name|localFileName
init|=
operator|new
name|Path
argument_list|(
name|tokensFileName
argument_list|)
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
decl_stmt|;
try|try
block|{
comment|// read JSON
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|nm
init|=
name|READER
operator|.
name|readValue
argument_list|(
operator|new
name|File
argument_list|(
name|localFileName
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|ent
range|:
name|nm
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|credentials
operator|.
name|addSecretKey
argument_list|(
operator|new
name|Text
argument_list|(
name|ent
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|,
name|ent
operator|.
name|getValue
argument_list|()
operator|.
name|getBytes
argument_list|(
name|Charsets
operator|.
name|UTF_8
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|JsonMappingException
decl||
name|JsonParseException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"couldn't parse Token Cache JSON file with user secret keys"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//get secret keys and tokens and store them into TokenCache
DECL|method|populateTokenCache (Configuration conf, Credentials credentials)
specifier|private
name|void
name|populateTokenCache
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Credentials
name|credentials
parameter_list|)
throws|throws
name|IOException
block|{
name|readTokensFromFiles
argument_list|(
name|conf
argument_list|,
name|credentials
argument_list|)
expr_stmt|;
comment|// add the delegation tokens from configuration
name|String
index|[]
name|nameNodes
init|=
name|conf
operator|.
name|getStrings
argument_list|(
name|MRJobConfig
operator|.
name|JOB_NAMENODES
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"adding the following namenodes' delegation tokens:"
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|nameNodes
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|nameNodes
operator|!=
literal|null
condition|)
block|{
name|Path
index|[]
name|ps
init|=
operator|new
name|Path
index|[
name|nameNodes
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nameNodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|ps
index|[
name|i
index|]
operator|=
operator|new
name|Path
argument_list|(
name|nameNodes
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
name|TokenCache
operator|.
name|obtainTokensForNamenodes
argument_list|(
name|credentials
argument_list|,
name|ps
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|addMRFrameworkToDistributedCache (Configuration conf)
specifier|private
specifier|static
name|void
name|addMRFrameworkToDistributedCache
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|framework
init|=
name|conf
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_APPLICATION_FRAMEWORK_PATH
argument_list|,
literal|""
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|framework
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|URI
name|uri
decl_stmt|;
try|try
block|{
name|uri
operator|=
operator|new
name|URI
argument_list|(
name|framework
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Unable to parse '"
operator|+
name|framework
operator|+
literal|"' as a URI, check the setting for "
operator|+
name|MRJobConfig
operator|.
name|MAPREDUCE_APPLICATION_FRAMEWORK_PATH
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|String
name|linkedName
init|=
name|uri
operator|.
name|getFragment
argument_list|()
decl_stmt|;
comment|// resolve any symlinks in the URI path so using a "current" symlink
comment|// to point to a specific version shows the specific version
comment|// in the distributed cache configuration
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Path
name|frameworkPath
init|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
name|uri
operator|.
name|getScheme
argument_list|()
argument_list|,
name|uri
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|uri
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|FileContext
name|fc
init|=
name|FileContext
operator|.
name|getFileContext
argument_list|(
name|frameworkPath
operator|.
name|toUri
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|frameworkPath
operator|=
name|fc
operator|.
name|resolvePath
argument_list|(
name|frameworkPath
argument_list|)
expr_stmt|;
name|uri
operator|=
name|frameworkPath
operator|.
name|toUri
argument_list|()
expr_stmt|;
try|try
block|{
name|uri
operator|=
operator|new
name|URI
argument_list|(
name|uri
operator|.
name|getScheme
argument_list|()
argument_list|,
name|uri
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|uri
operator|.
name|getPath
argument_list|()
argument_list|,
literal|null
argument_list|,
name|linkedName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|DistributedCache
operator|.
name|addCacheArchive
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

