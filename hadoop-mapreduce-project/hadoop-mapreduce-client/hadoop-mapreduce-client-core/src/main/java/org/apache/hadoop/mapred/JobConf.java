begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLDecoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Enumeration
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|RawComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|CompressionCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|HashPartitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|KeyFieldBasedComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|KeyFieldBasedPartitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|filecache
operator|.
name|DistributedCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|util
operator|.
name|ConfigUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|log4j
operator|.
name|Level
import|;
end_import

begin_comment
comment|/**   * A map/reduce job configuration.  *   *<p><code>JobConf</code> is the primary interface for a user to describe a   * map-reduce job to the Hadoop framework for execution. The framework tries to  * faithfully execute the job as-is described by<code>JobConf</code>, however:  *<ol>  *<li>  *   Some configuration parameters might have been marked as   *<a href="{@docRoot}/org/apache/hadoop/conf/Configuration.html#FinalParams">  *   final</a> by administrators and hence cannot be altered.  *</li>  *<li>  *   While some job parameters are straight-forward to set   *   (e.g. {@link #setNumReduceTasks(int)}), some parameters interact subtly   *   rest of the framework and/or job-configuration and is relatively more   *   complex for the user to control finely (e.g. {@link #setNumMapTasks(int)}).  *</li>  *</ol></p>  *   *<p><code>JobConf</code> typically specifies the {@link Mapper}, combiner   * (if any), {@link Partitioner}, {@link Reducer}, {@link InputFormat} and   * {@link OutputFormat} implementations to be used etc.  *  *<p>Optionally<code>JobConf</code> is used to specify other advanced facets   * of the job such as<code>Comparator</code>s to be used, files to be put in    * the {@link DistributedCache}, whether or not intermediate and/or job outputs   * are to be compressed (and how), debugability via user-provided scripts   * ( {@link #setMapDebugScript(String)}/{@link #setReduceDebugScript(String)}),  * for doing post-processing on task logs, task's stdout, stderr, syslog.   * and etc.</p>  *   *<p>Here is an example on how to configure a job via<code>JobConf</code>:</p>  *<p><blockquote><pre>  *     // Create a new JobConf  *     JobConf job = new JobConf(new Configuration(), MyJob.class);  *       *     // Specify various job-specific parameters       *     job.setJobName("myjob");  *       *     FileInputFormat.setInputPaths(job, new Path("in"));  *     FileOutputFormat.setOutputPath(job, new Path("out"));  *       *     job.setMapperClass(MyJob.MyMapper.class);  *     job.setCombinerClass(MyJob.MyReducer.class);  *     job.setReducerClass(MyJob.MyReducer.class);  *       *     job.setInputFormat(SequenceFileInputFormat.class);  *     job.setOutputFormat(SequenceFileOutputFormat.class);  *</pre></blockquote></p>  *   * @see JobClient  * @see ClusterStatus  * @see Tool  * @see DistributedCache  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Stable
DECL|class|JobConf
specifier|public
class|class
name|JobConf
extends|extends
name|Configuration
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|JobConf
operator|.
name|class
argument_list|)
decl_stmt|;
static|static
block|{
name|ConfigUtil
operator|.
name|loadResources
argument_list|()
expr_stmt|;
block|}
comment|/**    * @deprecated Use {@link #MAPRED_JOB_MAP_MEMORY_MB_PROPERTY} and    * {@link #MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY}    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_MAXVMEM_PROPERTY
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_MAXVMEM_PROPERTY
init|=
literal|"mapred.task.maxvmem"
decl_stmt|;
comment|/**    * @deprecated     */
annotation|@
name|Deprecated
DECL|field|UPPER_LIMIT_ON_TASK_VMEM_PROPERTY
specifier|public
specifier|static
specifier|final
name|String
name|UPPER_LIMIT_ON_TASK_VMEM_PROPERTY
init|=
literal|"mapred.task.limit.maxvmem"
decl_stmt|;
comment|/**    * @deprecated    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY
init|=
literal|"mapred.task.default.maxvmem"
decl_stmt|;
comment|/**    * @deprecated    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_MAXPMEM_PROPERTY
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_MAXPMEM_PROPERTY
init|=
literal|"mapred.task.maxpmem"
decl_stmt|;
comment|/**    * A value which if set for memory related configuration options,    * indicates that the options are turned off.    */
DECL|field|DISABLED_MEMORY_LIMIT
specifier|public
specifier|static
specifier|final
name|long
name|DISABLED_MEMORY_LIMIT
init|=
operator|-
literal|1L
decl_stmt|;
comment|/**    * Property name for the configuration property mapreduce.cluster.local.dir    */
DECL|field|MAPRED_LOCAL_DIR_PROPERTY
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_LOCAL_DIR_PROPERTY
init|=
name|MRConfig
operator|.
name|LOCAL_DIR
decl_stmt|;
comment|/**    * Name of the queue to which jobs will be submitted, if no queue    * name is mentioned.    */
DECL|field|DEFAULT_QUEUE_NAME
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_QUEUE_NAME
init|=
literal|"default"
decl_stmt|;
DECL|field|MAPRED_JOB_MAP_MEMORY_MB_PROPERTY
specifier|static
specifier|final
name|String
name|MAPRED_JOB_MAP_MEMORY_MB_PROPERTY
init|=
name|JobContext
operator|.
name|MAP_MEMORY_MB
decl_stmt|;
DECL|field|MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY
specifier|static
specifier|final
name|String
name|MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY
init|=
name|JobContext
operator|.
name|REDUCE_MEMORY_MB
decl_stmt|;
comment|/** Pattern for the default unpacking behavior for job jars */
DECL|field|UNPACK_JAR_PATTERN_DEFAULT
specifier|public
specifier|static
specifier|final
name|Pattern
name|UNPACK_JAR_PATTERN_DEFAULT
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"(?:classes/|lib/).*"
argument_list|)
decl_stmt|;
comment|/**    * Configuration key to set the java command line options for the child    * map and reduce tasks.    *     * Java opts for the task tracker child processes.    * The following symbol, if present, will be interpolated: @taskid@.     * It is replaced by current TaskID. Any other occurrences of '@' will go     * unchanged.    * For example, to enable verbose gc logging to a file named for the taskid in    * /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:    *          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    *     * The configuration variable {@link #MAPRED_TASK_ENV} can be used to pass     * other environment variables to the child processes.    *     * @deprecated Use {@link #MAPRED_MAP_TASK_JAVA_OPTS} or     *                 {@link #MAPRED_REDUCE_TASK_JAVA_OPTS}    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_JAVA_OPTS
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_JAVA_OPTS
init|=
literal|"mapred.child.java.opts"
decl_stmt|;
comment|/**    * Configuration key to set the java command line options for the map tasks.    *     * Java opts for the task tracker child map processes.    * The following symbol, if present, will be interpolated: @taskid@.     * It is replaced by current TaskID. Any other occurrences of '@' will go     * unchanged.    * For example, to enable verbose gc logging to a file named for the taskid in    * /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:    *          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    *     * The configuration variable {@link #MAPRED_MAP_TASK_ENV} can be used to pass     * other environment variables to the map processes.    */
DECL|field|MAPRED_MAP_TASK_JAVA_OPTS
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_MAP_TASK_JAVA_OPTS
init|=
name|JobContext
operator|.
name|MAP_JAVA_OPTS
decl_stmt|;
comment|/**    * Configuration key to set the java command line options for the reduce tasks.    *     * Java opts for the task tracker child reduce processes.    * The following symbol, if present, will be interpolated: @taskid@.     * It is replaced by current TaskID. Any other occurrences of '@' will go     * unchanged.    * For example, to enable verbose gc logging to a file named for the taskid in    * /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:    *          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    *     * The configuration variable {@link #MAPRED_REDUCE_TASK_ENV} can be used to     * pass process environment variables to the reduce processes.    */
DECL|field|MAPRED_REDUCE_TASK_JAVA_OPTS
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_REDUCE_TASK_JAVA_OPTS
init|=
name|JobContext
operator|.
name|REDUCE_JAVA_OPTS
decl_stmt|;
DECL|field|DEFAULT_MAPRED_TASK_JAVA_OPTS
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_MAPRED_TASK_JAVA_OPTS
init|=
literal|"-Xmx200m"
decl_stmt|;
comment|/**    * @deprecated    * Configuration key to set the maximum virtual memory available to the child    * map and reduce tasks (in kilo-bytes). This has been deprecated and will no    * longer have any effect.    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_ULIMIT
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_ULIMIT
init|=
literal|"mapred.child.ulimit"
decl_stmt|;
comment|/**    * @deprecated    * Configuration key to set the maximum virtual memory available to the    * map tasks (in kilo-bytes). This has been deprecated and will no    * longer have any effect.    */
annotation|@
name|Deprecated
DECL|field|MAPRED_MAP_TASK_ULIMIT
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_MAP_TASK_ULIMIT
init|=
literal|"mapreduce.map.ulimit"
decl_stmt|;
comment|/**    * @deprecated    * Configuration key to set the maximum virtual memory available to the    * reduce tasks (in kilo-bytes). This has been deprecated and will no    * longer have any effect.    */
annotation|@
name|Deprecated
DECL|field|MAPRED_REDUCE_TASK_ULIMIT
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_REDUCE_TASK_ULIMIT
init|=
literal|"mapreduce.reduce.ulimit"
decl_stmt|;
comment|/**    * Configuration key to set the environment of the child map/reduce tasks.    *     * The format of the value is<code>k1=v1,k2=v2</code>. Further it can     * reference existing environment variables via<code>$key</code>.    *     * Example:    *<ul>    *<li> A=foo - This will set the env variable A to foo.</li>    *<li> B=$X:c This is inherit tasktracker's X env variable.</li>    *</ul>    *     * @deprecated Use {@link #MAPRED_MAP_TASK_ENV} or     *                 {@link #MAPRED_REDUCE_TASK_ENV}    */
annotation|@
name|Deprecated
DECL|field|MAPRED_TASK_ENV
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_TASK_ENV
init|=
literal|"mapred.child.env"
decl_stmt|;
comment|/**    * Configuration key to set the maximum virutal memory available to the    * map tasks.    *     * The format of the value is<code>k1=v1,k2=v2</code>. Further it can     * reference existing environment variables via<code>$key</code>.    *     * Example:    *<ul>    *<li> A=foo - This will set the env variable A to foo.</li>    *<li> B=$X:c This is inherit tasktracker's X env variable.</li>    *</ul>    */
DECL|field|MAPRED_MAP_TASK_ENV
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_MAP_TASK_ENV
init|=
name|JobContext
operator|.
name|MAP_ENV
decl_stmt|;
comment|/**    * Configuration key to set the maximum virutal memory available to the    * reduce tasks.    *     * The format of the value is<code>k1=v1,k2=v2</code>. Further it can     * reference existing environment variables via<code>$key</code>.    *     * Example:    *<ul>    *<li> A=foo - This will set the env variable A to foo.</li>    *<li> B=$X:c This is inherit tasktracker's X env variable.</li>    *</ul>    */
DECL|field|MAPRED_REDUCE_TASK_ENV
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_REDUCE_TASK_ENV
init|=
name|JobContext
operator|.
name|REDUCE_ENV
decl_stmt|;
DECL|field|credentials
specifier|private
name|Credentials
name|credentials
init|=
operator|new
name|Credentials
argument_list|()
decl_stmt|;
comment|/**    * Configuration key to set the logging {@link Level} for the map task.    *    * The allowed logging levels are:    * OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL.    */
DECL|field|MAPRED_MAP_TASK_LOG_LEVEL
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_MAP_TASK_LOG_LEVEL
init|=
name|JobContext
operator|.
name|MAP_LOG_LEVEL
decl_stmt|;
comment|/**    * Configuration key to set the logging {@link Level} for the reduce task.    *    * The allowed logging levels are:    * OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL.    */
DECL|field|MAPRED_REDUCE_TASK_LOG_LEVEL
specifier|public
specifier|static
specifier|final
name|String
name|MAPRED_REDUCE_TASK_LOG_LEVEL
init|=
name|JobContext
operator|.
name|REDUCE_LOG_LEVEL
decl_stmt|;
comment|/**    * Default logging level for map/reduce tasks.    */
DECL|field|DEFAULT_LOG_LEVEL
specifier|public
specifier|static
specifier|final
name|Level
name|DEFAULT_LOG_LEVEL
init|=
name|Level
operator|.
name|INFO
decl_stmt|;
comment|/**    * Construct a map/reduce job configuration.    */
DECL|method|JobConf ()
specifier|public
name|JobConf
parameter_list|()
block|{
name|checkAndWarnDeprecation
argument_list|()
expr_stmt|;
block|}
comment|/**     * Construct a map/reduce job configuration.    *     * @param exampleClass a class whose containing jar is used as the job's jar.    */
DECL|method|JobConf (Class exampleClass)
specifier|public
name|JobConf
parameter_list|(
name|Class
name|exampleClass
parameter_list|)
block|{
name|setJarByClass
argument_list|(
name|exampleClass
argument_list|)
expr_stmt|;
name|checkAndWarnDeprecation
argument_list|()
expr_stmt|;
block|}
comment|/**    * Construct a map/reduce job configuration.    *     * @param conf a Configuration whose settings will be inherited.    */
DECL|method|JobConf (Configuration conf)
specifier|public
name|JobConf
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|instanceof
name|JobConf
condition|)
block|{
name|JobConf
name|that
init|=
operator|(
name|JobConf
operator|)
name|conf
decl_stmt|;
name|credentials
operator|=
name|that
operator|.
name|credentials
expr_stmt|;
block|}
name|checkAndWarnDeprecation
argument_list|()
expr_stmt|;
block|}
comment|/** Construct a map/reduce job configuration.    *     * @param conf a Configuration whose settings will be inherited.    * @param exampleClass a class whose containing jar is used as the job's jar.    */
DECL|method|JobConf (Configuration conf, Class exampleClass)
specifier|public
name|JobConf
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Class
name|exampleClass
parameter_list|)
block|{
name|this
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|setJarByClass
argument_list|(
name|exampleClass
argument_list|)
expr_stmt|;
block|}
comment|/** Construct a map/reduce configuration.    *    * @param config a Configuration-format XML job description file.    */
DECL|method|JobConf (String config)
specifier|public
name|JobConf
parameter_list|(
name|String
name|config
parameter_list|)
block|{
name|this
argument_list|(
operator|new
name|Path
argument_list|(
name|config
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/** Construct a map/reduce configuration.    *    * @param config a Configuration-format XML job description file.    */
DECL|method|JobConf (Path config)
specifier|public
name|JobConf
parameter_list|(
name|Path
name|config
parameter_list|)
block|{
name|super
argument_list|()
expr_stmt|;
name|addResource
argument_list|(
name|config
argument_list|)
expr_stmt|;
name|checkAndWarnDeprecation
argument_list|()
expr_stmt|;
block|}
comment|/** A new map/reduce configuration where the behavior of reading from the    * default resources can be turned off.    *<p/>    * If the parameter {@code loadDefaults} is false, the new instance    * will not load resources from the default files.    *    * @param loadDefaults specifies whether to load from the default files    */
DECL|method|JobConf (boolean loadDefaults)
specifier|public
name|JobConf
parameter_list|(
name|boolean
name|loadDefaults
parameter_list|)
block|{
name|super
argument_list|(
name|loadDefaults
argument_list|)
expr_stmt|;
name|checkAndWarnDeprecation
argument_list|()
expr_stmt|;
block|}
comment|/**    * Get credentials for the job.    * @return credentials for the job    */
DECL|method|getCredentials ()
specifier|public
name|Credentials
name|getCredentials
parameter_list|()
block|{
return|return
name|credentials
return|;
block|}
DECL|method|setCredentials (Credentials credentials)
name|void
name|setCredentials
parameter_list|(
name|Credentials
name|credentials
parameter_list|)
block|{
name|this
operator|.
name|credentials
operator|=
name|credentials
expr_stmt|;
block|}
comment|/**    * Get the user jar for the map-reduce job.    *     * @return the user jar for the map-reduce job.    */
DECL|method|getJar ()
specifier|public
name|String
name|getJar
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|JAR
argument_list|)
return|;
block|}
comment|/**    * Set the user jar for the map-reduce job.    *     * @param jar the user jar for the map-reduce job.    */
DECL|method|setJar (String jar)
specifier|public
name|void
name|setJar
parameter_list|(
name|String
name|jar
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|JAR
argument_list|,
name|jar
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the pattern for jar contents to unpack on the tasktracker    */
DECL|method|getJarUnpackPattern ()
specifier|public
name|Pattern
name|getJarUnpackPattern
parameter_list|()
block|{
return|return
name|getPattern
argument_list|(
name|JobContext
operator|.
name|JAR_UNPACK_PATTERN
argument_list|,
name|UNPACK_JAR_PATTERN_DEFAULT
argument_list|)
return|;
block|}
comment|/**    * Set the job's jar file by finding an example class location.    *     * @param cls the example class.    */
DECL|method|setJarByClass (Class cls)
specifier|public
name|void
name|setJarByClass
parameter_list|(
name|Class
name|cls
parameter_list|)
block|{
name|String
name|jar
init|=
name|findContainingJar
argument_list|(
name|cls
argument_list|)
decl_stmt|;
if|if
condition|(
name|jar
operator|!=
literal|null
condition|)
block|{
name|setJar
argument_list|(
name|jar
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|getLocalDirs ()
specifier|public
name|String
index|[]
name|getLocalDirs
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getTrimmedStrings
argument_list|(
name|MRConfig
operator|.
name|LOCAL_DIR
argument_list|)
return|;
block|}
comment|/**    * Use MRAsyncDiskService.moveAndDeleteAllVolumes instead.    */
annotation|@
name|Deprecated
DECL|method|deleteLocalFiles ()
specifier|public
name|void
name|deleteLocalFiles
parameter_list|()
throws|throws
name|IOException
block|{
name|String
index|[]
name|localDirs
init|=
name|getLocalDirs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|localDirs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|this
argument_list|)
operator|.
name|delete
argument_list|(
operator|new
name|Path
argument_list|(
name|localDirs
index|[
name|i
index|]
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|deleteLocalFiles (String subdir)
specifier|public
name|void
name|deleteLocalFiles
parameter_list|(
name|String
name|subdir
parameter_list|)
throws|throws
name|IOException
block|{
name|String
index|[]
name|localDirs
init|=
name|getLocalDirs
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|localDirs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|this
argument_list|)
operator|.
name|delete
argument_list|(
operator|new
name|Path
argument_list|(
name|localDirs
index|[
name|i
index|]
argument_list|,
name|subdir
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**     * Constructs a local file name. Files are distributed among configured    * local directories.    */
DECL|method|getLocalPath (String pathString)
specifier|public
name|Path
name|getLocalPath
parameter_list|(
name|String
name|pathString
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getLocalPath
argument_list|(
name|MRConfig
operator|.
name|LOCAL_DIR
argument_list|,
name|pathString
argument_list|)
return|;
block|}
comment|/**    * Get the reported username for this job.    *     * @return the username    */
DECL|method|getUser ()
specifier|public
name|String
name|getUser
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|USER_NAME
argument_list|)
return|;
block|}
comment|/**    * Set the reported username for this job.    *     * @param user the username for this job.    */
DECL|method|setUser (String user)
specifier|public
name|void
name|setUser
parameter_list|(
name|String
name|user
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|USER_NAME
argument_list|,
name|user
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set whether the framework should keep the intermediate files for     * failed tasks.    *     * @param keep<code>true</code> if framework should keep the intermediate files     *             for failed tasks,<code>false</code> otherwise.    *     */
DECL|method|setKeepFailedTaskFiles (boolean keep)
specifier|public
name|void
name|setKeepFailedTaskFiles
parameter_list|(
name|boolean
name|keep
parameter_list|)
block|{
name|setBoolean
argument_list|(
name|JobContext
operator|.
name|PRESERVE_FAILED_TASK_FILES
argument_list|,
name|keep
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should the temporary files for failed tasks be kept?    *     * @return should the files be kept?    */
DECL|method|getKeepFailedTaskFiles ()
specifier|public
name|boolean
name|getKeepFailedTaskFiles
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
name|JobContext
operator|.
name|PRESERVE_FAILED_TASK_FILES
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set a regular expression for task names that should be kept.     * The regular expression ".*_m_000123_0" would keep the files    * for the first instance of map 123 that ran.    *     * @param pattern the java.util.regex.Pattern to match against the     *        task names.    */
DECL|method|setKeepTaskFilesPattern (String pattern)
specifier|public
name|void
name|setKeepTaskFilesPattern
parameter_list|(
name|String
name|pattern
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|PRESERVE_FILES_PATTERN
argument_list|,
name|pattern
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the regular expression that is matched against the task names    * to see if we need to keep the files.    *     * @return the pattern as a string, if it was set, othewise null.    */
DECL|method|getKeepTaskFilesPattern ()
specifier|public
name|String
name|getKeepTaskFilesPattern
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|PRESERVE_FILES_PATTERN
argument_list|)
return|;
block|}
comment|/**    * Set the current working directory for the default file system.    *     * @param dir the new current working directory.    */
DECL|method|setWorkingDirectory (Path dir)
specifier|public
name|void
name|setWorkingDirectory
parameter_list|(
name|Path
name|dir
parameter_list|)
block|{
name|dir
operator|=
operator|new
name|Path
argument_list|(
name|getWorkingDirectory
argument_list|()
argument_list|,
name|dir
argument_list|)
expr_stmt|;
name|set
argument_list|(
name|JobContext
operator|.
name|WORKING_DIR
argument_list|,
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the current working directory for the default file system.    *     * @return the directory name.    */
DECL|method|getWorkingDirectory ()
specifier|public
name|Path
name|getWorkingDirectory
parameter_list|()
block|{
name|String
name|name
init|=
name|get
argument_list|(
name|JobContext
operator|.
name|WORKING_DIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|name
operator|!=
literal|null
condition|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|name
argument_list|)
return|;
block|}
else|else
block|{
try|try
block|{
name|Path
name|dir
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|this
argument_list|)
operator|.
name|getWorkingDirectory
argument_list|()
decl_stmt|;
name|set
argument_list|(
name|JobContext
operator|.
name|WORKING_DIR
argument_list|,
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|dir
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Sets the number of tasks that a spawned task JVM should run    * before it exits    * @param numTasks the number of tasks to execute; defaults to 1;    * -1 signifies no limit    */
DECL|method|setNumTasksToExecutePerJvm (int numTasks)
specifier|public
name|void
name|setNumTasksToExecutePerJvm
parameter_list|(
name|int
name|numTasks
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|JVM_NUMTASKS_TORUN
argument_list|,
name|numTasks
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the number of tasks that a spawned JVM should execute    */
DECL|method|getNumTasksToExecutePerJvm ()
specifier|public
name|int
name|getNumTasksToExecutePerJvm
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|JVM_NUMTASKS_TORUN
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Get the {@link InputFormat} implementation for the map-reduce job,    * defaults to {@link TextInputFormat} if not specified explicity.    *     * @return the {@link InputFormat} implementation for the map-reduce job.    */
DECL|method|getInputFormat ()
specifier|public
name|InputFormat
name|getInputFormat
parameter_list|()
block|{
return|return
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|getClass
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|TextInputFormat
operator|.
name|class
argument_list|,
name|InputFormat
operator|.
name|class
argument_list|)
argument_list|,
name|this
argument_list|)
return|;
block|}
comment|/**    * Set the {@link InputFormat} implementation for the map-reduce job.    *     * @param theClass the {@link InputFormat} implementation for the map-reduce     *                 job.    */
DECL|method|setInputFormat (Class<? extends InputFormat> theClass)
specifier|public
name|void
name|setInputFormat
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|InputFormat
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.input.format.class"
argument_list|,
name|theClass
argument_list|,
name|InputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link OutputFormat} implementation for the map-reduce job,    * defaults to {@link TextOutputFormat} if not specified explicity.    *     * @return the {@link OutputFormat} implementation for the map-reduce job.    */
DECL|method|getOutputFormat ()
specifier|public
name|OutputFormat
name|getOutputFormat
parameter_list|()
block|{
return|return
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|getClass
argument_list|(
literal|"mapred.output.format.class"
argument_list|,
name|TextOutputFormat
operator|.
name|class
argument_list|,
name|OutputFormat
operator|.
name|class
argument_list|)
argument_list|,
name|this
argument_list|)
return|;
block|}
comment|/**    * Get the {@link OutputCommitter} implementation for the map-reduce job,    * defaults to {@link FileOutputCommitter} if not specified explicitly.    *     * @return the {@link OutputCommitter} implementation for the map-reduce job.    */
DECL|method|getOutputCommitter ()
specifier|public
name|OutputCommitter
name|getOutputCommitter
parameter_list|()
block|{
return|return
operator|(
name|OutputCommitter
operator|)
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|getClass
argument_list|(
literal|"mapred.output.committer.class"
argument_list|,
name|FileOutputCommitter
operator|.
name|class
argument_list|,
name|OutputCommitter
operator|.
name|class
argument_list|)
argument_list|,
name|this
argument_list|)
return|;
block|}
comment|/**    * Set the {@link OutputCommitter} implementation for the map-reduce job.    *     * @param theClass the {@link OutputCommitter} implementation for the map-reduce     *                 job.    */
DECL|method|setOutputCommitter (Class<? extends OutputCommitter> theClass)
specifier|public
name|void
name|setOutputCommitter
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|OutputCommitter
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.output.committer.class"
argument_list|,
name|theClass
argument_list|,
name|OutputCommitter
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the {@link OutputFormat} implementation for the map-reduce job.    *     * @param theClass the {@link OutputFormat} implementation for the map-reduce     *                 job.    */
DECL|method|setOutputFormat (Class<? extends OutputFormat> theClass)
specifier|public
name|void
name|setOutputFormat
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|OutputFormat
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.output.format.class"
argument_list|,
name|theClass
argument_list|,
name|OutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should the map outputs be compressed before transfer?    * Uses the SequenceFile compression.    *     * @param compress should the map outputs be compressed?    */
DECL|method|setCompressMapOutput (boolean compress)
specifier|public
name|void
name|setCompressMapOutput
parameter_list|(
name|boolean
name|compress
parameter_list|)
block|{
name|setBoolean
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_COMPRESS
argument_list|,
name|compress
argument_list|)
expr_stmt|;
block|}
comment|/**    * Are the outputs of the maps be compressed?    *     * @return<code>true</code> if the outputs of the maps are to be compressed,    *<code>false</code> otherwise.    */
DECL|method|getCompressMapOutput ()
specifier|public
name|boolean
name|getCompressMapOutput
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_COMPRESS
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set the given class as the  {@link CompressionCodec} for the map outputs.    *     * @param codecClass the {@link CompressionCodec} class that will compress      *                   the map outputs.    */
specifier|public
name|void
DECL|method|setMapOutputCompressorClass (Class<? extends CompressionCodec> codecClass)
name|setMapOutputCompressorClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|CompressionCodec
argument_list|>
name|codecClass
parameter_list|)
block|{
name|setCompressMapOutput
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setClass
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_COMPRESS_CODEC
argument_list|,
name|codecClass
argument_list|,
name|CompressionCodec
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link CompressionCodec} for compressing the map outputs.    *     * @param defaultValue the {@link CompressionCodec} to return if not set    * @return the {@link CompressionCodec} class that should be used to compress the     *         map outputs.    * @throws IllegalArgumentException if the class was specified, but not found    */
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|CompressionCodec
argument_list|>
DECL|method|getMapOutputCompressorClass (Class<? extends CompressionCodec> defaultValue)
name|getMapOutputCompressorClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|CompressionCodec
argument_list|>
name|defaultValue
parameter_list|)
block|{
name|Class
argument_list|<
name|?
extends|extends
name|CompressionCodec
argument_list|>
name|codecClass
init|=
name|defaultValue
decl_stmt|;
name|String
name|name
init|=
name|get
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_COMPRESS_CODEC
argument_list|)
decl_stmt|;
if|if
condition|(
name|name
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|codecClass
operator|=
name|getClassByName
argument_list|(
name|name
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|CompressionCodec
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Compression codec "
operator|+
name|name
operator|+
literal|" was not found."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|codecClass
return|;
block|}
comment|/**    * Get the key class for the map output data. If it is not set, use the    * (final) output key class. This allows the map output key class to be    * different than the final output key class.    *      * @return the map output key class.    */
DECL|method|getMapOutputKeyClass ()
specifier|public
name|Class
argument_list|<
name|?
argument_list|>
name|getMapOutputKeyClass
parameter_list|()
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|retv
init|=
name|getClass
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_KEY_CLASS
argument_list|,
literal|null
argument_list|,
name|Object
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|retv
operator|==
literal|null
condition|)
block|{
name|retv
operator|=
name|getOutputKeyClass
argument_list|()
expr_stmt|;
block|}
return|return
name|retv
return|;
block|}
comment|/**    * Set the key class for the map output data. This allows the user to    * specify the map output key class to be different than the final output    * value class.    *     * @param theClass the map output key class.    */
DECL|method|setMapOutputKeyClass (Class<?> theClass)
specifier|public
name|void
name|setMapOutputKeyClass
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_KEY_CLASS
argument_list|,
name|theClass
argument_list|,
name|Object
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the value class for the map output data. If it is not set, use the    * (final) output value class This allows the map output value class to be    * different than the final output value class.    *      * @return the map output value class.    */
DECL|method|getMapOutputValueClass ()
specifier|public
name|Class
argument_list|<
name|?
argument_list|>
name|getMapOutputValueClass
parameter_list|()
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|retv
init|=
name|getClass
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_VALUE_CLASS
argument_list|,
literal|null
argument_list|,
name|Object
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|retv
operator|==
literal|null
condition|)
block|{
name|retv
operator|=
name|getOutputValueClass
argument_list|()
expr_stmt|;
block|}
return|return
name|retv
return|;
block|}
comment|/**    * Set the value class for the map output data. This allows the user to    * specify the map output value class to be different than the final output    * value class.    *     * @param theClass the map output value class.    */
DECL|method|setMapOutputValueClass (Class<?> theClass)
specifier|public
name|void
name|setMapOutputValueClass
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|MAP_OUTPUT_VALUE_CLASS
argument_list|,
name|theClass
argument_list|,
name|Object
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the key class for the job output data.    *     * @return the key class for the job output data.    */
DECL|method|getOutputKeyClass ()
specifier|public
name|Class
argument_list|<
name|?
argument_list|>
name|getOutputKeyClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
name|JobContext
operator|.
name|OUTPUT_KEY_CLASS
argument_list|,
name|LongWritable
operator|.
name|class
argument_list|,
name|Object
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the key class for the job output data.    *     * @param theClass the key class for the job output data.    */
DECL|method|setOutputKeyClass (Class<?> theClass)
specifier|public
name|void
name|setOutputKeyClass
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|OUTPUT_KEY_CLASS
argument_list|,
name|theClass
argument_list|,
name|Object
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link RawComparator} comparator used to compare keys.    *     * @return the {@link RawComparator} comparator used to compare keys.    */
DECL|method|getOutputKeyComparator ()
specifier|public
name|RawComparator
name|getOutputKeyComparator
parameter_list|()
block|{
name|Class
argument_list|<
name|?
extends|extends
name|RawComparator
argument_list|>
name|theClass
init|=
name|getClass
argument_list|(
name|JobContext
operator|.
name|KEY_COMPARATOR
argument_list|,
literal|null
argument_list|,
name|RawComparator
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|theClass
operator|!=
literal|null
condition|)
return|return
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|theClass
argument_list|,
name|this
argument_list|)
return|;
return|return
name|WritableComparator
operator|.
name|get
argument_list|(
name|getMapOutputKeyClass
argument_list|()
operator|.
name|asSubclass
argument_list|(
name|WritableComparable
operator|.
name|class
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Set the {@link RawComparator} comparator used to compare keys.    *     * @param theClass the {@link RawComparator} comparator used to     *                 compare keys.    * @see #setOutputValueGroupingComparator(Class)                     */
DECL|method|setOutputKeyComparatorClass (Class<? extends RawComparator> theClass)
specifier|public
name|void
name|setOutputKeyComparatorClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|RawComparator
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|KEY_COMPARATOR
argument_list|,
name|theClass
argument_list|,
name|RawComparator
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the {@link KeyFieldBasedComparator} options used to compare keys.    *     * @param keySpec the key specification of the form -k pos1[,pos2], where,    *  pos is of the form f[.c][opts], where f is the number    *  of the key field to use, and c is the number of the first character from    *  the beginning of the field. Fields and character posns are numbered     *  starting with 1; a character position of zero in pos2 indicates the    *  field's last character. If '.c' is omitted from pos1, it defaults to 1    *  (the beginning of the field); if omitted from pos2, it defaults to 0     *  (the end of the field). opts are ordering options. The supported options    *  are:    *    -n, (Sort numerically)    *    -r, (Reverse the result of comparison)                     */
DECL|method|setKeyFieldComparatorOptions (String keySpec)
specifier|public
name|void
name|setKeyFieldComparatorOptions
parameter_list|(
name|String
name|keySpec
parameter_list|)
block|{
name|setOutputKeyComparatorClass
argument_list|(
name|KeyFieldBasedComparator
operator|.
name|class
argument_list|)
expr_stmt|;
name|set
argument_list|(
name|KeyFieldBasedComparator
operator|.
name|COMPARATOR_OPTIONS
argument_list|,
name|keySpec
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link KeyFieldBasedComparator} options    */
DECL|method|getKeyFieldComparatorOption ()
specifier|public
name|String
name|getKeyFieldComparatorOption
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|KeyFieldBasedComparator
operator|.
name|COMPARATOR_OPTIONS
argument_list|)
return|;
block|}
comment|/**    * Set the {@link KeyFieldBasedPartitioner} options used for     * {@link Partitioner}    *     * @param keySpec the key specification of the form -k pos1[,pos2], where,    *  pos is of the form f[.c][opts], where f is the number    *  of the key field to use, and c is the number of the first character from    *  the beginning of the field. Fields and character posns are numbered     *  starting with 1; a character position of zero in pos2 indicates the    *  field's last character. If '.c' is omitted from pos1, it defaults to 1    *  (the beginning of the field); if omitted from pos2, it defaults to 0     *  (the end of the field).    */
DECL|method|setKeyFieldPartitionerOptions (String keySpec)
specifier|public
name|void
name|setKeyFieldPartitionerOptions
parameter_list|(
name|String
name|keySpec
parameter_list|)
block|{
name|setPartitionerClass
argument_list|(
name|KeyFieldBasedPartitioner
operator|.
name|class
argument_list|)
expr_stmt|;
name|set
argument_list|(
name|KeyFieldBasedPartitioner
operator|.
name|PARTITIONER_OPTIONS
argument_list|,
name|keySpec
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link KeyFieldBasedPartitioner} options    */
DECL|method|getKeyFieldPartitionerOption ()
specifier|public
name|String
name|getKeyFieldPartitionerOption
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|KeyFieldBasedPartitioner
operator|.
name|PARTITIONER_OPTIONS
argument_list|)
return|;
block|}
comment|/**     * Get the user defined {@link WritableComparable} comparator for     * grouping keys of inputs to the reduce.    *     * @return comparator set by the user for grouping values.    * @see #setOutputValueGroupingComparator(Class) for details.      */
DECL|method|getOutputValueGroupingComparator ()
specifier|public
name|RawComparator
name|getOutputValueGroupingComparator
parameter_list|()
block|{
name|Class
argument_list|<
name|?
extends|extends
name|RawComparator
argument_list|>
name|theClass
init|=
name|getClass
argument_list|(
name|JobContext
operator|.
name|GROUP_COMPARATOR_CLASS
argument_list|,
literal|null
argument_list|,
name|RawComparator
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|theClass
operator|==
literal|null
condition|)
block|{
return|return
name|getOutputKeyComparator
argument_list|()
return|;
block|}
return|return
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|theClass
argument_list|,
name|this
argument_list|)
return|;
block|}
comment|/**     * Set the user defined {@link RawComparator} comparator for     * grouping keys in the input to the reduce.    *     *<p>This comparator should be provided if the equivalence rules for keys    * for sorting the intermediates are different from those for grouping keys    * before each call to     * {@link Reducer#reduce(Object, java.util.Iterator, OutputCollector, Reporter)}.</p>    *      *<p>For key-value pairs (K1,V1) and (K2,V2), the values (V1, V2) are passed    * in a single call to the reduce function if K1 and K2 compare as equal.</p>    *     *<p>Since {@link #setOutputKeyComparatorClass(Class)} can be used to control     * how keys are sorted, this can be used in conjunction to simulate     *<i>secondary sort on values</i>.</p>    *      *<p><i>Note</i>: This is not a guarantee of the reduce sort being     *<i>stable</i> in any sense. (In any case, with the order of available     * map-outputs to the reduce being non-deterministic, it wouldn't make     * that much sense.)</p>    *     * @param theClass the comparator class to be used for grouping keys.     *                 It should implement<code>RawComparator</code>.    * @see #setOutputKeyComparatorClass(Class)                     */
DECL|method|setOutputValueGroupingComparator ( Class<? extends RawComparator> theClass)
specifier|public
name|void
name|setOutputValueGroupingComparator
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|RawComparator
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|GROUP_COMPARATOR_CLASS
argument_list|,
name|theClass
argument_list|,
name|RawComparator
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should the framework use the new context-object code for running    * the mapper?    * @return true, if the new api should be used    */
DECL|method|getUseNewMapper ()
specifier|public
name|boolean
name|getUseNewMapper
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
literal|"mapred.mapper.new-api"
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set whether the framework should use the new api for the mapper.    * This is the default for jobs submitted with the new Job api.    * @param flag true, if the new api should be used    */
DECL|method|setUseNewMapper (boolean flag)
specifier|public
name|void
name|setUseNewMapper
parameter_list|(
name|boolean
name|flag
parameter_list|)
block|{
name|setBoolean
argument_list|(
literal|"mapred.mapper.new-api"
argument_list|,
name|flag
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should the framework use the new context-object code for running    * the reducer?    * @return true, if the new api should be used    */
DECL|method|getUseNewReducer ()
specifier|public
name|boolean
name|getUseNewReducer
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
literal|"mapred.reducer.new-api"
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set whether the framework should use the new api for the reducer.     * This is the default for jobs submitted with the new Job api.    * @param flag true, if the new api should be used    */
DECL|method|setUseNewReducer (boolean flag)
specifier|public
name|void
name|setUseNewReducer
parameter_list|(
name|boolean
name|flag
parameter_list|)
block|{
name|setBoolean
argument_list|(
literal|"mapred.reducer.new-api"
argument_list|,
name|flag
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the value class for job outputs.    *     * @return the value class for job outputs.    */
DECL|method|getOutputValueClass ()
specifier|public
name|Class
argument_list|<
name|?
argument_list|>
name|getOutputValueClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
name|JobContext
operator|.
name|OUTPUT_VALUE_CLASS
argument_list|,
name|Text
operator|.
name|class
argument_list|,
name|Object
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the value class for job outputs.    *     * @param theClass the value class for job outputs.    */
DECL|method|setOutputValueClass (Class<?> theClass)
specifier|public
name|void
name|setOutputValueClass
parameter_list|(
name|Class
argument_list|<
name|?
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
name|JobContext
operator|.
name|OUTPUT_VALUE_CLASS
argument_list|,
name|theClass
argument_list|,
name|Object
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link Mapper} class for the job.    *     * @return the {@link Mapper} class for the job.    */
DECL|method|getMapperClass ()
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Mapper
argument_list|>
name|getMapperClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
literal|"mapred.mapper.class"
argument_list|,
name|IdentityMapper
operator|.
name|class
argument_list|,
name|Mapper
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the {@link Mapper} class for the job.    *     * @param theClass the {@link Mapper} class for the job.    */
DECL|method|setMapperClass (Class<? extends Mapper> theClass)
specifier|public
name|void
name|setMapperClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|Mapper
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.mapper.class"
argument_list|,
name|theClass
argument_list|,
name|Mapper
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link MapRunnable} class for the job.    *     * @return the {@link MapRunnable} class for the job.    */
DECL|method|getMapRunnerClass ()
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|MapRunnable
argument_list|>
name|getMapRunnerClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
literal|"mapred.map.runner.class"
argument_list|,
name|MapRunner
operator|.
name|class
argument_list|,
name|MapRunnable
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Expert: Set the {@link MapRunnable} class for the job.    *     * Typically used to exert greater control on {@link Mapper}s.    *     * @param theClass the {@link MapRunnable} class for the job.    */
DECL|method|setMapRunnerClass (Class<? extends MapRunnable> theClass)
specifier|public
name|void
name|setMapRunnerClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|MapRunnable
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.map.runner.class"
argument_list|,
name|theClass
argument_list|,
name|MapRunnable
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link Partitioner} used to partition {@link Mapper}-outputs     * to be sent to the {@link Reducer}s.    *     * @return the {@link Partitioner} used to partition map-outputs.    */
DECL|method|getPartitionerClass ()
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Partitioner
argument_list|>
name|getPartitionerClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
literal|"mapred.partitioner.class"
argument_list|,
name|HashPartitioner
operator|.
name|class
argument_list|,
name|Partitioner
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the {@link Partitioner} class used to partition     * {@link Mapper}-outputs to be sent to the {@link Reducer}s.    *     * @param theClass the {@link Partitioner} used to partition map-outputs.    */
DECL|method|setPartitionerClass (Class<? extends Partitioner> theClass)
specifier|public
name|void
name|setPartitionerClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|Partitioner
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.partitioner.class"
argument_list|,
name|theClass
argument_list|,
name|Partitioner
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link Reducer} class for the job.    *     * @return the {@link Reducer} class for the job.    */
DECL|method|getReducerClass ()
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Reducer
argument_list|>
name|getReducerClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
literal|"mapred.reducer.class"
argument_list|,
name|IdentityReducer
operator|.
name|class
argument_list|,
name|Reducer
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the {@link Reducer} class for the job.    *     * @param theClass the {@link Reducer} class for the job.    */
DECL|method|setReducerClass (Class<? extends Reducer> theClass)
specifier|public
name|void
name|setReducerClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|Reducer
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.reducer.class"
argument_list|,
name|theClass
argument_list|,
name|Reducer
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the user-defined<i>combiner</i> class used to combine map-outputs     * before being sent to the reducers. Typically the combiner is same as the    * the {@link Reducer} for the job i.e. {@link #getReducerClass()}.    *     * @return the user-defined combiner class used to combine map-outputs.    */
DECL|method|getCombinerClass ()
specifier|public
name|Class
argument_list|<
name|?
extends|extends
name|Reducer
argument_list|>
name|getCombinerClass
parameter_list|()
block|{
return|return
name|getClass
argument_list|(
literal|"mapred.combiner.class"
argument_list|,
literal|null
argument_list|,
name|Reducer
operator|.
name|class
argument_list|)
return|;
block|}
comment|/**    * Set the user-defined<i>combiner</i> class used to combine map-outputs     * before being sent to the reducers.     *     *<p>The combiner is an application-specified aggregation operation, which    * can help cut down the amount of data transferred between the     * {@link Mapper} and the {@link Reducer}, leading to better performance.</p>    *     *<p>The framework may invoke the combiner 0, 1, or multiple times, in both    * the mapper and reducer tasks. In general, the combiner is called as the    * sort/merge result is written to disk. The combiner must:    *<ul>    *<li> be side-effect free</li>    *<li> have the same input and output key types and the same input and     *        output value types</li>    *</ul></p>    *     *<p>Typically the combiner is same as the<code>Reducer</code> for the      * job i.e. {@link #setReducerClass(Class)}.</p>    *     * @param theClass the user-defined combiner class used to combine     *                 map-outputs.    */
DECL|method|setCombinerClass (Class<? extends Reducer> theClass)
specifier|public
name|void
name|setCombinerClass
parameter_list|(
name|Class
argument_list|<
name|?
extends|extends
name|Reducer
argument_list|>
name|theClass
parameter_list|)
block|{
name|setClass
argument_list|(
literal|"mapred.combiner.class"
argument_list|,
name|theClass
argument_list|,
name|Reducer
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should speculative execution be used for this job?     * Defaults to<code>true</code>.    *     * @return<code>true</code> if speculative execution be used for this job,    *<code>false</code> otherwise.    */
DECL|method|getSpeculativeExecution ()
specifier|public
name|boolean
name|getSpeculativeExecution
parameter_list|()
block|{
return|return
operator|(
name|getMapSpeculativeExecution
argument_list|()
operator|||
name|getReduceSpeculativeExecution
argument_list|()
operator|)
return|;
block|}
comment|/**    * Turn speculative execution on or off for this job.     *     * @param speculativeExecution<code>true</code> if speculative execution     *                             should be turned on, else<code>false</code>.    */
DECL|method|setSpeculativeExecution (boolean speculativeExecution)
specifier|public
name|void
name|setSpeculativeExecution
parameter_list|(
name|boolean
name|speculativeExecution
parameter_list|)
block|{
name|setMapSpeculativeExecution
argument_list|(
name|speculativeExecution
argument_list|)
expr_stmt|;
name|setReduceSpeculativeExecution
argument_list|(
name|speculativeExecution
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should speculative execution be used for this job for map tasks?     * Defaults to<code>true</code>.    *     * @return<code>true</code> if speculative execution be     *                           used for this job for map tasks,    *<code>false</code> otherwise.    */
DECL|method|getMapSpeculativeExecution ()
specifier|public
name|boolean
name|getMapSpeculativeExecution
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
name|JobContext
operator|.
name|MAP_SPECULATIVE
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Turn speculative execution on or off for this job for map tasks.     *     * @param speculativeExecution<code>true</code> if speculative execution     *                             should be turned on for map tasks,    *                             else<code>false</code>.    */
DECL|method|setMapSpeculativeExecution (boolean speculativeExecution)
specifier|public
name|void
name|setMapSpeculativeExecution
parameter_list|(
name|boolean
name|speculativeExecution
parameter_list|)
block|{
name|setBoolean
argument_list|(
name|JobContext
operator|.
name|MAP_SPECULATIVE
argument_list|,
name|speculativeExecution
argument_list|)
expr_stmt|;
block|}
comment|/**    * Should speculative execution be used for this job for reduce tasks?     * Defaults to<code>true</code>.    *     * @return<code>true</code> if speculative execution be used     *                           for reduce tasks for this job,    *<code>false</code> otherwise.    */
DECL|method|getReduceSpeculativeExecution ()
specifier|public
name|boolean
name|getReduceSpeculativeExecution
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
name|JobContext
operator|.
name|REDUCE_SPECULATIVE
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Turn speculative execution on or off for this job for reduce tasks.     *     * @param speculativeExecution<code>true</code> if speculative execution     *                             should be turned on for reduce tasks,    *                             else<code>false</code>.    */
DECL|method|setReduceSpeculativeExecution (boolean speculativeExecution)
specifier|public
name|void
name|setReduceSpeculativeExecution
parameter_list|(
name|boolean
name|speculativeExecution
parameter_list|)
block|{
name|setBoolean
argument_list|(
name|JobContext
operator|.
name|REDUCE_SPECULATIVE
argument_list|,
name|speculativeExecution
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get configured the number of reduce tasks for this job.    * Defaults to<code>1</code>.    *     * @return the number of reduce tasks for this job.    */
DECL|method|getNumMapTasks ()
specifier|public
name|int
name|getNumMapTasks
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|NUM_MAPS
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Set the number of map tasks for this job.    *     *<p><i>Note</i>: This is only a<i>hint</i> to the framework. The actual     * number of spawned map tasks depends on the number of {@link InputSplit}s     * generated by the job's {@link InputFormat#getSplits(JobConf, int)}.    *      * A custom {@link InputFormat} is typically used to accurately control     * the number of map tasks for the job.</p>    *     *<h4 id="NoOfMaps">How many maps?</h4>    *     *<p>The number of maps is usually driven by the total size of the inputs     * i.e. total number of blocks of the input files.</p>    *      *<p>The right level of parallelism for maps seems to be around 10-100 maps     * per-node, although it has been set up to 300 or so for very cpu-light map     * tasks. Task setup takes awhile, so it is best if the maps take at least a     * minute to execute.</p>    *     *<p>The default behavior of file-based {@link InputFormat}s is to split the     * input into<i>logical</i> {@link InputSplit}s based on the total size, in     * bytes, of input files. However, the {@link FileSystem} blocksize of the     * input files is treated as an upper bound for input splits. A lower bound     * on the split size can be set via     *<a href="{@docRoot}/../mapred-default.html#mapreduce.input.fileinputformat.split.minsize">    * mapreduce.input.fileinputformat.split.minsize</a>.</p>    *      *<p>Thus, if you expect 10TB of input data and have a blocksize of 128MB,     * you'll end up with 82,000 maps, unless {@link #setNumMapTasks(int)} is     * used to set it even higher.</p>    *     * @param n the number of map tasks for this job.    * @see InputFormat#getSplits(JobConf, int)    * @see FileInputFormat    * @see FileSystem#getDefaultBlockSize()    * @see FileStatus#getBlockSize()    */
DECL|method|setNumMapTasks (int n)
specifier|public
name|void
name|setNumMapTasks
parameter_list|(
name|int
name|n
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|NUM_MAPS
argument_list|,
name|n
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get configured the number of reduce tasks for this job. Defaults to     *<code>1</code>.    *     * @return the number of reduce tasks for this job.    */
DECL|method|getNumReduceTasks ()
specifier|public
name|int
name|getNumReduceTasks
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|NUM_REDUCES
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Set the requisite number of reduce tasks for this job.    *     *<h4 id="NoOfReduces">How many reduces?</h4>    *     *<p>The right number of reduces seems to be<code>0.95</code> or     *<code>1.75</code> multiplied by (&lt;<i>no. of nodes</i>&gt; *     *<a href="{@docRoot}/../mapred-default.html#mapreduce.tasktracker.reduce.tasks.maximum">    * mapreduce.tasktracker.reduce.tasks.maximum</a>).    *</p>    *     *<p>With<code>0.95</code> all of the reduces can launch immediately and     * start transfering map outputs as the maps finish. With<code>1.75</code>     * the faster nodes will finish their first round of reduces and launch a     * second wave of reduces doing a much better job of load balancing.</p>    *     *<p>Increasing the number of reduces increases the framework overhead, but     * increases load balancing and lowers the cost of failures.</p>    *     *<p>The scaling factors above are slightly less than whole numbers to     * reserve a few reduce slots in the framework for speculative-tasks, failures    * etc.</p>     *    *<h4 id="ReducerNone">Reducer NONE</h4>    *     *<p>It is legal to set the number of reduce-tasks to<code>zero</code>.</p>    *     *<p>In this case the output of the map-tasks directly go to distributed     * file-system, to the path set by     * {@link FileOutputFormat#setOutputPath(JobConf, Path)}. Also, the     * framework doesn't sort the map-outputs before writing it out to HDFS.</p>    *     * @param n the number of reduce tasks for this job.    */
DECL|method|setNumReduceTasks (int n)
specifier|public
name|void
name|setNumReduceTasks
parameter_list|(
name|int
name|n
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|NUM_REDUCES
argument_list|,
name|n
argument_list|)
expr_stmt|;
block|}
comment|/**     * Get the configured number of maximum attempts that will be made to run a    * map task, as specified by the<code>mapreduce.map.maxattempts</code>    * property. If this property is not already set, the default is 4 attempts.    *      * @return the max number of attempts per map task.    */
DECL|method|getMaxMapAttempts ()
specifier|public
name|int
name|getMaxMapAttempts
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|MAP_MAX_ATTEMPTS
argument_list|,
literal|4
argument_list|)
return|;
block|}
comment|/**     * Expert: Set the number of maximum attempts that will be made to run a    * map task.    *     * @param n the number of attempts per map task.    */
DECL|method|setMaxMapAttempts (int n)
specifier|public
name|void
name|setMaxMapAttempts
parameter_list|(
name|int
name|n
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|MAP_MAX_ATTEMPTS
argument_list|,
name|n
argument_list|)
expr_stmt|;
block|}
comment|/**     * Get the configured number of maximum attempts  that will be made to run a    * reduce task, as specified by the<code>mapreduce.reduce.maxattempts</code>    * property. If this property is not already set, the default is 4 attempts.    *     * @return the max number of attempts per reduce task.    */
DECL|method|getMaxReduceAttempts ()
specifier|public
name|int
name|getMaxReduceAttempts
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|REDUCE_MAX_ATTEMPTS
argument_list|,
literal|4
argument_list|)
return|;
block|}
comment|/**     * Expert: Set the number of maximum attempts that will be made to run a    * reduce task.    *     * @param n the number of attempts per reduce task.    */
DECL|method|setMaxReduceAttempts (int n)
specifier|public
name|void
name|setMaxReduceAttempts
parameter_list|(
name|int
name|n
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|REDUCE_MAX_ATTEMPTS
argument_list|,
name|n
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the user-specified job name. This is only used to identify the     * job to the user.    *     * @return the job's name, defaulting to "".    */
DECL|method|getJobName ()
specifier|public
name|String
name|getJobName
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|JOB_NAME
argument_list|,
literal|""
argument_list|)
return|;
block|}
comment|/**    * Set the user-specified job name.    *     * @param name the job's new name.    */
DECL|method|setJobName (String name)
specifier|public
name|void
name|setJobName
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|JOB_NAME
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the user-specified session identifier. The default is the empty string.    *    * The session identifier is used to tag metric data that is reported to some    * performance metrics system via the org.apache.hadoop.metrics API.  The     * session identifier is intended, in particular, for use by Hadoop-On-Demand     * (HOD) which allocates a virtual Hadoop cluster dynamically and transiently.     * HOD will set the session identifier by modifying the mapred-site.xml file     * before starting the cluster.    *    * When not running under HOD, this identifer is expected to remain set to     * the empty string.    *    * @return the session identifier, defaulting to "".    */
annotation|@
name|Deprecated
DECL|method|getSessionId ()
specifier|public
name|String
name|getSessionId
parameter_list|()
block|{
return|return
name|get
argument_list|(
literal|"session.id"
argument_list|,
literal|""
argument_list|)
return|;
block|}
comment|/**    * Set the user-specified session identifier.      *    * @param sessionId the new session id.    */
annotation|@
name|Deprecated
DECL|method|setSessionId (String sessionId)
specifier|public
name|void
name|setSessionId
parameter_list|(
name|String
name|sessionId
parameter_list|)
block|{
name|set
argument_list|(
literal|"session.id"
argument_list|,
name|sessionId
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the maximum no. of failures of a given job per tasktracker.    * If the no. of task failures exceeds<code>noFailures</code>, the     * tasktracker is<i>blacklisted</i> for this job.     *     * @param noFailures maximum no. of failures of a given job per tasktracker.    */
DECL|method|setMaxTaskFailuresPerTracker (int noFailures)
specifier|public
name|void
name|setMaxTaskFailuresPerTracker
parameter_list|(
name|int
name|noFailures
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|MAX_TASK_FAILURES_PER_TRACKER
argument_list|,
name|noFailures
argument_list|)
expr_stmt|;
block|}
comment|/**    * Expert: Get the maximum no. of failures of a given job per tasktracker.    * If the no. of task failures exceeds this, the tasktracker is    *<i>blacklisted</i> for this job.     *     * @return the maximum no. of failures of a given job per tasktracker.    */
DECL|method|getMaxTaskFailuresPerTracker ()
specifier|public
name|int
name|getMaxTaskFailuresPerTracker
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|MAX_TASK_FAILURES_PER_TRACKER
argument_list|,
literal|3
argument_list|)
return|;
block|}
comment|/**    * Get the maximum percentage of map tasks that can fail without     * the job being aborted.     *     * Each map task is executed a minimum of {@link #getMaxMapAttempts()}     * attempts before being declared as<i>failed</i>.    *      * Defaults to<code>zero</code>, i.e.<i>any</i> failed map-task results in    * the job being declared as {@link JobStatus#FAILED}.    *     * @return the maximum percentage of map tasks that can fail without    *         the job being aborted.    */
DECL|method|getMaxMapTaskFailuresPercent ()
specifier|public
name|int
name|getMaxMapTaskFailuresPercent
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|MAP_FAILURES_MAX_PERCENT
argument_list|,
literal|0
argument_list|)
return|;
block|}
comment|/**    * Expert: Set the maximum percentage of map tasks that can fail without the    * job being aborted.     *     * Each map task is executed a minimum of {@link #getMaxMapAttempts} attempts     * before being declared as<i>failed</i>.    *     * @param percent the maximum percentage of map tasks that can fail without     *                the job being aborted.    */
DECL|method|setMaxMapTaskFailuresPercent (int percent)
specifier|public
name|void
name|setMaxMapTaskFailuresPercent
parameter_list|(
name|int
name|percent
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|MAP_FAILURES_MAX_PERCENT
argument_list|,
name|percent
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the maximum percentage of reduce tasks that can fail without     * the job being aborted.     *     * Each reduce task is executed a minimum of {@link #getMaxReduceAttempts()}     * attempts before being declared as<i>failed</i>.    *     * Defaults to<code>zero</code>, i.e.<i>any</i> failed reduce-task results     * in the job being declared as {@link JobStatus#FAILED}.    *     * @return the maximum percentage of reduce tasks that can fail without    *         the job being aborted.    */
DECL|method|getMaxReduceTaskFailuresPercent ()
specifier|public
name|int
name|getMaxReduceTaskFailuresPercent
parameter_list|()
block|{
return|return
name|getInt
argument_list|(
name|JobContext
operator|.
name|REDUCE_FAILURES_MAXPERCENT
argument_list|,
literal|0
argument_list|)
return|;
block|}
comment|/**    * Set the maximum percentage of reduce tasks that can fail without the job    * being aborted.    *     * Each reduce task is executed a minimum of {@link #getMaxReduceAttempts()}     * attempts before being declared as<i>failed</i>.    *     * @param percent the maximum percentage of reduce tasks that can fail without     *                the job being aborted.    */
DECL|method|setMaxReduceTaskFailuresPercent (int percent)
specifier|public
name|void
name|setMaxReduceTaskFailuresPercent
parameter_list|(
name|int
name|percent
parameter_list|)
block|{
name|setInt
argument_list|(
name|JobContext
operator|.
name|REDUCE_FAILURES_MAXPERCENT
argument_list|,
name|percent
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set {@link JobPriority} for this job.    *     * @param prio the {@link JobPriority} for this job.    */
DECL|method|setJobPriority (JobPriority prio)
specifier|public
name|void
name|setJobPriority
parameter_list|(
name|JobPriority
name|prio
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|PRIORITY
argument_list|,
name|prio
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the {@link JobPriority} for this job.    *     * @return the {@link JobPriority} for this job.    */
DECL|method|getJobPriority ()
specifier|public
name|JobPriority
name|getJobPriority
parameter_list|()
block|{
name|String
name|prio
init|=
name|get
argument_list|(
name|JobContext
operator|.
name|PRIORITY
argument_list|)
decl_stmt|;
if|if
condition|(
name|prio
operator|==
literal|null
condition|)
block|{
return|return
name|JobPriority
operator|.
name|NORMAL
return|;
block|}
return|return
name|JobPriority
operator|.
name|valueOf
argument_list|(
name|prio
argument_list|)
return|;
block|}
comment|/**    * Set JobSubmitHostName for this job.    *     * @param hostname the JobSubmitHostName for this job.    */
DECL|method|setJobSubmitHostName (String hostname)
name|void
name|setJobSubmitHostName
parameter_list|(
name|String
name|hostname
parameter_list|)
block|{
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOST
argument_list|,
name|hostname
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the  JobSubmitHostName for this job.    *     * @return the JobSubmitHostName for this job.    */
DECL|method|getJobSubmitHostName ()
name|String
name|getJobSubmitHostName
parameter_list|()
block|{
name|String
name|hostname
init|=
name|get
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOST
argument_list|)
decl_stmt|;
return|return
name|hostname
return|;
block|}
comment|/**    * Set JobSubmitHostAddress for this job.    *     * @param hostadd the JobSubmitHostAddress for this job.    */
DECL|method|setJobSubmitHostAddress (String hostadd)
name|void
name|setJobSubmitHostAddress
parameter_list|(
name|String
name|hostadd
parameter_list|)
block|{
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOSTADDR
argument_list|,
name|hostadd
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get JobSubmitHostAddress for this job.    *     * @return  JobSubmitHostAddress for this job.    */
DECL|method|getJobSubmitHostAddress ()
name|String
name|getJobSubmitHostAddress
parameter_list|()
block|{
name|String
name|hostadd
init|=
name|get
argument_list|(
name|MRJobConfig
operator|.
name|JOB_SUBMITHOSTADDR
argument_list|)
decl_stmt|;
return|return
name|hostadd
return|;
block|}
comment|/**    * Get whether the task profiling is enabled.    * @return true if some tasks will be profiled    */
DECL|method|getProfileEnabled ()
specifier|public
name|boolean
name|getProfileEnabled
parameter_list|()
block|{
return|return
name|getBoolean
argument_list|(
name|JobContext
operator|.
name|TASK_PROFILE
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set whether the system should collect profiler information for some of     * the tasks in this job? The information is stored in the user log     * directory.    * @param newValue true means it should be gathered    */
DECL|method|setProfileEnabled (boolean newValue)
specifier|public
name|void
name|setProfileEnabled
parameter_list|(
name|boolean
name|newValue
parameter_list|)
block|{
name|setBoolean
argument_list|(
name|JobContext
operator|.
name|TASK_PROFILE
argument_list|,
name|newValue
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the profiler configuration arguments.    *    * The default value for this property is    * "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s"    *     * @return the parameters to pass to the task child to configure profiling    */
DECL|method|getProfileParams ()
specifier|public
name|String
name|getProfileParams
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|TASK_PROFILE_PARAMS
argument_list|,
literal|"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,"
operator|+
literal|"verbose=n,file=%s"
argument_list|)
return|;
block|}
comment|/**    * Set the profiler configuration arguments. If the string contains a '%s' it    * will be replaced with the name of the profiling output file when the task    * runs.    *    * This value is passed to the task child JVM on the command line.    *    * @param value the configuration string    */
DECL|method|setProfileParams (String value)
specifier|public
name|void
name|setProfileParams
parameter_list|(
name|String
name|value
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|TASK_PROFILE_PARAMS
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the range of maps or reduces to profile.    * @param isMap is the task a map?    * @return the task ranges    */
DECL|method|getProfileTaskRange (boolean isMap)
specifier|public
name|IntegerRanges
name|getProfileTaskRange
parameter_list|(
name|boolean
name|isMap
parameter_list|)
block|{
return|return
name|getRange
argument_list|(
operator|(
name|isMap
condition|?
name|JobContext
operator|.
name|NUM_MAP_PROFILES
else|:
name|JobContext
operator|.
name|NUM_REDUCE_PROFILES
operator|)
argument_list|,
literal|"0-2"
argument_list|)
return|;
block|}
comment|/**    * Set the ranges of maps or reduces to profile. setProfileEnabled(true)     * must also be called.    * @param newValue a set of integer ranges of the map ids    */
DECL|method|setProfileTaskRange (boolean isMap, String newValue)
specifier|public
name|void
name|setProfileTaskRange
parameter_list|(
name|boolean
name|isMap
parameter_list|,
name|String
name|newValue
parameter_list|)
block|{
comment|// parse the value to make sure it is legal
operator|new
name|Configuration
operator|.
name|IntegerRanges
argument_list|(
name|newValue
argument_list|)
expr_stmt|;
name|set
argument_list|(
operator|(
name|isMap
condition|?
name|JobContext
operator|.
name|NUM_MAP_PROFILES
else|:
name|JobContext
operator|.
name|NUM_REDUCE_PROFILES
operator|)
argument_list|,
name|newValue
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the debug script to run when the map tasks fail.    *     *<p>The debug script can aid debugging of failed map tasks. The script is     * given task's stdout, stderr, syslog, jobconf files as arguments.</p>    *     *<p>The debug command, run on the node where the map failed, is:</p>    *<p><pre><blockquote>     * $script $stdout $stderr $syslog $jobconf.    *</blockquote></pre></p>    *     *<p> The script file is distributed through {@link DistributedCache}     * APIs. The script needs to be symlinked.</p>    *     *<p>Here is an example on how to submit a script     *<p><blockquote><pre>    * job.setMapDebugScript("./myscript");    * DistributedCache.createSymlink(job);    * DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");    *</pre></blockquote></p>    *     * @param mDbgScript the script name    */
DECL|method|setMapDebugScript (String mDbgScript)
specifier|public
name|void
name|setMapDebugScript
parameter_list|(
name|String
name|mDbgScript
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|MAP_DEBUG_SCRIPT
argument_list|,
name|mDbgScript
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the map task's debug script.    *     * @return the debug Script for the mapred job for failed map tasks.    * @see #setMapDebugScript(String)    */
DECL|method|getMapDebugScript ()
specifier|public
name|String
name|getMapDebugScript
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|MAP_DEBUG_SCRIPT
argument_list|)
return|;
block|}
comment|/**    * Set the debug script to run when the reduce tasks fail.    *     *<p>The debug script can aid debugging of failed reduce tasks. The script    * is given task's stdout, stderr, syslog, jobconf files as arguments.</p>    *     *<p>The debug command, run on the node where the map failed, is:</p>    *<p><pre><blockquote>     * $script $stdout $stderr $syslog $jobconf.    *</blockquote></pre></p>    *     *<p> The script file is distributed through {@link DistributedCache}     * APIs. The script file needs to be symlinked</p>    *     *<p>Here is an example on how to submit a script     *<p><blockquote><pre>    * job.setReduceDebugScript("./myscript");    * DistributedCache.createSymlink(job);    * DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");    *</pre></blockquote></p>    *     * @param rDbgScript the script name    */
DECL|method|setReduceDebugScript (String rDbgScript)
specifier|public
name|void
name|setReduceDebugScript
parameter_list|(
name|String
name|rDbgScript
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|REDUCE_DEBUG_SCRIPT
argument_list|,
name|rDbgScript
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the reduce task's debug Script    *     * @return the debug script for the mapred job for failed reduce tasks.    * @see #setReduceDebugScript(String)    */
DECL|method|getReduceDebugScript ()
specifier|public
name|String
name|getReduceDebugScript
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|REDUCE_DEBUG_SCRIPT
argument_list|)
return|;
block|}
comment|/**    * Get the uri to be invoked in-order to send a notification after the job     * has completed (success/failure).     *     * @return the job end notification uri,<code>null</code> if it hasn't    *         been set.    * @see #setJobEndNotificationURI(String)    */
DECL|method|getJobEndNotificationURI ()
specifier|public
name|String
name|getJobEndNotificationURI
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|MR_JOB_END_NOTIFICATION_URL
argument_list|)
return|;
block|}
comment|/**    * Set the uri to be invoked in-order to send a notification after the job    * has completed (success/failure).    *     *<p>The uri can contain 2 special parameters:<tt>$jobId</tt> and     *<tt>$jobStatus</tt>. Those, if present, are replaced by the job's     * identifier and completion-status respectively.</p>    *     *<p>This is typically used by application-writers to implement chaining of     * Map-Reduce jobs in an<i>asynchronous manner</i>.</p>    *     * @param uri the job end notification uri    * @see JobStatus    * @see<a href="{@docRoot}/org/apache/hadoop/mapred/JobClient.html#    *       JobCompletionAndChaining">Job Completion and Chaining</a>    */
DECL|method|setJobEndNotificationURI (String uri)
specifier|public
name|void
name|setJobEndNotificationURI
parameter_list|(
name|String
name|uri
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|MR_JOB_END_NOTIFICATION_URL
argument_list|,
name|uri
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get job-specific shared directory for use as scratch space    *     *<p>    * When a job starts, a shared directory is created at location    *<code>    * ${mapreduce.cluster.local.dir}/taskTracker/$user/jobcache/$jobid/work/</code>.    * This directory is exposed to the users through     *<code>mapreduce.job.local.dir</code>.    * So, the tasks can use this space     * as scratch space and share files among them.</p>    * This value is available as System property also.    *     * @return The localized job specific shared directory    */
DECL|method|getJobLocalDir ()
specifier|public
name|String
name|getJobLocalDir
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|JOB_LOCAL_DIR
argument_list|)
return|;
block|}
comment|/**    * Get memory required to run a map task of the job, in MB.    *     * If a value is specified in the configuration, it is returned.    * Else, it returns {@link #DISABLED_MEMORY_LIMIT}.    *<p/>    * For backward compatibility, if the job configuration sets the    * key {@link #MAPRED_TASK_MAXVMEM_PROPERTY} to a value different    * from {@link #DISABLED_MEMORY_LIMIT}, that value will be used    * after converting it from bytes to MB.    * @return memory required to run a map task of the job, in MB,    *          or {@link #DISABLED_MEMORY_LIMIT} if unset.    */
DECL|method|getMemoryForMapTask ()
specifier|public
name|long
name|getMemoryForMapTask
parameter_list|()
block|{
name|long
name|value
init|=
name|getDeprecatedMemoryValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|value
operator|==
name|DISABLED_MEMORY_LIMIT
condition|)
block|{
name|value
operator|=
name|normalizeMemoryConfigValue
argument_list|(
name|getLong
argument_list|(
name|JobConf
operator|.
name|MAPRED_JOB_MAP_MEMORY_MB_PROPERTY
argument_list|,
name|DISABLED_MEMORY_LIMIT
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|value
return|;
block|}
DECL|method|setMemoryForMapTask (long mem)
specifier|public
name|void
name|setMemoryForMapTask
parameter_list|(
name|long
name|mem
parameter_list|)
block|{
name|setLong
argument_list|(
name|JobConf
operator|.
name|MAPRED_JOB_MAP_MEMORY_MB_PROPERTY
argument_list|,
name|mem
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get memory required to run a reduce task of the job, in MB.    *     * If a value is specified in the configuration, it is returned.    * Else, it returns {@link #DISABLED_MEMORY_LIMIT}.    *<p/>    * For backward compatibility, if the job configuration sets the    * key {@link #MAPRED_TASK_MAXVMEM_PROPERTY} to a value different    * from {@link #DISABLED_MEMORY_LIMIT}, that value will be used    * after converting it from bytes to MB.    * @return memory required to run a reduce task of the job, in MB,    *          or {@link #DISABLED_MEMORY_LIMIT} if unset.    */
DECL|method|getMemoryForReduceTask ()
specifier|public
name|long
name|getMemoryForReduceTask
parameter_list|()
block|{
name|long
name|value
init|=
name|getDeprecatedMemoryValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|value
operator|==
name|DISABLED_MEMORY_LIMIT
condition|)
block|{
name|value
operator|=
name|normalizeMemoryConfigValue
argument_list|(
name|getLong
argument_list|(
name|JobConf
operator|.
name|MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY
argument_list|,
name|DISABLED_MEMORY_LIMIT
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|value
return|;
block|}
comment|// Return the value set to the key MAPRED_TASK_MAXVMEM_PROPERTY,
comment|// converted into MBs.
comment|// Returns DISABLED_MEMORY_LIMIT if unset, or set to a negative
comment|// value.
DECL|method|getDeprecatedMemoryValue ()
specifier|private
name|long
name|getDeprecatedMemoryValue
parameter_list|()
block|{
name|long
name|oldValue
init|=
name|getLong
argument_list|(
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|,
name|DISABLED_MEMORY_LIMIT
argument_list|)
decl_stmt|;
name|oldValue
operator|=
name|normalizeMemoryConfigValue
argument_list|(
name|oldValue
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldValue
operator|!=
name|DISABLED_MEMORY_LIMIT
condition|)
block|{
name|oldValue
operator|/=
operator|(
literal|1024
operator|*
literal|1024
operator|)
expr_stmt|;
block|}
return|return
name|oldValue
return|;
block|}
DECL|method|setMemoryForReduceTask (long mem)
specifier|public
name|void
name|setMemoryForReduceTask
parameter_list|(
name|long
name|mem
parameter_list|)
block|{
name|setLong
argument_list|(
name|JobConf
operator|.
name|MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY
argument_list|,
name|mem
argument_list|)
expr_stmt|;
block|}
comment|/**    * Return the name of the queue to which this job is submitted.    * Defaults to 'default'.    *     * @return name of the queue    */
DECL|method|getQueueName ()
specifier|public
name|String
name|getQueueName
parameter_list|()
block|{
return|return
name|get
argument_list|(
name|JobContext
operator|.
name|QUEUE_NAME
argument_list|,
name|DEFAULT_QUEUE_NAME
argument_list|)
return|;
block|}
comment|/**    * Set the name of the queue to which this job should be submitted.    *     * @param queueName Name of the queue    */
DECL|method|setQueueName (String queueName)
specifier|public
name|void
name|setQueueName
parameter_list|(
name|String
name|queueName
parameter_list|)
block|{
name|set
argument_list|(
name|JobContext
operator|.
name|QUEUE_NAME
argument_list|,
name|queueName
argument_list|)
expr_stmt|;
block|}
comment|/**    * Normalize the negative values in configuration    *     * @param val    * @return normalized value    */
DECL|method|normalizeMemoryConfigValue (long val)
specifier|public
specifier|static
name|long
name|normalizeMemoryConfigValue
parameter_list|(
name|long
name|val
parameter_list|)
block|{
if|if
condition|(
name|val
operator|<
literal|0
condition|)
block|{
name|val
operator|=
name|DISABLED_MEMORY_LIMIT
expr_stmt|;
block|}
return|return
name|val
return|;
block|}
comment|/**    * Compute the number of slots required to run a single map task-attempt    * of this job.    * @param slotSizePerMap cluster-wide value of the amount of memory required    *                       to run a map-task    * @return the number of slots required to run a single map task-attempt    *          1 if memory parameters are disabled.    */
DECL|method|computeNumSlotsPerMap (long slotSizePerMap)
name|int
name|computeNumSlotsPerMap
parameter_list|(
name|long
name|slotSizePerMap
parameter_list|)
block|{
if|if
condition|(
operator|(
name|slotSizePerMap
operator|==
name|DISABLED_MEMORY_LIMIT
operator|)
operator|||
operator|(
name|getMemoryForMapTask
argument_list|()
operator|==
name|DISABLED_MEMORY_LIMIT
operator|)
condition|)
block|{
return|return
literal|1
return|;
block|}
return|return
call|(
name|int
call|)
argument_list|(
name|Math
operator|.
name|ceil
argument_list|(
operator|(
name|float
operator|)
name|getMemoryForMapTask
argument_list|()
operator|/
operator|(
name|float
operator|)
name|slotSizePerMap
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Compute the number of slots required to run a single reduce task-attempt    * of this job.    * @param slotSizePerReduce cluster-wide value of the amount of memory     *                          required to run a reduce-task    * @return the number of slots required to run a single reduce task-attempt    *          1 if memory parameters are disabled    */
DECL|method|computeNumSlotsPerReduce (long slotSizePerReduce)
name|int
name|computeNumSlotsPerReduce
parameter_list|(
name|long
name|slotSizePerReduce
parameter_list|)
block|{
if|if
condition|(
operator|(
name|slotSizePerReduce
operator|==
name|DISABLED_MEMORY_LIMIT
operator|)
operator|||
operator|(
name|getMemoryForReduceTask
argument_list|()
operator|==
name|DISABLED_MEMORY_LIMIT
operator|)
condition|)
block|{
return|return
literal|1
return|;
block|}
return|return
call|(
name|int
call|)
argument_list|(
name|Math
operator|.
name|ceil
argument_list|(
operator|(
name|float
operator|)
name|getMemoryForReduceTask
argument_list|()
operator|/
operator|(
name|float
operator|)
name|slotSizePerReduce
argument_list|)
argument_list|)
return|;
block|}
comment|/**     * Find a jar that contains a class of the same name, if any.    * It will return a jar file, even if that is not the first thing    * on the class path that has a class with the same name.    *     * @param my_class the class to find.    * @return a jar file that contains the class, or null.    * @throws IOException    */
DECL|method|findContainingJar (Class my_class)
specifier|public
specifier|static
name|String
name|findContainingJar
parameter_list|(
name|Class
name|my_class
parameter_list|)
block|{
name|ClassLoader
name|loader
init|=
name|my_class
operator|.
name|getClassLoader
argument_list|()
decl_stmt|;
name|String
name|class_file
init|=
name|my_class
operator|.
name|getName
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"\\."
argument_list|,
literal|"/"
argument_list|)
operator|+
literal|".class"
decl_stmt|;
try|try
block|{
for|for
control|(
name|Enumeration
name|itr
init|=
name|loader
operator|.
name|getResources
argument_list|(
name|class_file
argument_list|)
init|;
name|itr
operator|.
name|hasMoreElements
argument_list|()
condition|;
control|)
block|{
name|URL
name|url
init|=
operator|(
name|URL
operator|)
name|itr
operator|.
name|nextElement
argument_list|()
decl_stmt|;
if|if
condition|(
literal|"jar"
operator|.
name|equals
argument_list|(
name|url
operator|.
name|getProtocol
argument_list|()
argument_list|)
condition|)
block|{
name|String
name|toReturn
init|=
name|url
operator|.
name|getPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|toReturn
operator|.
name|startsWith
argument_list|(
literal|"file:"
argument_list|)
condition|)
block|{
name|toReturn
operator|=
name|toReturn
operator|.
name|substring
argument_list|(
literal|"file:"
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// URLDecoder is a misnamed class, since it actually decodes
comment|// x-www-form-urlencoded MIME type rather than actual
comment|// URL encoding (which the file path has). Therefore it would
comment|// decode +s to ' 's which is incorrect (spaces are actually
comment|// either unencoded or encoded as "%20"). Replace +s first, so
comment|// that they are kept sacred during the decoding process.
name|toReturn
operator|=
name|toReturn
operator|.
name|replaceAll
argument_list|(
literal|"\\+"
argument_list|,
literal|"%2B"
argument_list|)
expr_stmt|;
name|toReturn
operator|=
name|URLDecoder
operator|.
name|decode
argument_list|(
name|toReturn
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
return|return
name|toReturn
operator|.
name|replaceAll
argument_list|(
literal|"!.*$"
argument_list|,
literal|""
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Get the memory required to run a task of this job, in bytes. See    * {@link #MAPRED_TASK_MAXVMEM_PROPERTY}    *<p/>    * This method is deprecated. Now, different memory limits can be    * set for map and reduce tasks of a job, in MB.     *<p/>    * For backward compatibility, if the job configuration sets the    * key {@link #MAPRED_TASK_MAXVMEM_PROPERTY} to a value different    * from {@link #DISABLED_MEMORY_LIMIT}, that value is returned.     * Otherwise, this method will return the larger of the values returned by     * {@link #getMemoryForMapTask()} and {@link #getMemoryForReduceTask()}    * after converting them into bytes.    *    * @return Memory required to run a task of this job, in bytes,    *          or {@link #DISABLED_MEMORY_LIMIT}, if unset.    * @see #setMaxVirtualMemoryForTask(long)    * @deprecated Use {@link #getMemoryForMapTask()} and    *             {@link #getMemoryForReduceTask()}    */
annotation|@
name|Deprecated
DECL|method|getMaxVirtualMemoryForTask ()
specifier|public
name|long
name|getMaxVirtualMemoryForTask
parameter_list|()
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"getMaxVirtualMemoryForTask() is deprecated. "
operator|+
literal|"Instead use getMemoryForMapTask() and getMemoryForReduceTask()"
argument_list|)
expr_stmt|;
name|long
name|value
init|=
name|getLong
argument_list|(
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|,
name|DISABLED_MEMORY_LIMIT
argument_list|)
decl_stmt|;
name|value
operator|=
name|normalizeMemoryConfigValue
argument_list|(
name|value
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|==
name|DISABLED_MEMORY_LIMIT
condition|)
block|{
name|value
operator|=
name|Math
operator|.
name|max
argument_list|(
name|getMemoryForMapTask
argument_list|()
argument_list|,
name|getMemoryForReduceTask
argument_list|()
argument_list|)
expr_stmt|;
name|value
operator|=
name|normalizeMemoryConfigValue
argument_list|(
name|value
argument_list|)
expr_stmt|;
if|if
condition|(
name|value
operator|!=
name|DISABLED_MEMORY_LIMIT
condition|)
block|{
name|value
operator|*=
literal|1024
operator|*
literal|1024
expr_stmt|;
block|}
block|}
return|return
name|value
return|;
block|}
comment|/**    * Set the maximum amount of memory any task of this job can use. See    * {@link #MAPRED_TASK_MAXVMEM_PROPERTY}    *<p/>    * mapred.task.maxvmem is split into    * mapreduce.map.memory.mb    * and mapreduce.map.memory.mb,mapred    * each of the new key are set    * as mapred.task.maxvmem / 1024    * as new values are in MB    *    * @param vmem Maximum amount of virtual memory in bytes any task of this job    *             can use.    * @see #getMaxVirtualMemoryForTask()    * @deprecated    *  Use {@link #setMemoryForMapTask(long mem)}  and    *  Use {@link #setMemoryForReduceTask(long mem)}    */
annotation|@
name|Deprecated
DECL|method|setMaxVirtualMemoryForTask (long vmem)
specifier|public
name|void
name|setMaxVirtualMemoryForTask
parameter_list|(
name|long
name|vmem
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"setMaxVirtualMemoryForTask() is deprecated."
operator|+
literal|"Instead use setMemoryForMapTask() and setMemoryForReduceTask()"
argument_list|)
expr_stmt|;
if|if
condition|(
name|vmem
operator|!=
name|DISABLED_MEMORY_LIMIT
operator|&&
name|vmem
operator|<
literal|0
condition|)
block|{
name|setMemoryForMapTask
argument_list|(
name|DISABLED_MEMORY_LIMIT
argument_list|)
expr_stmt|;
name|setMemoryForReduceTask
argument_list|(
name|DISABLED_MEMORY_LIMIT
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|get
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|)
operator|==
literal|null
condition|)
block|{
name|setMemoryForMapTask
argument_list|(
name|vmem
operator|/
operator|(
literal|1024
operator|*
literal|1024
operator|)
argument_list|)
expr_stmt|;
comment|//Changing bytes to mb
name|setMemoryForReduceTask
argument_list|(
name|vmem
operator|/
operator|(
literal|1024
operator|*
literal|1024
operator|)
argument_list|)
expr_stmt|;
comment|//Changing bytes to mb
block|}
else|else
block|{
name|this
operator|.
name|setLong
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|,
name|vmem
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @deprecated this variable is deprecated and nolonger in use.    */
annotation|@
name|Deprecated
DECL|method|getMaxPhysicalMemoryForTask ()
specifier|public
name|long
name|getMaxPhysicalMemoryForTask
parameter_list|()
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The API getMaxPhysicalMemoryForTask() is deprecated."
operator|+
literal|" Refer to the APIs getMemoryForMapTask() and"
operator|+
literal|" getMemoryForReduceTask() for details."
argument_list|)
expr_stmt|;
return|return
operator|-
literal|1
return|;
block|}
comment|/*    * @deprecated this    */
annotation|@
name|Deprecated
DECL|method|setMaxPhysicalMemoryForTask (long mem)
specifier|public
name|void
name|setMaxPhysicalMemoryForTask
parameter_list|(
name|long
name|mem
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The API setMaxPhysicalMemoryForTask() is deprecated."
operator|+
literal|" The value set is ignored. Refer to "
operator|+
literal|" setMemoryForMapTask() and setMemoryForReduceTask() for details."
argument_list|)
expr_stmt|;
block|}
DECL|method|deprecatedString (String key)
specifier|static
name|String
name|deprecatedString
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
literal|"The variable "
operator|+
name|key
operator|+
literal|" is no longer used."
return|;
block|}
DECL|method|checkAndWarnDeprecation ()
specifier|private
name|void
name|checkAndWarnDeprecation
parameter_list|()
block|{
if|if
condition|(
name|get
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|JobConf
operator|.
name|deprecatedString
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_MAXVMEM_PROPERTY
argument_list|)
operator|+
literal|" Instead use "
operator|+
name|JobConf
operator|.
name|MAPRED_JOB_MAP_MEMORY_MB_PROPERTY
operator|+
literal|" and "
operator|+
name|JobConf
operator|.
name|MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|get
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_ULIMIT
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|JobConf
operator|.
name|deprecatedString
argument_list|(
name|JobConf
operator|.
name|MAPRED_TASK_ULIMIT
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|get
argument_list|(
name|JobConf
operator|.
name|MAPRED_MAP_TASK_ULIMIT
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|JobConf
operator|.
name|deprecatedString
argument_list|(
name|JobConf
operator|.
name|MAPRED_MAP_TASK_ULIMIT
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|get
argument_list|(
name|JobConf
operator|.
name|MAPRED_REDUCE_TASK_ULIMIT
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|JobConf
operator|.
name|deprecatedString
argument_list|(
name|JobConf
operator|.
name|MAPRED_REDUCE_TASK_ULIMIT
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

