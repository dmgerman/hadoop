begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
operator|.
name|Private
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
operator|.
name|Unstable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DistributedFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|SystemErasureCodingPolicies
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|filecache
operator|.
name|ClientDistributedCacheManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|filecache
operator|.
name|DistributedCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|ApplicationId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|client
operator|.
name|api
operator|.
name|SharedCacheClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|exceptions
operator|.
name|YarnException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_comment
comment|/**  * This class is responsible for uploading resources from the client to HDFS  * that are associated with a MapReduce job.  */
end_comment

begin_class
annotation|@
name|Private
annotation|@
name|Unstable
DECL|class|JobResourceUploader
class|class
name|JobResourceUploader
block|{
DECL|field|LOG
specifier|protected
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|JobResourceUploader
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|useWildcard
specifier|private
specifier|final
name|boolean
name|useWildcard
decl_stmt|;
DECL|field|jtFs
specifier|private
specifier|final
name|FileSystem
name|jtFs
decl_stmt|;
DECL|field|scClient
specifier|private
name|SharedCacheClient
name|scClient
init|=
literal|null
decl_stmt|;
DECL|field|scConfig
specifier|private
name|SharedCacheConfig
name|scConfig
init|=
operator|new
name|SharedCacheConfig
argument_list|()
decl_stmt|;
DECL|field|appId
specifier|private
name|ApplicationId
name|appId
init|=
literal|null
decl_stmt|;
DECL|method|JobResourceUploader (FileSystem submitFs, boolean useWildcard)
name|JobResourceUploader
parameter_list|(
name|FileSystem
name|submitFs
parameter_list|,
name|boolean
name|useWildcard
parameter_list|)
block|{
name|this
operator|.
name|jtFs
operator|=
name|submitFs
expr_stmt|;
name|this
operator|.
name|useWildcard
operator|=
name|useWildcard
expr_stmt|;
block|}
DECL|method|initSharedCache (JobID jobid, Configuration conf)
specifier|private
name|void
name|initSharedCache
parameter_list|(
name|JobID
name|jobid
parameter_list|,
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|scConfig
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|scConfig
operator|.
name|isSharedCacheEnabled
argument_list|()
condition|)
block|{
name|this
operator|.
name|scClient
operator|=
name|createSharedCacheClient
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|appId
operator|=
name|jobIDToAppId
argument_list|(
name|jobid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * We added this method so that we could do the conversion between JobId and    * ApplicationId for the shared cache client. This logic is very similar to    * the org.apache.hadoop.mapreduce.TypeConverter#toYarn method. We don't use    * that because mapreduce-client-core can not depend on    * mapreduce-client-common.    */
DECL|method|jobIDToAppId (JobID jobId)
specifier|private
name|ApplicationId
name|jobIDToAppId
parameter_list|(
name|JobID
name|jobId
parameter_list|)
block|{
return|return
name|ApplicationId
operator|.
name|newInstance
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|jobId
operator|.
name|getJtIdentifier
argument_list|()
argument_list|)
argument_list|,
name|jobId
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
DECL|method|stopSharedCache ()
specifier|private
name|void
name|stopSharedCache
parameter_list|()
block|{
if|if
condition|(
name|scClient
operator|!=
literal|null
condition|)
block|{
name|scClient
operator|.
name|stop
argument_list|()
expr_stmt|;
name|scClient
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Create, initialize and start a new shared cache client.    */
annotation|@
name|VisibleForTesting
DECL|method|createSharedCacheClient (Configuration conf)
specifier|protected
name|SharedCacheClient
name|createSharedCacheClient
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|SharedCacheClient
name|scc
init|=
name|SharedCacheClient
operator|.
name|createSharedCacheClient
argument_list|()
decl_stmt|;
name|scc
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|scc
operator|.
name|start
argument_list|()
expr_stmt|;
return|return
name|scc
return|;
block|}
comment|/**    * Upload and configure files, libjars, jobjars, and archives pertaining to    * the passed job.    *<p>    * This client will use the shared cache for libjars, files, archives and    * jobjars if it is enabled. When shared cache is enabled, it will try to use    * the shared cache and fall back to the default behavior when the scm isn't    * available.    *<p>    * 1. For the resources that have been successfully shared, we will continue    * to use them in a shared fashion.    *<p>    * 2. For the resources that weren't in the cache and need to be uploaded by    * NM, we won't ask NM to upload them.    *    * @param job the job containing the files to be uploaded    * @param submitJobDir the submission directory of the job    * @throws IOException    */
DECL|method|uploadResources (Job job, Path submitJobDir)
specifier|public
name|void
name|uploadResources
parameter_list|(
name|Job
name|job
parameter_list|,
name|Path
name|submitJobDir
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|initSharedCache
argument_list|(
name|job
operator|.
name|getJobID
argument_list|()
argument_list|,
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|uploadResourcesInternal
argument_list|(
name|job
argument_list|,
name|submitJobDir
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|stopSharedCache
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|uploadResourcesInternal (Job job, Path submitJobDir)
specifier|private
name|void
name|uploadResourcesInternal
parameter_list|(
name|Job
name|job
parameter_list|,
name|Path
name|submitJobDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|short
name|replication
init|=
operator|(
name|short
operator|)
name|conf
operator|.
name|getInt
argument_list|(
name|Job
operator|.
name|SUBMIT_REPLICATION
argument_list|,
name|Job
operator|.
name|DEFAULT_SUBMIT_REPLICATION
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|Job
operator|.
name|USED_GENERIC_PARSER
argument_list|,
literal|false
argument_list|)
operator|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Hadoop command-line option parsing not performed. "
operator|+
literal|"Implement the Tool interface and execute your application "
operator|+
literal|"with ToolRunner to remedy this."
argument_list|)
expr_stmt|;
block|}
comment|//
comment|// Figure out what fs the JobTracker is using. Copy the
comment|// job to it, under a temporary name. This allows DFS to work,
comment|// and under the local fs also provides UNIX-like object loading
comment|// semantics. (that is, if the job file is deleted right after
comment|// submission, we can still run the submission to completion)
comment|//
comment|// Create a number of filenames in the JobTracker's fs namespace
name|LOG
operator|.
name|debug
argument_list|(
literal|"default FileSystem: "
operator|+
name|jtFs
operator|.
name|getUri
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|jtFs
operator|.
name|exists
argument_list|(
name|submitJobDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Not submitting job. Job directory "
operator|+
name|submitJobDir
operator|+
literal|" already exists!! This is unexpected.Please check what's there in"
operator|+
literal|" that directory"
argument_list|)
throw|;
block|}
comment|// Create the submission directory for the MapReduce job.
name|submitJobDir
operator|=
name|jtFs
operator|.
name|makeQualified
argument_list|(
name|submitJobDir
argument_list|)
expr_stmt|;
name|submitJobDir
operator|=
operator|new
name|Path
argument_list|(
name|submitJobDir
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|FsPermission
name|mapredSysPerms
init|=
operator|new
name|FsPermission
argument_list|(
name|JobSubmissionFiles
operator|.
name|JOB_DIR_PERMISSION
argument_list|)
decl_stmt|;
name|mkdirs
argument_list|(
name|jtFs
argument_list|,
name|submitJobDir
argument_list|,
name|mapredSysPerms
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
name|MRJobConfig
operator|.
name|MR_AM_STAGING_DIR_ERASURECODING_ENABLED
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_MR_AM_STAGING_ERASURECODING_ENABLED
argument_list|)
condition|)
block|{
name|disableErasureCodingForPath
argument_list|(
name|jtFs
argument_list|,
name|submitJobDir
argument_list|)
expr_stmt|;
block|}
comment|// Get the resources that have been added via command line arguments in the
comment|// GenericOptionsParser (i.e. files, libjars, archives).
name|Collection
argument_list|<
name|String
argument_list|>
name|files
init|=
name|conf
operator|.
name|getStringCollection
argument_list|(
literal|"tmpfiles"
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|libjars
init|=
name|conf
operator|.
name|getStringCollection
argument_list|(
literal|"tmpjars"
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|archives
init|=
name|conf
operator|.
name|getStringCollection
argument_list|(
literal|"tmparchives"
argument_list|)
decl_stmt|;
name|String
name|jobJar
init|=
name|job
operator|.
name|getJar
argument_list|()
decl_stmt|;
comment|// Merge resources that have been programmatically specified for the shared
comment|// cache via the Job API.
name|files
operator|.
name|addAll
argument_list|(
name|conf
operator|.
name|getStringCollection
argument_list|(
name|MRJobConfig
operator|.
name|FILES_FOR_SHARED_CACHE
argument_list|)
argument_list|)
expr_stmt|;
name|libjars
operator|.
name|addAll
argument_list|(
name|conf
operator|.
name|getStringCollection
argument_list|(
name|MRJobConfig
operator|.
name|FILES_FOR_CLASSPATH_AND_SHARED_CACHE
argument_list|)
argument_list|)
expr_stmt|;
name|archives
operator|.
name|addAll
argument_list|(
name|conf
operator|.
name|getStringCollection
argument_list|(
name|MRJobConfig
operator|.
name|ARCHIVES_FOR_SHARED_CACHE
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
init|=
operator|new
name|HashMap
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
name|checkLocalizationLimits
argument_list|(
name|conf
argument_list|,
name|files
argument_list|,
name|libjars
argument_list|,
name|archives
argument_list|,
name|jobJar
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
name|fileSCUploadPolicies
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
name|archiveSCUploadPolicies
init|=
operator|new
name|LinkedHashMap
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
argument_list|()
decl_stmt|;
name|uploadFiles
argument_list|(
name|job
argument_list|,
name|files
argument_list|,
name|submitJobDir
argument_list|,
name|mapredSysPerms
argument_list|,
name|replication
argument_list|,
name|fileSCUploadPolicies
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
name|uploadLibJars
argument_list|(
name|job
argument_list|,
name|libjars
argument_list|,
name|submitJobDir
argument_list|,
name|mapredSysPerms
argument_list|,
name|replication
argument_list|,
name|fileSCUploadPolicies
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
name|uploadArchives
argument_list|(
name|job
argument_list|,
name|archives
argument_list|,
name|submitJobDir
argument_list|,
name|mapredSysPerms
argument_list|,
name|replication
argument_list|,
name|archiveSCUploadPolicies
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
name|uploadJobJar
argument_list|(
name|job
argument_list|,
name|jobJar
argument_list|,
name|submitJobDir
argument_list|,
name|replication
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
name|addLog4jToDistributedCache
argument_list|(
name|job
argument_list|,
name|submitJobDir
argument_list|)
expr_stmt|;
comment|// Note, we do not consider resources in the distributed cache for the
comment|// shared cache at this time. Only resources specified via the
comment|// GenericOptionsParser or the jobjar.
name|Job
operator|.
name|setFileSharedCacheUploadPolicies
argument_list|(
name|conf
argument_list|,
name|fileSCUploadPolicies
argument_list|)
expr_stmt|;
name|Job
operator|.
name|setArchiveSharedCacheUploadPolicies
argument_list|(
name|conf
argument_list|,
name|archiveSCUploadPolicies
argument_list|)
expr_stmt|;
comment|// set the timestamps of the archives and files
comment|// set the public/private visibility of the archives and files
name|ClientDistributedCacheManager
operator|.
name|determineTimestampsAndCacheVisibilities
argument_list|(
name|conf
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
comment|// get DelegationToken for cached file
name|ClientDistributedCacheManager
operator|.
name|getDelegationTokens
argument_list|(
name|conf
argument_list|,
name|job
operator|.
name|getCredentials
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|uploadFiles (Job job, Collection<String> files, Path submitJobDir, FsPermission mapredSysPerms, short submitReplication, Map<String, Boolean> fileSCUploadPolicies, Map<URI, FileStatus> statCache)
name|void
name|uploadFiles
parameter_list|(
name|Job
name|job
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|files
parameter_list|,
name|Path
name|submitJobDir
parameter_list|,
name|FsPermission
name|mapredSysPerms
parameter_list|,
name|short
name|submitReplication
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
name|fileSCUploadPolicies
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|Path
name|filesDir
init|=
name|JobSubmissionFiles
operator|.
name|getJobDistCacheFiles
argument_list|(
name|submitJobDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|files
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|mkdirs
argument_list|(
name|jtFs
argument_list|,
name|filesDir
argument_list|,
name|mapredSysPerms
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|tmpFile
range|:
name|files
control|)
block|{
name|URI
name|tmpURI
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tmpURI
operator|=
operator|new
name|URI
argument_list|(
name|tmpFile
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Error parsing files argument."
operator|+
literal|" Argument must be a valid URI: "
operator|+
name|tmpFile
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Path
name|tmp
init|=
operator|new
name|Path
argument_list|(
name|tmpURI
argument_list|)
decl_stmt|;
name|URI
name|newURI
init|=
literal|null
decl_stmt|;
name|boolean
name|uploadToSharedCache
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheFilesEnabled
argument_list|()
condition|)
block|{
name|newURI
operator|=
name|useSharedCache
argument_list|(
name|tmpURI
argument_list|,
name|tmp
operator|.
name|getName
argument_list|()
argument_list|,
name|statCache
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|uploadToSharedCache
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|Path
name|newPath
init|=
name|copyRemoteFiles
argument_list|(
name|filesDir
argument_list|,
name|tmp
argument_list|,
name|conf
argument_list|,
name|submitReplication
argument_list|)
decl_stmt|;
try|try
block|{
name|newURI
operator|=
name|getPathURI
argument_list|(
name|newPath
argument_list|,
name|tmpURI
operator|.
name|getFragment
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ue
parameter_list|)
block|{
comment|// should not throw a uri exception
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to create a URI (URISyntaxException) for the"
operator|+
literal|" remote path "
operator|+
name|newPath
operator|+
literal|". This was based on the files parameter: "
operator|+
name|tmpFile
argument_list|,
name|ue
argument_list|)
throw|;
block|}
block|}
name|job
operator|.
name|addCacheFile
argument_list|(
name|newURI
argument_list|)
expr_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheFilesEnabled
argument_list|()
condition|)
block|{
name|fileSCUploadPolicies
operator|.
name|put
argument_list|(
name|newURI
operator|.
name|toString
argument_list|()
argument_list|,
name|uploadToSharedCache
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// Suppress warning for use of DistributedCache (it is everywhere).
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
annotation|@
name|VisibleForTesting
DECL|method|uploadLibJars (Job job, Collection<String> libjars, Path submitJobDir, FsPermission mapredSysPerms, short submitReplication, Map<String, Boolean> fileSCUploadPolicies, Map<URI, FileStatus> statCache)
name|void
name|uploadLibJars
parameter_list|(
name|Job
name|job
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|libjars
parameter_list|,
name|Path
name|submitJobDir
parameter_list|,
name|FsPermission
name|mapredSysPerms
parameter_list|,
name|short
name|submitReplication
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
name|fileSCUploadPolicies
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|Path
name|libjarsDir
init|=
name|JobSubmissionFiles
operator|.
name|getJobDistCacheLibjars
argument_list|(
name|submitJobDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|libjars
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|mkdirs
argument_list|(
name|jtFs
argument_list|,
name|libjarsDir
argument_list|,
name|mapredSysPerms
argument_list|)
expr_stmt|;
name|Collection
argument_list|<
name|URI
argument_list|>
name|libjarURIs
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
name|boolean
name|foundFragment
init|=
literal|false
decl_stmt|;
for|for
control|(
name|String
name|tmpjars
range|:
name|libjars
control|)
block|{
name|URI
name|tmpURI
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tmpURI
operator|=
operator|new
name|URI
argument_list|(
name|tmpjars
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Error parsing libjars argument."
operator|+
literal|" Argument must be a valid URI: "
operator|+
name|tmpjars
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Path
name|tmp
init|=
operator|new
name|Path
argument_list|(
name|tmpURI
argument_list|)
decl_stmt|;
name|URI
name|newURI
init|=
literal|null
decl_stmt|;
name|boolean
name|uploadToSharedCache
init|=
literal|false
decl_stmt|;
name|boolean
name|fromSharedCache
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheLibjarsEnabled
argument_list|()
condition|)
block|{
name|newURI
operator|=
name|useSharedCache
argument_list|(
name|tmpURI
argument_list|,
name|tmp
operator|.
name|getName
argument_list|()
argument_list|,
name|statCache
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|uploadToSharedCache
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|fromSharedCache
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|Path
name|newPath
init|=
name|copyRemoteFiles
argument_list|(
name|libjarsDir
argument_list|,
name|tmp
argument_list|,
name|conf
argument_list|,
name|submitReplication
argument_list|)
decl_stmt|;
try|try
block|{
name|newURI
operator|=
name|getPathURI
argument_list|(
name|newPath
argument_list|,
name|tmpURI
operator|.
name|getFragment
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ue
parameter_list|)
block|{
comment|// should not throw a uri exception
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to create a URI (URISyntaxException) for the"
operator|+
literal|" remote path "
operator|+
name|newPath
operator|+
literal|". This was based on the libjar parameter: "
operator|+
name|tmpjars
argument_list|,
name|ue
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|foundFragment
condition|)
block|{
comment|// We do not count shared cache paths containing fragments as a
comment|// "foundFragment." This is because these resources are not in the
comment|// staging directory and will be added to the distributed cache
comment|// separately.
name|foundFragment
operator|=
operator|(
name|newURI
operator|.
name|getFragment
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|!
name|fromSharedCache
expr_stmt|;
block|}
name|DistributedCache
operator|.
name|addFileToClassPath
argument_list|(
operator|new
name|Path
argument_list|(
name|newURI
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|,
name|jtFs
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|fromSharedCache
condition|)
block|{
comment|// We simply add this URI to the distributed cache. It will not come
comment|// from the staging directory (it is in the shared cache), so we
comment|// must add it to the cache regardless of the wildcard feature.
name|DistributedCache
operator|.
name|addCacheFile
argument_list|(
name|newURI
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|libjarURIs
operator|.
name|add
argument_list|(
name|newURI
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheLibjarsEnabled
argument_list|()
condition|)
block|{
name|fileSCUploadPolicies
operator|.
name|put
argument_list|(
name|newURI
operator|.
name|toString
argument_list|()
argument_list|,
name|uploadToSharedCache
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|useWildcard
operator|&&
operator|!
name|foundFragment
condition|)
block|{
comment|// Add the whole directory to the cache using a wild card
name|Path
name|libJarsDirWildcard
init|=
name|jtFs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
name|libjarsDir
argument_list|,
name|DistributedCache
operator|.
name|WILDCARD
argument_list|)
argument_list|)
decl_stmt|;
name|DistributedCache
operator|.
name|addCacheFile
argument_list|(
name|libJarsDirWildcard
operator|.
name|toUri
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|URI
name|uri
range|:
name|libjarURIs
control|)
block|{
name|DistributedCache
operator|.
name|addCacheFile
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|uploadArchives (Job job, Collection<String> archives, Path submitJobDir, FsPermission mapredSysPerms, short submitReplication, Map<String, Boolean> archiveSCUploadPolicies, Map<URI, FileStatus> statCache)
name|void
name|uploadArchives
parameter_list|(
name|Job
name|job
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|archives
parameter_list|,
name|Path
name|submitJobDir
parameter_list|,
name|FsPermission
name|mapredSysPerms
parameter_list|,
name|short
name|submitReplication
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|Boolean
argument_list|>
name|archiveSCUploadPolicies
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|Path
name|archivesDir
init|=
name|JobSubmissionFiles
operator|.
name|getJobDistCacheArchives
argument_list|(
name|submitJobDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|archives
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|mkdirs
argument_list|(
name|jtFs
argument_list|,
name|archivesDir
argument_list|,
name|mapredSysPerms
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|tmpArchives
range|:
name|archives
control|)
block|{
name|URI
name|tmpURI
decl_stmt|;
try|try
block|{
name|tmpURI
operator|=
operator|new
name|URI
argument_list|(
name|tmpArchives
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Error parsing archives argument."
operator|+
literal|" Argument must be a valid URI: "
operator|+
name|tmpArchives
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Path
name|tmp
init|=
operator|new
name|Path
argument_list|(
name|tmpURI
argument_list|)
decl_stmt|;
name|URI
name|newURI
init|=
literal|null
decl_stmt|;
name|boolean
name|uploadToSharedCache
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheArchivesEnabled
argument_list|()
condition|)
block|{
name|newURI
operator|=
name|useSharedCache
argument_list|(
name|tmpURI
argument_list|,
name|tmp
operator|.
name|getName
argument_list|()
argument_list|,
name|statCache
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|uploadToSharedCache
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|Path
name|newPath
init|=
name|copyRemoteFiles
argument_list|(
name|archivesDir
argument_list|,
name|tmp
argument_list|,
name|conf
argument_list|,
name|submitReplication
argument_list|)
decl_stmt|;
try|try
block|{
name|newURI
operator|=
name|getPathURI
argument_list|(
name|newPath
argument_list|,
name|tmpURI
operator|.
name|getFragment
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ue
parameter_list|)
block|{
comment|// should not throw a uri exception
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to create a URI (URISyntaxException) for the"
operator|+
literal|" remote path "
operator|+
name|newPath
operator|+
literal|". This was based on the archive parameter: "
operator|+
name|tmpArchives
argument_list|,
name|ue
argument_list|)
throw|;
block|}
block|}
name|job
operator|.
name|addCacheArchive
argument_list|(
name|newURI
argument_list|)
expr_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheArchivesEnabled
argument_list|()
condition|)
block|{
name|archiveSCUploadPolicies
operator|.
name|put
argument_list|(
name|newURI
operator|.
name|toString
argument_list|()
argument_list|,
name|uploadToSharedCache
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|uploadJobJar (Job job, String jobJar, Path submitJobDir, short submitReplication, Map<URI, FileStatus> statCache)
name|void
name|uploadJobJar
parameter_list|(
name|Job
name|job
parameter_list|,
name|String
name|jobJar
parameter_list|,
name|Path
name|submitJobDir
parameter_list|,
name|short
name|submitReplication
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
if|if
condition|(
name|jobJar
operator|!=
literal|null
condition|)
block|{
comment|// copy jar to JobTracker's fs
comment|// use jar name if job is not named.
if|if
condition|(
literal|""
operator|.
name|equals
argument_list|(
name|job
operator|.
name|getJobName
argument_list|()
argument_list|)
condition|)
block|{
name|job
operator|.
name|setJobName
argument_list|(
operator|new
name|Path
argument_list|(
name|jobJar
argument_list|)
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Path
name|jobJarPath
init|=
operator|new
name|Path
argument_list|(
name|jobJar
argument_list|)
decl_stmt|;
name|URI
name|jobJarURI
init|=
name|jobJarPath
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|Path
name|newJarPath
init|=
literal|null
decl_stmt|;
name|boolean
name|uploadToSharedCache
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|jobJarURI
operator|.
name|getScheme
argument_list|()
operator|==
literal|null
operator|||
name|jobJarURI
operator|.
name|getScheme
argument_list|()
operator|.
name|equals
argument_list|(
literal|"file"
argument_list|)
condition|)
block|{
comment|// job jar is on the local file system
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheJobjarEnabled
argument_list|()
condition|)
block|{
comment|// We must have a qualified path for the shared cache client. We can
comment|// assume this is for the local filesystem
name|jobJarPath
operator|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|jobJarPath
argument_list|)
expr_stmt|;
comment|// Don't add a resource name here because the resource name (i.e.
comment|// job.jar directory symlink) will always be hard coded to job.jar for
comment|// the job.jar
name|URI
name|newURI
init|=
name|useSharedCache
argument_list|(
name|jobJarPath
operator|.
name|toUri
argument_list|()
argument_list|,
literal|null
argument_list|,
name|statCache
argument_list|,
name|conf
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|uploadToSharedCache
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|newJarPath
operator|=
name|stringToPath
argument_list|(
name|newURI
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// The job jar is coming from the shared cache (i.e. a public
comment|// place), so we want the job.jar to have a public visibility.
name|conf
operator|.
name|setBoolean
argument_list|(
name|MRJobConfig
operator|.
name|JOBJAR_VISIBILITY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newJarPath
operator|==
literal|null
condition|)
block|{
name|newJarPath
operator|=
name|JobSubmissionFiles
operator|.
name|getJobJar
argument_list|(
name|submitJobDir
argument_list|)
expr_stmt|;
name|copyJar
argument_list|(
name|jobJarPath
argument_list|,
name|newJarPath
argument_list|,
name|submitReplication
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// job jar is in a remote file system
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheJobjarEnabled
argument_list|()
condition|)
block|{
comment|// Don't add a resource name here because the resource name (i.e.
comment|// job.jar directory symlink) will always be hard coded to job.jar for
comment|// the job.jar
name|URI
name|newURI
init|=
name|useSharedCache
argument_list|(
name|jobJarURI
argument_list|,
literal|null
argument_list|,
name|statCache
argument_list|,
name|conf
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|newURI
operator|==
literal|null
condition|)
block|{
name|uploadToSharedCache
operator|=
literal|true
expr_stmt|;
name|newJarPath
operator|=
name|jobJarPath
expr_stmt|;
block|}
else|else
block|{
name|newJarPath
operator|=
name|stringToPath
argument_list|(
name|newURI
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// The job jar is coming from the shared cache (i.e. a public
comment|// place), so we want the job.jar to have a public visibility.
name|conf
operator|.
name|setBoolean
argument_list|(
name|MRJobConfig
operator|.
name|JOBJAR_VISIBILITY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// we don't need to upload the jobjar to the staging directory because
comment|// it is already in an accessible place
name|newJarPath
operator|=
name|jobJarPath
expr_stmt|;
block|}
block|}
name|job
operator|.
name|setJar
argument_list|(
name|newJarPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|scConfig
operator|.
name|isSharedCacheJobjarEnabled
argument_list|()
condition|)
block|{
name|conf
operator|.
name|setBoolean
argument_list|(
name|MRJobConfig
operator|.
name|JOBJAR_SHARED_CACHE_UPLOAD_POLICY
argument_list|,
name|uploadToSharedCache
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No job jar file set.  User classes may not be found. "
operator|+
literal|"See Job or Job#setJar(String)."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Verify that the resources this job is going to localize are within the    * localization limits. We count all resources towards these limits regardless    * of where they are coming from (i.e. local, distributed cache, or shared    * cache).    */
annotation|@
name|VisibleForTesting
DECL|method|checkLocalizationLimits (Configuration conf, Collection<String> files, Collection<String> libjars, Collection<String> archives, String jobJar, Map<URI, FileStatus> statCache)
name|void
name|checkLocalizationLimits
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|files
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|libjars
parameter_list|,
name|Collection
argument_list|<
name|String
argument_list|>
name|archives
parameter_list|,
name|String
name|jobJar
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|LimitChecker
name|limitChecker
init|=
operator|new
name|LimitChecker
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|limitChecker
operator|.
name|hasLimits
argument_list|()
condition|)
block|{
comment|// there are no limits set, so we are done.
return|return;
block|}
comment|// Get the files and archives that are already in the distributed cache
name|Collection
argument_list|<
name|String
argument_list|>
name|dcFiles
init|=
name|conf
operator|.
name|getStringCollection
argument_list|(
name|MRJobConfig
operator|.
name|CACHE_FILES
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|dcArchives
init|=
name|conf
operator|.
name|getStringCollection
argument_list|(
name|MRJobConfig
operator|.
name|CACHE_ARCHIVES
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|uri
range|:
name|dcFiles
control|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|uri
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|uri
range|:
name|dcArchives
control|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|uri
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|uri
range|:
name|files
control|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|uri
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|uri
range|:
name|libjars
control|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|uri
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|uri
range|:
name|archives
control|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|uri
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|jobJar
operator|!=
literal|null
condition|)
block|{
name|explorePath
argument_list|(
name|conf
argument_list|,
name|stringToPath
argument_list|(
name|jobJar
argument_list|)
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Convert a String to a Path and gracefully remove fragments/queries if they    * exist in the String.    */
annotation|@
name|VisibleForTesting
DECL|method|stringToPath (String s)
name|Path
name|stringToPath
parameter_list|(
name|String
name|s
parameter_list|)
block|{
try|try
block|{
name|URI
name|uri
init|=
operator|new
name|URI
argument_list|(
name|s
argument_list|)
decl_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|uri
operator|.
name|getScheme
argument_list|()
argument_list|,
name|uri
operator|.
name|getAuthority
argument_list|()
argument_list|,
name|uri
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Error parsing argument."
operator|+
literal|" Argument must be a valid URI: "
operator|+
name|s
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|field|MAX_RESOURCE_ERR_MSG
specifier|protected
specifier|static
specifier|final
name|String
name|MAX_RESOURCE_ERR_MSG
init|=
literal|"This job has exceeded the maximum number of submitted resources"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|MAX_TOTAL_RESOURCE_MB_ERR_MSG
specifier|protected
specifier|static
specifier|final
name|String
name|MAX_TOTAL_RESOURCE_MB_ERR_MSG
init|=
literal|"This job has exceeded the maximum size of submitted resources"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|MAX_SINGLE_RESOURCE_MB_ERR_MSG
specifier|protected
specifier|static
specifier|final
name|String
name|MAX_SINGLE_RESOURCE_MB_ERR_MSG
init|=
literal|"This job has exceeded the maximum size of a single submitted resource"
decl_stmt|;
DECL|class|LimitChecker
specifier|private
specifier|static
class|class
name|LimitChecker
block|{
DECL|method|LimitChecker (Configuration conf)
name|LimitChecker
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|maxNumOfResources
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|MAX_RESOURCES
argument_list|,
name|MRJobConfig
operator|.
name|MAX_RESOURCES_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxSizeMB
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MRJobConfig
operator|.
name|MAX_RESOURCES_MB
argument_list|,
name|MRJobConfig
operator|.
name|MAX_RESOURCES_MB_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxSizeOfResourceMB
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MRJobConfig
operator|.
name|MAX_SINGLE_RESOURCE_MB
argument_list|,
name|MRJobConfig
operator|.
name|MAX_SINGLE_RESOURCE_MB_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalConfigSizeBytes
operator|=
name|maxSizeMB
operator|*
literal|1024
operator|*
literal|1024
expr_stmt|;
name|this
operator|.
name|totalConfigSizeOfResourceBytes
operator|=
name|maxSizeOfResourceMB
operator|*
literal|1024
operator|*
literal|1024
expr_stmt|;
block|}
DECL|field|totalSizeBytes
specifier|private
name|long
name|totalSizeBytes
init|=
literal|0
decl_stmt|;
DECL|field|totalNumberOfResources
specifier|private
name|int
name|totalNumberOfResources
init|=
literal|0
decl_stmt|;
DECL|field|currentMaxSizeOfFileBytes
specifier|private
name|long
name|currentMaxSizeOfFileBytes
init|=
literal|0
decl_stmt|;
DECL|field|maxSizeMB
specifier|private
specifier|final
name|long
name|maxSizeMB
decl_stmt|;
DECL|field|maxNumOfResources
specifier|private
specifier|final
name|int
name|maxNumOfResources
decl_stmt|;
DECL|field|maxSizeOfResourceMB
specifier|private
specifier|final
name|long
name|maxSizeOfResourceMB
decl_stmt|;
DECL|field|totalConfigSizeBytes
specifier|private
specifier|final
name|long
name|totalConfigSizeBytes
decl_stmt|;
DECL|field|totalConfigSizeOfResourceBytes
specifier|private
specifier|final
name|long
name|totalConfigSizeOfResourceBytes
decl_stmt|;
DECL|method|hasLimits ()
specifier|private
name|boolean
name|hasLimits
parameter_list|()
block|{
return|return
name|maxNumOfResources
operator|>
literal|0
operator|||
name|maxSizeMB
operator|>
literal|0
operator|||
name|maxSizeOfResourceMB
operator|>
literal|0
return|;
block|}
DECL|method|addFile (Path p, long fileSizeBytes)
specifier|private
name|void
name|addFile
parameter_list|(
name|Path
name|p
parameter_list|,
name|long
name|fileSizeBytes
parameter_list|)
throws|throws
name|IOException
block|{
name|totalNumberOfResources
operator|++
expr_stmt|;
name|totalSizeBytes
operator|+=
name|fileSizeBytes
expr_stmt|;
if|if
condition|(
name|fileSizeBytes
operator|>
name|currentMaxSizeOfFileBytes
condition|)
block|{
name|currentMaxSizeOfFileBytes
operator|=
name|fileSizeBytes
expr_stmt|;
block|}
if|if
condition|(
name|totalConfigSizeBytes
operator|>
literal|0
operator|&&
name|totalSizeBytes
operator|>
name|totalConfigSizeBytes
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|MAX_TOTAL_RESOURCE_MB_ERR_MSG
operator|+
literal|" (Max: "
operator|+
name|maxSizeMB
operator|+
literal|"MB)."
argument_list|)
throw|;
block|}
if|if
condition|(
name|maxNumOfResources
operator|>
literal|0
operator|&&
name|totalNumberOfResources
operator|>
name|maxNumOfResources
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|MAX_RESOURCE_ERR_MSG
operator|+
literal|" (Max: "
operator|+
name|maxNumOfResources
operator|+
literal|")."
argument_list|)
throw|;
block|}
if|if
condition|(
name|totalConfigSizeOfResourceBytes
operator|>
literal|0
operator|&&
name|currentMaxSizeOfFileBytes
operator|>
name|totalConfigSizeOfResourceBytes
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|MAX_SINGLE_RESOURCE_MB_ERR_MSG
operator|+
literal|" (Max: "
operator|+
name|maxSizeOfResourceMB
operator|+
literal|"MB, Violating resource: "
operator|+
name|p
operator|+
literal|")."
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Recursively explore the given path and enforce the limits for resource    * localization. This method assumes that there are no symlinks in the    * directory structure.    */
DECL|method|explorePath (Configuration job, Path p, LimitChecker limitChecker, Map<URI, FileStatus> statCache)
specifier|private
name|void
name|explorePath
parameter_list|(
name|Configuration
name|job
parameter_list|,
name|Path
name|p
parameter_list|,
name|LimitChecker
name|limitChecker
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|pathWithScheme
init|=
name|p
decl_stmt|;
if|if
condition|(
operator|!
name|pathWithScheme
operator|.
name|toUri
argument_list|()
operator|.
name|isAbsolute
argument_list|()
condition|)
block|{
comment|// the path does not have a scheme, so we assume it is a path from the
comment|// local filesystem
name|FileSystem
name|localFs
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|pathWithScheme
operator|=
name|localFs
operator|.
name|makeQualified
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|FileStatus
name|status
init|=
name|getFileStatus
argument_list|(
name|statCache
argument_list|,
name|job
argument_list|,
name|pathWithScheme
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|FileStatus
index|[]
name|statusArray
init|=
name|pathWithScheme
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
operator|.
name|listStatus
argument_list|(
name|pathWithScheme
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|s
range|:
name|statusArray
control|)
block|{
name|explorePath
argument_list|(
name|job
argument_list|,
name|s
operator|.
name|getPath
argument_list|()
argument_list|,
name|limitChecker
argument_list|,
name|statCache
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|limitChecker
operator|.
name|addFile
argument_list|(
name|pathWithScheme
argument_list|,
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|getFileStatus (Map<URI, FileStatus> statCache, Configuration job, Path p)
name|FileStatus
name|getFileStatus
parameter_list|(
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|,
name|Configuration
name|job
parameter_list|,
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|URI
name|u
init|=
name|p
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|FileStatus
name|status
init|=
name|statCache
operator|.
name|get
argument_list|(
name|u
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|==
literal|null
condition|)
block|{
name|status
operator|=
name|p
operator|.
name|getFileSystem
argument_list|(
name|job
argument_list|)
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|statCache
operator|.
name|put
argument_list|(
name|u
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
return|return
name|status
return|;
block|}
comment|/**    * Create a new directory in the passed filesystem. This wrapper method exists    * so that it can be overridden/stubbed during testing.    */
annotation|@
name|VisibleForTesting
DECL|method|mkdirs (FileSystem fs, Path dir, FsPermission permission)
name|boolean
name|mkdirs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|FileSystem
operator|.
name|mkdirs
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|permission
argument_list|)
return|;
block|}
comment|// copies a file to the jobtracker filesystem and returns the path where it
comment|// was copied to
annotation|@
name|VisibleForTesting
DECL|method|copyRemoteFiles (Path parentDir, Path originalPath, Configuration conf, short replication)
name|Path
name|copyRemoteFiles
parameter_list|(
name|Path
name|parentDir
parameter_list|,
name|Path
name|originalPath
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|short
name|replication
parameter_list|)
throws|throws
name|IOException
block|{
comment|// check if we do not need to copy the files
comment|// is jt using the same file system.
comment|// just checking for uri strings... doing no dns lookups
comment|// to see if the filesystems are the same. This is not optimal.
comment|// but avoids name resolution.
name|FileSystem
name|remoteFs
init|=
literal|null
decl_stmt|;
name|remoteFs
operator|=
name|originalPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
name|FileUtil
operator|.
name|compareFs
argument_list|(
name|remoteFs
argument_list|,
name|jtFs
argument_list|)
condition|)
block|{
return|return
name|originalPath
return|;
block|}
comment|// this might have name collisions. copy will throw an exception
comment|// parse the original path to create new path
name|Path
name|newPath
init|=
operator|new
name|Path
argument_list|(
name|parentDir
argument_list|,
name|originalPath
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|FileUtil
operator|.
name|copy
argument_list|(
name|remoteFs
argument_list|,
name|originalPath
argument_list|,
name|jtFs
argument_list|,
name|newPath
argument_list|,
literal|false
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|jtFs
operator|.
name|setReplication
argument_list|(
name|newPath
argument_list|,
name|replication
argument_list|)
expr_stmt|;
name|jtFs
operator|.
name|makeQualified
argument_list|(
name|newPath
argument_list|)
expr_stmt|;
return|return
name|newPath
return|;
block|}
comment|/**    * Checksum a local resource file and call use for that resource with the scm.    */
DECL|method|useSharedCache (URI sourceFile, String resourceName, Map<URI, FileStatus> statCache, Configuration conf, boolean honorFragment)
specifier|private
name|URI
name|useSharedCache
parameter_list|(
name|URI
name|sourceFile
parameter_list|,
name|String
name|resourceName
parameter_list|,
name|Map
argument_list|<
name|URI
argument_list|,
name|FileStatus
argument_list|>
name|statCache
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|honorFragment
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|scClient
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|Path
name|filePath
init|=
operator|new
name|Path
argument_list|(
name|sourceFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|getFileStatus
argument_list|(
name|statCache
argument_list|,
name|conf
argument_list|,
name|filePath
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Shared cache does not support directories"
operator|+
literal|" (see YARN-6097)."
operator|+
literal|" Will not upload "
operator|+
name|filePath
operator|+
literal|" to the shared cache."
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|String
name|rn
init|=
name|resourceName
decl_stmt|;
if|if
condition|(
name|honorFragment
condition|)
block|{
if|if
condition|(
name|sourceFile
operator|.
name|getFragment
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|rn
operator|=
name|sourceFile
operator|.
name|getFragment
argument_list|()
expr_stmt|;
block|}
block|}
comment|// If for whatever reason, we can't even calculate checksum for
comment|// a resource, something is really wrong with the file system;
comment|// even non-SCM approach won't work. Let us just throw the exception.
name|String
name|checksum
init|=
name|scClient
operator|.
name|getFileChecksum
argument_list|(
name|filePath
argument_list|)
decl_stmt|;
name|URL
name|url
init|=
literal|null
decl_stmt|;
try|try
block|{
name|url
operator|=
name|scClient
operator|.
name|use
argument_list|(
name|this
operator|.
name|appId
argument_list|,
name|checksum
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|YarnException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error trying to contact the shared cache manager,"
operator|+
literal|" disabling the SCMClient for the rest of this job submission"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|/*        * If we fail to contact the SCM, we do not use it for the rest of this        * JobResourceUploader's life. This prevents us from having to timeout        * each time we try to upload a file while the SCM is unavailable. Instead        * we timeout/error the first time and quickly revert to the default        * behavior without the shared cache. We do this by stopping the shared        * cache client and setting it to null.        */
name|stopSharedCache
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|url
operator|!=
literal|null
condition|)
block|{
comment|// Because we deal with URI's in mapreduce, we need to convert the URL to
comment|// a URI and add a fragment if necessary.
name|URI
name|uri
init|=
literal|null
decl_stmt|;
try|try
block|{
name|String
name|name
init|=
operator|new
name|Path
argument_list|(
name|url
operator|.
name|getFile
argument_list|()
argument_list|)
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|rn
operator|!=
literal|null
operator|&&
operator|!
name|name
operator|.
name|equals
argument_list|(
name|rn
argument_list|)
condition|)
block|{
comment|// A name was specified that is different then the URL in the shared
comment|// cache. Therefore, we need to set the fragment portion of the URI to
comment|// preserve the user's desired name. We assume that there is no
comment|// existing fragment in the URL since the shared cache manager does
comment|// not use fragments.
name|uri
operator|=
operator|new
name|URI
argument_list|(
name|url
operator|.
name|getScheme
argument_list|()
argument_list|,
name|url
operator|.
name|getUserInfo
argument_list|()
argument_list|,
name|url
operator|.
name|getHost
argument_list|()
argument_list|,
name|url
operator|.
name|getPort
argument_list|()
argument_list|,
name|url
operator|.
name|getFile
argument_list|()
argument_list|,
literal|null
argument_list|,
name|rn
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|uri
operator|=
operator|new
name|URI
argument_list|(
name|url
operator|.
name|getScheme
argument_list|()
argument_list|,
name|url
operator|.
name|getUserInfo
argument_list|()
argument_list|,
name|url
operator|.
name|getHost
argument_list|()
argument_list|,
name|url
operator|.
name|getPort
argument_list|()
argument_list|,
name|url
operator|.
name|getFile
argument_list|()
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
return|return
name|uri
return|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error trying to convert URL received from shared cache to"
operator|+
literal|" a URI: "
operator|+
name|url
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|copyJar (Path originalJarPath, Path submitJarFile, short replication)
name|void
name|copyJar
parameter_list|(
name|Path
name|originalJarPath
parameter_list|,
name|Path
name|submitJarFile
parameter_list|,
name|short
name|replication
parameter_list|)
throws|throws
name|IOException
block|{
name|jtFs
operator|.
name|copyFromLocalFile
argument_list|(
name|originalJarPath
argument_list|,
name|submitJarFile
argument_list|)
expr_stmt|;
name|jtFs
operator|.
name|setReplication
argument_list|(
name|submitJarFile
argument_list|,
name|replication
argument_list|)
expr_stmt|;
name|jtFs
operator|.
name|setPermission
argument_list|(
name|submitJarFile
argument_list|,
operator|new
name|FsPermission
argument_list|(
name|JobSubmissionFiles
operator|.
name|JOB_FILE_PERMISSION
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|addLog4jToDistributedCache (Job job, Path jobSubmitDir)
specifier|private
name|void
name|addLog4jToDistributedCache
parameter_list|(
name|Job
name|job
parameter_list|,
name|Path
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|String
name|log4jPropertyFile
init|=
name|conf
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE
argument_list|,
literal|""
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|log4jPropertyFile
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|short
name|replication
init|=
operator|(
name|short
operator|)
name|conf
operator|.
name|getInt
argument_list|(
name|Job
operator|.
name|SUBMIT_REPLICATION
argument_list|,
literal|10
argument_list|)
decl_stmt|;
name|copyLog4jPropertyFile
argument_list|(
name|job
argument_list|,
name|jobSubmitDir
argument_list|,
name|replication
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|getPathURI (Path destPath, String fragment)
specifier|private
name|URI
name|getPathURI
parameter_list|(
name|Path
name|destPath
parameter_list|,
name|String
name|fragment
parameter_list|)
throws|throws
name|URISyntaxException
block|{
name|URI
name|pathURI
init|=
name|destPath
operator|.
name|toUri
argument_list|()
decl_stmt|;
if|if
condition|(
name|pathURI
operator|.
name|getFragment
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|fragment
operator|==
literal|null
condition|)
block|{
comment|// no fragment, just return existing pathURI from destPath
block|}
else|else
block|{
name|pathURI
operator|=
operator|new
name|URI
argument_list|(
name|pathURI
operator|.
name|toString
argument_list|()
operator|+
literal|"#"
operator|+
name|fragment
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|pathURI
return|;
block|}
comment|// copy user specified log4j.property file in local
comment|// to HDFS with putting on distributed cache and adding its parent directory
comment|// to classpath.
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|copyLog4jPropertyFile (Job job, Path submitJobDir, short replication)
specifier|private
name|void
name|copyLog4jPropertyFile
parameter_list|(
name|Job
name|job
parameter_list|,
name|Path
name|submitJobDir
parameter_list|,
name|short
name|replication
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|String
name|file
init|=
name|validateFilePath
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"default FileSystem: "
operator|+
name|jtFs
operator|.
name|getUri
argument_list|()
argument_list|)
expr_stmt|;
name|FsPermission
name|mapredSysPerms
init|=
operator|new
name|FsPermission
argument_list|(
name|JobSubmissionFiles
operator|.
name|JOB_DIR_PERMISSION
argument_list|)
decl_stmt|;
try|try
block|{
name|jtFs
operator|.
name|getFileStatus
argument_list|(
name|submitJobDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot find job submission directory! "
operator|+
literal|"It should just be created, so something wrong here."
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|Path
name|fileDir
init|=
name|JobSubmissionFiles
operator|.
name|getJobLog4jFile
argument_list|(
name|submitJobDir
argument_list|)
decl_stmt|;
comment|// first copy local log4j.properties file to HDFS under submitJobDir
if|if
condition|(
name|file
operator|!=
literal|null
condition|)
block|{
name|FileSystem
operator|.
name|mkdirs
argument_list|(
name|jtFs
argument_list|,
name|fileDir
argument_list|,
name|mapredSysPerms
argument_list|)
expr_stmt|;
name|URI
name|tmpURI
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tmpURI
operator|=
operator|new
name|URI
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|Path
name|tmp
init|=
operator|new
name|Path
argument_list|(
name|tmpURI
argument_list|)
decl_stmt|;
name|Path
name|newPath
init|=
name|copyRemoteFiles
argument_list|(
name|fileDir
argument_list|,
name|tmp
argument_list|,
name|conf
argument_list|,
name|replication
argument_list|)
decl_stmt|;
name|DistributedCache
operator|.
name|addFileToClassPath
argument_list|(
operator|new
name|Path
argument_list|(
name|newPath
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * takes input as a path string for file and verifies if it exist. It defaults    * for file:/// if the files specified do not have a scheme. it returns the    * paths uri converted defaulting to file:///. So an input of /home/user/file1    * would return file:///home/user/file1    *     * @param file    * @param conf    * @return    */
DECL|method|validateFilePath (String file, Configuration conf)
specifier|private
name|String
name|validateFilePath
parameter_list|(
name|String
name|file
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|file
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|file
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"File name can't be empty string"
argument_list|)
throw|;
block|}
name|String
name|finalPath
decl_stmt|;
name|URI
name|pathURI
decl_stmt|;
try|try
block|{
name|pathURI
operator|=
operator|new
name|URI
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
name|pathURI
argument_list|)
decl_stmt|;
name|FileSystem
name|localFs
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|pathURI
operator|.
name|getScheme
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// default to the local file system
comment|// check if the file exists or not first
name|localFs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|finalPath
operator|=
name|path
operator|.
name|makeQualified
argument_list|(
name|localFs
operator|.
name|getUri
argument_list|()
argument_list|,
name|localFs
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// check if the file exists in this file system
comment|// we need to recreate this filesystem object to copy
comment|// these files to the file system ResourceManager is running
comment|// on.
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|finalPath
operator|=
name|path
operator|.
name|makeQualified
argument_list|(
name|fs
operator|.
name|getUri
argument_list|()
argument_list|,
name|fs
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
return|return
name|finalPath
return|;
block|}
DECL|method|disableErasureCodingForPath (FileSystem fs, Path path)
specifier|private
name|void
name|disableErasureCodingForPath
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|jtFs
operator|instanceof
name|DistributedFileSystem
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Disabling Erasure Coding for path: "
operator|+
name|path
argument_list|)
expr_stmt|;
name|DistributedFileSystem
name|dfs
init|=
operator|(
name|DistributedFileSystem
operator|)
name|jtFs
decl_stmt|;
name|dfs
operator|.
name|setErasureCodingPolicy
argument_list|(
name|path
argument_list|,
name|SystemErasureCodingPolicies
operator|.
name|getReplicationPolicy
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

