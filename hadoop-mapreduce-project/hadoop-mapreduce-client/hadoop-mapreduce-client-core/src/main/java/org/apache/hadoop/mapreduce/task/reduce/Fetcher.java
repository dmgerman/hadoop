begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce.task.reduce
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|task
operator|.
name|reduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|MalformedURLException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLConnection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|SecretKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|CodecPool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|CompressionCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|Decompressor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|DefaultCodec
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Counters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|IFileInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Reporter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|SecureShuffleUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|task
operator|.
name|reduce
operator|.
name|MapOutput
operator|.
name|Type
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_class
DECL|class|Fetcher
class|class
name|Fetcher
parameter_list|<
name|K
parameter_list|,
name|V
parameter_list|>
extends|extends
name|Thread
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|Fetcher
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** Number of ms before timing out a copy */
DECL|field|DEFAULT_STALLED_COPY_TIMEOUT
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_STALLED_COPY_TIMEOUT
init|=
literal|3
operator|*
literal|60
operator|*
literal|1000
decl_stmt|;
comment|/** Basic/unit connection timeout (in milliseconds) */
DECL|field|UNIT_CONNECT_TIMEOUT
specifier|private
specifier|final
specifier|static
name|int
name|UNIT_CONNECT_TIMEOUT
init|=
literal|60
operator|*
literal|1000
decl_stmt|;
comment|/* Default read timeout (in milliseconds) */
DECL|field|DEFAULT_READ_TIMEOUT
specifier|private
specifier|final
specifier|static
name|int
name|DEFAULT_READ_TIMEOUT
init|=
literal|3
operator|*
literal|60
operator|*
literal|1000
decl_stmt|;
DECL|field|reporter
specifier|private
specifier|final
name|Progressable
name|reporter
decl_stmt|;
DECL|enum|ShuffleErrors
DECL|enumConstant|IO_ERROR
DECL|enumConstant|WRONG_LENGTH
DECL|enumConstant|BAD_ID
DECL|enumConstant|WRONG_MAP
specifier|private
specifier|static
enum|enum
name|ShuffleErrors
block|{
name|IO_ERROR
block|,
name|WRONG_LENGTH
block|,
name|BAD_ID
block|,
name|WRONG_MAP
block|,
DECL|enumConstant|CONNECTION
DECL|enumConstant|WRONG_REDUCE
name|CONNECTION
block|,
name|WRONG_REDUCE
block|}
DECL|field|SHUFFLE_ERR_GRP_NAME
specifier|private
specifier|final
specifier|static
name|String
name|SHUFFLE_ERR_GRP_NAME
init|=
literal|"Shuffle Errors"
decl_stmt|;
DECL|field|connectionErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|connectionErrs
decl_stmt|;
DECL|field|ioErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|ioErrs
decl_stmt|;
DECL|field|wrongLengthErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|wrongLengthErrs
decl_stmt|;
DECL|field|badIdErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|badIdErrs
decl_stmt|;
DECL|field|wrongMapErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|wrongMapErrs
decl_stmt|;
DECL|field|wrongReduceErrs
specifier|private
specifier|final
name|Counters
operator|.
name|Counter
name|wrongReduceErrs
decl_stmt|;
DECL|field|merger
specifier|private
specifier|final
name|MergeManager
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|merger
decl_stmt|;
DECL|field|scheduler
specifier|private
specifier|final
name|ShuffleScheduler
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|scheduler
decl_stmt|;
DECL|field|metrics
specifier|private
specifier|final
name|ShuffleClientMetrics
name|metrics
decl_stmt|;
DECL|field|exceptionReporter
specifier|private
specifier|final
name|ExceptionReporter
name|exceptionReporter
decl_stmt|;
DECL|field|id
specifier|private
specifier|final
name|int
name|id
decl_stmt|;
DECL|field|nextId
specifier|private
specifier|static
name|int
name|nextId
init|=
literal|0
decl_stmt|;
DECL|field|reduce
specifier|private
specifier|final
name|int
name|reduce
decl_stmt|;
DECL|field|connectionTimeout
specifier|private
specifier|final
name|int
name|connectionTimeout
decl_stmt|;
DECL|field|readTimeout
specifier|private
specifier|final
name|int
name|readTimeout
decl_stmt|;
comment|// Decompression of map-outputs
DECL|field|codec
specifier|private
specifier|final
name|CompressionCodec
name|codec
decl_stmt|;
DECL|field|decompressor
specifier|private
specifier|final
name|Decompressor
name|decompressor
decl_stmt|;
DECL|field|jobTokenSecret
specifier|private
specifier|final
name|SecretKey
name|jobTokenSecret
decl_stmt|;
DECL|method|Fetcher (JobConf job, TaskAttemptID reduceId, ShuffleScheduler<K,V> scheduler, MergeManager<K,V> merger, Reporter reporter, ShuffleClientMetrics metrics, ExceptionReporter exceptionReporter, SecretKey jobTokenSecret)
specifier|public
name|Fetcher
parameter_list|(
name|JobConf
name|job
parameter_list|,
name|TaskAttemptID
name|reduceId
parameter_list|,
name|ShuffleScheduler
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|scheduler
parameter_list|,
name|MergeManager
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|merger
parameter_list|,
name|Reporter
name|reporter
parameter_list|,
name|ShuffleClientMetrics
name|metrics
parameter_list|,
name|ExceptionReporter
name|exceptionReporter
parameter_list|,
name|SecretKey
name|jobTokenSecret
parameter_list|)
block|{
name|this
operator|.
name|reporter
operator|=
name|reporter
expr_stmt|;
name|this
operator|.
name|scheduler
operator|=
name|scheduler
expr_stmt|;
name|this
operator|.
name|merger
operator|=
name|merger
expr_stmt|;
name|this
operator|.
name|metrics
operator|=
name|metrics
expr_stmt|;
name|this
operator|.
name|exceptionReporter
operator|=
name|exceptionReporter
expr_stmt|;
name|this
operator|.
name|id
operator|=
operator|++
name|nextId
expr_stmt|;
name|this
operator|.
name|reduce
operator|=
name|reduceId
operator|.
name|getTaskID
argument_list|()
operator|.
name|getId
argument_list|()
expr_stmt|;
name|this
operator|.
name|jobTokenSecret
operator|=
name|jobTokenSecret
expr_stmt|;
name|ioErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|IO_ERROR
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|wrongLengthErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|WRONG_LENGTH
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|badIdErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|BAD_ID
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|wrongMapErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|WRONG_MAP
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|connectionErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|CONNECTION
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|wrongReduceErrs
operator|=
name|reporter
operator|.
name|getCounter
argument_list|(
name|SHUFFLE_ERR_GRP_NAME
argument_list|,
name|ShuffleErrors
operator|.
name|WRONG_REDUCE
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|job
operator|.
name|getCompressMapOutput
argument_list|()
condition|)
block|{
name|Class
argument_list|<
name|?
extends|extends
name|CompressionCodec
argument_list|>
name|codecClass
init|=
name|job
operator|.
name|getMapOutputCompressorClass
argument_list|(
name|DefaultCodec
operator|.
name|class
argument_list|)
decl_stmt|;
name|codec
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|codecClass
argument_list|,
name|job
argument_list|)
expr_stmt|;
name|decompressor
operator|=
name|CodecPool
operator|.
name|getDecompressor
argument_list|(
name|codec
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|codec
operator|=
literal|null
expr_stmt|;
name|decompressor
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|connectionTimeout
operator|=
name|job
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|SHUFFLE_CONNECT_TIMEOUT
argument_list|,
name|DEFAULT_STALLED_COPY_TIMEOUT
argument_list|)
expr_stmt|;
name|this
operator|.
name|readTimeout
operator|=
name|job
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|SHUFFLE_READ_TIMEOUT
argument_list|,
name|DEFAULT_READ_TIMEOUT
argument_list|)
expr_stmt|;
name|setName
argument_list|(
literal|"fetcher#"
operator|+
name|id
argument_list|)
expr_stmt|;
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
literal|true
operator|&&
operator|!
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
name|MapHost
name|host
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// If merge is on, block
name|merger
operator|.
name|waitForInMemoryMerge
argument_list|()
expr_stmt|;
comment|// Get a host to shuffle from
name|host
operator|=
name|scheduler
operator|.
name|getHost
argument_list|()
expr_stmt|;
name|metrics
operator|.
name|threadBusy
argument_list|()
expr_stmt|;
comment|// Shuffle
name|copyFromHost
argument_list|(
name|host
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|host
operator|!=
literal|null
condition|)
block|{
name|scheduler
operator|.
name|freeHost
argument_list|(
name|host
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|threadFree
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
return|return;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|exceptionReporter
operator|.
name|reportException
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * The crux of the matter...    *     * @param host {@link MapHost} from which we need to      *              shuffle available map-outputs.    */
DECL|method|copyFromHost (MapHost host)
specifier|private
name|void
name|copyFromHost
parameter_list|(
name|MapHost
name|host
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Get completed maps on 'host'
name|List
argument_list|<
name|TaskAttemptID
argument_list|>
name|maps
init|=
name|scheduler
operator|.
name|getMapsForHost
argument_list|(
name|host
argument_list|)
decl_stmt|;
comment|// Sanity check to catch hosts with only 'OBSOLETE' maps,
comment|// especially at the tail of large jobs
if|if
condition|(
name|maps
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Fetcher "
operator|+
name|id
operator|+
literal|" going to fetch from "
operator|+
name|host
argument_list|)
expr_stmt|;
for|for
control|(
name|TaskAttemptID
name|tmp
range|:
name|maps
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|tmp
argument_list|)
expr_stmt|;
block|}
comment|// List of maps to be fetched yet
name|Set
argument_list|<
name|TaskAttemptID
argument_list|>
name|remaining
init|=
operator|new
name|HashSet
argument_list|<
name|TaskAttemptID
argument_list|>
argument_list|(
name|maps
argument_list|)
decl_stmt|;
comment|// Construct the url and connect
name|DataInputStream
name|input
decl_stmt|;
name|boolean
name|connectSucceeded
init|=
literal|false
decl_stmt|;
try|try
block|{
name|URL
name|url
init|=
name|getMapOutputURL
argument_list|(
name|host
argument_list|,
name|maps
argument_list|)
decl_stmt|;
name|URLConnection
name|connection
init|=
name|url
operator|.
name|openConnection
argument_list|()
decl_stmt|;
comment|// generate hash of the url
name|String
name|msgToEncode
init|=
name|SecureShuffleUtils
operator|.
name|buildMsgFrom
argument_list|(
name|url
argument_list|)
decl_stmt|;
name|String
name|encHash
init|=
name|SecureShuffleUtils
operator|.
name|hashFromString
argument_list|(
name|msgToEncode
argument_list|,
name|jobTokenSecret
argument_list|)
decl_stmt|;
comment|// put url hash into http header
name|connection
operator|.
name|addRequestProperty
argument_list|(
name|SecureShuffleUtils
operator|.
name|HTTP_HEADER_URL_HASH
argument_list|,
name|encHash
argument_list|)
expr_stmt|;
comment|// set the read timeout
name|connection
operator|.
name|setReadTimeout
argument_list|(
name|readTimeout
argument_list|)
expr_stmt|;
name|connect
argument_list|(
name|connection
argument_list|,
name|connectionTimeout
argument_list|)
expr_stmt|;
name|connectSucceeded
operator|=
literal|true
expr_stmt|;
name|input
operator|=
operator|new
name|DataInputStream
argument_list|(
name|connection
operator|.
name|getInputStream
argument_list|()
argument_list|)
expr_stmt|;
comment|// get the replyHash which is HMac of the encHash we sent to the server
name|String
name|replyHash
init|=
name|connection
operator|.
name|getHeaderField
argument_list|(
name|SecureShuffleUtils
operator|.
name|HTTP_HEADER_REPLY_URL_HASH
argument_list|)
decl_stmt|;
if|if
condition|(
name|replyHash
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"security validation of TT Map output failed"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"url="
operator|+
name|msgToEncode
operator|+
literal|";encHash="
operator|+
name|encHash
operator|+
literal|";replyHash="
operator|+
name|replyHash
argument_list|)
expr_stmt|;
comment|// verify that replyHash is HMac of encHash
name|SecureShuffleUtils
operator|.
name|verifyReply
argument_list|(
name|replyHash
argument_list|,
name|encHash
argument_list|,
name|jobTokenSecret
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"for url="
operator|+
name|msgToEncode
operator|+
literal|" sent hash and receievd reply"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|ioErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to connect to "
operator|+
name|host
operator|+
literal|" with "
operator|+
name|remaining
operator|.
name|size
argument_list|()
operator|+
literal|" map outputs"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
comment|// If connect did not succeed, just mark all the maps as failed,
comment|// indirectly penalizing the host
if|if
condition|(
operator|!
name|connectSucceeded
condition|)
block|{
for|for
control|(
name|TaskAttemptID
name|left
range|:
name|remaining
control|)
block|{
name|scheduler
operator|.
name|copyFailed
argument_list|(
name|left
argument_list|,
name|host
argument_list|,
name|connectSucceeded
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// If we got a read error at this stage, it implies there was a problem
comment|// with the first map, typically lost map. So, penalize only that map
comment|// and add the rest
name|TaskAttemptID
name|firstMap
init|=
name|maps
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|scheduler
operator|.
name|copyFailed
argument_list|(
name|firstMap
argument_list|,
name|host
argument_list|,
name|connectSucceeded
argument_list|)
expr_stmt|;
block|}
comment|// Add back all the remaining maps, WITHOUT marking them as failed
for|for
control|(
name|TaskAttemptID
name|left
range|:
name|remaining
control|)
block|{
name|scheduler
operator|.
name|putBackKnownMapOutput
argument_list|(
name|host
argument_list|,
name|left
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
try|try
block|{
comment|// Loop through available map-outputs and fetch them
comment|// On any error, good becomes false and we exit after putting back
comment|// the remaining maps to the yet_to_be_fetched list
name|boolean
name|good
init|=
literal|true
decl_stmt|;
while|while
condition|(
operator|!
name|remaining
operator|.
name|isEmpty
argument_list|()
operator|&&
name|good
condition|)
block|{
name|good
operator|=
name|copyMapOutput
argument_list|(
name|host
argument_list|,
name|input
argument_list|,
name|remaining
argument_list|)
expr_stmt|;
block|}
name|IOUtils
operator|.
name|cleanup
argument_list|(
name|LOG
argument_list|,
name|input
argument_list|)
expr_stmt|;
comment|// Sanity check
if|if
condition|(
name|good
operator|&&
operator|!
name|remaining
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"server didn't return all expected map outputs: "
operator|+
name|remaining
operator|.
name|size
argument_list|()
operator|+
literal|" left."
argument_list|)
throw|;
block|}
block|}
finally|finally
block|{
for|for
control|(
name|TaskAttemptID
name|left
range|:
name|remaining
control|)
block|{
name|scheduler
operator|.
name|putBackKnownMapOutput
argument_list|(
name|host
argument_list|,
name|left
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|copyMapOutput (MapHost host, DataInputStream input, Set<TaskAttemptID> remaining)
specifier|private
name|boolean
name|copyMapOutput
parameter_list|(
name|MapHost
name|host
parameter_list|,
name|DataInputStream
name|input
parameter_list|,
name|Set
argument_list|<
name|TaskAttemptID
argument_list|>
name|remaining
parameter_list|)
block|{
name|MapOutput
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|mapOutput
init|=
literal|null
decl_stmt|;
name|TaskAttemptID
name|mapId
init|=
literal|null
decl_stmt|;
name|long
name|decompressedLength
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|compressedLength
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|int
name|forReduce
init|=
operator|-
literal|1
decl_stmt|;
comment|//Read the shuffle header
try|try
block|{
name|ShuffleHeader
name|header
init|=
operator|new
name|ShuffleHeader
argument_list|()
decl_stmt|;
name|header
operator|.
name|readFields
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|mapId
operator|=
name|TaskAttemptID
operator|.
name|forName
argument_list|(
name|header
operator|.
name|mapId
argument_list|)
expr_stmt|;
name|compressedLength
operator|=
name|header
operator|.
name|compressedLength
expr_stmt|;
name|decompressedLength
operator|=
name|header
operator|.
name|uncompressedLength
expr_stmt|;
name|forReduce
operator|=
name|header
operator|.
name|forReduce
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|badIdErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid map id "
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Do some basic sanity verification
if|if
condition|(
operator|!
name|verifySanity
argument_list|(
name|compressedLength
argument_list|,
name|decompressedLength
argument_list|,
name|forReduce
argument_list|,
name|remaining
argument_list|,
name|mapId
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"header: "
operator|+
name|mapId
operator|+
literal|", len: "
operator|+
name|compressedLength
operator|+
literal|", decomp len: "
operator|+
name|decompressedLength
argument_list|)
expr_stmt|;
comment|// Get the location for the map output - either in-memory or on-disk
name|mapOutput
operator|=
name|merger
operator|.
name|reserve
argument_list|(
name|mapId
argument_list|,
name|decompressedLength
argument_list|,
name|id
argument_list|)
expr_stmt|;
comment|// Check if we can shuffle *now* ...
if|if
condition|(
name|mapOutput
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|WAIT
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"fetcher#"
operator|+
name|id
operator|+
literal|" - MergerManager returned Status.WAIT ..."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Go!
name|LOG
operator|.
name|info
argument_list|(
literal|"fetcher#"
operator|+
name|id
operator|+
literal|" about to shuffle output of map "
operator|+
name|mapOutput
operator|.
name|getMapId
argument_list|()
operator|+
literal|" decomp: "
operator|+
name|decompressedLength
operator|+
literal|" len: "
operator|+
name|compressedLength
operator|+
literal|" to "
operator|+
name|mapOutput
operator|.
name|getType
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|mapOutput
operator|.
name|getType
argument_list|()
operator|==
name|Type
operator|.
name|MEMORY
condition|)
block|{
name|shuffleToMemory
argument_list|(
name|host
argument_list|,
name|mapOutput
argument_list|,
name|input
argument_list|,
operator|(
name|int
operator|)
name|decompressedLength
argument_list|,
operator|(
name|int
operator|)
name|compressedLength
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|shuffleToDisk
argument_list|(
name|host
argument_list|,
name|mapOutput
argument_list|,
name|input
argument_list|,
name|compressedLength
argument_list|)
expr_stmt|;
block|}
comment|// Inform the shuffle scheduler
name|long
name|endTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|scheduler
operator|.
name|copySucceeded
argument_list|(
name|mapId
argument_list|,
name|host
argument_list|,
name|compressedLength
argument_list|,
name|endTime
operator|-
name|startTime
argument_list|,
name|mapOutput
argument_list|)
expr_stmt|;
comment|// Note successful shuffle
name|remaining
operator|.
name|remove
argument_list|(
name|mapId
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|successFetch
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|ioErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|mapId
operator|==
literal|null
operator|||
name|mapOutput
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"fetcher#"
operator|+
name|id
operator|+
literal|" failed to read map header"
operator|+
name|mapId
operator|+
literal|" decomp: "
operator|+
name|decompressedLength
operator|+
literal|", "
operator|+
name|compressedLength
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to shuffle output of "
operator|+
name|mapId
operator|+
literal|" from "
operator|+
name|host
operator|.
name|getHostName
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|// Inform the shuffle-scheduler
name|mapOutput
operator|.
name|abort
argument_list|()
expr_stmt|;
name|scheduler
operator|.
name|copyFailed
argument_list|(
name|mapId
argument_list|,
name|host
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|failedFetch
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Do some basic verification on the input received -- Being defensive    * @param compressedLength    * @param decompressedLength    * @param forReduce    * @param remaining    * @param mapId    * @return true/false, based on if the verification succeeded or not    */
DECL|method|verifySanity (long compressedLength, long decompressedLength, int forReduce, Set<TaskAttemptID> remaining, TaskAttemptID mapId)
specifier|private
name|boolean
name|verifySanity
parameter_list|(
name|long
name|compressedLength
parameter_list|,
name|long
name|decompressedLength
parameter_list|,
name|int
name|forReduce
parameter_list|,
name|Set
argument_list|<
name|TaskAttemptID
argument_list|>
name|remaining
parameter_list|,
name|TaskAttemptID
name|mapId
parameter_list|)
block|{
if|if
condition|(
name|compressedLength
operator|<
literal|0
operator|||
name|decompressedLength
operator|<
literal|0
condition|)
block|{
name|wrongLengthErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|getName
argument_list|()
operator|+
literal|" invalid lengths in map output header: id: "
operator|+
name|mapId
operator|+
literal|" len: "
operator|+
name|compressedLength
operator|+
literal|", decomp len: "
operator|+
name|decompressedLength
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|forReduce
operator|!=
name|reduce
condition|)
block|{
name|wrongReduceErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|getName
argument_list|()
operator|+
literal|" data for the wrong reduce map: "
operator|+
name|mapId
operator|+
literal|" len: "
operator|+
name|compressedLength
operator|+
literal|" decomp len: "
operator|+
name|decompressedLength
operator|+
literal|" for reduce "
operator|+
name|forReduce
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Sanity check
if|if
condition|(
operator|!
name|remaining
operator|.
name|contains
argument_list|(
name|mapId
argument_list|)
condition|)
block|{
name|wrongMapErrs
operator|.
name|increment
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid map-output! Received output for "
operator|+
name|mapId
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Create the map-output-url. This will contain all the map ids    * separated by commas    * @param host    * @param maps    * @return    * @throws MalformedURLException    */
DECL|method|getMapOutputURL (MapHost host, List<TaskAttemptID> maps )
specifier|private
name|URL
name|getMapOutputURL
parameter_list|(
name|MapHost
name|host
parameter_list|,
name|List
argument_list|<
name|TaskAttemptID
argument_list|>
name|maps
parameter_list|)
throws|throws
name|MalformedURLException
block|{
comment|// Get the base url
name|StringBuffer
name|url
init|=
operator|new
name|StringBuffer
argument_list|(
name|host
operator|.
name|getBaseUrl
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|first
init|=
literal|true
decl_stmt|;
for|for
control|(
name|TaskAttemptID
name|mapId
range|:
name|maps
control|)
block|{
if|if
condition|(
operator|!
name|first
condition|)
block|{
name|url
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|url
operator|.
name|append
argument_list|(
name|mapId
argument_list|)
expr_stmt|;
name|first
operator|=
literal|false
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"MapOutput URL for "
operator|+
name|host
operator|+
literal|" -> "
operator|+
name|url
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|URL
argument_list|(
name|url
operator|.
name|toString
argument_list|()
argument_list|)
return|;
block|}
comment|/**     * The connection establishment is attempted multiple times and is given up     * only on the last failure. Instead of connecting with a timeout of     * X, we try connecting with a timeout of x< X but multiple times.     */
DECL|method|connect (URLConnection connection, int connectionTimeout)
specifier|private
name|void
name|connect
parameter_list|(
name|URLConnection
name|connection
parameter_list|,
name|int
name|connectionTimeout
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|unit
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|connectionTimeout
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid timeout "
operator|+
literal|"[timeout = "
operator|+
name|connectionTimeout
operator|+
literal|" ms]"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|connectionTimeout
operator|>
literal|0
condition|)
block|{
name|unit
operator|=
name|Math
operator|.
name|min
argument_list|(
name|UNIT_CONNECT_TIMEOUT
argument_list|,
name|connectionTimeout
argument_list|)
expr_stmt|;
block|}
comment|// set the connect timeout to the unit-connect-timeout
name|connection
operator|.
name|setConnectTimeout
argument_list|(
name|unit
argument_list|)
expr_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
name|connection
operator|.
name|connect
argument_list|()
expr_stmt|;
break|break;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// update the total remaining connect-timeout
name|connectionTimeout
operator|-=
name|unit
expr_stmt|;
comment|// throw an exception if we have waited for timeout amount of time
comment|// note that the updated value if timeout is used here
if|if
condition|(
name|connectionTimeout
operator|==
literal|0
condition|)
block|{
throw|throw
name|ioe
throw|;
block|}
comment|// reset the connect timeout for the last try
if|if
condition|(
name|connectionTimeout
operator|<
name|unit
condition|)
block|{
name|unit
operator|=
name|connectionTimeout
expr_stmt|;
comment|// reset the connect time out for the final connect
name|connection
operator|.
name|setConnectTimeout
argument_list|(
name|unit
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|shuffleToMemory (MapHost host, MapOutput<K,V> mapOutput, InputStream input, int decompressedLength, int compressedLength)
specifier|private
name|void
name|shuffleToMemory
parameter_list|(
name|MapHost
name|host
parameter_list|,
name|MapOutput
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|mapOutput
parameter_list|,
name|InputStream
name|input
parameter_list|,
name|int
name|decompressedLength
parameter_list|,
name|int
name|compressedLength
parameter_list|)
throws|throws
name|IOException
block|{
name|IFileInputStream
name|checksumIn
init|=
operator|new
name|IFileInputStream
argument_list|(
name|input
argument_list|,
name|compressedLength
argument_list|)
decl_stmt|;
name|input
operator|=
name|checksumIn
expr_stmt|;
comment|// Are map-outputs compressed?
if|if
condition|(
name|codec
operator|!=
literal|null
condition|)
block|{
name|decompressor
operator|.
name|reset
argument_list|()
expr_stmt|;
name|input
operator|=
name|codec
operator|.
name|createInputStream
argument_list|(
name|input
argument_list|,
name|decompressor
argument_list|)
expr_stmt|;
block|}
comment|// Copy map-output into an in-memory buffer
name|byte
index|[]
name|shuffleData
init|=
name|mapOutput
operator|.
name|getMemory
argument_list|()
decl_stmt|;
try|try
block|{
name|IOUtils
operator|.
name|readFully
argument_list|(
name|input
argument_list|,
name|shuffleData
argument_list|,
literal|0
argument_list|,
name|shuffleData
operator|.
name|length
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|inputBytes
argument_list|(
name|shuffleData
operator|.
name|length
argument_list|)
expr_stmt|;
name|reporter
operator|.
name|progress
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Read "
operator|+
name|shuffleData
operator|.
name|length
operator|+
literal|" bytes from map-output for "
operator|+
name|mapOutput
operator|.
name|getMapId
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Close the streams
name|IOUtils
operator|.
name|cleanup
argument_list|(
name|LOG
argument_list|,
name|input
argument_list|)
expr_stmt|;
comment|// Re-throw
throw|throw
name|ioe
throw|;
block|}
block|}
DECL|method|shuffleToDisk (MapHost host, MapOutput<K,V> mapOutput, InputStream input, long compressedLength)
specifier|private
name|void
name|shuffleToDisk
parameter_list|(
name|MapHost
name|host
parameter_list|,
name|MapOutput
argument_list|<
name|K
argument_list|,
name|V
argument_list|>
name|mapOutput
parameter_list|,
name|InputStream
name|input
parameter_list|,
name|long
name|compressedLength
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Copy data to local-disk
name|OutputStream
name|output
init|=
name|mapOutput
operator|.
name|getDisk
argument_list|()
decl_stmt|;
name|long
name|bytesLeft
init|=
name|compressedLength
decl_stmt|;
try|try
block|{
specifier|final
name|int
name|BYTES_TO_READ
init|=
literal|64
operator|*
literal|1024
decl_stmt|;
name|byte
index|[]
name|buf
init|=
operator|new
name|byte
index|[
name|BYTES_TO_READ
index|]
decl_stmt|;
while|while
condition|(
name|bytesLeft
operator|>
literal|0
condition|)
block|{
name|int
name|n
init|=
name|input
operator|.
name|read
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|bytesLeft
argument_list|,
name|BYTES_TO_READ
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"read past end of stream reading "
operator|+
name|mapOutput
operator|.
name|getMapId
argument_list|()
argument_list|)
throw|;
block|}
name|output
operator|.
name|write
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
name|n
argument_list|)
expr_stmt|;
name|bytesLeft
operator|-=
name|n
expr_stmt|;
name|metrics
operator|.
name|inputBytes
argument_list|(
name|n
argument_list|)
expr_stmt|;
name|reporter
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Read "
operator|+
operator|(
name|compressedLength
operator|-
name|bytesLeft
operator|)
operator|+
literal|" bytes from map-output for "
operator|+
name|mapOutput
operator|.
name|getMapId
argument_list|()
argument_list|)
expr_stmt|;
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Close the streams
name|IOUtils
operator|.
name|cleanup
argument_list|(
name|LOG
argument_list|,
name|input
argument_list|,
name|output
argument_list|)
expr_stmt|;
comment|// Re-throw
throw|throw
name|ioe
throw|;
block|}
comment|// Sanity check
if|if
condition|(
name|bytesLeft
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incomplete map output received for "
operator|+
name|mapOutput
operator|.
name|getMapId
argument_list|()
operator|+
literal|" from "
operator|+
name|host
operator|.
name|getHostName
argument_list|()
operator|+
literal|" ("
operator|+
name|bytesLeft
operator|+
literal|" bytes missing of "
operator|+
name|compressedLength
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

