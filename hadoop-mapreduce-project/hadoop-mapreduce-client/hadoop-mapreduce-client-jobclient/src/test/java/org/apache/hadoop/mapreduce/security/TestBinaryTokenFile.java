begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/** Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapreduce.security
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|fail
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NameNodeAdapter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IntWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|SleepJob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|v2
operator|.
name|MiniMRYarnCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|TokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|conf
operator|.
name|YarnConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_class
DECL|class|TestBinaryTokenFile
specifier|public
class|class
name|TestBinaryTokenFile
block|{
DECL|field|KEY_SECURITY_TOKEN_FILE_NAME
specifier|private
specifier|static
specifier|final
name|String
name|KEY_SECURITY_TOKEN_FILE_NAME
init|=
literal|"key-security-token-file"
decl_stmt|;
DECL|field|DELEGATION_TOKEN_KEY
specifier|private
specifier|static
specifier|final
name|String
name|DELEGATION_TOKEN_KEY
init|=
literal|"Hdfs"
decl_stmt|;
comment|// my sleep class
DECL|class|MySleepMapper
specifier|static
class|class
name|MySleepMapper
extends|extends
name|SleepJob
operator|.
name|SleepMapper
block|{
comment|/**      * attempts to access tokenCache as from client      */
annotation|@
name|Override
DECL|method|map (IntWritable key, IntWritable value, Context context)
specifier|public
name|void
name|map
parameter_list|(
name|IntWritable
name|key
parameter_list|,
name|IntWritable
name|value
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// get context token storage:
specifier|final
name|Credentials
name|contextCredentials
init|=
name|context
operator|.
name|getCredentials
argument_list|()
decl_stmt|;
specifier|final
name|Collection
argument_list|<
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
argument_list|>
name|contextTokenCollection
init|=
name|contextCredentials
operator|.
name|getAllTokens
argument_list|()
decl_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|t
range|:
name|contextTokenCollection
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Context token: ["
operator|+
name|t
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|contextTokenCollection
operator|.
name|size
argument_list|()
operator|!=
literal|2
condition|)
block|{
comment|// one job token and one delegation token
comment|// fail the test:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Exactly 2 tokens are expected in the contextTokenCollection: "
operator|+
literal|"one job token and one delegation token, but was found "
operator|+
name|contextTokenCollection
operator|.
name|size
argument_list|()
operator|+
literal|" tokens."
argument_list|)
throw|;
block|}
specifier|final
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|dt
init|=
name|contextCredentials
operator|.
name|getToken
argument_list|(
operator|new
name|Text
argument_list|(
name|DELEGATION_TOKEN_KEY
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|dt
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Token for key ["
operator|+
name|DELEGATION_TOKEN_KEY
operator|+
literal|"] not found in the job context."
argument_list|)
throw|;
block|}
name|String
name|tokenFile0
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_CREDENTIALS_BINARY
argument_list|)
decl_stmt|;
if|if
condition|(
name|tokenFile0
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Token file key ["
operator|+
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_CREDENTIALS_BINARY
operator|+
literal|"] found in the configuration. It should have been removed from the configuration."
argument_list|)
throw|;
block|}
specifier|final
name|String
name|tokenFile
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|KEY_SECURITY_TOKEN_FILE_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|tokenFile
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Token file key ["
operator|+
name|KEY_SECURITY_TOKEN_FILE_NAME
operator|+
literal|"] not found in the job configuration."
argument_list|)
throw|;
block|}
specifier|final
name|Credentials
name|binaryCredentials
init|=
operator|new
name|Credentials
argument_list|()
decl_stmt|;
name|binaryCredentials
operator|.
name|readTokenStorageStream
argument_list|(
operator|new
name|DataInputStream
argument_list|(
operator|new
name|FileInputStream
argument_list|(
name|tokenFile
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
specifier|final
name|Collection
argument_list|<
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
argument_list|>
name|binaryTokenCollection
init|=
name|binaryCredentials
operator|.
name|getAllTokens
argument_list|()
decl_stmt|;
if|if
condition|(
name|binaryTokenCollection
operator|.
name|size
argument_list|()
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"The token collection read from file ["
operator|+
name|tokenFile
operator|+
literal|"] must have size = 1."
argument_list|)
throw|;
block|}
specifier|final
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|binTok
init|=
name|binaryTokenCollection
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"The token read from binary file: t = ["
operator|+
name|binTok
operator|+
literal|"]"
argument_list|)
expr_stmt|;
comment|// Verify that dt is same as the token in the file:
if|if
condition|(
operator|!
name|dt
operator|.
name|equals
argument_list|(
name|binTok
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Delegation token in job is not same as the token passed in file:"
operator|+
literal|" tokenInFile=["
operator|+
name|binTok
operator|+
literal|"], dt=["
operator|+
name|dt
operator|+
literal|"]."
argument_list|)
throw|;
block|}
comment|// Now test the user tokens.
specifier|final
name|UserGroupInformation
name|ugi
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
decl_stmt|;
comment|// Print all the UGI tokens for diagnostic purposes:
specifier|final
name|Collection
argument_list|<
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
argument_list|>
name|ugiTokenCollection
init|=
name|ugi
operator|.
name|getTokens
argument_list|()
decl_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|t
range|:
name|ugiTokenCollection
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"UGI token: ["
operator|+
name|t
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
specifier|final
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|ugiToken
init|=
name|ugi
operator|.
name|getCredentials
argument_list|()
operator|.
name|getToken
argument_list|(
operator|new
name|Text
argument_list|(
name|DELEGATION_TOKEN_KEY
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|ugiToken
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Token for key ["
operator|+
name|DELEGATION_TOKEN_KEY
operator|+
literal|"] not found among the UGI tokens."
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|ugiToken
operator|.
name|equals
argument_list|(
name|binTok
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"UGI token is not same as the token passed in binary file:"
operator|+
literal|" tokenInBinFile=["
operator|+
name|binTok
operator|+
literal|"], ugiTok=["
operator|+
name|ugiToken
operator|+
literal|"]."
argument_list|)
throw|;
block|}
name|super
operator|.
name|map
argument_list|(
name|key
argument_list|,
name|value
argument_list|,
name|context
argument_list|)
expr_stmt|;
block|}
block|}
DECL|class|MySleepJob
class|class
name|MySleepJob
extends|extends
name|SleepJob
block|{
annotation|@
name|Override
DECL|method|createJob (int numMapper, int numReducer, long mapSleepTime, int mapSleepCount, long reduceSleepTime, int reduceSleepCount)
specifier|public
name|Job
name|createJob
parameter_list|(
name|int
name|numMapper
parameter_list|,
name|int
name|numReducer
parameter_list|,
name|long
name|mapSleepTime
parameter_list|,
name|int
name|mapSleepCount
parameter_list|,
name|long
name|reduceSleepTime
parameter_list|,
name|int
name|reduceSleepCount
parameter_list|)
throws|throws
name|IOException
block|{
name|Job
name|job
init|=
name|super
operator|.
name|createJob
argument_list|(
name|numMapper
argument_list|,
name|numReducer
argument_list|,
name|mapSleepTime
argument_list|,
name|mapSleepCount
argument_list|,
name|reduceSleepTime
argument_list|,
name|reduceSleepCount
argument_list|)
decl_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|MySleepMapper
operator|.
name|class
argument_list|)
expr_stmt|;
comment|//Populate tokens here because security is disabled.
name|setupBinaryTokenFile
argument_list|(
name|job
argument_list|)
expr_stmt|;
return|return
name|job
return|;
block|}
DECL|method|setupBinaryTokenFile (Job job)
specifier|private
name|void
name|setupBinaryTokenFile
parameter_list|(
name|Job
name|job
parameter_list|)
block|{
comment|// Credentials in the job will not have delegation tokens
comment|// because security is disabled. Fetch delegation tokens
comment|// and store in binary token file.
name|createBinaryTokenFile
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|MAPREDUCE_JOB_CREDENTIALS_BINARY
argument_list|,
name|binaryTokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// NB: the MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY
comment|// key now gets deleted from config,
comment|// so it's not accessible in the job's config. So,
comment|// we use another key to pass the file name into the job configuration:
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|set
argument_list|(
name|KEY_SECURITY_TOKEN_FILE_NAME
argument_list|,
name|binaryTokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|field|mrCluster
specifier|private
specifier|static
name|MiniMRYarnCluster
name|mrCluster
decl_stmt|;
DECL|field|dfsCluster
specifier|private
specifier|static
name|MiniDFSCluster
name|dfsCluster
decl_stmt|;
DECL|field|TEST_DIR
specifier|private
specifier|static
specifier|final
name|Path
name|TEST_DIR
init|=
operator|new
name|Path
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
literal|"/tmp"
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|binaryTokenFileName
specifier|private
specifier|static
specifier|final
name|Path
name|binaryTokenFileName
init|=
operator|new
name|Path
argument_list|(
name|TEST_DIR
argument_list|,
literal|"tokenFile.binary"
argument_list|)
decl_stmt|;
DECL|field|numSlaves
specifier|private
specifier|static
specifier|final
name|int
name|numSlaves
init|=
literal|1
decl_stmt|;
comment|// num of data nodes
DECL|field|noOfNMs
specifier|private
specifier|static
specifier|final
name|int
name|noOfNMs
init|=
literal|1
decl_stmt|;
DECL|field|p1
specifier|private
specifier|static
name|Path
name|p1
decl_stmt|;
annotation|@
name|BeforeClass
DECL|method|setUp ()
specifier|public
specifier|static
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRConfig
operator|.
name|FRAMEWORK_NAME
argument_list|,
name|MRConfig
operator|.
name|YARN_FRAMEWORK_NAME
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|YarnConfiguration
operator|.
name|RM_PRINCIPAL
argument_list|,
literal|"jt_id/"
operator|+
name|SecurityUtil
operator|.
name|HOSTNAME_PATTERN
operator|+
literal|"@APACHE.ORG"
argument_list|)
expr_stmt|;
specifier|final
name|MiniDFSCluster
operator|.
name|Builder
name|builder
init|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|builder
operator|.
name|checkExitOnShutdown
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|builder
operator|.
name|numDataNodes
argument_list|(
name|numSlaves
argument_list|)
expr_stmt|;
name|builder
operator|.
name|format
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|builder
operator|.
name|racks
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|dfsCluster
operator|=
name|builder
operator|.
name|build
argument_list|()
expr_stmt|;
name|mrCluster
operator|=
operator|new
name|MiniMRYarnCluster
argument_list|(
name|TestBinaryTokenFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|noOfNMs
argument_list|)
expr_stmt|;
name|mrCluster
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|mrCluster
operator|.
name|start
argument_list|()
expr_stmt|;
name|NameNodeAdapter
operator|.
name|getDtSecretManager
argument_list|(
name|dfsCluster
operator|.
name|getNamesystem
argument_list|()
argument_list|)
operator|.
name|startThreads
argument_list|()
expr_stmt|;
name|FileSystem
name|fs
init|=
name|dfsCluster
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|p1
operator|=
operator|new
name|Path
argument_list|(
literal|"file1"
argument_list|)
expr_stmt|;
name|p1
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
name|p1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|AfterClass
DECL|method|tearDown ()
specifier|public
specifier|static
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|mrCluster
operator|!=
literal|null
condition|)
block|{
name|mrCluster
operator|.
name|stop
argument_list|()
expr_stmt|;
name|mrCluster
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|dfsCluster
operator|!=
literal|null
condition|)
block|{
name|dfsCluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|dfsCluster
operator|=
literal|null
expr_stmt|;
block|}
block|}
DECL|method|createBinaryTokenFile (Configuration conf)
specifier|private
specifier|static
name|void
name|createBinaryTokenFile
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
comment|// Fetch delegation tokens and store in binary token file.
try|try
block|{
name|Credentials
name|cred1
init|=
operator|new
name|Credentials
argument_list|()
decl_stmt|;
name|Credentials
name|cred2
init|=
operator|new
name|Credentials
argument_list|()
decl_stmt|;
name|TokenCache
operator|.
name|obtainTokensForNamenodesInternal
argument_list|(
name|cred1
argument_list|,
operator|new
name|Path
index|[]
block|{
name|p1
block|}
argument_list|,
name|conf
argument_list|)
expr_stmt|;
for|for
control|(
name|Token
argument_list|<
name|?
extends|extends
name|TokenIdentifier
argument_list|>
name|t
range|:
name|cred1
operator|.
name|getAllTokens
argument_list|()
control|)
block|{
name|cred2
operator|.
name|addToken
argument_list|(
operator|new
name|Text
argument_list|(
name|DELEGATION_TOKEN_KEY
argument_list|)
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
name|DataOutputStream
name|os
init|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|FileOutputStream
argument_list|(
name|binaryTokenFileName
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|cred2
operator|.
name|writeTokenStorageToStream
argument_list|(
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|os
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Assert
operator|.
name|fail
argument_list|(
literal|"Exception "
operator|+
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * run a distributed job and verify that TokenCache is available    * @throws IOException    */
annotation|@
name|Test
DECL|method|testBinaryTokenFile ()
specifier|public
name|void
name|testBinaryTokenFile
parameter_list|()
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|mrCluster
operator|.
name|getConfig
argument_list|()
decl_stmt|;
comment|// provide namenodes names for the job to get the delegation tokens for
specifier|final
name|String
name|nnUri
init|=
name|dfsCluster
operator|.
name|getURI
argument_list|(
literal|0
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_NAMENODES
argument_list|,
name|nnUri
operator|+
literal|","
operator|+
name|nnUri
argument_list|)
expr_stmt|;
comment|// using argument to pass the file name
specifier|final
name|String
index|[]
name|args
init|=
block|{
literal|"-m"
block|,
literal|"1"
block|,
literal|"-r"
block|,
literal|"1"
block|,
literal|"-mt"
block|,
literal|"1"
block|,
literal|"-rt"
block|,
literal|"1"
block|}
decl_stmt|;
name|int
name|res
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|res
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|conf
argument_list|,
operator|new
name|MySleepJob
argument_list|()
argument_list|,
name|args
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Job failed with "
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
name|e
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|out
argument_list|)
expr_stmt|;
name|fail
argument_list|(
literal|"Job failed"
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"dist job res is not 0:"
argument_list|,
literal|0
argument_list|,
name|res
argument_list|)
expr_stmt|;
block|}
comment|/**    * run a distributed job with -tokenCacheFile option parameter and    * verify that no exception happens.    * @throws IOException   */
annotation|@
name|Test
DECL|method|testTokenCacheFile ()
specifier|public
name|void
name|testTokenCacheFile
parameter_list|()
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|mrCluster
operator|.
name|getConfig
argument_list|()
decl_stmt|;
name|createBinaryTokenFile
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// provide namenodes names for the job to get the delegation tokens for
specifier|final
name|String
name|nnUri
init|=
name|dfsCluster
operator|.
name|getURI
argument_list|(
literal|0
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRJobConfig
operator|.
name|JOB_NAMENODES
argument_list|,
name|nnUri
operator|+
literal|","
operator|+
name|nnUri
argument_list|)
expr_stmt|;
comment|// using argument to pass the file name
specifier|final
name|String
index|[]
name|args
init|=
block|{
literal|"-tokenCacheFile"
block|,
name|binaryTokenFileName
operator|.
name|toString
argument_list|()
block|,
literal|"-m"
block|,
literal|"1"
block|,
literal|"-r"
block|,
literal|"1"
block|,
literal|"-mt"
block|,
literal|"1"
block|,
literal|"-rt"
block|,
literal|"1"
block|}
decl_stmt|;
name|int
name|res
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|res
operator|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|conf
argument_list|,
operator|new
name|SleepJob
argument_list|()
argument_list|,
name|args
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Job failed with "
operator|+
name|e
operator|.
name|getLocalizedMessage
argument_list|()
argument_list|)
expr_stmt|;
name|e
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|out
argument_list|)
expr_stmt|;
name|fail
argument_list|(
literal|"Job failed"
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"dist job res is not 0:"
argument_list|,
literal|0
argument_list|,
name|res
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

