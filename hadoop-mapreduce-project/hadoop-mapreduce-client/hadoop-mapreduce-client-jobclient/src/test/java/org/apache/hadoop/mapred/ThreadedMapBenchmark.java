begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SortValidator
operator|.
name|RecordStatsChecker
operator|.
name|NonSplitableSequenceFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_comment
comment|/**  * Distributed threaded map benchmark.  *<p>  * This benchmark generates random data per map and tests the performance   * of having multiple spills (using multiple threads) over having just one   * spill. Following are the parameters that can be specified  *<li>File size per map.  *<li>Number of spills per map.   *<li>Number of maps per host.  *<p>  * Sort is used for benchmarking the performance.   */
end_comment

begin_class
DECL|class|ThreadedMapBenchmark
specifier|public
class|class
name|ThreadedMapBenchmark
extends|extends
name|Configured
implements|implements
name|Tool
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|BASE_DIR
specifier|private
specifier|static
name|Path
name|BASE_DIR
init|=
operator|new
name|Path
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
name|File
operator|.
name|separator
operator|+
literal|"benchmarks"
operator|+
name|File
operator|.
name|separator
operator|+
literal|"ThreadedMapBenchmark"
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|INPUT_DIR
specifier|private
specifier|static
name|Path
name|INPUT_DIR
init|=
operator|new
name|Path
argument_list|(
name|BASE_DIR
argument_list|,
literal|"input"
argument_list|)
decl_stmt|;
DECL|field|OUTPUT_DIR
specifier|private
specifier|static
name|Path
name|OUTPUT_DIR
init|=
operator|new
name|Path
argument_list|(
name|BASE_DIR
argument_list|,
literal|"output"
argument_list|)
decl_stmt|;
DECL|field|FACTOR
specifier|private
specifier|static
specifier|final
name|float
name|FACTOR
init|=
literal|2.3f
decl_stmt|;
comment|// mapreduce.task.io.sort.mb set to
comment|// (FACTOR * data_size) should
comment|// result in only 1 spill
DECL|enum|Counters
DECL|enumConstant|RECORDS_WRITTEN
DECL|enumConstant|BYTES_WRITTEN
specifier|static
enum|enum
name|Counters
block|{
name|RECORDS_WRITTEN
block|,
name|BYTES_WRITTEN
block|}
comment|/**    * Generates random input data of given size with keys and values of given     * sizes. By default it generates 128mb input data with 10 byte keys and 10     * byte values.    */
DECL|class|Map
specifier|public
specifier|static
class|class
name|Map
extends|extends
name|MapReduceBase
implements|implements
name|Mapper
argument_list|<
name|WritableComparable
argument_list|,
name|Writable
argument_list|,
name|BytesWritable
argument_list|,
name|BytesWritable
argument_list|>
block|{
DECL|field|numBytesToWrite
specifier|private
name|long
name|numBytesToWrite
decl_stmt|;
DECL|field|minKeySize
specifier|private
name|int
name|minKeySize
decl_stmt|;
DECL|field|keySizeRange
specifier|private
name|int
name|keySizeRange
decl_stmt|;
DECL|field|minValueSize
specifier|private
name|int
name|minValueSize
decl_stmt|;
DECL|field|valueSizeRange
specifier|private
name|int
name|valueSizeRange
decl_stmt|;
DECL|field|random
specifier|private
name|Random
name|random
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
DECL|field|randomKey
specifier|private
name|BytesWritable
name|randomKey
init|=
operator|new
name|BytesWritable
argument_list|()
decl_stmt|;
DECL|field|randomValue
specifier|private
name|BytesWritable
name|randomValue
init|=
operator|new
name|BytesWritable
argument_list|()
decl_stmt|;
DECL|method|randomizeBytes (byte[] data, int offset, int length)
specifier|private
name|void
name|randomizeBytes
parameter_list|(
name|byte
index|[]
name|data
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
name|offset
operator|+
name|length
operator|-
literal|1
init|;
name|i
operator|>=
name|offset
condition|;
operator|--
name|i
control|)
block|{
name|data
index|[
name|i
index|]
operator|=
operator|(
name|byte
operator|)
name|random
operator|.
name|nextInt
argument_list|(
literal|256
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|map (WritableComparable key, Writable value, OutputCollector<BytesWritable, BytesWritable> output, Reporter reporter)
specifier|public
name|void
name|map
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|value
parameter_list|,
name|OutputCollector
argument_list|<
name|BytesWritable
argument_list|,
name|BytesWritable
argument_list|>
name|output
parameter_list|,
name|Reporter
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|itemCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|numBytesToWrite
operator|>
literal|0
condition|)
block|{
name|int
name|keyLength
init|=
name|minKeySize
operator|+
operator|(
name|keySizeRange
operator|!=
literal|0
condition|?
name|random
operator|.
name|nextInt
argument_list|(
name|keySizeRange
argument_list|)
else|:
literal|0
operator|)
decl_stmt|;
name|randomKey
operator|.
name|setSize
argument_list|(
name|keyLength
argument_list|)
expr_stmt|;
name|randomizeBytes
argument_list|(
name|randomKey
operator|.
name|getBytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|randomKey
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|valueLength
init|=
name|minValueSize
operator|+
operator|(
name|valueSizeRange
operator|!=
literal|0
condition|?
name|random
operator|.
name|nextInt
argument_list|(
name|valueSizeRange
argument_list|)
else|:
literal|0
operator|)
decl_stmt|;
name|randomValue
operator|.
name|setSize
argument_list|(
name|valueLength
argument_list|)
expr_stmt|;
name|randomizeBytes
argument_list|(
name|randomValue
operator|.
name|getBytes
argument_list|()
argument_list|,
literal|0
argument_list|,
name|randomValue
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|output
operator|.
name|collect
argument_list|(
name|randomKey
argument_list|,
name|randomValue
argument_list|)
expr_stmt|;
name|numBytesToWrite
operator|-=
name|keyLength
operator|+
name|valueLength
expr_stmt|;
name|reporter
operator|.
name|incrCounter
argument_list|(
name|Counters
operator|.
name|BYTES_WRITTEN
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|reporter
operator|.
name|incrCounter
argument_list|(
name|Counters
operator|.
name|RECORDS_WRITTEN
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|itemCount
operator|%
literal|200
operator|==
literal|0
condition|)
block|{
name|reporter
operator|.
name|setStatus
argument_list|(
literal|"wrote record "
operator|+
name|itemCount
operator|+
literal|". "
operator|+
name|numBytesToWrite
operator|+
literal|" bytes left."
argument_list|)
expr_stmt|;
block|}
block|}
name|reporter
operator|.
name|setStatus
argument_list|(
literal|"done with "
operator|+
name|itemCount
operator|+
literal|" records."
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|configure (JobConf job)
specifier|public
name|void
name|configure
parameter_list|(
name|JobConf
name|job
parameter_list|)
block|{
name|numBytesToWrite
operator|=
name|job
operator|.
name|getLong
argument_list|(
literal|"test.tmb.bytes_per_map"
argument_list|,
literal|128
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
expr_stmt|;
name|minKeySize
operator|=
name|job
operator|.
name|getInt
argument_list|(
literal|"test.tmb.min_key"
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|keySizeRange
operator|=
name|job
operator|.
name|getInt
argument_list|(
literal|"test.tmb.max_key"
argument_list|,
literal|10
argument_list|)
operator|-
name|minKeySize
expr_stmt|;
name|minValueSize
operator|=
name|job
operator|.
name|getInt
argument_list|(
literal|"test.tmb.min_value"
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|valueSizeRange
operator|=
name|job
operator|.
name|getInt
argument_list|(
literal|"test.tmb.max_value"
argument_list|,
literal|10
argument_list|)
operator|-
name|minValueSize
expr_stmt|;
block|}
block|}
comment|/**    * Generate input data for the benchmark    */
DECL|method|generateInputData (int dataSizePerMap, int numSpillsPerMap, int numMapsPerHost, JobConf masterConf)
specifier|public
specifier|static
name|void
name|generateInputData
parameter_list|(
name|int
name|dataSizePerMap
parameter_list|,
name|int
name|numSpillsPerMap
parameter_list|,
name|int
name|numMapsPerHost
parameter_list|,
name|JobConf
name|masterConf
parameter_list|)
throws|throws
name|Exception
block|{
name|JobConf
name|job
init|=
operator|new
name|JobConf
argument_list|(
name|masterConf
argument_list|,
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
decl_stmt|;
name|job
operator|.
name|setJobName
argument_list|(
literal|"threaded-map-benchmark-random-writer"
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormat
argument_list|(
name|UtilsForTests
operator|.
name|RandomInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormat
argument_list|(
name|SequenceFileOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|Map
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|IdentityReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputKeyClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputValueClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|JobClient
name|client
init|=
operator|new
name|JobClient
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|ClusterStatus
name|cluster
init|=
name|client
operator|.
name|getClusterStatus
argument_list|()
decl_stmt|;
name|long
name|totalDataSize
init|=
name|dataSizePerMap
operator|*
name|numMapsPerHost
operator|*
name|cluster
operator|.
name|getTaskTrackers
argument_list|()
decl_stmt|;
name|job
operator|.
name|set
argument_list|(
literal|"test.tmb.bytes_per_map"
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|dataSizePerMap
operator|*
literal|1024
operator|*
literal|1024
argument_list|)
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// none reduce
name|job
operator|.
name|setNumMapTasks
argument_list|(
name|numMapsPerHost
operator|*
name|cluster
operator|.
name|getTaskTrackers
argument_list|()
argument_list|)
expr_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|INPUT_DIR
argument_list|)
expr_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|BASE_DIR
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Generating random input for the benchmark"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Total data : "
operator|+
name|totalDataSize
operator|+
literal|" mb"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Data per map: "
operator|+
name|dataSizePerMap
operator|+
literal|" mb"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of spills : "
operator|+
name|numSpillsPerMap
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of maps per host : "
operator|+
name|numMapsPerHost
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of hosts : "
operator|+
name|cluster
operator|.
name|getTaskTrackers
argument_list|()
argument_list|)
expr_stmt|;
name|JobClient
operator|.
name|runJob
argument_list|(
name|job
argument_list|)
expr_stmt|;
comment|// generates the input for the benchmark
block|}
comment|/**    * This is the main routine for launching the benchmark. It generates random     * input data. The input is non-splittable. Sort is used for benchmarking.     * This benchmark reports the effect of having multiple sort and spill     * cycles over a single sort and spill.     *     * @throws IOException     */
DECL|method|run (String[] args)
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting the benchmark for threaded spills"
argument_list|)
expr_stmt|;
name|String
name|version
init|=
literal|"ThreadedMapBenchmark.0.0.1"
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|version
argument_list|)
expr_stmt|;
name|String
name|usage
init|=
literal|"Usage: threadedmapbenchmark "
operator|+
literal|"[-dataSizePerMap<data size (in mb) per map, default is 128 mb>] "
operator|+
literal|"[-numSpillsPerMap<number of spills per map, default is 2>] "
operator|+
literal|"[-numMapsPerHost<number of maps per host, default is 1>]"
decl_stmt|;
name|int
name|dataSizePerMap
init|=
literal|128
decl_stmt|;
comment|// in mb
name|int
name|numSpillsPerMap
init|=
literal|2
decl_stmt|;
name|int
name|numMapsPerHost
init|=
literal|1
decl_stmt|;
name|JobConf
name|masterConf
init|=
operator|new
name|JobConf
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// parse command line
if|if
condition|(
name|args
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
literal|"-dataSizePerMap"
argument_list|)
condition|)
block|{
name|dataSizePerMap
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|args
index|[
operator|++
name|i
index|]
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|args
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
literal|"-numSpillsPerMap"
argument_list|)
condition|)
block|{
name|numSpillsPerMap
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|args
index|[
operator|++
name|i
index|]
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|args
index|[
name|i
index|]
operator|.
name|equals
argument_list|(
literal|"-numMapsPerHost"
argument_list|)
condition|)
block|{
name|numMapsPerHost
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|args
index|[
operator|++
name|i
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
name|usage
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|dataSizePerMap
operator|<
literal|1
operator|||
comment|// verify arguments
name|numSpillsPerMap
operator|<
literal|1
operator|||
name|numMapsPerHost
operator|<
literal|1
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
name|usage
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// using random-writer to generate the input data
name|generateInputData
argument_list|(
name|dataSizePerMap
argument_list|,
name|numSpillsPerMap
argument_list|,
name|numMapsPerHost
argument_list|,
name|masterConf
argument_list|)
expr_stmt|;
comment|// configure job for sorting
name|JobConf
name|job
init|=
operator|new
name|JobConf
argument_list|(
name|masterConf
argument_list|,
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
decl_stmt|;
name|job
operator|.
name|setJobName
argument_list|(
literal|"threaded-map-benchmark-unspilled"
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormat
argument_list|(
name|NonSplitableSequenceFileInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormat
argument_list|(
name|SequenceFileOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputKeyClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputValueClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|IdentityMapper
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|IdentityReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|FileInputFormat
operator|.
name|addInputPath
argument_list|(
name|job
argument_list|,
name|INPUT_DIR
argument_list|)
expr_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|OUTPUT_DIR
argument_list|)
expr_stmt|;
name|JobClient
name|client
init|=
operator|new
name|JobClient
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|ClusterStatus
name|cluster
init|=
name|client
operator|.
name|getClusterStatus
argument_list|()
decl_stmt|;
name|job
operator|.
name|setNumMapTasks
argument_list|(
name|numMapsPerHost
operator|*
name|cluster
operator|.
name|getTaskTrackers
argument_list|()
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
literal|1
argument_list|)
expr_stmt|;
comment|// set mapreduce.task.io.sort.mb to avoid spill
name|int
name|ioSortMb
init|=
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
name|FACTOR
operator|*
name|dataSizePerMap
argument_list|)
decl_stmt|;
name|job
operator|.
name|set
argument_list|(
name|JobContext
operator|.
name|IO_SORT_MB
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|ioSortMb
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running sort with 1 spill per map"
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|JobClient
operator|.
name|runJob
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|long
name|endTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Total time taken : "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|endTime
operator|-
name|startTime
argument_list|)
operator|+
literal|" millisec"
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|OUTPUT_DIR
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// set mapreduce.task.io.sort.mb to have multiple spills
name|JobConf
name|spilledJob
init|=
operator|new
name|JobConf
argument_list|(
name|job
argument_list|,
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
decl_stmt|;
name|ioSortMb
operator|=
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
name|FACTOR
operator|*
name|Math
operator|.
name|ceil
argument_list|(
operator|(
name|double
operator|)
name|dataSizePerMap
operator|/
name|numSpillsPerMap
argument_list|)
argument_list|)
expr_stmt|;
name|spilledJob
operator|.
name|set
argument_list|(
name|JobContext
operator|.
name|IO_SORT_MB
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|ioSortMb
argument_list|)
argument_list|)
expr_stmt|;
name|spilledJob
operator|.
name|setJobName
argument_list|(
literal|"threaded-map-benchmark-spilled"
argument_list|)
expr_stmt|;
name|spilledJob
operator|.
name|setJarByClass
argument_list|(
name|ThreadedMapBenchmark
operator|.
name|class
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running sort with "
operator|+
name|numSpillsPerMap
operator|+
literal|" spills per map"
argument_list|)
expr_stmt|;
name|startTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|JobClient
operator|.
name|runJob
argument_list|(
name|spilledJob
argument_list|)
expr_stmt|;
name|endTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Total time taken : "
operator|+
name|String
operator|.
name|valueOf
argument_list|(
name|endTime
operator|-
name|startTime
argument_list|)
operator|+
literal|" millisec"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|fs
operator|!=
literal|null
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|BASE_DIR
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|0
return|;
block|}
DECL|method|main (String[] args)
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|res
init|=
name|ToolRunner
operator|.
name|run
argument_list|(
operator|new
name|ThreadedMapBenchmark
argument_list|()
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|System
operator|.
name|exit
argument_list|(
name|res
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

