begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|junit
operator|.
name|framework
operator|.
name|TestCase
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|BytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SortValidator
operator|.
name|RecordStatsChecker
operator|.
name|NonSplitableSequenceFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|lib
operator|.
name|IdentityReducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobCounter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Ignore
import|;
end_import

begin_comment
comment|/**  * This test checks whether the task caches are created and used properly.  */
end_comment

begin_class
annotation|@
name|Ignore
DECL|class|TestMultipleLevelCaching
specifier|public
class|class
name|TestMultipleLevelCaching
extends|extends
name|TestCase
block|{
DECL|field|MAX_LEVEL
specifier|private
specifier|static
specifier|final
name|int
name|MAX_LEVEL
init|=
literal|5
decl_stmt|;
DECL|field|inDir
specifier|final
name|Path
name|inDir
init|=
operator|new
name|Path
argument_list|(
literal|"/cachetesting"
argument_list|)
decl_stmt|;
DECL|field|outputPath
specifier|final
name|Path
name|outputPath
init|=
operator|new
name|Path
argument_list|(
literal|"/output"
argument_list|)
decl_stmt|;
comment|/**    * Returns a string representing a rack with level + 1 nodes in the topology    * for the rack.    * For id = 2, level = 2 we get /a/b2/c2    *     id = 1, level = 3 we get /a/b1/c1/d1    * NOTE There should always be one shared node i.e /a     * @param id Unique Id for the rack    * @param level The level in the topology where the separation starts    */
DECL|method|getRack (int id, int level)
specifier|private
specifier|static
name|String
name|getRack
parameter_list|(
name|int
name|id
parameter_list|,
name|int
name|level
parameter_list|)
block|{
name|StringBuilder
name|rack
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|char
name|alpha
init|=
literal|'a'
decl_stmt|;
name|int
name|length
init|=
name|level
operator|+
literal|1
decl_stmt|;
while|while
condition|(
name|length
operator|>
name|level
condition|)
block|{
name|rack
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
name|rack
operator|.
name|append
argument_list|(
name|alpha
argument_list|)
expr_stmt|;
operator|++
name|alpha
expr_stmt|;
operator|--
name|length
expr_stmt|;
block|}
while|while
condition|(
name|length
operator|>
literal|0
condition|)
block|{
name|rack
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
name|rack
operator|.
name|append
argument_list|(
name|alpha
argument_list|)
expr_stmt|;
name|rack
operator|.
name|append
argument_list|(
name|id
argument_list|)
expr_stmt|;
operator|++
name|alpha
expr_stmt|;
operator|--
name|length
expr_stmt|;
block|}
return|return
name|rack
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|testMultiLevelCaching ()
specifier|public
name|void
name|testMultiLevelCaching
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|MAX_LEVEL
condition|;
operator|++
name|i
control|)
block|{
name|testCachingAtLevel
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testCachingAtLevel (int level)
specifier|private
name|void
name|testCachingAtLevel
parameter_list|(
name|int
name|level
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|namenode
init|=
literal|null
decl_stmt|;
name|MiniDFSCluster
name|dfs
init|=
literal|null
decl_stmt|;
name|MiniMRCluster
name|mr
init|=
literal|null
decl_stmt|;
name|FileSystem
name|fileSys
init|=
literal|null
decl_stmt|;
name|String
name|testName
init|=
literal|"TestMultiLevelCaching"
decl_stmt|;
try|try
block|{
specifier|final
name|int
name|taskTrackers
init|=
literal|1
decl_stmt|;
comment|// generate the racks
comment|// use rack1 for data node
name|String
name|rack1
init|=
name|getRack
argument_list|(
literal|0
argument_list|,
name|level
argument_list|)
decl_stmt|;
comment|// use rack2 for task tracker
name|String
name|rack2
init|=
name|getRack
argument_list|(
literal|1
argument_list|,
name|level
argument_list|)
decl_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
comment|// Run a datanode on host1 under /a/b/c/..../d1/e1/f1
name|dfs
operator|=
operator|new
name|MiniDFSCluster
argument_list|(
name|conf
argument_list|,
literal|1
argument_list|,
literal|true
argument_list|,
operator|new
name|String
index|[]
block|{
name|rack1
block|}
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"host1.com"
block|}
argument_list|)
expr_stmt|;
name|dfs
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|fileSys
operator|=
name|dfs
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|fileSys
operator|.
name|mkdirs
argument_list|(
name|inDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mkdirs failed to create "
operator|+
name|inDir
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
name|UtilsForTests
operator|.
name|writeFile
argument_list|(
name|dfs
operator|.
name|getNameNode
argument_list|()
argument_list|,
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|inDir
operator|+
literal|"/file"
argument_list|)
argument_list|,
operator|(
name|short
operator|)
literal|1
argument_list|)
expr_stmt|;
name|namenode
operator|=
operator|(
name|dfs
operator|.
name|getFileSystem
argument_list|()
operator|)
operator|.
name|getUri
argument_list|()
operator|.
name|getHost
argument_list|()
operator|+
literal|":"
operator|+
operator|(
name|dfs
operator|.
name|getFileSystem
argument_list|()
operator|)
operator|.
name|getUri
argument_list|()
operator|.
name|getPort
argument_list|()
expr_stmt|;
comment|// Run a job with the (only)tasktracker on host2 under diff topology
comment|// e.g /a/b/c/..../d2/e2/f2.
name|JobConf
name|jc
init|=
operator|new
name|JobConf
argument_list|()
decl_stmt|;
comment|// cache-level = level (unshared levels) + 1(topmost shared node i.e /a)
comment|//               + 1 (for host)
name|jc
operator|.
name|setInt
argument_list|(
name|JTConfig
operator|.
name|JT_TASKCACHE_LEVELS
argument_list|,
name|level
operator|+
literal|2
argument_list|)
expr_stmt|;
name|mr
operator|=
operator|new
name|MiniMRCluster
argument_list|(
name|taskTrackers
argument_list|,
name|namenode
argument_list|,
literal|1
argument_list|,
operator|new
name|String
index|[]
block|{
name|rack2
block|}
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"host2.com"
block|}
argument_list|,
name|jc
argument_list|)
expr_stmt|;
comment|/* The job is configured with 1 map for one (non-splittable) file.         * Since the datanode is running under different subtree, there is no        * node-level data locality but there should be topological locality.        */
name|launchJobAndTestCounters
argument_list|(
name|testName
argument_list|,
name|mr
argument_list|,
name|fileSys
argument_list|,
name|inDir
argument_list|,
name|outputPath
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|mr
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
literal|null
operator|!=
name|fileSys
condition|)
block|{
comment|// inDir, outputPath only exist if fileSys is valid.
name|fileSys
operator|.
name|delete
argument_list|(
name|inDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|fileSys
operator|.
name|delete
argument_list|(
name|outputPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dfs
operator|!=
literal|null
condition|)
block|{
name|dfs
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Launches a MR job and tests the job counters against the expected values.    * @param testName The name for the job    * @param mr The MR cluster    * @param fileSys The FileSystem    * @param in Input path    * @param out Output path    * @param numMaps Number of maps    * @param otherLocalMaps Expected value of other local maps    * @param datalocalMaps Expected value of data(node) local maps    * @param racklocalMaps Expected value of rack local maps    */
DECL|method|launchJobAndTestCounters (String jobName, MiniMRCluster mr, FileSystem fileSys, Path in, Path out, int numMaps, int otherLocalMaps, int dataLocalMaps, int rackLocalMaps)
specifier|static
name|void
name|launchJobAndTestCounters
parameter_list|(
name|String
name|jobName
parameter_list|,
name|MiniMRCluster
name|mr
parameter_list|,
name|FileSystem
name|fileSys
parameter_list|,
name|Path
name|in
parameter_list|,
name|Path
name|out
parameter_list|,
name|int
name|numMaps
parameter_list|,
name|int
name|otherLocalMaps
parameter_list|,
name|int
name|dataLocalMaps
parameter_list|,
name|int
name|rackLocalMaps
parameter_list|)
throws|throws
name|IOException
block|{
name|JobConf
name|jobConf
init|=
name|mr
operator|.
name|createJobConf
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileSys
operator|.
name|exists
argument_list|(
name|out
argument_list|)
condition|)
block|{
name|fileSys
operator|.
name|delete
argument_list|(
name|out
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|RunningJob
name|job
init|=
name|launchJob
argument_list|(
name|jobConf
argument_list|,
name|in
argument_list|,
name|out
argument_list|,
name|numMaps
argument_list|,
name|jobName
argument_list|)
decl_stmt|;
name|Counters
name|counters
init|=
name|job
operator|.
name|getCounters
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
literal|"Number of local maps"
argument_list|,
name|counters
operator|.
name|getCounter
argument_list|(
name|JobCounter
operator|.
name|OTHER_LOCAL_MAPS
argument_list|)
argument_list|,
name|otherLocalMaps
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"Number of Data-local maps"
argument_list|,
name|counters
operator|.
name|getCounter
argument_list|(
name|JobCounter
operator|.
name|DATA_LOCAL_MAPS
argument_list|)
argument_list|,
name|dataLocalMaps
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"Number of Rack-local maps"
argument_list|,
name|counters
operator|.
name|getCounter
argument_list|(
name|JobCounter
operator|.
name|RACK_LOCAL_MAPS
argument_list|)
argument_list|,
name|rackLocalMaps
argument_list|)
expr_stmt|;
name|mr
operator|.
name|waitUntilIdle
argument_list|()
expr_stmt|;
name|mr
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
DECL|method|launchJob (JobConf jobConf, Path inDir, Path outputPath, int numMaps, String jobName)
specifier|static
name|RunningJob
name|launchJob
parameter_list|(
name|JobConf
name|jobConf
parameter_list|,
name|Path
name|inDir
parameter_list|,
name|Path
name|outputPath
parameter_list|,
name|int
name|numMaps
parameter_list|,
name|String
name|jobName
parameter_list|)
throws|throws
name|IOException
block|{
name|jobConf
operator|.
name|setJobName
argument_list|(
name|jobName
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setInputFormat
argument_list|(
name|NonSplitableSequenceFileInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setOutputFormat
argument_list|(
name|SequenceFileOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|FileInputFormat
operator|.
name|setInputPaths
argument_list|(
name|jobConf
argument_list|,
name|inDir
argument_list|)
expr_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|jobConf
argument_list|,
name|outputPath
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setMapperClass
argument_list|(
name|IdentityMapper
operator|.
name|class
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setReducerClass
argument_list|(
name|IdentityReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setOutputKeyClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setOutputValueClass
argument_list|(
name|BytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setNumMapTasks
argument_list|(
name|numMaps
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setNumReduceTasks
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setJar
argument_list|(
literal|"build/test/mapred/testjar/testjob.jar"
argument_list|)
expr_stmt|;
return|return
name|JobClient
operator|.
name|runJob
argument_list|(
name|jobConf
argument_list|)
return|;
block|}
block|}
end_class

end_unit

