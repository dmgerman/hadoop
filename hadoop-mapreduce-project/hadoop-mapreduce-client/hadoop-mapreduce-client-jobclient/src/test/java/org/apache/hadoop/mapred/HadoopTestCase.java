begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_comment
comment|/**  * Abstract Test case class to run MR in local or cluster mode and in local FS  * or DFS.  *  * The Hadoop instance is started and stopped on each test method.  *  * If using DFS the filesystem is reformated at each start (test method).  *  * Job Configurations should be created using a configuration returned by the  * 'createJobConf()' method.  */
end_comment

begin_class
DECL|class|HadoopTestCase
specifier|public
specifier|abstract
class|class
name|HadoopTestCase
block|{
DECL|field|LOCAL_MR
specifier|public
specifier|static
specifier|final
name|int
name|LOCAL_MR
init|=
literal|1
decl_stmt|;
DECL|field|CLUSTER_MR
specifier|public
specifier|static
specifier|final
name|int
name|CLUSTER_MR
init|=
literal|2
decl_stmt|;
DECL|field|LOCAL_FS
specifier|public
specifier|static
specifier|final
name|int
name|LOCAL_FS
init|=
literal|4
decl_stmt|;
DECL|field|DFS_FS
specifier|public
specifier|static
specifier|final
name|int
name|DFS_FS
init|=
literal|8
decl_stmt|;
DECL|field|localMR
specifier|private
name|boolean
name|localMR
decl_stmt|;
DECL|field|localFS
specifier|private
name|boolean
name|localFS
decl_stmt|;
DECL|field|taskTrackers
specifier|private
name|int
name|taskTrackers
decl_stmt|;
DECL|field|dataNodes
specifier|private
name|int
name|dataNodes
decl_stmt|;
comment|/**    * Creates a testcase for local or cluster MR using DFS.    *    * The DFS will be formatted regardless if there was one or not before in the    * given location.    *    * @param mrMode indicates if the MR should be local (LOCAL_MR) or cluster    * (CLUSTER_MR)    * @param fsMode indicates if the FS should be local (LOCAL_FS) or DFS (DFS_FS)    *    * local FS when using relative PATHs)    *    * @param taskTrackers number of task trackers to start when using cluster    *    * @param dataNodes number of data nodes to start when using DFS    *    * @throws IOException thrown if the base directory cannot be set.    */
DECL|method|HadoopTestCase (int mrMode, int fsMode, int taskTrackers, int dataNodes)
specifier|public
name|HadoopTestCase
parameter_list|(
name|int
name|mrMode
parameter_list|,
name|int
name|fsMode
parameter_list|,
name|int
name|taskTrackers
parameter_list|,
name|int
name|dataNodes
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|mrMode
operator|!=
name|LOCAL_MR
operator|&&
name|mrMode
operator|!=
name|CLUSTER_MR
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid MapRed mode, must be LOCAL_MR or CLUSTER_MR"
argument_list|)
throw|;
block|}
if|if
condition|(
name|fsMode
operator|!=
name|LOCAL_FS
operator|&&
name|fsMode
operator|!=
name|DFS_FS
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid FileSystem mode, must be LOCAL_FS or DFS_FS"
argument_list|)
throw|;
block|}
if|if
condition|(
name|taskTrackers
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid taskTrackers value, must be greater than 0"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dataNodes
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid dataNodes value, must be greater than 0"
argument_list|)
throw|;
block|}
name|localMR
operator|=
operator|(
name|mrMode
operator|==
name|LOCAL_MR
operator|)
expr_stmt|;
name|localFS
operator|=
operator|(
name|fsMode
operator|==
name|LOCAL_FS
operator|)
expr_stmt|;
comment|/*       JobConf conf = new JobConf();       fsRoot = conf.get("hadoop.tmp.dir");        if (fsRoot == null) {       throw new IllegalArgumentException(       "hadoop.tmp.dir is not defined");       }        fsRoot = fsRoot.replace(' ', '+') + "/fs";        File file = new File(fsRoot);       if (!file.exists()) {       if (!file.mkdirs()) {       throw new RuntimeException("Could not create FS base path: " + file);       }       }     */
name|this
operator|.
name|taskTrackers
operator|=
name|taskTrackers
expr_stmt|;
name|this
operator|.
name|dataNodes
operator|=
name|dataNodes
expr_stmt|;
block|}
comment|/**    * Indicates if the MR is running in local or cluster mode.    *    * @return returns TRUE if the MR is running locally, FALSE if running in    * cluster mode.    */
DECL|method|isLocalMR ()
specifier|public
name|boolean
name|isLocalMR
parameter_list|()
block|{
return|return
name|localMR
return|;
block|}
comment|/**    * Indicates if the filesystem is local or DFS.    *    * @return returns TRUE if the filesystem is local, FALSE if it is DFS.    */
DECL|method|isLocalFS ()
specifier|public
name|boolean
name|isLocalFS
parameter_list|()
block|{
return|return
name|localFS
return|;
block|}
DECL|field|dfsCluster
specifier|private
name|MiniDFSCluster
name|dfsCluster
init|=
literal|null
decl_stmt|;
DECL|field|mrCluster
specifier|private
name|MiniMRCluster
name|mrCluster
init|=
literal|null
decl_stmt|;
DECL|field|fileSystem
specifier|private
name|FileSystem
name|fileSystem
init|=
literal|null
decl_stmt|;
comment|/**    * Creates Hadoop instance based on constructor configuration before    * a test case is run.    *    * @throws Exception    */
annotation|@
name|Before
DECL|method|setUp ()
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|localFS
condition|)
block|{
name|fileSystem
operator|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
operator|new
name|JobConf
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|dfsCluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
operator|new
name|JobConf
argument_list|()
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|dataNodes
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|fileSystem
operator|=
name|dfsCluster
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|localMR
condition|)
block|{     }
else|else
block|{
comment|//noinspection deprecation
name|mrCluster
operator|=
operator|new
name|MiniMRCluster
argument_list|(
name|taskTrackers
argument_list|,
name|fileSystem
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Destroys Hadoop instance based on constructor configuration after    * a test case is run.    *    * @throws Exception    */
annotation|@
name|After
DECL|method|tearDown ()
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
try|try
block|{
if|if
condition|(
name|mrCluster
operator|!=
literal|null
condition|)
block|{
name|mrCluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|dfsCluster
operator|!=
literal|null
condition|)
block|{
name|dfsCluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Returns the Filesystem in use.    *    * TestCases should use this Filesystem as it    * is properly configured with the workingDir for relative PATHs.    *    * @return the filesystem used by Hadoop.    */
DECL|method|getFileSystem ()
specifier|protected
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|fileSystem
return|;
block|}
comment|/**    * Returns a job configuration preconfigured to run against the Hadoop    * managed by the testcase.    * @return configuration that works on the testcase Hadoop instance    */
DECL|method|createJobConf ()
specifier|protected
name|JobConf
name|createJobConf
parameter_list|()
block|{
if|if
condition|(
name|localMR
condition|)
block|{
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|()
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRConfig
operator|.
name|FRAMEWORK_NAME
argument_list|,
name|MRConfig
operator|.
name|LOCAL_FRAMEWORK_NAME
argument_list|)
expr_stmt|;
return|return
name|conf
return|;
block|}
else|else
block|{
return|return
name|mrCluster
operator|.
name|createJobConf
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

