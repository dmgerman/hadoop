begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|NoSuchAlgorithmException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|crypto
operator|.
name|KeyGenerator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|ProtocolSignature
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Cluster
operator|.
name|JobTrackerStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|ClusterMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|CryptoUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MRJobConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|QueueInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskCompletionEvent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskTrackerInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|checkpoint
operator|.
name|TaskCheckpointID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|protocol
operator|.
name|ClientProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|TokenCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|security
operator|.
name|token
operator|.
name|delegation
operator|.
name|DelegationTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|split
operator|.
name|JobSplit
operator|.
name|TaskSplitMetaInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|split
operator|.
name|SplitMetaInfoReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|task
operator|.
name|TaskAttemptContextImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|v2
operator|.
name|LogParams
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|Credentials
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|authorize
operator|.
name|AccessControlList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|concurrent
operator|.
name|HadoopExecutors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/** Implements MapReduce locally, in-process, for debugging. */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|class|LocalJobRunner
specifier|public
class|class
name|LocalJobRunner
implements|implements
name|ClientProtocol
block|{
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|LocalJobRunner
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** The maximum number of map tasks to run in parallel in LocalJobRunner */
DECL|field|LOCAL_MAX_MAPS
specifier|public
specifier|static
specifier|final
name|String
name|LOCAL_MAX_MAPS
init|=
literal|"mapreduce.local.map.tasks.maximum"
decl_stmt|;
comment|/** The maximum number of reduce tasks to run in parallel in LocalJobRunner */
DECL|field|LOCAL_MAX_REDUCES
specifier|public
specifier|static
specifier|final
name|String
name|LOCAL_MAX_REDUCES
init|=
literal|"mapreduce.local.reduce.tasks.maximum"
decl_stmt|;
DECL|field|INTERMEDIATE_DATA_ENCRYPTION_ALGO
specifier|public
specifier|static
specifier|final
name|String
name|INTERMEDIATE_DATA_ENCRYPTION_ALGO
init|=
literal|"HmacSHA1"
decl_stmt|;
DECL|field|fs
specifier|private
name|FileSystem
name|fs
decl_stmt|;
DECL|field|jobs
specifier|private
name|HashMap
argument_list|<
name|JobID
argument_list|,
name|Job
argument_list|>
name|jobs
init|=
operator|new
name|HashMap
argument_list|<
name|JobID
argument_list|,
name|Job
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|conf
specifier|private
name|JobConf
name|conf
decl_stmt|;
DECL|field|map_tasks
specifier|private
name|AtomicInteger
name|map_tasks
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
DECL|field|reduce_tasks
specifier|private
name|AtomicInteger
name|reduce_tasks
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
DECL|field|rand
specifier|final
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
DECL|field|myMetrics
specifier|private
name|LocalJobRunnerMetrics
name|myMetrics
init|=
literal|null
decl_stmt|;
DECL|field|jobDir
specifier|private
specifier|static
specifier|final
name|String
name|jobDir
init|=
literal|"localRunner/"
decl_stmt|;
DECL|method|getProtocolVersion (String protocol, long clientVersion)
specifier|public
name|long
name|getProtocolVersion
parameter_list|(
name|String
name|protocol
parameter_list|,
name|long
name|clientVersion
parameter_list|)
block|{
return|return
name|ClientProtocol
operator|.
name|versionID
return|;
block|}
annotation|@
name|Override
DECL|method|getProtocolSignature (String protocol, long clientVersion, int clientMethodsHash)
specifier|public
name|ProtocolSignature
name|getProtocolSignature
parameter_list|(
name|String
name|protocol
parameter_list|,
name|long
name|clientVersion
parameter_list|,
name|int
name|clientMethodsHash
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|ProtocolSignature
operator|.
name|getProtocolSignature
argument_list|(
name|this
argument_list|,
name|protocol
argument_list|,
name|clientVersion
argument_list|,
name|clientMethodsHash
argument_list|)
return|;
block|}
DECL|class|Job
specifier|private
class|class
name|Job
extends|extends
name|Thread
implements|implements
name|TaskUmbilicalProtocol
block|{
comment|// The job directory on the system: JobClient places job configurations here.
comment|// This is analogous to JobTracker's system directory.
DECL|field|systemJobDir
specifier|private
name|Path
name|systemJobDir
decl_stmt|;
DECL|field|systemJobFile
specifier|private
name|Path
name|systemJobFile
decl_stmt|;
comment|// The job directory for the task.  Analagous to a task's job directory.
DECL|field|localJobDir
specifier|private
name|Path
name|localJobDir
decl_stmt|;
DECL|field|localJobFile
specifier|private
name|Path
name|localJobFile
decl_stmt|;
DECL|field|id
specifier|private
name|JobID
name|id
decl_stmt|;
DECL|field|job
specifier|private
name|JobConf
name|job
decl_stmt|;
DECL|field|numMapTasks
specifier|private
name|int
name|numMapTasks
decl_stmt|;
DECL|field|numReduceTasks
specifier|private
name|int
name|numReduceTasks
decl_stmt|;
DECL|field|partialMapProgress
specifier|private
name|float
index|[]
name|partialMapProgress
decl_stmt|;
DECL|field|partialReduceProgress
specifier|private
name|float
index|[]
name|partialReduceProgress
decl_stmt|;
DECL|field|mapCounters
specifier|private
name|Counters
index|[]
name|mapCounters
decl_stmt|;
DECL|field|reduceCounters
specifier|private
name|Counters
index|[]
name|reduceCounters
decl_stmt|;
DECL|field|status
specifier|private
name|JobStatus
name|status
decl_stmt|;
DECL|field|mapIds
specifier|private
name|List
argument_list|<
name|TaskAttemptID
argument_list|>
name|mapIds
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|TaskAttemptID
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
DECL|field|profile
specifier|private
name|JobProfile
name|profile
decl_stmt|;
DECL|field|localFs
specifier|private
name|FileSystem
name|localFs
decl_stmt|;
DECL|field|killed
name|boolean
name|killed
init|=
literal|false
decl_stmt|;
DECL|field|localDistributedCacheManager
specifier|private
name|LocalDistributedCacheManager
name|localDistributedCacheManager
decl_stmt|;
DECL|method|getProtocolVersion (String protocol, long clientVersion)
specifier|public
name|long
name|getProtocolVersion
parameter_list|(
name|String
name|protocol
parameter_list|,
name|long
name|clientVersion
parameter_list|)
block|{
return|return
name|TaskUmbilicalProtocol
operator|.
name|versionID
return|;
block|}
annotation|@
name|Override
DECL|method|getProtocolSignature (String protocol, long clientVersion, int clientMethodsHash)
specifier|public
name|ProtocolSignature
name|getProtocolSignature
parameter_list|(
name|String
name|protocol
parameter_list|,
name|long
name|clientVersion
parameter_list|,
name|int
name|clientMethodsHash
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|ProtocolSignature
operator|.
name|getProtocolSignature
argument_list|(
name|this
argument_list|,
name|protocol
argument_list|,
name|clientVersion
argument_list|,
name|clientMethodsHash
argument_list|)
return|;
block|}
DECL|method|Job (JobID jobid, String jobSubmitDir)
specifier|public
name|Job
parameter_list|(
name|JobID
name|jobid
parameter_list|,
name|String
name|jobSubmitDir
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|systemJobDir
operator|=
operator|new
name|Path
argument_list|(
name|jobSubmitDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|systemJobFile
operator|=
operator|new
name|Path
argument_list|(
name|systemJobDir
argument_list|,
literal|"job.xml"
argument_list|)
expr_stmt|;
name|this
operator|.
name|id
operator|=
name|jobid
expr_stmt|;
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|(
name|systemJobFile
argument_list|)
decl_stmt|;
name|this
operator|.
name|localFs
operator|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|String
name|user
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
name|this
operator|.
name|localJobDir
operator|=
name|localFs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|getLocalPath
argument_list|(
name|jobDir
argument_list|)
argument_list|,
name|user
argument_list|)
argument_list|,
name|jobid
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|localJobFile
operator|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|localJobDir
argument_list|,
name|id
operator|+
literal|".xml"
argument_list|)
expr_stmt|;
comment|// Manage the distributed cache.  If there are files to be copied,
comment|// this will trigger localFile to be re-written again.
name|localDistributedCacheManager
operator|=
operator|new
name|LocalDistributedCacheManager
argument_list|()
expr_stmt|;
name|localDistributedCacheManager
operator|.
name|setup
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Write out configuration file.  Instead of copying it from
comment|// systemJobFile, we re-write it, since setup(), above, may have
comment|// updated it.
name|OutputStream
name|out
init|=
name|localFs
operator|.
name|create
argument_list|(
name|localJobFile
argument_list|)
decl_stmt|;
try|try
block|{
name|conf
operator|.
name|writeXml
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|job
operator|=
operator|new
name|JobConf
argument_list|(
name|localJobFile
argument_list|)
expr_stmt|;
comment|// Job (the current object) is a Thread, so we wrap its class loader.
if|if
condition|(
name|localDistributedCacheManager
operator|.
name|hasLocalClasspaths
argument_list|()
condition|)
block|{
name|setContextClassLoader
argument_list|(
name|localDistributedCacheManager
operator|.
name|makeClassLoader
argument_list|(
name|getContextClassLoader
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|profile
operator|=
operator|new
name|JobProfile
argument_list|(
name|job
operator|.
name|getUser
argument_list|()
argument_list|,
name|id
argument_list|,
name|systemJobFile
operator|.
name|toString
argument_list|()
argument_list|,
literal|"http://localhost:8080/"
argument_list|,
name|job
operator|.
name|getJobName
argument_list|()
argument_list|)
expr_stmt|;
name|status
operator|=
operator|new
name|JobStatus
argument_list|(
name|id
argument_list|,
literal|0.0f
argument_list|,
literal|0.0f
argument_list|,
name|JobStatus
operator|.
name|RUNNING
argument_list|,
name|profile
operator|.
name|getUser
argument_list|()
argument_list|,
name|profile
operator|.
name|getJobName
argument_list|()
argument_list|,
name|profile
operator|.
name|getJobFile
argument_list|()
argument_list|,
name|profile
operator|.
name|getURL
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|jobs
operator|.
name|put
argument_list|(
name|id
argument_list|,
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|CryptoUtils
operator|.
name|isEncryptedSpillEnabled
argument_list|(
name|job
argument_list|)
condition|)
block|{
try|try
block|{
name|int
name|keyLen
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MRJobConfig
operator|.
name|MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS
argument_list|,
name|MRJobConfig
operator|.
name|DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS
argument_list|)
decl_stmt|;
name|KeyGenerator
name|keyGen
init|=
name|KeyGenerator
operator|.
name|getInstance
argument_list|(
name|INTERMEDIATE_DATA_ENCRYPTION_ALGO
argument_list|)
decl_stmt|;
name|keyGen
operator|.
name|init
argument_list|(
name|keyLen
argument_list|)
expr_stmt|;
name|Credentials
name|creds
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getCredentials
argument_list|()
decl_stmt|;
name|TokenCache
operator|.
name|setEncryptedSpillKey
argument_list|(
name|keyGen
operator|.
name|generateKey
argument_list|()
operator|.
name|getEncoded
argument_list|()
argument_list|,
name|creds
argument_list|)
expr_stmt|;
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|addCredentials
argument_list|(
name|creds
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchAlgorithmException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Error generating encrypted spill key"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|this
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
DECL|class|RunnableWithThrowable
specifier|protected
specifier|abstract
class|class
name|RunnableWithThrowable
implements|implements
name|Runnable
block|{
DECL|field|storedException
specifier|public
specifier|volatile
name|Throwable
name|storedException
decl_stmt|;
block|}
comment|/**      * A Runnable instance that handles a map task to be run by an executor.      */
DECL|class|MapTaskRunnable
specifier|protected
class|class
name|MapTaskRunnable
extends|extends
name|RunnableWithThrowable
block|{
DECL|field|taskId
specifier|private
specifier|final
name|int
name|taskId
decl_stmt|;
DECL|field|info
specifier|private
specifier|final
name|TaskSplitMetaInfo
name|info
decl_stmt|;
DECL|field|jobId
specifier|private
specifier|final
name|JobID
name|jobId
decl_stmt|;
DECL|field|localConf
specifier|private
specifier|final
name|JobConf
name|localConf
decl_stmt|;
comment|// This is a reference to a shared object passed in by the
comment|// external context; this delivers state to the reducers regarding
comment|// where to fetch mapper outputs.
DECL|field|mapOutputFiles
specifier|private
specifier|final
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
decl_stmt|;
DECL|method|MapTaskRunnable (TaskSplitMetaInfo info, int taskId, JobID jobId, Map<TaskAttemptID, MapOutputFile> mapOutputFiles)
specifier|public
name|MapTaskRunnable
parameter_list|(
name|TaskSplitMetaInfo
name|info
parameter_list|,
name|int
name|taskId
parameter_list|,
name|JobID
name|jobId
parameter_list|,
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
parameter_list|)
block|{
name|this
operator|.
name|info
operator|=
name|info
expr_stmt|;
name|this
operator|.
name|taskId
operator|=
name|taskId
expr_stmt|;
name|this
operator|.
name|mapOutputFiles
operator|=
name|mapOutputFiles
expr_stmt|;
name|this
operator|.
name|jobId
operator|=
name|jobId
expr_stmt|;
name|this
operator|.
name|localConf
operator|=
operator|new
name|JobConf
argument_list|(
name|job
argument_list|)
expr_stmt|;
block|}
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|TaskAttemptID
name|mapId
init|=
operator|new
name|TaskAttemptID
argument_list|(
operator|new
name|TaskID
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|MAP
argument_list|,
name|taskId
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting task: "
operator|+
name|mapId
argument_list|)
expr_stmt|;
name|mapIds
operator|.
name|add
argument_list|(
name|mapId
argument_list|)
expr_stmt|;
name|MapTask
name|map
init|=
operator|new
name|MapTask
argument_list|(
name|systemJobFile
operator|.
name|toString
argument_list|()
argument_list|,
name|mapId
argument_list|,
name|taskId
argument_list|,
name|info
operator|.
name|getSplitIndex
argument_list|()
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|map
operator|.
name|setUser
argument_list|(
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
argument_list|)
expr_stmt|;
name|setupChildMapredLocalDirs
argument_list|(
name|map
argument_list|,
name|localConf
argument_list|)
expr_stmt|;
name|MapOutputFile
name|mapOutput
init|=
operator|new
name|MROutputFiles
argument_list|()
decl_stmt|;
name|mapOutput
operator|.
name|setConf
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
name|mapOutputFiles
operator|.
name|put
argument_list|(
name|mapId
argument_list|,
name|mapOutput
argument_list|)
expr_stmt|;
name|map
operator|.
name|setJobFile
argument_list|(
name|localJobFile
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|localConf
operator|.
name|setUser
argument_list|(
name|map
operator|.
name|getUser
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|localizeConfiguration
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
name|map
operator|.
name|setConf
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
try|try
block|{
name|map_tasks
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
name|myMetrics
operator|.
name|launchMap
argument_list|(
name|mapId
argument_list|)
expr_stmt|;
name|map
operator|.
name|run
argument_list|(
name|localConf
argument_list|,
name|Job
operator|.
name|this
argument_list|)
expr_stmt|;
name|myMetrics
operator|.
name|completeMap
argument_list|(
name|mapId
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|map_tasks
operator|.
name|getAndDecrement
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Finishing task: "
operator|+
name|mapId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
name|this
operator|.
name|storedException
operator|=
name|e
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Create Runnables to encapsulate map tasks for use by the executor      * service.      * @param taskInfo Info about the map task splits      * @param jobId the job id      * @param mapOutputFiles a mapping from task attempts to output files      * @return a List of Runnables, one per map task.      */
DECL|method|getMapTaskRunnables ( TaskSplitMetaInfo [] taskInfo, JobID jobId, Map<TaskAttemptID, MapOutputFile> mapOutputFiles)
specifier|protected
name|List
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|getMapTaskRunnables
parameter_list|(
name|TaskSplitMetaInfo
index|[]
name|taskInfo
parameter_list|,
name|JobID
name|jobId
parameter_list|,
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
parameter_list|)
block|{
name|int
name|numTasks
init|=
literal|0
decl_stmt|;
name|ArrayList
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<
name|RunnableWithThrowable
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|TaskSplitMetaInfo
name|task
range|:
name|taskInfo
control|)
block|{
name|list
operator|.
name|add
argument_list|(
operator|new
name|MapTaskRunnable
argument_list|(
name|task
argument_list|,
name|numTasks
operator|++
argument_list|,
name|jobId
argument_list|,
name|mapOutputFiles
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|list
return|;
block|}
DECL|class|ReduceTaskRunnable
specifier|protected
class|class
name|ReduceTaskRunnable
extends|extends
name|RunnableWithThrowable
block|{
DECL|field|taskId
specifier|private
specifier|final
name|int
name|taskId
decl_stmt|;
DECL|field|jobId
specifier|private
specifier|final
name|JobID
name|jobId
decl_stmt|;
DECL|field|localConf
specifier|private
specifier|final
name|JobConf
name|localConf
decl_stmt|;
comment|// This is a reference to a shared object passed in by the
comment|// external context; this delivers state to the reducers regarding
comment|// where to fetch mapper outputs.
DECL|field|mapOutputFiles
specifier|private
specifier|final
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
decl_stmt|;
DECL|method|ReduceTaskRunnable (int taskId, JobID jobId, Map<TaskAttemptID, MapOutputFile> mapOutputFiles)
specifier|public
name|ReduceTaskRunnable
parameter_list|(
name|int
name|taskId
parameter_list|,
name|JobID
name|jobId
parameter_list|,
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
parameter_list|)
block|{
name|this
operator|.
name|taskId
operator|=
name|taskId
expr_stmt|;
name|this
operator|.
name|jobId
operator|=
name|jobId
expr_stmt|;
name|this
operator|.
name|mapOutputFiles
operator|=
name|mapOutputFiles
expr_stmt|;
name|this
operator|.
name|localConf
operator|=
operator|new
name|JobConf
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|this
operator|.
name|localConf
operator|.
name|set
argument_list|(
literal|"mapreduce.jobtracker.address"
argument_list|,
literal|"local"
argument_list|)
expr_stmt|;
block|}
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|TaskAttemptID
name|reduceId
init|=
operator|new
name|TaskAttemptID
argument_list|(
operator|new
name|TaskID
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|REDUCE
argument_list|,
name|taskId
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting task: "
operator|+
name|reduceId
argument_list|)
expr_stmt|;
name|ReduceTask
name|reduce
init|=
operator|new
name|ReduceTask
argument_list|(
name|systemJobFile
operator|.
name|toString
argument_list|()
argument_list|,
name|reduceId
argument_list|,
name|taskId
argument_list|,
name|mapIds
operator|.
name|size
argument_list|()
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|reduce
operator|.
name|setUser
argument_list|(
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
argument_list|)
expr_stmt|;
name|setupChildMapredLocalDirs
argument_list|(
name|reduce
argument_list|,
name|localConf
argument_list|)
expr_stmt|;
name|reduce
operator|.
name|setLocalMapFiles
argument_list|(
name|mapOutputFiles
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|Job
operator|.
name|this
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
name|reduce
operator|.
name|setJobFile
argument_list|(
name|localJobFile
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|localConf
operator|.
name|setUser
argument_list|(
name|reduce
operator|.
name|getUser
argument_list|()
argument_list|)
expr_stmt|;
name|reduce
operator|.
name|localizeConfiguration
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
name|reduce
operator|.
name|setConf
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
try|try
block|{
name|reduce_tasks
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
name|myMetrics
operator|.
name|launchReduce
argument_list|(
name|reduce
operator|.
name|getTaskID
argument_list|()
argument_list|)
expr_stmt|;
name|reduce
operator|.
name|run
argument_list|(
name|localConf
argument_list|,
name|Job
operator|.
name|this
argument_list|)
expr_stmt|;
name|myMetrics
operator|.
name|completeReduce
argument_list|(
name|reduce
operator|.
name|getTaskID
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|reduce_tasks
operator|.
name|getAndDecrement
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Finishing task: "
operator|+
name|reduceId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|InterruptedException
argument_list|()
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
comment|// store this to be rethrown in the initial thread context.
name|this
operator|.
name|storedException
operator|=
name|t
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Create Runnables to encapsulate reduce tasks for use by the executor      * service.      * @param jobId the job id      * @param mapOutputFiles a mapping from task attempts to output files      * @return a List of Runnables, one per reduce task.      */
DECL|method|getReduceTaskRunnables ( JobID jobId, Map<TaskAttemptID, MapOutputFile> mapOutputFiles)
specifier|protected
name|List
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|getReduceTaskRunnables
parameter_list|(
name|JobID
name|jobId
parameter_list|,
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
parameter_list|)
block|{
name|int
name|taskId
init|=
literal|0
decl_stmt|;
name|ArrayList
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|list
init|=
operator|new
name|ArrayList
argument_list|<
name|RunnableWithThrowable
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|numReduceTasks
condition|;
name|i
operator|++
control|)
block|{
name|list
operator|.
name|add
argument_list|(
operator|new
name|ReduceTaskRunnable
argument_list|(
name|taskId
operator|++
argument_list|,
name|jobId
argument_list|,
name|mapOutputFiles
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|list
return|;
block|}
comment|/**      * Initialize the counters that will hold partial-progress from      * the various task attempts.      * @param numMaps the number of map tasks in this job.      */
DECL|method|initCounters (int numMaps, int numReduces)
specifier|private
specifier|synchronized
name|void
name|initCounters
parameter_list|(
name|int
name|numMaps
parameter_list|,
name|int
name|numReduces
parameter_list|)
block|{
comment|// Initialize state trackers for all map tasks.
name|this
operator|.
name|partialMapProgress
operator|=
operator|new
name|float
index|[
name|numMaps
index|]
expr_stmt|;
name|this
operator|.
name|mapCounters
operator|=
operator|new
name|Counters
index|[
name|numMaps
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numMaps
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|mapCounters
index|[
name|i
index|]
operator|=
operator|new
name|Counters
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|partialReduceProgress
operator|=
operator|new
name|float
index|[
name|numReduces
index|]
expr_stmt|;
name|this
operator|.
name|reduceCounters
operator|=
operator|new
name|Counters
index|[
name|numReduces
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numReduces
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|reduceCounters
index|[
name|i
index|]
operator|=
operator|new
name|Counters
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|numMapTasks
operator|=
name|numMaps
expr_stmt|;
name|this
operator|.
name|numReduceTasks
operator|=
name|numReduces
expr_stmt|;
block|}
comment|/**      * Creates the executor service used to run map tasks.      *      * @return an ExecutorService instance that handles map tasks      */
DECL|method|createMapExecutor ()
specifier|protected
specifier|synchronized
name|ExecutorService
name|createMapExecutor
parameter_list|()
block|{
comment|// Determine the size of the thread pool to use
name|int
name|maxMapThreads
init|=
name|job
operator|.
name|getInt
argument_list|(
name|LOCAL_MAX_MAPS
argument_list|,
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxMapThreads
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Configured "
operator|+
name|LOCAL_MAX_MAPS
operator|+
literal|" must be>= 1"
argument_list|)
throw|;
block|}
name|maxMapThreads
operator|=
name|Math
operator|.
name|min
argument_list|(
name|maxMapThreads
argument_list|,
name|this
operator|.
name|numMapTasks
argument_list|)
expr_stmt|;
name|maxMapThreads
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxMapThreads
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|// In case of no tasks.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Starting mapper thread pool executor."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Max local threads: "
operator|+
name|maxMapThreads
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Map tasks to process: "
operator|+
name|this
operator|.
name|numMapTasks
argument_list|)
expr_stmt|;
comment|// Create a new executor service to drain the work queue.
name|ThreadFactory
name|tf
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setNameFormat
argument_list|(
literal|"LocalJobRunner Map Task Executor #%d"
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|ExecutorService
name|executor
init|=
name|HadoopExecutors
operator|.
name|newFixedThreadPool
argument_list|(
name|maxMapThreads
argument_list|,
name|tf
argument_list|)
decl_stmt|;
return|return
name|executor
return|;
block|}
comment|/**      * Creates the executor service used to run reduce tasks.      *      * @return an ExecutorService instance that handles reduce tasks      */
DECL|method|createReduceExecutor ()
specifier|protected
specifier|synchronized
name|ExecutorService
name|createReduceExecutor
parameter_list|()
block|{
comment|// Determine the size of the thread pool to use
name|int
name|maxReduceThreads
init|=
name|job
operator|.
name|getInt
argument_list|(
name|LOCAL_MAX_REDUCES
argument_list|,
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxReduceThreads
operator|<
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Configured "
operator|+
name|LOCAL_MAX_REDUCES
operator|+
literal|" must be>= 1"
argument_list|)
throw|;
block|}
name|maxReduceThreads
operator|=
name|Math
operator|.
name|min
argument_list|(
name|maxReduceThreads
argument_list|,
name|this
operator|.
name|numReduceTasks
argument_list|)
expr_stmt|;
name|maxReduceThreads
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxReduceThreads
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|// In case of no tasks.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Starting reduce thread pool executor."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Max local threads: "
operator|+
name|maxReduceThreads
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Reduce tasks to process: "
operator|+
name|this
operator|.
name|numReduceTasks
argument_list|)
expr_stmt|;
comment|// Create a new executor service to drain the work queue.
name|ExecutorService
name|executor
init|=
name|HadoopExecutors
operator|.
name|newFixedThreadPool
argument_list|(
name|maxReduceThreads
argument_list|)
decl_stmt|;
return|return
name|executor
return|;
block|}
comment|/** Run a set of tasks and waits for them to complete. */
DECL|method|runTasks (List<RunnableWithThrowable> runnables, ExecutorService service, String taskType)
specifier|private
name|void
name|runTasks
parameter_list|(
name|List
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|runnables
parameter_list|,
name|ExecutorService
name|service
parameter_list|,
name|String
name|taskType
parameter_list|)
throws|throws
name|Exception
block|{
comment|// Start populating the executor with work units.
comment|// They may begin running immediately (in other threads).
for|for
control|(
name|Runnable
name|r
range|:
name|runnables
control|)
block|{
name|service
operator|.
name|submit
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|service
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Instructs queue to drain.
comment|// Wait for tasks to finish; do not use a time-based timeout.
comment|// (See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6179024)
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for "
operator|+
name|taskType
operator|+
literal|" tasks"
argument_list|)
expr_stmt|;
name|service
operator|.
name|awaitTermination
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Cancel all threads.
name|service
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
throw|throw
name|ie
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
name|taskType
operator|+
literal|" task executor complete."
argument_list|)
expr_stmt|;
comment|// After waiting for the tasks to complete, if any of these
comment|// have thrown an exception, rethrow it now in the main thread context.
for|for
control|(
name|RunnableWithThrowable
name|r
range|:
name|runnables
control|)
block|{
if|if
condition|(
name|r
operator|.
name|storedException
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|Exception
argument_list|(
name|r
operator|.
name|storedException
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputCommitter
DECL|method|createOutputCommitter (boolean newApiCommitter, JobID jobId, Configuration conf)
name|createOutputCommitter
parameter_list|(
name|boolean
name|newApiCommitter
parameter_list|,
name|JobID
name|jobId
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|Exception
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputCommitter
name|committer
init|=
literal|null
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"OutputCommitter set in config "
operator|+
name|conf
operator|.
name|get
argument_list|(
literal|"mapred.output.committer.class"
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|newApiCommitter
condition|)
block|{
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskID
name|taskId
init|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskID
argument_list|(
name|jobId
argument_list|,
name|TaskType
operator|.
name|MAP
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
name|taskAttemptID
init|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
argument_list|(
name|taskId
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptContext
name|taskContext
init|=
operator|new
name|TaskAttemptContextImpl
argument_list|(
name|conf
argument_list|,
name|taskAttemptID
argument_list|)
decl_stmt|;
name|OutputFormat
name|outputFormat
init|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|taskContext
operator|.
name|getOutputFormatClass
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|committer
operator|=
name|outputFormat
operator|.
name|getOutputCommitter
argument_list|(
name|taskContext
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|committer
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|conf
operator|.
name|getClass
argument_list|(
literal|"mapred.output.committer.class"
argument_list|,
name|FileOutputCommitter
operator|.
name|class
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|OutputCommitter
operator|.
name|class
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"OutputCommitter is "
operator|+
name|committer
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|committer
return|;
block|}
annotation|@
name|Override
DECL|method|run ()
specifier|public
name|void
name|run
parameter_list|()
block|{
name|JobID
name|jobId
init|=
name|profile
operator|.
name|getJobID
argument_list|()
decl_stmt|;
name|JobContext
name|jContext
init|=
operator|new
name|JobContextImpl
argument_list|(
name|job
argument_list|,
name|jobId
argument_list|)
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|OutputCommitter
name|outputCommitter
init|=
literal|null
decl_stmt|;
try|try
block|{
name|outputCommitter
operator|=
name|createOutputCommitter
argument_list|(
name|conf
operator|.
name|getUseNewMapper
argument_list|()
argument_list|,
name|jobId
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to createOutputCommitter"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
try|try
block|{
name|TaskSplitMetaInfo
index|[]
name|taskSplitMetaInfos
init|=
name|SplitMetaInfoReader
operator|.
name|readSplitMetaInfo
argument_list|(
name|jobId
argument_list|,
name|localFs
argument_list|,
name|conf
argument_list|,
name|systemJobDir
argument_list|)
decl_stmt|;
name|int
name|numReduceTasks
init|=
name|job
operator|.
name|getNumReduceTasks
argument_list|()
decl_stmt|;
name|outputCommitter
operator|.
name|setupJob
argument_list|(
name|jContext
argument_list|)
expr_stmt|;
name|status
operator|.
name|setSetupProgress
argument_list|(
literal|1.0f
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
name|mapOutputFiles
init|=
name|Collections
operator|.
name|synchronizedMap
argument_list|(
operator|new
name|HashMap
argument_list|<
name|TaskAttemptID
argument_list|,
name|MapOutputFile
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|mapRunnables
init|=
name|getMapTaskRunnables
argument_list|(
name|taskSplitMetaInfos
argument_list|,
name|jobId
argument_list|,
name|mapOutputFiles
argument_list|)
decl_stmt|;
name|initCounters
argument_list|(
name|mapRunnables
operator|.
name|size
argument_list|()
argument_list|,
name|numReduceTasks
argument_list|)
expr_stmt|;
name|ExecutorService
name|mapService
init|=
name|createMapExecutor
argument_list|()
decl_stmt|;
name|runTasks
argument_list|(
name|mapRunnables
argument_list|,
name|mapService
argument_list|,
literal|"map"
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|numReduceTasks
operator|>
literal|0
condition|)
block|{
name|List
argument_list|<
name|RunnableWithThrowable
argument_list|>
name|reduceRunnables
init|=
name|getReduceTaskRunnables
argument_list|(
name|jobId
argument_list|,
name|mapOutputFiles
argument_list|)
decl_stmt|;
name|ExecutorService
name|reduceService
init|=
name|createReduceExecutor
argument_list|()
decl_stmt|;
name|runTasks
argument_list|(
name|reduceRunnables
argument_list|,
name|reduceService
argument_list|,
literal|"reduce"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
for|for
control|(
name|MapOutputFile
name|output
range|:
name|mapOutputFiles
operator|.
name|values
argument_list|()
control|)
block|{
name|output
operator|.
name|removeAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|// delete the temporary directory in output directory
name|outputCommitter
operator|.
name|commitJob
argument_list|(
name|jContext
argument_list|)
expr_stmt|;
name|status
operator|.
name|setCleanupProgress
argument_list|(
literal|1.0f
argument_list|)
expr_stmt|;
if|if
condition|(
name|killed
condition|)
block|{
name|this
operator|.
name|status
operator|.
name|setRunState
argument_list|(
name|JobStatus
operator|.
name|KILLED
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|status
operator|.
name|setRunState
argument_list|(
name|JobStatus
operator|.
name|SUCCEEDED
argument_list|)
expr_stmt|;
block|}
name|JobEndNotifier
operator|.
name|localRunnerNotification
argument_list|(
name|job
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
try|try
block|{
name|outputCommitter
operator|.
name|abortJob
argument_list|(
name|jContext
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
operator|.
name|State
operator|.
name|FAILED
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Error cleaning up job:"
operator|+
name|id
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|setCleanupProgress
argument_list|(
literal|1.0f
argument_list|)
expr_stmt|;
if|if
condition|(
name|killed
condition|)
block|{
name|this
operator|.
name|status
operator|.
name|setRunState
argument_list|(
name|JobStatus
operator|.
name|KILLED
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|status
operator|.
name|setRunState
argument_list|(
name|JobStatus
operator|.
name|FAILED
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
name|id
operator|.
name|toString
argument_list|()
argument_list|,
name|t
argument_list|)
expr_stmt|;
name|JobEndNotifier
operator|.
name|localRunnerNotification
argument_list|(
name|job
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
try|try
block|{
name|fs
operator|.
name|delete
argument_list|(
name|systemJobFile
operator|.
name|getParent
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// delete submit dir
name|localFs
operator|.
name|delete
argument_list|(
name|localJobFile
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// delete local copy
comment|// Cleanup distributed cache
name|localDistributedCacheManager
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error cleaning up "
operator|+
name|id
operator|+
literal|": "
operator|+
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// TaskUmbilicalProtocol methods
annotation|@
name|Override
DECL|method|getTask (JvmContext context)
specifier|public
name|JvmTask
name|getTask
parameter_list|(
name|JvmContext
name|context
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|statusUpdate (TaskAttemptID taskId, TaskStatus taskStatus)
specifier|public
specifier|synchronized
name|AMFeedback
name|statusUpdate
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|TaskStatus
name|taskStatus
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|AMFeedback
name|feedback
init|=
operator|new
name|AMFeedback
argument_list|()
decl_stmt|;
name|feedback
operator|.
name|setTaskFound
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
literal|null
operator|==
name|taskStatus
condition|)
block|{
return|return
name|feedback
return|;
block|}
comment|// Serialize as we would if distributed in order to make deep copy
name|ByteArrayOutputStream
name|baos
init|=
operator|new
name|ByteArrayOutputStream
argument_list|()
decl_stmt|;
name|DataOutputStream
name|dos
init|=
operator|new
name|DataOutputStream
argument_list|(
name|baos
argument_list|)
decl_stmt|;
name|taskStatus
operator|.
name|write
argument_list|(
name|dos
argument_list|)
expr_stmt|;
name|dos
operator|.
name|close
argument_list|()
expr_stmt|;
name|taskStatus
operator|=
name|TaskStatus
operator|.
name|createTaskStatus
argument_list|(
name|taskStatus
operator|.
name|getIsMap
argument_list|()
argument_list|)
expr_stmt|;
name|taskStatus
operator|.
name|readFields
argument_list|(
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|baos
operator|.
name|toByteArray
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|taskStatus
operator|.
name|getStateString
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|mapTaskIndex
init|=
name|mapIds
operator|.
name|indexOf
argument_list|(
name|taskId
argument_list|)
decl_stmt|;
if|if
condition|(
name|mapTaskIndex
operator|>=
literal|0
condition|)
block|{
comment|// mapping
name|float
name|numTasks
init|=
operator|(
name|float
operator|)
name|this
operator|.
name|numMapTasks
decl_stmt|;
name|partialMapProgress
index|[
name|mapTaskIndex
index|]
operator|=
name|taskStatus
operator|.
name|getProgress
argument_list|()
expr_stmt|;
name|mapCounters
index|[
name|mapTaskIndex
index|]
operator|=
name|taskStatus
operator|.
name|getCounters
argument_list|()
expr_stmt|;
name|float
name|partialProgress
init|=
literal|0.0f
decl_stmt|;
for|for
control|(
name|float
name|f
range|:
name|partialMapProgress
control|)
block|{
name|partialProgress
operator|+=
name|f
expr_stmt|;
block|}
name|status
operator|.
name|setMapProgress
argument_list|(
name|partialProgress
operator|/
name|numTasks
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// reducing
name|int
name|reduceTaskIndex
init|=
name|taskId
operator|.
name|getTaskID
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
name|float
name|numTasks
init|=
operator|(
name|float
operator|)
name|this
operator|.
name|numReduceTasks
decl_stmt|;
name|partialReduceProgress
index|[
name|reduceTaskIndex
index|]
operator|=
name|taskStatus
operator|.
name|getProgress
argument_list|()
expr_stmt|;
name|reduceCounters
index|[
name|reduceTaskIndex
index|]
operator|=
name|taskStatus
operator|.
name|getCounters
argument_list|()
expr_stmt|;
name|float
name|partialProgress
init|=
literal|0.0f
decl_stmt|;
for|for
control|(
name|float
name|f
range|:
name|partialReduceProgress
control|)
block|{
name|partialProgress
operator|+=
name|f
expr_stmt|;
block|}
name|status
operator|.
name|setReduceProgress
argument_list|(
name|partialProgress
operator|/
name|numTasks
argument_list|)
expr_stmt|;
block|}
comment|// ignore phase
return|return
name|feedback
return|;
block|}
comment|/** Return the current values of the counters for this job,      * including tasks that are in progress.      */
DECL|method|getCurrentCounters ()
specifier|public
specifier|synchronized
name|Counters
name|getCurrentCounters
parameter_list|()
block|{
if|if
condition|(
literal|null
operator|==
name|mapCounters
condition|)
block|{
comment|// Counters not yet initialized for job.
return|return
operator|new
name|Counters
argument_list|()
return|;
block|}
name|Counters
name|current
init|=
operator|new
name|Counters
argument_list|()
decl_stmt|;
for|for
control|(
name|Counters
name|c
range|:
name|mapCounters
control|)
block|{
name|current
operator|=
name|Counters
operator|.
name|sum
argument_list|(
name|current
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
literal|null
operator|!=
name|reduceCounters
operator|&&
name|reduceCounters
operator|.
name|length
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|Counters
name|c
range|:
name|reduceCounters
control|)
block|{
name|current
operator|=
name|Counters
operator|.
name|sum
argument_list|(
name|current
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|current
return|;
block|}
comment|/**      * Task is reporting that it is in commit_pending      * and it is waiting for the commit Response      */
DECL|method|commitPending (TaskAttemptID taskid, TaskStatus taskStatus)
specifier|public
name|void
name|commitPending
parameter_list|(
name|TaskAttemptID
name|taskid
parameter_list|,
name|TaskStatus
name|taskStatus
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|statusUpdate
argument_list|(
name|taskid
argument_list|,
name|taskStatus
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|reportDiagnosticInfo (TaskAttemptID taskid, String trace)
specifier|public
name|void
name|reportDiagnosticInfo
parameter_list|(
name|TaskAttemptID
name|taskid
parameter_list|,
name|String
name|trace
parameter_list|)
block|{
comment|// Ignore for now
block|}
annotation|@
name|Override
DECL|method|reportNextRecordRange (TaskAttemptID taskid, SortedRanges.Range range)
specifier|public
name|void
name|reportNextRecordRange
parameter_list|(
name|TaskAttemptID
name|taskid
parameter_list|,
name|SortedRanges
operator|.
name|Range
name|range
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Task "
operator|+
name|taskid
operator|+
literal|" reportedNextRecordRange "
operator|+
name|range
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|canCommit (TaskAttemptID taskid)
specifier|public
name|boolean
name|canCommit
parameter_list|(
name|TaskAttemptID
name|taskid
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
DECL|method|done (TaskAttemptID taskId)
specifier|public
name|void
name|done
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|taskIndex
init|=
name|mapIds
operator|.
name|indexOf
argument_list|(
name|taskId
argument_list|)
decl_stmt|;
if|if
condition|(
name|taskIndex
operator|>=
literal|0
condition|)
block|{
comment|// mapping
name|status
operator|.
name|setMapProgress
argument_list|(
literal|1.0f
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|status
operator|.
name|setReduceProgress
argument_list|(
literal|1.0f
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|fsError (TaskAttemptID taskId, String message)
specifier|public
specifier|synchronized
name|void
name|fsError
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|String
name|message
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"FSError: "
operator|+
name|message
operator|+
literal|"from task: "
operator|+
name|taskId
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|shuffleError (TaskAttemptID taskId, String message)
specifier|public
name|void
name|shuffleError
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|String
name|message
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"shuffleError: "
operator|+
name|message
operator|+
literal|"from task: "
operator|+
name|taskId
argument_list|)
expr_stmt|;
block|}
DECL|method|fatalError (TaskAttemptID taskId, String msg)
specifier|public
specifier|synchronized
name|void
name|fatalError
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|String
name|msg
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Fatal: "
operator|+
name|msg
operator|+
literal|"from task: "
operator|+
name|taskId
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getMapCompletionEvents (JobID jobId, int fromEventId, int maxLocs, TaskAttemptID id)
specifier|public
name|MapTaskCompletionEventsUpdate
name|getMapCompletionEvents
parameter_list|(
name|JobID
name|jobId
parameter_list|,
name|int
name|fromEventId
parameter_list|,
name|int
name|maxLocs
parameter_list|,
name|TaskAttemptID
name|id
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|MapTaskCompletionEventsUpdate
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|TaskCompletionEvent
operator|.
name|EMPTY_ARRAY
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|preempted (TaskAttemptID taskId, TaskStatus taskStatus)
specifier|public
name|void
name|preempted
parameter_list|(
name|TaskAttemptID
name|taskId
parameter_list|,
name|TaskStatus
name|taskStatus
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// ignore
block|}
annotation|@
name|Override
DECL|method|getCheckpointID (TaskID taskId)
specifier|public
name|TaskCheckpointID
name|getCheckpointID
parameter_list|(
name|TaskID
name|taskId
parameter_list|)
block|{
comment|// ignore
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|setCheckpointID (TaskID downgrade, TaskCheckpointID cid)
specifier|public
name|void
name|setCheckpointID
parameter_list|(
name|TaskID
name|downgrade
parameter_list|,
name|TaskCheckpointID
name|cid
parameter_list|)
block|{
comment|// ignore
block|}
block|}
DECL|method|LocalJobRunner (Configuration conf)
specifier|public
name|LocalJobRunner
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
operator|new
name|JobConf
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Deprecated
DECL|method|LocalJobRunner (JobConf conf)
specifier|public
name|LocalJobRunner
parameter_list|(
name|JobConf
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|myMetrics
operator|=
name|LocalJobRunnerMetrics
operator|.
name|create
argument_list|()
expr_stmt|;
block|}
comment|// JobSubmissionProtocol methods
DECL|field|jobid
specifier|private
specifier|static
name|int
name|jobid
init|=
literal|0
decl_stmt|;
comment|// used for making sure that local jobs run in different jvms don't
comment|// collide on staging or job directories
DECL|field|randid
specifier|private
name|int
name|randid
decl_stmt|;
DECL|method|getNewJobID ()
specifier|public
specifier|synchronized
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|getNewJobID
parameter_list|()
block|{
return|return
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
argument_list|(
literal|"local"
operator|+
name|randid
argument_list|,
operator|++
name|jobid
argument_list|)
return|;
block|}
DECL|method|submitJob ( org.apache.hadoop.mapreduce.JobID jobid, String jobSubmitDir, Credentials credentials)
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
name|submitJob
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|jobid
parameter_list|,
name|String
name|jobSubmitDir
parameter_list|,
name|Credentials
name|credentials
parameter_list|)
throws|throws
name|IOException
block|{
name|Job
name|job
init|=
operator|new
name|Job
argument_list|(
name|JobID
operator|.
name|downgrade
argument_list|(
name|jobid
argument_list|)
argument_list|,
name|jobSubmitDir
argument_list|)
decl_stmt|;
name|job
operator|.
name|job
operator|.
name|setCredentials
argument_list|(
name|credentials
argument_list|)
expr_stmt|;
return|return
name|job
operator|.
name|status
return|;
block|}
DECL|method|killJob (org.apache.hadoop.mapreduce.JobID id)
specifier|public
name|void
name|killJob
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|id
parameter_list|)
block|{
name|jobs
operator|.
name|get
argument_list|(
name|JobID
operator|.
name|downgrade
argument_list|(
name|id
argument_list|)
argument_list|)
operator|.
name|killed
operator|=
literal|true
expr_stmt|;
name|jobs
operator|.
name|get
argument_list|(
name|JobID
operator|.
name|downgrade
argument_list|(
name|id
argument_list|)
argument_list|)
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
DECL|method|setJobPriority (org.apache.hadoop.mapreduce.JobID id, String jp)
specifier|public
name|void
name|setJobPriority
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|id
parameter_list|,
name|String
name|jp
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Changing job priority "
operator|+
literal|"in LocalJobRunner is not supported."
argument_list|)
throw|;
block|}
comment|/** Throws {@link UnsupportedOperationException} */
DECL|method|killTask (org.apache.hadoop.mapreduce.TaskAttemptID taskId, boolean shouldFail)
specifier|public
name|boolean
name|killTask
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
name|taskId
parameter_list|,
name|boolean
name|shouldFail
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Killing tasks in "
operator|+
literal|"LocalJobRunner is not supported"
argument_list|)
throw|;
block|}
DECL|method|getTaskReports ( org.apache.hadoop.mapreduce.JobID id, TaskType type)
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskReport
index|[]
name|getTaskReports
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|id
parameter_list|,
name|TaskType
name|type
parameter_list|)
block|{
return|return
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskReport
index|[
literal|0
index|]
return|;
block|}
DECL|method|getJobStatus ( org.apache.hadoop.mapreduce.JobID id)
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
name|getJobStatus
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|id
parameter_list|)
block|{
name|Job
name|job
init|=
name|jobs
operator|.
name|get
argument_list|(
name|JobID
operator|.
name|downgrade
argument_list|(
name|id
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|job
operator|!=
literal|null
condition|)
return|return
name|job
operator|.
name|status
return|;
else|else
return|return
literal|null
return|;
block|}
DECL|method|getJobCounters ( org.apache.hadoop.mapreduce.JobID id)
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Counters
name|getJobCounters
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|id
parameter_list|)
block|{
name|Job
name|job
init|=
name|jobs
operator|.
name|get
argument_list|(
name|JobID
operator|.
name|downgrade
argument_list|(
name|id
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Counters
argument_list|(
name|job
operator|.
name|getCurrentCounters
argument_list|()
argument_list|)
return|;
block|}
DECL|method|getFilesystemName ()
specifier|public
name|String
name|getFilesystemName
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|fs
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|getClusterMetrics ()
specifier|public
name|ClusterMetrics
name|getClusterMetrics
parameter_list|()
block|{
name|int
name|numMapTasks
init|=
name|map_tasks
operator|.
name|get
argument_list|()
decl_stmt|;
name|int
name|numReduceTasks
init|=
name|reduce_tasks
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
operator|new
name|ClusterMetrics
argument_list|(
name|numMapTasks
argument_list|,
name|numReduceTasks
argument_list|,
name|numMapTasks
argument_list|,
name|numReduceTasks
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|,
name|jobs
operator|.
name|size
argument_list|()
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
block|}
DECL|method|getJobTrackerStatus ()
specifier|public
name|JobTrackerStatus
name|getJobTrackerStatus
parameter_list|()
block|{
return|return
name|JobTrackerStatus
operator|.
name|RUNNING
return|;
block|}
DECL|method|getTaskTrackerExpiryInterval ()
specifier|public
name|long
name|getTaskTrackerExpiryInterval
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
literal|0
return|;
block|}
comment|/**     * Get all active trackers in cluster.     * @return array of TaskTrackerInfo    */
DECL|method|getActiveTrackers ()
specifier|public
name|TaskTrackerInfo
index|[]
name|getActiveTrackers
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
operator|new
name|TaskTrackerInfo
index|[
literal|0
index|]
return|;
block|}
comment|/**     * Get all blacklisted trackers in cluster.     * @return array of TaskTrackerInfo    */
DECL|method|getBlacklistedTrackers ()
specifier|public
name|TaskTrackerInfo
index|[]
name|getBlacklistedTrackers
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
operator|new
name|TaskTrackerInfo
index|[
literal|0
index|]
return|;
block|}
DECL|method|getTaskCompletionEvents ( org.apache.hadoop.mapreduce.JobID jobid , int fromEventId, int maxEvents)
specifier|public
name|TaskCompletionEvent
index|[]
name|getTaskCompletionEvents
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|jobid
parameter_list|,
name|int
name|fromEventId
parameter_list|,
name|int
name|maxEvents
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|TaskCompletionEvent
operator|.
name|EMPTY_ARRAY
return|;
block|}
DECL|method|getAllJobs ()
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobStatus
index|[]
name|getAllJobs
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
comment|/**    * Returns the diagnostic information for a particular task in the given job.    * To be implemented    */
DECL|method|getTaskDiagnostics ( org.apache.hadoop.mapreduce.TaskAttemptID taskid)
specifier|public
name|String
index|[]
name|getTaskDiagnostics
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
name|taskid
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|String
index|[
literal|0
index|]
return|;
block|}
comment|/**    * @see org.apache.hadoop.mapreduce.protocol.ClientProtocol#getSystemDir()    */
DECL|method|getSystemDir ()
specifier|public
name|String
name|getSystemDir
parameter_list|()
block|{
name|Path
name|sysDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|JTConfig
operator|.
name|JT_SYSTEM_DIR
argument_list|,
literal|"/tmp/hadoop/mapred/system"
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|makeQualified
argument_list|(
name|sysDir
argument_list|)
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * @see org.apache.hadoop.mapreduce.protocol.ClientProtocol#getQueueAdmins(String)    */
DECL|method|getQueueAdmins (String queueName)
specifier|public
name|AccessControlList
name|getQueueAdmins
parameter_list|(
name|String
name|queueName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|AccessControlList
argument_list|(
literal|" "
argument_list|)
return|;
comment|// no queue admins for local job runner
block|}
comment|/**    * @see org.apache.hadoop.mapreduce.protocol.ClientProtocol#getStagingAreaDir()    */
DECL|method|getStagingAreaDir ()
specifier|public
name|String
name|getStagingAreaDir
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|stagingRootDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|JTConfig
operator|.
name|JT_STAGING_AREA_ROOT
argument_list|,
literal|"/tmp/hadoop/mapred/staging"
argument_list|)
argument_list|)
decl_stmt|;
name|UserGroupInformation
name|ugi
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
decl_stmt|;
name|String
name|user
decl_stmt|;
name|randid
operator|=
name|rand
operator|.
name|nextInt
argument_list|(
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
if|if
condition|(
name|ugi
operator|!=
literal|null
condition|)
block|{
name|user
operator|=
name|ugi
operator|.
name|getShortUserName
argument_list|()
operator|+
name|randid
expr_stmt|;
block|}
else|else
block|{
name|user
operator|=
literal|"dummy"
operator|+
name|randid
expr_stmt|;
block|}
return|return
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
name|stagingRootDir
argument_list|,
name|user
operator|+
literal|"/.staging"
argument_list|)
argument_list|)
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|getJobHistoryDir ()
specifier|public
name|String
name|getJobHistoryDir
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getChildQueues (String queueName)
specifier|public
name|QueueInfo
index|[]
name|getChildQueues
parameter_list|(
name|String
name|queueName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getRootQueues ()
specifier|public
name|QueueInfo
index|[]
name|getRootQueues
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getQueues ()
specifier|public
name|QueueInfo
index|[]
name|getQueues
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|getQueue (String queue)
specifier|public
name|QueueInfo
name|getQueue
parameter_list|(
name|String
name|queue
parameter_list|)
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|QueueAclsInfo
index|[]
DECL|method|getQueueAclsForCurrentUser ()
name|getQueueAclsForCurrentUser
parameter_list|()
throws|throws
name|IOException
block|{
return|return
literal|null
return|;
block|}
comment|/**    * Set the max number of map tasks to run concurrently in the LocalJobRunner.    * @param job the job to configure    * @param maxMaps the maximum number of map tasks to allow.    */
DECL|method|setLocalMaxRunningMaps ( org.apache.hadoop.mapreduce.JobContext job, int maxMaps)
specifier|public
specifier|static
name|void
name|setLocalMaxRunningMaps
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
name|job
parameter_list|,
name|int
name|maxMaps
parameter_list|)
block|{
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
name|LOCAL_MAX_MAPS
argument_list|,
name|maxMaps
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return the max number of map tasks to run concurrently in the    * LocalJobRunner.    */
DECL|method|getLocalMaxRunningMaps ( org.apache.hadoop.mapreduce.JobContext job)
specifier|public
specifier|static
name|int
name|getLocalMaxRunningMaps
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
name|job
parameter_list|)
block|{
return|return
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getInt
argument_list|(
name|LOCAL_MAX_MAPS
argument_list|,
literal|1
argument_list|)
return|;
block|}
comment|/**    * Set the max number of reduce tasks to run concurrently in the LocalJobRunner.    * @param job the job to configure    * @param maxReduces the maximum number of reduce tasks to allow.    */
DECL|method|setLocalMaxRunningReduces ( org.apache.hadoop.mapreduce.JobContext job, int maxReduces)
specifier|public
specifier|static
name|void
name|setLocalMaxRunningReduces
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
name|job
parameter_list|,
name|int
name|maxReduces
parameter_list|)
block|{
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
name|LOCAL_MAX_REDUCES
argument_list|,
name|maxReduces
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return the max number of reduce tasks to run concurrently in the    * LocalJobRunner.    */
DECL|method|getLocalMaxRunningReduces ( org.apache.hadoop.mapreduce.JobContext job)
specifier|public
specifier|static
name|int
name|getLocalMaxRunningReduces
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
name|job
parameter_list|)
block|{
return|return
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getInt
argument_list|(
name|LOCAL_MAX_REDUCES
argument_list|,
literal|1
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|cancelDelegationToken (Token<DelegationTokenIdentifier> token )
specifier|public
name|void
name|cancelDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{   }
annotation|@
name|Override
specifier|public
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
DECL|method|getDelegationToken (Text renewer)
name|getDelegationToken
parameter_list|(
name|Text
name|renewer
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
DECL|method|renewDelegationToken (Token<DelegationTokenIdentifier> token )
specifier|public
name|long
name|renewDelegationToken
parameter_list|(
name|Token
argument_list|<
name|DelegationTokenIdentifier
argument_list|>
name|token
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
literal|0
return|;
block|}
annotation|@
name|Override
DECL|method|getLogFileParams (org.apache.hadoop.mapreduce.JobID jobID, org.apache.hadoop.mapreduce.TaskAttemptID taskAttemptID)
specifier|public
name|LogParams
name|getLogFileParams
parameter_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobID
name|jobID
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptID
name|taskAttemptID
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Not supported"
argument_list|)
throw|;
block|}
DECL|method|setupChildMapredLocalDirs (Task t, JobConf conf)
specifier|static
name|void
name|setupChildMapredLocalDirs
parameter_list|(
name|Task
name|t
parameter_list|,
name|JobConf
name|conf
parameter_list|)
block|{
name|String
index|[]
name|localDirs
init|=
name|conf
operator|.
name|getTrimmedStrings
argument_list|(
name|MRConfig
operator|.
name|LOCAL_DIR
argument_list|)
decl_stmt|;
name|String
name|jobId
init|=
name|t
operator|.
name|getJobID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|taskId
init|=
name|t
operator|.
name|getTaskID
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|boolean
name|isCleanup
init|=
name|t
operator|.
name|isTaskCleanupTask
argument_list|()
decl_stmt|;
name|String
name|user
init|=
name|t
operator|.
name|getUser
argument_list|()
decl_stmt|;
name|StringBuffer
name|childMapredLocalDir
init|=
operator|new
name|StringBuffer
argument_list|(
name|localDirs
index|[
literal|0
index|]
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|getLocalTaskDir
argument_list|(
name|user
argument_list|,
name|jobId
argument_list|,
name|taskId
argument_list|,
name|isCleanup
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|localDirs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|childMapredLocalDir
operator|.
name|append
argument_list|(
literal|","
operator|+
name|localDirs
index|[
name|i
index|]
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|getLocalTaskDir
argument_list|(
name|user
argument_list|,
name|jobId
argument_list|,
name|taskId
argument_list|,
name|isCleanup
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
name|MRConfig
operator|.
name|LOCAL_DIR
operator|+
literal|" for child : "
operator|+
name|childMapredLocalDir
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MRConfig
operator|.
name|LOCAL_DIR
argument_list|,
name|childMapredLocalDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|field|TASK_CLEANUP_SUFFIX
specifier|static
specifier|final
name|String
name|TASK_CLEANUP_SUFFIX
init|=
literal|".cleanup"
decl_stmt|;
DECL|field|JOBCACHE
specifier|static
specifier|final
name|String
name|JOBCACHE
init|=
literal|"jobcache"
decl_stmt|;
DECL|method|getLocalTaskDir (String user, String jobid, String taskid, boolean isCleanupAttempt)
specifier|static
name|String
name|getLocalTaskDir
parameter_list|(
name|String
name|user
parameter_list|,
name|String
name|jobid
parameter_list|,
name|String
name|taskid
parameter_list|,
name|boolean
name|isCleanupAttempt
parameter_list|)
block|{
name|String
name|taskDir
init|=
name|jobDir
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|user
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|JOBCACHE
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|jobid
operator|+
name|Path
operator|.
name|SEPARATOR
operator|+
name|taskid
decl_stmt|;
if|if
condition|(
name|isCleanupAttempt
condition|)
block|{
name|taskDir
operator|=
name|taskDir
operator|+
name|TASK_CLEANUP_SUFFIX
expr_stmt|;
block|}
return|return
name|taskDir
return|;
block|}
block|}
end_class

end_unit

