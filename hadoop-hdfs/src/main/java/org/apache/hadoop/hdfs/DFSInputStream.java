begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|Socket
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|AbstractMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ChecksumException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|UnresolvedLinkException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ClientDatanodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|ExtendedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LocatedBlocks
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|BlockTokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|security
operator|.
name|token
operator|.
name|block
operator|.
name|InvalidBlockTokenException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|ReplicaNotFoundException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RPC
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|net
operator|.
name|NetUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_comment
comment|/****************************************************************  * DFSInputStream provides bytes from a named file.  It handles   * negotiation of the namenode and various datanodes as necessary.  ****************************************************************/
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|DFSInputStream
specifier|public
class|class
name|DFSInputStream
extends|extends
name|FSInputStream
block|{
DECL|field|socketCache
specifier|private
specifier|final
name|SocketCache
name|socketCache
decl_stmt|;
DECL|field|dfsClient
specifier|private
specifier|final
name|DFSClient
name|dfsClient
decl_stmt|;
DECL|field|closed
specifier|private
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
DECL|field|src
specifier|private
specifier|final
name|String
name|src
decl_stmt|;
DECL|field|prefetchSize
specifier|private
name|long
name|prefetchSize
decl_stmt|;
DECL|field|blockReader
specifier|private
name|BlockReader
name|blockReader
init|=
literal|null
decl_stmt|;
DECL|field|verifyChecksum
specifier|private
name|boolean
name|verifyChecksum
decl_stmt|;
DECL|field|locatedBlocks
specifier|private
name|LocatedBlocks
name|locatedBlocks
init|=
literal|null
decl_stmt|;
DECL|field|lastBlockBeingWrittenLength
specifier|private
name|long
name|lastBlockBeingWrittenLength
init|=
literal|0
decl_stmt|;
DECL|field|currentNode
specifier|private
name|DatanodeInfo
name|currentNode
init|=
literal|null
decl_stmt|;
DECL|field|currentLocatedBlock
specifier|private
name|LocatedBlock
name|currentLocatedBlock
init|=
literal|null
decl_stmt|;
DECL|field|pos
specifier|private
name|long
name|pos
init|=
literal|0
decl_stmt|;
DECL|field|blockEnd
specifier|private
name|long
name|blockEnd
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * This variable tracks the number of failures since the start of the    * most recent user-facing operation. That is to say, it should be reset    * whenever the user makes a call on this stream, and if at any point    * during the retry logic, the failure count exceeds a threshold,    * the errors will be thrown back to the operation.    *    * Specifically this counts the number of times the client has gone    * back to the namenode to get a new list of block locations, and is    * capped at maxBlockAcquireFailures    */
DECL|field|failures
specifier|private
name|int
name|failures
init|=
literal|0
decl_stmt|;
DECL|field|timeWindow
specifier|private
name|int
name|timeWindow
decl_stmt|;
comment|/* XXX Use of CocurrentHashMap is temp fix. Need to fix     * parallel accesses to DFSInputStream (through ptreads) properly */
DECL|field|deadNodes
specifier|private
name|ConcurrentHashMap
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|deadNodes
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
argument_list|()
decl_stmt|;
DECL|field|buffersize
specifier|private
name|int
name|buffersize
init|=
literal|1
decl_stmt|;
DECL|field|oneByteBuf
specifier|private
name|byte
index|[]
name|oneByteBuf
init|=
operator|new
name|byte
index|[
literal|1
index|]
decl_stmt|;
comment|// used for 'int read()'
DECL|field|nCachedConnRetry
specifier|private
name|int
name|nCachedConnRetry
decl_stmt|;
DECL|method|addToDeadNodes (DatanodeInfo dnInfo)
name|void
name|addToDeadNodes
parameter_list|(
name|DatanodeInfo
name|dnInfo
parameter_list|)
block|{
name|deadNodes
operator|.
name|put
argument_list|(
name|dnInfo
argument_list|,
name|dnInfo
argument_list|)
expr_stmt|;
block|}
DECL|method|DFSInputStream (DFSClient dfsClient, String src, int buffersize, boolean verifyChecksum )
name|DFSInputStream
parameter_list|(
name|DFSClient
name|dfsClient
parameter_list|,
name|String
name|src
parameter_list|,
name|int
name|buffersize
parameter_list|,
name|boolean
name|verifyChecksum
parameter_list|)
throws|throws
name|IOException
throws|,
name|UnresolvedLinkException
block|{
name|this
operator|.
name|dfsClient
operator|=
name|dfsClient
expr_stmt|;
name|this
operator|.
name|verifyChecksum
operator|=
name|verifyChecksum
expr_stmt|;
name|this
operator|.
name|buffersize
operator|=
name|buffersize
expr_stmt|;
name|this
operator|.
name|src
operator|=
name|src
expr_stmt|;
name|this
operator|.
name|socketCache
operator|=
name|dfsClient
operator|.
name|socketCache
expr_stmt|;
name|prefetchSize
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|prefetchSize
expr_stmt|;
name|timeWindow
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|timeWindow
expr_stmt|;
name|nCachedConnRetry
operator|=
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|nCachedConnRetry
expr_stmt|;
name|openInfo
argument_list|()
expr_stmt|;
block|}
comment|/**    * Grab the open-file info from namenode    */
DECL|method|openInfo ()
specifier|synchronized
name|void
name|openInfo
parameter_list|()
throws|throws
name|IOException
throws|,
name|UnresolvedLinkException
block|{
name|LocatedBlocks
name|newInfo
init|=
name|DFSClient
operator|.
name|callGetBlockLocations
argument_list|(
name|dfsClient
operator|.
name|namenode
argument_list|,
name|src
argument_list|,
literal|0
argument_list|,
name|prefetchSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"newInfo = "
operator|+
name|newInfo
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|newInfo
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot open filename "
operator|+
name|src
argument_list|)
throw|;
block|}
if|if
condition|(
name|locatedBlocks
operator|!=
literal|null
condition|)
block|{
name|Iterator
argument_list|<
name|LocatedBlock
argument_list|>
name|oldIter
init|=
name|locatedBlocks
operator|.
name|getLocatedBlocks
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|LocatedBlock
argument_list|>
name|newIter
init|=
name|newInfo
operator|.
name|getLocatedBlocks
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|oldIter
operator|.
name|hasNext
argument_list|()
operator|&&
name|newIter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|oldIter
operator|.
name|next
argument_list|()
operator|.
name|getBlock
argument_list|()
operator|.
name|equals
argument_list|(
name|newIter
operator|.
name|next
argument_list|()
operator|.
name|getBlock
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blocklist for "
operator|+
name|src
operator|+
literal|" has changed!"
argument_list|)
throw|;
block|}
block|}
block|}
name|locatedBlocks
operator|=
name|newInfo
expr_stmt|;
name|lastBlockBeingWrittenLength
operator|=
literal|0
expr_stmt|;
if|if
condition|(
operator|!
name|locatedBlocks
operator|.
name|isLastBlockComplete
argument_list|()
condition|)
block|{
specifier|final
name|LocatedBlock
name|last
init|=
name|locatedBlocks
operator|.
name|getLastLocatedBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
block|{
specifier|final
name|long
name|len
init|=
name|readBlockLength
argument_list|(
name|last
argument_list|)
decl_stmt|;
name|last
operator|.
name|getBlock
argument_list|()
operator|.
name|setNumBytes
argument_list|(
name|len
argument_list|)
expr_stmt|;
name|lastBlockBeingWrittenLength
operator|=
name|len
expr_stmt|;
block|}
block|}
name|currentNode
operator|=
literal|null
expr_stmt|;
block|}
comment|/** Read the block length from one of the datanodes. */
DECL|method|readBlockLength (LocatedBlock locatedblock)
specifier|private
name|long
name|readBlockLength
parameter_list|(
name|LocatedBlock
name|locatedblock
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|locatedblock
operator|==
literal|null
operator|||
name|locatedblock
operator|.
name|getLocations
argument_list|()
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return
literal|0
return|;
block|}
name|int
name|replicaNotFoundCount
init|=
name|locatedblock
operator|.
name|getLocations
argument_list|()
operator|.
name|length
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|datanode
range|:
name|locatedblock
operator|.
name|getLocations
argument_list|()
control|)
block|{
name|ClientDatanodeProtocol
name|cdp
init|=
literal|null
decl_stmt|;
try|try
block|{
name|cdp
operator|=
name|DFSUtil
operator|.
name|createClientDatanodeProtocolProxy
argument_list|(
name|datanode
argument_list|,
name|dfsClient
operator|.
name|conf
argument_list|,
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
argument_list|,
name|locatedblock
argument_list|)
expr_stmt|;
specifier|final
name|long
name|n
init|=
name|cdp
operator|.
name|getReplicaVisibleLength
argument_list|(
name|locatedblock
operator|.
name|getBlock
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|n
operator|>=
literal|0
condition|)
block|{
return|return
name|n
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|instanceof
name|RemoteException
operator|&&
operator|(
operator|(
operator|(
name|RemoteException
operator|)
name|ioe
operator|)
operator|.
name|unwrapRemoteException
argument_list|()
operator|instanceof
name|ReplicaNotFoundException
operator|)
condition|)
block|{
comment|// special case : replica might not be on the DN, treat as 0 length
name|replicaNotFoundCount
operator|--
expr_stmt|;
block|}
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to getReplicaVisibleLength from datanode "
operator|+
name|datanode
operator|+
literal|" for block "
operator|+
name|locatedblock
operator|.
name|getBlock
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|cdp
operator|!=
literal|null
condition|)
block|{
name|RPC
operator|.
name|stopProxy
argument_list|(
name|cdp
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Namenode told us about these locations, but none know about the replica
comment|// means that we hit the race between pipeline creation start and end.
comment|// we require all 3 because some other exception could have happened
comment|// on a DN that has it.  we want to report that error
if|if
condition|(
name|replicaNotFoundCount
operator|==
literal|0
condition|)
block|{
return|return
literal|0
return|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot obtain block length for "
operator|+
name|locatedblock
argument_list|)
throw|;
block|}
DECL|method|getFileLength ()
specifier|public
specifier|synchronized
name|long
name|getFileLength
parameter_list|()
block|{
return|return
name|locatedBlocks
operator|==
literal|null
condition|?
literal|0
else|:
name|locatedBlocks
operator|.
name|getFileLength
argument_list|()
operator|+
name|lastBlockBeingWrittenLength
return|;
block|}
comment|/**    * Returns the datanode from which the stream is currently reading.    */
DECL|method|getCurrentDatanode ()
specifier|public
name|DatanodeInfo
name|getCurrentDatanode
parameter_list|()
block|{
return|return
name|currentNode
return|;
block|}
comment|/**    * Returns the block containing the target position.     */
DECL|method|getCurrentBlock ()
specifier|synchronized
specifier|public
name|ExtendedBlock
name|getCurrentBlock
parameter_list|()
block|{
if|if
condition|(
name|currentLocatedBlock
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|currentLocatedBlock
operator|.
name|getBlock
argument_list|()
return|;
block|}
comment|/**    * Return collection of blocks that has already been located.    */
DECL|method|getAllBlocks ()
specifier|synchronized
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|getAllBlocks
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getBlockRange
argument_list|(
literal|0
argument_list|,
name|getFileLength
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get block at the specified position.    * Fetch it from the namenode if not cached.    *     * @param offset    * @param updatePosition whether to update current position    * @return located block    * @throws IOException    */
DECL|method|getBlockAt (long offset, boolean updatePosition)
specifier|private
specifier|synchronized
name|LocatedBlock
name|getBlockAt
parameter_list|(
name|long
name|offset
parameter_list|,
name|boolean
name|updatePosition
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
operator|(
name|locatedBlocks
operator|!=
literal|null
operator|)
operator|:
literal|"locatedBlocks is null"
assert|;
specifier|final
name|LocatedBlock
name|blk
decl_stmt|;
comment|//check offset
if|if
condition|(
name|offset
operator|<
literal|0
operator|||
name|offset
operator|>=
name|getFileLength
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"offset< 0 || offset> getFileLength(), offset="
operator|+
name|offset
operator|+
literal|", updatePosition="
operator|+
name|updatePosition
operator|+
literal|", locatedBlocks="
operator|+
name|locatedBlocks
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|offset
operator|>=
name|locatedBlocks
operator|.
name|getFileLength
argument_list|()
condition|)
block|{
comment|// offset to the portion of the last block,
comment|// which is not known to the name-node yet;
comment|// getting the last block
name|blk
operator|=
name|locatedBlocks
operator|.
name|getLastLocatedBlock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// search cached blocks first
name|int
name|targetBlockIdx
init|=
name|locatedBlocks
operator|.
name|findBlock
argument_list|(
name|offset
argument_list|)
decl_stmt|;
if|if
condition|(
name|targetBlockIdx
operator|<
literal|0
condition|)
block|{
comment|// block is not cached
name|targetBlockIdx
operator|=
name|LocatedBlocks
operator|.
name|getInsertIndex
argument_list|(
name|targetBlockIdx
argument_list|)
expr_stmt|;
comment|// fetch more blocks
name|LocatedBlocks
name|newBlocks
decl_stmt|;
name|newBlocks
operator|=
name|DFSClient
operator|.
name|callGetBlockLocations
argument_list|(
name|dfsClient
operator|.
name|namenode
argument_list|,
name|src
argument_list|,
name|offset
argument_list|,
name|prefetchSize
argument_list|)
expr_stmt|;
assert|assert
operator|(
name|newBlocks
operator|!=
literal|null
operator|)
operator|:
literal|"Could not find target position "
operator|+
name|offset
assert|;
name|locatedBlocks
operator|.
name|insertRange
argument_list|(
name|targetBlockIdx
argument_list|,
name|newBlocks
operator|.
name|getLocatedBlocks
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|blk
operator|=
name|locatedBlocks
operator|.
name|get
argument_list|(
name|targetBlockIdx
argument_list|)
expr_stmt|;
block|}
comment|// update current position
if|if
condition|(
name|updatePosition
condition|)
block|{
name|pos
operator|=
name|offset
expr_stmt|;
name|blockEnd
operator|=
name|blk
operator|.
name|getStartOffset
argument_list|()
operator|+
name|blk
operator|.
name|getBlockSize
argument_list|()
operator|-
literal|1
expr_stmt|;
name|currentLocatedBlock
operator|=
name|blk
expr_stmt|;
block|}
return|return
name|blk
return|;
block|}
comment|/** Fetch a block from namenode and cache it */
DECL|method|fetchBlockAt (long offset)
specifier|private
specifier|synchronized
name|void
name|fetchBlockAt
parameter_list|(
name|long
name|offset
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|targetBlockIdx
init|=
name|locatedBlocks
operator|.
name|findBlock
argument_list|(
name|offset
argument_list|)
decl_stmt|;
if|if
condition|(
name|targetBlockIdx
operator|<
literal|0
condition|)
block|{
comment|// block is not cached
name|targetBlockIdx
operator|=
name|LocatedBlocks
operator|.
name|getInsertIndex
argument_list|(
name|targetBlockIdx
argument_list|)
expr_stmt|;
block|}
comment|// fetch blocks
name|LocatedBlocks
name|newBlocks
decl_stmt|;
name|newBlocks
operator|=
name|DFSClient
operator|.
name|callGetBlockLocations
argument_list|(
name|dfsClient
operator|.
name|namenode
argument_list|,
name|src
argument_list|,
name|offset
argument_list|,
name|prefetchSize
argument_list|)
expr_stmt|;
if|if
condition|(
name|newBlocks
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not find target position "
operator|+
name|offset
argument_list|)
throw|;
block|}
name|locatedBlocks
operator|.
name|insertRange
argument_list|(
name|targetBlockIdx
argument_list|,
name|newBlocks
operator|.
name|getLocatedBlocks
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get blocks in the specified range.    * Fetch them from the namenode if not cached. This function    * will not get a read request beyond the EOF.    * @param offset    * @param length    * @return consequent segment of located blocks    * @throws IOException    */
DECL|method|getBlockRange (long offset, long length)
specifier|private
specifier|synchronized
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|getBlockRange
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
comment|// getFileLength(): returns total file length
comment|// locatedBlocks.getFileLength(): returns length of completed blocks
if|if
condition|(
name|offset
operator|>=
name|getFileLength
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Offset: "
operator|+
name|offset
operator|+
literal|" exceeds file length: "
operator|+
name|getFileLength
argument_list|()
argument_list|)
throw|;
block|}
specifier|final
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|blocks
decl_stmt|;
specifier|final
name|long
name|lengthOfCompleteBlk
init|=
name|locatedBlocks
operator|.
name|getFileLength
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|readOffsetWithinCompleteBlk
init|=
name|offset
operator|<
name|lengthOfCompleteBlk
decl_stmt|;
specifier|final
name|boolean
name|readLengthPastCompleteBlk
init|=
name|offset
operator|+
name|length
operator|>
name|lengthOfCompleteBlk
decl_stmt|;
if|if
condition|(
name|readOffsetWithinCompleteBlk
condition|)
block|{
comment|//get the blocks of finalized (completed) block range
name|blocks
operator|=
name|getFinalizedBlockRange
argument_list|(
name|offset
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|length
argument_list|,
name|lengthOfCompleteBlk
operator|-
name|offset
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|blocks
operator|=
operator|new
name|ArrayList
argument_list|<
name|LocatedBlock
argument_list|>
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// get the blocks from incomplete block range
if|if
condition|(
name|readLengthPastCompleteBlk
condition|)
block|{
name|blocks
operator|.
name|add
argument_list|(
name|locatedBlocks
operator|.
name|getLastLocatedBlock
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|blocks
return|;
block|}
comment|/**    * Get blocks in the specified range.    * Includes only the complete blocks.    * Fetch them from the namenode if not cached.    */
DECL|method|getFinalizedBlockRange ( long offset, long length)
specifier|private
specifier|synchronized
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|getFinalizedBlockRange
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
operator|(
name|locatedBlocks
operator|!=
literal|null
operator|)
operator|:
literal|"locatedBlocks is null"
assert|;
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|blockRange
init|=
operator|new
name|ArrayList
argument_list|<
name|LocatedBlock
argument_list|>
argument_list|()
decl_stmt|;
comment|// search cached blocks first
name|int
name|blockIdx
init|=
name|locatedBlocks
operator|.
name|findBlock
argument_list|(
name|offset
argument_list|)
decl_stmt|;
if|if
condition|(
name|blockIdx
operator|<
literal|0
condition|)
block|{
comment|// block is not cached
name|blockIdx
operator|=
name|LocatedBlocks
operator|.
name|getInsertIndex
argument_list|(
name|blockIdx
argument_list|)
expr_stmt|;
block|}
name|long
name|remaining
init|=
name|length
decl_stmt|;
name|long
name|curOff
init|=
name|offset
decl_stmt|;
while|while
condition|(
name|remaining
operator|>
literal|0
condition|)
block|{
name|LocatedBlock
name|blk
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|blockIdx
operator|<
name|locatedBlocks
operator|.
name|locatedBlockCount
argument_list|()
condition|)
name|blk
operator|=
name|locatedBlocks
operator|.
name|get
argument_list|(
name|blockIdx
argument_list|)
expr_stmt|;
if|if
condition|(
name|blk
operator|==
literal|null
operator|||
name|curOff
operator|<
name|blk
operator|.
name|getStartOffset
argument_list|()
condition|)
block|{
name|LocatedBlocks
name|newBlocks
decl_stmt|;
name|newBlocks
operator|=
name|DFSClient
operator|.
name|callGetBlockLocations
argument_list|(
name|dfsClient
operator|.
name|namenode
argument_list|,
name|src
argument_list|,
name|curOff
argument_list|,
name|remaining
argument_list|)
expr_stmt|;
name|locatedBlocks
operator|.
name|insertRange
argument_list|(
name|blockIdx
argument_list|,
name|newBlocks
operator|.
name|getLocatedBlocks
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
assert|assert
name|curOff
operator|>=
name|blk
operator|.
name|getStartOffset
argument_list|()
operator|:
literal|"Block not found"
assert|;
name|blockRange
operator|.
name|add
argument_list|(
name|blk
argument_list|)
expr_stmt|;
name|long
name|bytesRead
init|=
name|blk
operator|.
name|getStartOffset
argument_list|()
operator|+
name|blk
operator|.
name|getBlockSize
argument_list|()
operator|-
name|curOff
decl_stmt|;
name|remaining
operator|-=
name|bytesRead
expr_stmt|;
name|curOff
operator|+=
name|bytesRead
expr_stmt|;
name|blockIdx
operator|++
expr_stmt|;
block|}
return|return
name|blockRange
return|;
block|}
comment|/**    * Open a DataInputStream to a DataNode so that it can be read from.    * We get block ID and the IDs of the destinations at startup, from the namenode.    */
DECL|method|blockSeekTo (long target)
specifier|private
specifier|synchronized
name|DatanodeInfo
name|blockSeekTo
parameter_list|(
name|long
name|target
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|target
operator|>=
name|getFileLength
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Attempted to read past end of file"
argument_list|)
throw|;
block|}
comment|// Will be getting a new BlockReader.
if|if
condition|(
name|blockReader
operator|!=
literal|null
condition|)
block|{
name|closeBlockReader
argument_list|(
name|blockReader
argument_list|)
expr_stmt|;
name|blockReader
operator|=
literal|null
expr_stmt|;
block|}
comment|//
comment|// Connect to best DataNode for desired Block, with potential offset
comment|//
name|DatanodeInfo
name|chosenNode
init|=
literal|null
decl_stmt|;
name|int
name|refetchToken
init|=
literal|1
decl_stmt|;
comment|// only need to get a new access token once
while|while
condition|(
literal|true
condition|)
block|{
comment|//
comment|// Compute desired block
comment|//
name|LocatedBlock
name|targetBlock
init|=
name|getBlockAt
argument_list|(
name|target
argument_list|,
literal|true
argument_list|)
decl_stmt|;
assert|assert
operator|(
name|target
operator|==
name|pos
operator|)
operator|:
literal|"Wrong postion "
operator|+
name|pos
operator|+
literal|" expect "
operator|+
name|target
assert|;
name|long
name|offsetIntoBlock
init|=
name|target
operator|-
name|targetBlock
operator|.
name|getStartOffset
argument_list|()
decl_stmt|;
name|DNAddrPair
name|retval
init|=
name|chooseDataNode
argument_list|(
name|targetBlock
argument_list|)
decl_stmt|;
name|chosenNode
operator|=
name|retval
operator|.
name|info
expr_stmt|;
name|InetSocketAddress
name|targetAddr
init|=
name|retval
operator|.
name|addr
decl_stmt|;
try|try
block|{
name|ExtendedBlock
name|blk
init|=
name|targetBlock
operator|.
name|getBlock
argument_list|()
decl_stmt|;
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|accessToken
init|=
name|targetBlock
operator|.
name|getBlockToken
argument_list|()
decl_stmt|;
name|blockReader
operator|=
name|getBlockReader
argument_list|(
name|targetAddr
argument_list|,
name|src
argument_list|,
name|blk
argument_list|,
name|accessToken
argument_list|,
name|offsetIntoBlock
argument_list|,
name|blk
operator|.
name|getNumBytes
argument_list|()
operator|-
name|offsetIntoBlock
argument_list|,
name|buffersize
argument_list|,
name|verifyChecksum
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
return|return
name|chosenNode
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
if|if
condition|(
name|ex
operator|instanceof
name|InvalidBlockTokenException
operator|&&
name|refetchToken
operator|>
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Will fetch a new access token and retry, "
operator|+
literal|"access token was invalid when connecting to "
operator|+
name|targetAddr
operator|+
literal|" : "
operator|+
name|ex
argument_list|)
expr_stmt|;
comment|/*            * Get a new access token and retry. Retry is needed in 2 cases. 1)            * When both NN and DN re-started while DFSClient holding a cached            * access token. 2) In the case that NN fails to update its            * access key at pre-set interval (by a wide margin) and            * subsequently restarts. In this case, DN re-registers itself with            * NN and receives a new access key, but DN will delete the old            * access key from its memory since it's considered expired based on            * the estimated expiration date.            */
name|refetchToken
operator|--
expr_stmt|;
name|fetchBlockAt
argument_list|(
name|target
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to connect to "
operator|+
name|targetAddr
operator|+
literal|", add to deadNodes and continue "
operator|+
name|ex
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connection failure "
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
comment|// Put chosen node into dead list, continue
name|addToDeadNodes
argument_list|(
name|chosenNode
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Close it down!    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
return|return;
block|}
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|blockReader
operator|!=
literal|null
condition|)
block|{
name|closeBlockReader
argument_list|(
name|blockReader
argument_list|)
expr_stmt|;
name|blockReader
operator|=
literal|null
expr_stmt|;
block|}
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
name|closed
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|read ()
specifier|public
specifier|synchronized
name|int
name|read
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|ret
init|=
name|read
argument_list|(
name|oneByteBuf
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|)
decl_stmt|;
return|return
operator|(
name|ret
operator|<=
literal|0
operator|)
condition|?
operator|-
literal|1
else|:
operator|(
name|oneByteBuf
index|[
literal|0
index|]
operator|&
literal|0xff
operator|)
return|;
block|}
comment|/* This is a used by regular read() and handles ChecksumExceptions.    * name readBuffer() is chosen to imply similarity to readBuffer() in    * ChecksumFileSystem    */
DECL|method|readBuffer (byte buf[], int off, int len, Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap)
specifier|private
specifier|synchronized
name|int
name|readBuffer
parameter_list|(
name|byte
name|buf
index|[]
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|,
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
parameter_list|)
throws|throws
name|IOException
block|{
name|IOException
name|ioe
decl_stmt|;
comment|/* we retry current node only once. So this is set to true only here.      * Intention is to handle one common case of an error that is not a      * failure on datanode or client : when DataNode closes the connection      * since client is idle. If there are other cases of "non-errors" then      * then a datanode might be retried by setting this to true again.      */
name|boolean
name|retryCurrentNode
init|=
literal|true
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
comment|// retry as many times as seekToNewSource allows.
try|try
block|{
return|return
name|blockReader
operator|.
name|read
argument_list|(
name|buf
argument_list|,
name|off
argument_list|,
name|len
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|ChecksumException
name|ce
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found Checksum error for "
operator|+
name|getCurrentBlock
argument_list|()
operator|+
literal|" from "
operator|+
name|currentNode
operator|.
name|getName
argument_list|()
operator|+
literal|" at "
operator|+
name|ce
operator|.
name|getPos
argument_list|()
argument_list|)
expr_stmt|;
name|ioe
operator|=
name|ce
expr_stmt|;
name|retryCurrentNode
operator|=
literal|false
expr_stmt|;
comment|// we want to remember which block replicas we have tried
name|addIntoCorruptedBlockMap
argument_list|(
name|getCurrentBlock
argument_list|()
argument_list|,
name|currentNode
argument_list|,
name|corruptedBlockMap
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
operator|!
name|retryCurrentNode
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception while reading from "
operator|+
name|getCurrentBlock
argument_list|()
operator|+
literal|" of "
operator|+
name|src
operator|+
literal|" from "
operator|+
name|currentNode
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|ioe
operator|=
name|e
expr_stmt|;
block|}
name|boolean
name|sourceFound
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|retryCurrentNode
condition|)
block|{
comment|/* possibly retry the same node so that transient errors don't          * result in application level failures (e.g. Datanode could have          * closed the connection because the client is idle for too long).          */
name|sourceFound
operator|=
name|seekToBlockSource
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|addToDeadNodes
argument_list|(
name|currentNode
argument_list|)
expr_stmt|;
name|sourceFound
operator|=
name|seekToNewSource
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|sourceFound
condition|)
block|{
throw|throw
name|ioe
throw|;
block|}
name|retryCurrentNode
operator|=
literal|false
expr_stmt|;
block|}
block|}
comment|/**    * Read the entire buffer.    */
annotation|@
name|Override
DECL|method|read (byte buf[], int off, int len)
specifier|public
specifier|synchronized
name|int
name|read
parameter_list|(
name|byte
name|buf
index|[]
parameter_list|,
name|int
name|off
parameter_list|,
name|int
name|len
parameter_list|)
throws|throws
name|IOException
block|{
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Stream closed"
argument_list|)
throw|;
block|}
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
init|=
operator|new
name|HashMap
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|failures
operator|=
literal|0
expr_stmt|;
if|if
condition|(
name|pos
operator|<
name|getFileLength
argument_list|()
condition|)
block|{
name|int
name|retries
init|=
literal|2
decl_stmt|;
while|while
condition|(
name|retries
operator|>
literal|0
condition|)
block|{
try|try
block|{
if|if
condition|(
name|pos
operator|>
name|blockEnd
condition|)
block|{
name|currentNode
operator|=
name|blockSeekTo
argument_list|(
name|pos
argument_list|)
expr_stmt|;
block|}
name|int
name|realLen
init|=
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
operator|(
name|long
operator|)
name|len
argument_list|,
operator|(
name|blockEnd
operator|-
name|pos
operator|+
literal|1L
operator|)
argument_list|)
decl_stmt|;
name|int
name|result
init|=
name|readBuffer
argument_list|(
name|buf
argument_list|,
name|off
argument_list|,
name|realLen
argument_list|,
name|corruptedBlockMap
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|>=
literal|0
condition|)
block|{
name|pos
operator|+=
name|result
expr_stmt|;
block|}
else|else
block|{
comment|// got a EOS from reader though we expect more data on it.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unexpected EOS from the reader"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dfsClient
operator|.
name|stats
operator|!=
literal|null
operator|&&
name|result
operator|!=
operator|-
literal|1
condition|)
block|{
name|dfsClient
operator|.
name|stats
operator|.
name|incrementBytesRead
argument_list|(
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|ChecksumException
name|ce
parameter_list|)
block|{
throw|throw
name|ce
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|retries
operator|==
literal|1
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DFS Read"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|blockEnd
operator|=
operator|-
literal|1
expr_stmt|;
if|if
condition|(
name|currentNode
operator|!=
literal|null
condition|)
block|{
name|addToDeadNodes
argument_list|(
name|currentNode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|--
name|retries
operator|==
literal|0
condition|)
block|{
throw|throw
name|e
throw|;
block|}
block|}
finally|finally
block|{
comment|// Check if need to report block replicas corruption either read
comment|// was successful or ChecksumException occured.
name|reportCheckSumFailure
argument_list|(
name|corruptedBlockMap
argument_list|,
name|currentLocatedBlock
operator|.
name|getLocations
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
operator|-
literal|1
return|;
block|}
comment|/**    * Add corrupted block replica into map.    * @param corruptedBlockMap     */
DECL|method|addIntoCorruptedBlockMap (ExtendedBlock blk, DatanodeInfo node, Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap)
specifier|private
name|void
name|addIntoCorruptedBlockMap
parameter_list|(
name|ExtendedBlock
name|blk
parameter_list|,
name|DatanodeInfo
name|node
parameter_list|,
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
parameter_list|)
block|{
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
name|dnSet
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|(
name|corruptedBlockMap
operator|.
name|containsKey
argument_list|(
name|blk
argument_list|)
operator|)
condition|)
block|{
name|dnSet
operator|=
name|corruptedBlockMap
operator|.
name|get
argument_list|(
name|blk
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|dnSet
operator|=
operator|new
name|HashSet
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|dnSet
operator|.
name|contains
argument_list|(
name|node
argument_list|)
condition|)
block|{
name|dnSet
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
name|corruptedBlockMap
operator|.
name|put
argument_list|(
name|blk
argument_list|,
name|dnSet
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|chooseDataNode (LocatedBlock block)
specifier|private
name|DNAddrPair
name|chooseDataNode
parameter_list|(
name|LocatedBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
while|while
condition|(
literal|true
condition|)
block|{
name|DatanodeInfo
index|[]
name|nodes
init|=
name|block
operator|.
name|getLocations
argument_list|()
decl_stmt|;
try|try
block|{
name|DatanodeInfo
name|chosenNode
init|=
name|bestNode
argument_list|(
name|nodes
argument_list|,
name|deadNodes
argument_list|)
decl_stmt|;
name|InetSocketAddress
name|targetAddr
init|=
name|NetUtils
operator|.
name|createSocketAddr
argument_list|(
name|chosenNode
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
return|return
operator|new
name|DNAddrPair
argument_list|(
name|chosenNode
argument_list|,
name|targetAddr
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|String
name|blockInfo
init|=
name|block
operator|.
name|getBlock
argument_list|()
operator|+
literal|" file="
operator|+
name|src
decl_stmt|;
if|if
condition|(
name|failures
operator|>=
name|dfsClient
operator|.
name|getMaxBlockAcquireFailures
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|BlockMissingException
argument_list|(
name|src
argument_list|,
literal|"Could not obtain block: "
operator|+
name|blockInfo
argument_list|,
name|block
operator|.
name|getStartOffset
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|nodes
operator|==
literal|null
operator|||
name|nodes
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"No node available for block: "
operator|+
name|blockInfo
argument_list|)
expr_stmt|;
block|}
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Could not obtain block "
operator|+
name|block
operator|.
name|getBlock
argument_list|()
operator|+
literal|" from any node: "
operator|+
name|ie
operator|+
literal|". Will get new block locations from namenode and retry..."
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Introducing a random factor to the wait time before another retry.
comment|// The wait time is dependent on # of failures and a random factor.
comment|// At the first time of getting a BlockMissingException, the wait time
comment|// is a random number between 0..3000 ms. If the first retry
comment|// still fails, we will wait 3000 ms grace period before the 2nd retry.
comment|// Also at the second retry, the waiting window is expanded to 6000 ms
comment|// alleviating the request rate from the server. Similarly the 3rd retry
comment|// will wait 6000ms grace period before retry and the waiting window is
comment|// expanded to 9000ms.
name|double
name|waitTime
init|=
name|timeWindow
operator|*
name|failures
operator|+
comment|// grace period for the last round of attempt
name|timeWindow
operator|*
operator|(
name|failures
operator|+
literal|1
operator|)
operator|*
name|DFSUtil
operator|.
name|getRandom
argument_list|()
operator|.
name|nextDouble
argument_list|()
decl_stmt|;
comment|// expanding time window for each failure
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"DFS chooseDataNode: got # "
operator|+
operator|(
name|failures
operator|+
literal|1
operator|)
operator|+
literal|" IOException, will wait for "
operator|+
name|waitTime
operator|+
literal|" msec."
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
operator|(
name|long
operator|)
name|waitTime
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{         }
name|deadNodes
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|//2nd option is to remove only nodes[blockId]
name|openInfo
argument_list|()
expr_stmt|;
name|block
operator|=
name|getBlockAt
argument_list|(
name|block
operator|.
name|getStartOffset
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|failures
operator|++
expr_stmt|;
continue|continue;
block|}
block|}
block|}
DECL|method|fetchBlockByteRange (LocatedBlock block, long start, long end, byte[] buf, int offset, Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap)
specifier|private
name|void
name|fetchBlockByteRange
parameter_list|(
name|LocatedBlock
name|block
parameter_list|,
name|long
name|start
parameter_list|,
name|long
name|end
parameter_list|,
name|byte
index|[]
name|buf
parameter_list|,
name|int
name|offset
parameter_list|,
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
parameter_list|)
throws|throws
name|IOException
block|{
comment|//
comment|// Connect to best DataNode for desired Block, with potential offset
comment|//
name|int
name|refetchToken
init|=
literal|1
decl_stmt|;
comment|// only need to get a new access token once
while|while
condition|(
literal|true
condition|)
block|{
comment|// cached block locations may have been updated by chooseDataNode()
comment|// or fetchBlockAt(). Always get the latest list of locations at the
comment|// start of the loop.
name|block
operator|=
name|getBlockAt
argument_list|(
name|block
operator|.
name|getStartOffset
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|DNAddrPair
name|retval
init|=
name|chooseDataNode
argument_list|(
name|block
argument_list|)
decl_stmt|;
name|DatanodeInfo
name|chosenNode
init|=
name|retval
operator|.
name|info
decl_stmt|;
name|InetSocketAddress
name|targetAddr
init|=
name|retval
operator|.
name|addr
decl_stmt|;
name|BlockReader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
init|=
name|block
operator|.
name|getBlockToken
argument_list|()
decl_stmt|;
name|int
name|len
init|=
call|(
name|int
call|)
argument_list|(
name|end
operator|-
name|start
operator|+
literal|1
argument_list|)
decl_stmt|;
name|reader
operator|=
name|getBlockReader
argument_list|(
name|targetAddr
argument_list|,
name|src
argument_list|,
name|block
operator|.
name|getBlock
argument_list|()
argument_list|,
name|blockToken
argument_list|,
name|start
argument_list|,
name|len
argument_list|,
name|buffersize
argument_list|,
name|verifyChecksum
argument_list|,
name|dfsClient
operator|.
name|clientName
argument_list|)
expr_stmt|;
name|int
name|nread
init|=
name|reader
operator|.
name|readAll
argument_list|(
name|buf
argument_list|,
name|offset
argument_list|,
name|len
argument_list|)
decl_stmt|;
if|if
condition|(
name|nread
operator|!=
name|len
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"truncated return from reader.read(): "
operator|+
literal|"excpected "
operator|+
name|len
operator|+
literal|", got "
operator|+
name|nread
argument_list|)
throw|;
block|}
return|return;
block|}
catch|catch
parameter_list|(
name|ChecksumException
name|e
parameter_list|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"fetchBlockByteRange(). Got a checksum exception for "
operator|+
name|src
operator|+
literal|" at "
operator|+
name|block
operator|.
name|getBlock
argument_list|()
operator|+
literal|":"
operator|+
name|e
operator|.
name|getPos
argument_list|()
operator|+
literal|" from "
operator|+
name|chosenNode
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|// we want to remember what we have tried
name|addIntoCorruptedBlockMap
argument_list|(
name|block
operator|.
name|getBlock
argument_list|()
argument_list|,
name|chosenNode
argument_list|,
name|corruptedBlockMap
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|InvalidBlockTokenException
operator|&&
name|refetchToken
operator|>
literal|0
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Will get a new access token and retry, "
operator|+
literal|"access token was invalid when connecting to "
operator|+
name|targetAddr
operator|+
literal|" : "
operator|+
name|e
argument_list|)
expr_stmt|;
name|refetchToken
operator|--
expr_stmt|;
name|fetchBlockAt
argument_list|(
name|block
operator|.
name|getStartOffset
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
else|else
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to connect to "
operator|+
name|targetAddr
operator|+
literal|" for file "
operator|+
name|src
operator|+
literal|" for block "
operator|+
name|block
operator|.
name|getBlock
argument_list|()
operator|+
literal|":"
operator|+
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Connection failure "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
block|{
name|closeBlockReader
argument_list|(
name|reader
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Put chosen node into dead list, continue
name|addToDeadNodes
argument_list|(
name|chosenNode
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Close the given BlockReader and cache its socket.    */
DECL|method|closeBlockReader (BlockReader reader)
specifier|private
name|void
name|closeBlockReader
parameter_list|(
name|BlockReader
name|reader
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|reader
operator|.
name|hasSentStatusCode
argument_list|()
condition|)
block|{
name|Socket
name|oldSock
init|=
name|reader
operator|.
name|takeSocket
argument_list|()
decl_stmt|;
name|socketCache
operator|.
name|put
argument_list|(
name|oldSock
argument_list|)
expr_stmt|;
block|}
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Retrieve a BlockReader suitable for reading.    * This method will reuse the cached connection to the DN if appropriate.    * Otherwise, it will create a new connection.    *    * @param dnAddr  Address of the datanode    * @param file  File location    * @param block  The Block object    * @param blockToken  The access token for security    * @param startOffset  The read offset, relative to block head    * @param len  The number of bytes to read    * @param bufferSize  The IO buffer size (not the client buffer size)    * @param verifyChecksum  Whether to verify checksum    * @param clientName  Client name    * @return New BlockReader instance    */
DECL|method|getBlockReader (InetSocketAddress dnAddr, String file, ExtendedBlock block, Token<BlockTokenIdentifier> blockToken, long startOffset, long len, int bufferSize, boolean verifyChecksum, String clientName)
specifier|protected
name|BlockReader
name|getBlockReader
parameter_list|(
name|InetSocketAddress
name|dnAddr
parameter_list|,
name|String
name|file
parameter_list|,
name|ExtendedBlock
name|block
parameter_list|,
name|Token
argument_list|<
name|BlockTokenIdentifier
argument_list|>
name|blockToken
parameter_list|,
name|long
name|startOffset
parameter_list|,
name|long
name|len
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|boolean
name|verifyChecksum
parameter_list|,
name|String
name|clientName
parameter_list|)
throws|throws
name|IOException
block|{
name|IOException
name|err
init|=
literal|null
decl_stmt|;
name|boolean
name|fromCache
init|=
literal|true
decl_stmt|;
comment|// Allow retry since there is no way of knowing whether the cached socket
comment|// is good until we actually use it.
for|for
control|(
name|int
name|retries
init|=
literal|0
init|;
name|retries
operator|<=
name|nCachedConnRetry
operator|&&
name|fromCache
condition|;
operator|++
name|retries
control|)
block|{
name|Socket
name|sock
init|=
name|socketCache
operator|.
name|get
argument_list|(
name|dnAddr
argument_list|)
decl_stmt|;
if|if
condition|(
name|sock
operator|==
literal|null
condition|)
block|{
name|fromCache
operator|=
literal|false
expr_stmt|;
name|sock
operator|=
name|dfsClient
operator|.
name|socketFactory
operator|.
name|createSocket
argument_list|()
expr_stmt|;
comment|// TCP_NODELAY is crucial here because of bad interactions between
comment|// Nagle's Algorithm and Delayed ACKs. With connection keepalive
comment|// between the client and DN, the conversation looks like:
comment|//   1. Client -> DN: Read block X
comment|//   2. DN -> Client: data for block X
comment|//   3. Client -> DN: Status OK (successful read)
comment|//   4. Client -> DN: Read block Y
comment|// The fact that step #3 and #4 are both in the client->DN direction
comment|// triggers Nagling. If the DN is using delayed ACKs, this results
comment|// in a delay of 40ms or more.
comment|//
comment|// TCP_NODELAY disables nagling and thus avoids this performance
comment|// disaster.
name|sock
operator|.
name|setTcpNoDelay
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|NetUtils
operator|.
name|connect
argument_list|(
name|sock
argument_list|,
name|dnAddr
argument_list|,
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
name|sock
operator|.
name|setSoTimeout
argument_list|(
name|dfsClient
operator|.
name|getConf
argument_list|()
operator|.
name|socketTimeout
argument_list|)
expr_stmt|;
block|}
try|try
block|{
comment|// The OP_READ_BLOCK request is sent as we make the BlockReader
name|BlockReader
name|reader
init|=
name|BlockReaderFactory
operator|.
name|newBlockReader
argument_list|(
name|sock
argument_list|,
name|file
argument_list|,
name|block
argument_list|,
name|blockToken
argument_list|,
name|startOffset
argument_list|,
name|len
argument_list|,
name|bufferSize
argument_list|,
name|verifyChecksum
argument_list|,
name|clientName
argument_list|)
decl_stmt|;
return|return
name|reader
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Our socket is no good.
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Error making BlockReader. Closing stale "
operator|+
name|sock
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|sock
operator|.
name|close
argument_list|()
expr_stmt|;
name|err
operator|=
name|ex
expr_stmt|;
block|}
block|}
throw|throw
name|err
throw|;
block|}
comment|/**    * Read bytes starting from the specified position.    *     * @param position start read from this position    * @param buffer read buffer    * @param offset offset into buffer    * @param length number of bytes to read    *     * @return actual number of bytes read    */
annotation|@
name|Override
DECL|method|read (long position, byte[] buffer, int offset, int length)
specifier|public
name|int
name|read
parameter_list|(
name|long
name|position
parameter_list|,
name|byte
index|[]
name|buffer
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
comment|// sanity checks
name|dfsClient
operator|.
name|checkOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Stream closed"
argument_list|)
throw|;
block|}
name|failures
operator|=
literal|0
expr_stmt|;
name|long
name|filelen
init|=
name|getFileLength
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|position
operator|<
literal|0
operator|)
operator|||
operator|(
name|position
operator|>=
name|filelen
operator|)
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|int
name|realLen
init|=
name|length
decl_stmt|;
if|if
condition|(
operator|(
name|position
operator|+
name|length
operator|)
operator|>
name|filelen
condition|)
block|{
name|realLen
operator|=
call|(
name|int
call|)
argument_list|(
name|filelen
operator|-
name|position
argument_list|)
expr_stmt|;
block|}
comment|// determine the block and byte range within the block
comment|// corresponding to position and realLen
name|List
argument_list|<
name|LocatedBlock
argument_list|>
name|blockRange
init|=
name|getBlockRange
argument_list|(
name|position
argument_list|,
name|realLen
argument_list|)
decl_stmt|;
name|int
name|remaining
init|=
name|realLen
decl_stmt|;
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
init|=
operator|new
name|HashMap
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|LocatedBlock
name|blk
range|:
name|blockRange
control|)
block|{
name|long
name|targetStart
init|=
name|position
operator|-
name|blk
operator|.
name|getStartOffset
argument_list|()
decl_stmt|;
name|long
name|bytesToRead
init|=
name|Math
operator|.
name|min
argument_list|(
name|remaining
argument_list|,
name|blk
operator|.
name|getBlockSize
argument_list|()
operator|-
name|targetStart
argument_list|)
decl_stmt|;
try|try
block|{
name|fetchBlockByteRange
argument_list|(
name|blk
argument_list|,
name|targetStart
argument_list|,
name|targetStart
operator|+
name|bytesToRead
operator|-
literal|1
argument_list|,
name|buffer
argument_list|,
name|offset
argument_list|,
name|corruptedBlockMap
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// Check and report if any block replicas are corrupted.
comment|// BlockMissingException may be caught if all block replicas are
comment|// corrupted.
name|reportCheckSumFailure
argument_list|(
name|corruptedBlockMap
argument_list|,
name|blk
operator|.
name|getLocations
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
name|remaining
operator|-=
name|bytesToRead
expr_stmt|;
name|position
operator|+=
name|bytesToRead
expr_stmt|;
name|offset
operator|+=
name|bytesToRead
expr_stmt|;
block|}
assert|assert
name|remaining
operator|==
literal|0
operator|:
literal|"Wrong number of bytes read."
assert|;
if|if
condition|(
name|dfsClient
operator|.
name|stats
operator|!=
literal|null
condition|)
block|{
name|dfsClient
operator|.
name|stats
operator|.
name|incrementBytesRead
argument_list|(
name|realLen
argument_list|)
expr_stmt|;
block|}
return|return
name|realLen
return|;
block|}
comment|/**    * DFSInputStream reports checksum failure.    * Case I : client has tried multiple data nodes and at least one of the    * attempts has succeeded. We report the other failures as corrupted block to    * namenode.     * Case II: client has tried out all data nodes, but all failed. We    * only report if the total number of replica is 1. We do not    * report otherwise since this maybe due to the client is a handicapped client    * (who can not read).    * @param corruptedBlockMap, map of corrupted blocks    * @param dataNodeCount, number of data nodes who contains the block replicas    */
DECL|method|reportCheckSumFailure ( Map<ExtendedBlock, Set<DatanodeInfo>> corruptedBlockMap, int dataNodeCount)
specifier|private
name|void
name|reportCheckSumFailure
parameter_list|(
name|Map
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|corruptedBlockMap
parameter_list|,
name|int
name|dataNodeCount
parameter_list|)
block|{
if|if
condition|(
name|corruptedBlockMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
argument_list|>
name|it
init|=
name|corruptedBlockMap
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Entry
argument_list|<
name|ExtendedBlock
argument_list|,
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
argument_list|>
name|entry
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|ExtendedBlock
name|blk
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|DatanodeInfo
argument_list|>
name|dnSet
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
operator|(
name|dnSet
operator|.
name|size
argument_list|()
operator|<
name|dataNodeCount
operator|)
operator|&&
operator|(
name|dnSet
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
operator|)
operator|||
operator|(
operator|(
name|dataNodeCount
operator|==
literal|1
operator|)
operator|&&
operator|(
name|dnSet
operator|.
name|size
argument_list|()
operator|==
name|dataNodeCount
operator|)
operator|)
condition|)
block|{
name|DatanodeInfo
index|[]
name|locs
init|=
operator|new
name|DatanodeInfo
index|[
name|dnSet
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
for|for
control|(
name|DatanodeInfo
name|dn
range|:
name|dnSet
control|)
block|{
name|locs
index|[
name|i
operator|++
index|]
operator|=
name|dn
expr_stmt|;
block|}
name|LocatedBlock
index|[]
name|lblocks
init|=
block|{
operator|new
name|LocatedBlock
argument_list|(
name|blk
argument_list|,
name|locs
argument_list|)
block|}
decl_stmt|;
name|dfsClient
operator|.
name|reportChecksumFailure
argument_list|(
name|src
argument_list|,
name|lblocks
argument_list|)
expr_stmt|;
block|}
name|corruptedBlockMap
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|skip (long n)
specifier|public
name|long
name|skip
parameter_list|(
name|long
name|n
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|n
operator|>
literal|0
condition|)
block|{
name|long
name|curPos
init|=
name|getPos
argument_list|()
decl_stmt|;
name|long
name|fileLen
init|=
name|getFileLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|n
operator|+
name|curPos
operator|>
name|fileLen
condition|)
block|{
name|n
operator|=
name|fileLen
operator|-
name|curPos
expr_stmt|;
block|}
name|seek
argument_list|(
name|curPos
operator|+
name|n
argument_list|)
expr_stmt|;
return|return
name|n
return|;
block|}
return|return
name|n
operator|<
literal|0
condition|?
operator|-
literal|1
else|:
literal|0
return|;
block|}
comment|/**    * Seek to a new arbitrary location    */
annotation|@
name|Override
DECL|method|seek (long targetPos)
specifier|public
specifier|synchronized
name|void
name|seek
parameter_list|(
name|long
name|targetPos
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|targetPos
operator|>
name|getFileLength
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot seek after EOF"
argument_list|)
throw|;
block|}
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Stream is closed!"
argument_list|)
throw|;
block|}
name|boolean
name|done
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|pos
operator|<=
name|targetPos
operator|&&
name|targetPos
operator|<=
name|blockEnd
condition|)
block|{
comment|//
comment|// If this seek is to a positive position in the current
comment|// block, and this piece of data might already be lying in
comment|// the TCP buffer, then just eat up the intervening data.
comment|//
name|int
name|diff
init|=
call|(
name|int
call|)
argument_list|(
name|targetPos
operator|-
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|diff
operator|<=
name|DFSClient
operator|.
name|TCP_WINDOW_SIZE
condition|)
block|{
try|try
block|{
name|pos
operator|+=
name|blockReader
operator|.
name|skip
argument_list|(
name|diff
argument_list|)
expr_stmt|;
if|if
condition|(
name|pos
operator|==
name|targetPos
condition|)
block|{
name|done
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|//make following read to retry
if|if
condition|(
name|DFSClient
operator|.
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|DFSClient
operator|.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception while seek to "
operator|+
name|targetPos
operator|+
literal|" from "
operator|+
name|getCurrentBlock
argument_list|()
operator|+
literal|" of "
operator|+
name|src
operator|+
literal|" from "
operator|+
name|currentNode
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
operator|!
name|done
condition|)
block|{
name|pos
operator|=
name|targetPos
expr_stmt|;
name|blockEnd
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
comment|/**    * Same as {@link #seekToNewSource(long)} except that it does not exclude    * the current datanode and might connect to the same node.    */
DECL|method|seekToBlockSource (long targetPos)
specifier|private
specifier|synchronized
name|boolean
name|seekToBlockSource
parameter_list|(
name|long
name|targetPos
parameter_list|)
throws|throws
name|IOException
block|{
name|currentNode
operator|=
name|blockSeekTo
argument_list|(
name|targetPos
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Seek to given position on a node other than the current node.  If    * a node other than the current node is found, then returns true.     * If another node could not be found, then returns false.    */
annotation|@
name|Override
DECL|method|seekToNewSource (long targetPos)
specifier|public
specifier|synchronized
name|boolean
name|seekToNewSource
parameter_list|(
name|long
name|targetPos
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|markedDead
init|=
name|deadNodes
operator|.
name|containsKey
argument_list|(
name|currentNode
argument_list|)
decl_stmt|;
name|addToDeadNodes
argument_list|(
name|currentNode
argument_list|)
expr_stmt|;
name|DatanodeInfo
name|oldNode
init|=
name|currentNode
decl_stmt|;
name|DatanodeInfo
name|newNode
init|=
name|blockSeekTo
argument_list|(
name|targetPos
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|markedDead
condition|)
block|{
comment|/* remove it from deadNodes. blockSeekTo could have cleared         * deadNodes and added currentNode again. Thats ok. */
name|deadNodes
operator|.
name|remove
argument_list|(
name|oldNode
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|oldNode
operator|.
name|getStorageID
argument_list|()
operator|.
name|equals
argument_list|(
name|newNode
operator|.
name|getStorageID
argument_list|()
argument_list|)
condition|)
block|{
name|currentNode
operator|=
name|newNode
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
comment|/**    */
annotation|@
name|Override
DECL|method|getPos ()
specifier|public
specifier|synchronized
name|long
name|getPos
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|pos
return|;
block|}
comment|/** Return the size of the remaining available bytes    * if the size is less than or equal to {@link Integer#MAX_VALUE},    * otherwise, return {@link Integer#MAX_VALUE}.    */
annotation|@
name|Override
DECL|method|available ()
specifier|public
specifier|synchronized
name|int
name|available
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Stream closed"
argument_list|)
throw|;
block|}
specifier|final
name|long
name|remaining
init|=
name|getFileLength
argument_list|()
operator|-
name|pos
decl_stmt|;
return|return
name|remaining
operator|<=
name|Integer
operator|.
name|MAX_VALUE
condition|?
operator|(
name|int
operator|)
name|remaining
else|:
name|Integer
operator|.
name|MAX_VALUE
return|;
block|}
comment|/**    * We definitely don't support marks    */
annotation|@
name|Override
DECL|method|markSupported ()
specifier|public
name|boolean
name|markSupported
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
DECL|method|mark (int readLimit)
specifier|public
name|void
name|mark
parameter_list|(
name|int
name|readLimit
parameter_list|)
block|{   }
annotation|@
name|Override
DECL|method|reset ()
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mark/reset not supported"
argument_list|)
throw|;
block|}
comment|/**    * Pick the best node from which to stream the data.    * Entries in<i>nodes</i> are already in the priority order    */
DECL|method|bestNode (DatanodeInfo nodes[], AbstractMap<DatanodeInfo, DatanodeInfo> deadNodes)
specifier|static
name|DatanodeInfo
name|bestNode
parameter_list|(
name|DatanodeInfo
name|nodes
index|[]
parameter_list|,
name|AbstractMap
argument_list|<
name|DatanodeInfo
argument_list|,
name|DatanodeInfo
argument_list|>
name|deadNodes
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|nodes
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nodes
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|deadNodes
operator|.
name|containsKey
argument_list|(
name|nodes
index|[
name|i
index|]
argument_list|)
condition|)
block|{
return|return
name|nodes
index|[
name|i
index|]
return|;
block|}
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No live nodes contain current block"
argument_list|)
throw|;
block|}
comment|/** Utility class to encapsulate data node info and its ip address. */
DECL|class|DNAddrPair
specifier|static
class|class
name|DNAddrPair
block|{
DECL|field|info
name|DatanodeInfo
name|info
decl_stmt|;
DECL|field|addr
name|InetSocketAddress
name|addr
decl_stmt|;
DECL|method|DNAddrPair (DatanodeInfo info, InetSocketAddress addr)
name|DNAddrPair
parameter_list|(
name|DatanodeInfo
name|info
parameter_list|,
name|InetSocketAddress
name|addr
parameter_list|)
block|{
name|this
operator|.
name|info
operator|=
name|info
expr_stmt|;
name|this
operator|.
name|addr
operator|=
name|addr
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

