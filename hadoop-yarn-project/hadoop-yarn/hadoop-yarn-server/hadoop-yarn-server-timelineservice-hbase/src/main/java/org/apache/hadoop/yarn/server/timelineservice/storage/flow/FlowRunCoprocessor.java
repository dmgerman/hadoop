begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.yarn.server.timelineservice.storage.flow
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|timelineservice
operator|.
name|storage
operator|.
name|flow
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CoprocessorEnvironment
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Tag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Durability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
operator|.
name|BaseRegionObserver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
operator|.
name|ObserverContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
operator|.
name|RegionCoprocessorEnvironment
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|Region
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|InternalScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|RegionScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|ScanType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|Store
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|timelineservice
operator|.
name|storage
operator|.
name|common
operator|.
name|HBaseTimelineStorageUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|timelineservice
operator|.
name|storage
operator|.
name|common
operator|.
name|TimestampGenerator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Coprocessor for flow run table.  */
end_comment

begin_class
DECL|class|FlowRunCoprocessor
specifier|public
class|class
name|FlowRunCoprocessor
extends|extends
name|BaseRegionObserver
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|FlowRunCoprocessor
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|region
specifier|private
name|Region
name|region
decl_stmt|;
comment|/**    * generate a timestamp that is unique per row in a region this is per region.    */
DECL|field|timestampGenerator
specifier|private
specifier|final
name|TimestampGenerator
name|timestampGenerator
init|=
operator|new
name|TimestampGenerator
argument_list|()
decl_stmt|;
annotation|@
name|Override
DECL|method|start (CoprocessorEnvironment e)
specifier|public
name|void
name|start
parameter_list|(
name|CoprocessorEnvironment
name|e
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|e
operator|instanceof
name|RegionCoprocessorEnvironment
condition|)
block|{
name|RegionCoprocessorEnvironment
name|env
init|=
operator|(
name|RegionCoprocessorEnvironment
operator|)
name|e
decl_stmt|;
name|this
operator|.
name|region
operator|=
name|env
operator|.
name|getRegion
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * (non-Javadoc)    *    * This method adds the tags onto the cells in the Put. It is presumed that    * all the cells in one Put have the same set of Tags. The existing cell    * timestamp is overwritten for non-metric cells and each such cell gets a new    * unique timestamp generated by {@link TimestampGenerator}    *    * @see    * org.apache.hadoop.hbase.coprocessor.BaseRegionObserver#prePut(org.apache    * .hadoop.hbase.coprocessor.ObserverContext,    * org.apache.hadoop.hbase.client.Put,    * org.apache.hadoop.hbase.regionserver.wal.WALEdit,    * org.apache.hadoop.hbase.client.Durability)    */
annotation|@
name|Override
DECL|method|prePut (ObserverContext<RegionCoprocessorEnvironment> e, Put put, WALEdit edit, Durability durability)
specifier|public
name|void
name|prePut
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|e
parameter_list|,
name|Put
name|put
parameter_list|,
name|WALEdit
name|edit
parameter_list|,
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|byte
index|[]
argument_list|>
name|attributes
init|=
name|put
operator|.
name|getAttributesMap
argument_list|()
decl_stmt|;
comment|// Assumption is that all the cells in a put are the same operation.
name|List
argument_list|<
name|Tag
argument_list|>
name|tags
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|attributes
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|attributes
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|byte
index|[]
argument_list|>
name|attribute
range|:
name|attributes
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Tag
name|t
init|=
name|HBaseTimelineStorageUtils
operator|.
name|getTagFromAttribute
argument_list|(
name|attribute
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|tags
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
block|}
block|}
name|byte
index|[]
name|tagByteArray
init|=
name|Tag
operator|.
name|fromList
argument_list|(
name|tags
argument_list|)
decl_stmt|;
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|newFamilyMap
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|entry
range|:
name|put
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|newCells
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Cell
name|cell
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
comment|// for each cell in the put add the tags
comment|// Assumption is that all the cells in
comment|// one put are the same operation
comment|// also, get a unique cell timestamp for non-metric cells
comment|// this way we don't inadvertently overwrite cell versions
name|long
name|cellTimestamp
init|=
name|getCellTimestamp
argument_list|(
name|cell
operator|.
name|getTimestamp
argument_list|()
argument_list|,
name|tags
argument_list|)
decl_stmt|;
name|newCells
operator|.
name|add
argument_list|(
name|CellUtil
operator|.
name|createCell
argument_list|(
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|cell
argument_list|)
argument_list|,
name|CellUtil
operator|.
name|cloneFamily
argument_list|(
name|cell
argument_list|)
argument_list|,
name|CellUtil
operator|.
name|cloneQualifier
argument_list|(
name|cell
argument_list|)
argument_list|,
name|cellTimestamp
argument_list|,
name|KeyValue
operator|.
name|Type
operator|.
name|Put
argument_list|,
name|CellUtil
operator|.
name|cloneValue
argument_list|(
name|cell
argument_list|)
argument_list|,
name|tagByteArray
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|newFamilyMap
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|newCells
argument_list|)
expr_stmt|;
block|}
comment|// for each entry
comment|// Update the family map for the Put
name|put
operator|.
name|setFamilyCellMap
argument_list|(
name|newFamilyMap
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Determines if the current cell's timestamp is to be used or a new unique    * cell timestamp is to be used. The reason this is done is to inadvertently    * overwrite cells when writes come in very fast. But for metric cells, the    * cell timestamp signifies the metric timestamp. Hence we don't want to    * overwrite it.    *    * @param timestamp    * @param tags    * @return cell timestamp    */
DECL|method|getCellTimestamp (long timestamp, List<Tag> tags)
specifier|private
name|long
name|getCellTimestamp
parameter_list|(
name|long
name|timestamp
parameter_list|,
name|List
argument_list|<
name|Tag
argument_list|>
name|tags
parameter_list|)
block|{
comment|// if ts not set (hbase sets to HConstants.LATEST_TIMESTAMP by default)
comment|// then use the generator
if|if
condition|(
name|timestamp
operator|==
name|HConstants
operator|.
name|LATEST_TIMESTAMP
condition|)
block|{
return|return
name|timestampGenerator
operator|.
name|getUniqueTimestamp
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|timestamp
return|;
block|}
block|}
comment|/*    * (non-Javadoc)    *    * Creates a {@link FlowScanner} Scan so that it can correctly process the    * contents of {@link FlowRunTable}.    *    * @see    * org.apache.hadoop.hbase.coprocessor.BaseRegionObserver#preGetOp(org.apache    * .hadoop.hbase.coprocessor.ObserverContext,    * org.apache.hadoop.hbase.client.Get, java.util.List)    */
annotation|@
name|Override
DECL|method|preGetOp (ObserverContext<RegionCoprocessorEnvironment> e, Get get, List<Cell> results)
specifier|public
name|void
name|preGetOp
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|e
parameter_list|,
name|Get
name|get
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|(
name|get
argument_list|)
decl_stmt|;
name|scan
operator|.
name|setMaxVersions
argument_list|()
expr_stmt|;
name|RegionScanner
name|scanner
init|=
literal|null
decl_stmt|;
try|try
block|{
name|scanner
operator|=
operator|new
name|FlowScanner
argument_list|(
name|e
operator|.
name|getEnvironment
argument_list|()
argument_list|,
name|scan
argument_list|,
name|region
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|)
argument_list|,
name|FlowScannerOperation
operator|.
name|READ
argument_list|)
expr_stmt|;
name|scanner
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
name|e
operator|.
name|bypass
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|scanner
operator|!=
literal|null
condition|)
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/*    * (non-Javadoc)    *    * Ensures that max versions are set for the Scan so that metrics can be    * correctly aggregated and min/max can be correctly determined.    *    * @see    * org.apache.hadoop.hbase.coprocessor.BaseRegionObserver#preScannerOpen(org    * .apache.hadoop.hbase.coprocessor.ObserverContext,    * org.apache.hadoop.hbase.client.Scan,    * org.apache.hadoop.hbase.regionserver.RegionScanner)    */
annotation|@
name|Override
DECL|method|preScannerOpen ( ObserverContext<RegionCoprocessorEnvironment> e, Scan scan, RegionScanner scanner)
specifier|public
name|RegionScanner
name|preScannerOpen
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|e
parameter_list|,
name|Scan
name|scan
parameter_list|,
name|RegionScanner
name|scanner
parameter_list|)
throws|throws
name|IOException
block|{
comment|// set max versions for scan to see all
comment|// versions to aggregate for metrics
name|scan
operator|.
name|setMaxVersions
argument_list|()
expr_stmt|;
return|return
name|scanner
return|;
block|}
comment|/*    * (non-Javadoc)    *    * Creates a {@link FlowScanner} Scan so that it can correctly process the    * contents of {@link FlowRunTable}.    *    * @see    * org.apache.hadoop.hbase.coprocessor.BaseRegionObserver#postScannerOpen(    * org.apache.hadoop.hbase.coprocessor.ObserverContext,    * org.apache.hadoop.hbase.client.Scan,    * org.apache.hadoop.hbase.regionserver.RegionScanner)    */
annotation|@
name|Override
DECL|method|postScannerOpen ( ObserverContext<RegionCoprocessorEnvironment> e, Scan scan, RegionScanner scanner)
specifier|public
name|RegionScanner
name|postScannerOpen
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|e
parameter_list|,
name|Scan
name|scan
parameter_list|,
name|RegionScanner
name|scanner
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|FlowScanner
argument_list|(
name|e
operator|.
name|getEnvironment
argument_list|()
argument_list|,
name|scan
argument_list|,
name|scanner
argument_list|,
name|FlowScannerOperation
operator|.
name|READ
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|preFlush ( ObserverContext<RegionCoprocessorEnvironment> c, Store store, InternalScanner scanner)
specifier|public
name|InternalScanner
name|preFlush
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
name|Store
name|store
parameter_list|,
name|InternalScanner
name|scanner
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|store
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"preFlush store = "
operator|+
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|+
literal|" flushableSize="
operator|+
name|store
operator|.
name|getFlushableSize
argument_list|()
operator|+
literal|" flushedCellsCount="
operator|+
name|store
operator|.
name|getFlushedCellsCount
argument_list|()
operator|+
literal|" compactedCellsCount="
operator|+
name|store
operator|.
name|getCompactedCellsCount
argument_list|()
operator|+
literal|" majorCompactedCellsCount="
operator|+
name|store
operator|.
name|getMajorCompactedCellsCount
argument_list|()
operator|+
literal|" memstoreFlushSize="
operator|+
name|store
operator|.
name|getMemstoreFlushSize
argument_list|()
operator|+
literal|" memstoreSize="
operator|+
name|store
operator|.
name|getMemStoreSize
argument_list|()
operator|+
literal|" size="
operator|+
name|store
operator|.
name|getSize
argument_list|()
operator|+
literal|" storeFilesCount="
operator|+
name|store
operator|.
name|getStorefilesCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|FlowScanner
argument_list|(
name|c
operator|.
name|getEnvironment
argument_list|()
argument_list|,
name|scanner
argument_list|,
name|FlowScannerOperation
operator|.
name|FLUSH
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|postFlush (ObserverContext<RegionCoprocessorEnvironment> c, Store store, StoreFile resultFile)
specifier|public
name|void
name|postFlush
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
name|Store
name|store
parameter_list|,
name|StoreFile
name|resultFile
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|store
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"postFlush store = "
operator|+
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|+
literal|" flushableSize="
operator|+
name|store
operator|.
name|getFlushableSize
argument_list|()
operator|+
literal|" flushedCellsCount="
operator|+
name|store
operator|.
name|getFlushedCellsCount
argument_list|()
operator|+
literal|" compactedCellsCount="
operator|+
name|store
operator|.
name|getCompactedCellsCount
argument_list|()
operator|+
literal|" majorCompactedCellsCount="
operator|+
name|store
operator|.
name|getMajorCompactedCellsCount
argument_list|()
operator|+
literal|" memstoreFlushSize="
operator|+
name|store
operator|.
name|getMemstoreFlushSize
argument_list|()
operator|+
literal|" memstoreSize="
operator|+
name|store
operator|.
name|getMemStoreSize
argument_list|()
operator|+
literal|" size="
operator|+
name|store
operator|.
name|getSize
argument_list|()
operator|+
literal|" storeFilesCount="
operator|+
name|store
operator|.
name|getStorefilesCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|preCompact ( ObserverContext<RegionCoprocessorEnvironment> e, Store store, InternalScanner scanner, ScanType scanType, CompactionRequest request)
specifier|public
name|InternalScanner
name|preCompact
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|e
parameter_list|,
name|Store
name|store
parameter_list|,
name|InternalScanner
name|scanner
parameter_list|,
name|ScanType
name|scanType
parameter_list|,
name|CompactionRequest
name|request
parameter_list|)
throws|throws
name|IOException
block|{
name|FlowScannerOperation
name|requestOp
init|=
name|FlowScannerOperation
operator|.
name|MINOR_COMPACTION
decl_stmt|;
if|if
condition|(
name|request
operator|!=
literal|null
condition|)
block|{
name|requestOp
operator|=
operator|(
name|request
operator|.
name|isMajor
argument_list|()
condition|?
name|FlowScannerOperation
operator|.
name|MAJOR_COMPACTION
else|:
name|FlowScannerOperation
operator|.
name|MINOR_COMPACTION
operator|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Compactionrequest= "
operator|+
name|request
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|requestOp
operator|.
name|toString
argument_list|()
operator|+
literal|" RegionName="
operator|+
name|e
operator|.
name|getEnvironment
argument_list|()
operator|.
name|getRegion
argument_list|()
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|FlowScanner
argument_list|(
name|e
operator|.
name|getEnvironment
argument_list|()
argument_list|,
name|scanner
argument_list|,
name|requestOp
argument_list|)
return|;
block|}
block|}
end_class

end_unit

