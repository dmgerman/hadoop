begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.streaming
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|streaming
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|MiniMRCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|MapReduceTestUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Shell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|*
import|;
end_import

begin_comment
comment|/**  * This tests the environment set by TT for the child of task jvm.  * This will launch a streaming job with a shell script as mapper.  */
end_comment

begin_class
DECL|class|TestStreamingTaskLog
specifier|public
class|class
name|TestStreamingTaskLog
block|{
DECL|field|input
name|String
name|input
init|=
literal|"the dummy input"
decl_stmt|;
DECL|field|inputPath
name|Path
name|inputPath
init|=
operator|new
name|Path
argument_list|(
literal|"inDir"
argument_list|)
decl_stmt|;
DECL|field|outputPath
name|Path
name|outputPath
init|=
operator|new
name|Path
argument_list|(
literal|"outDir"
argument_list|)
decl_stmt|;
DECL|field|map
name|String
name|map
init|=
literal|null
decl_stmt|;
DECL|field|mr
name|MiniMRCluster
name|mr
init|=
literal|null
decl_stmt|;
DECL|field|fs
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
DECL|field|USERLOG_LIMIT_KB
specifier|final
name|long
name|USERLOG_LIMIT_KB
init|=
literal|5
decl_stmt|;
comment|//consider 5kb as logSize
DECL|method|genArgs ()
name|String
index|[]
name|genArgs
parameter_list|()
block|{
return|return
operator|new
name|String
index|[]
block|{
literal|"-input"
block|,
name|inputPath
operator|.
name|toString
argument_list|()
block|,
literal|"-output"
block|,
name|outputPath
operator|.
name|toString
argument_list|()
block|,
literal|"-mapper"
block|,
name|map
block|,
literal|"-reducer"
block|,
name|StreamJob
operator|.
name|REDUCE_NONE
block|,
literal|"-jobconf"
block|,
literal|"mapred.job.tracker="
operator|+
literal|"localhost:"
operator|+
name|mr
operator|.
name|getJobTrackerPort
argument_list|()
block|,
literal|"-jobconf"
block|,
literal|"fs.default.name="
operator|+
name|fs
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
block|,
literal|"-jobconf"
block|,
literal|"mapred.map.tasks=1"
block|,
literal|"-jobconf"
block|,
literal|"keep.failed.task.files=true"
block|,
literal|"-jobconf"
block|,
literal|"mapreduce.task.userlog.limit.kb="
operator|+
name|USERLOG_LIMIT_KB
block|,
literal|"-jobconf"
block|,
literal|"stream.tmpdir="
operator|+
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
literal|"/tmp"
argument_list|)
block|}
return|;
block|}
comment|/**    * This test validates the setting of HADOOP_ROOT_LOGGER to 'INFO,TLA' and the    * dependent properties    *  (a) hadoop.tasklog.taskid and    *  (b) hadoop.tasklog.totalLogFileSize    * for the children of java tasks in streaming jobs.    */
annotation|@
name|Test
DECL|method|testStreamingTaskLogWithHadoopCmd ()
specifier|public
name|void
name|testStreamingTaskLogWithHadoopCmd
parameter_list|()
block|{
try|try
block|{
specifier|final
name|int
name|numSlaves
init|=
literal|1
decl_stmt|;
name|JobConf
name|conf
init|=
operator|new
name|JobConf
argument_list|()
decl_stmt|;
name|fs
operator|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|Path
name|testDir
init|=
operator|new
name|Path
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.build.data"
argument_list|,
literal|"/tmp"
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|testDir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|testDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|testDir
argument_list|)
expr_stmt|;
name|File
name|scriptFile
init|=
name|createScript
argument_list|(
name|testDir
operator|.
name|toString
argument_list|()
operator|+
literal|"/testTaskLog.sh"
argument_list|)
decl_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|JTConfig
operator|.
name|JT_PERSIST_JOBSTATUS
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|mr
operator|=
operator|new
name|MiniMRCluster
argument_list|(
name|numSlaves
argument_list|,
name|fs
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
literal|1
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|writeInputFile
argument_list|(
name|fs
argument_list|,
name|inputPath
argument_list|)
expr_stmt|;
name|map
operator|=
name|scriptFile
operator|.
name|getAbsolutePath
argument_list|()
expr_stmt|;
name|runStreamJobAndValidateEnv
argument_list|()
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|outputPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|assertFalse
argument_list|(
literal|"output not cleaned up"
argument_list|,
name|fs
operator|.
name|exists
argument_list|(
name|outputPath
argument_list|)
argument_list|)
expr_stmt|;
name|mr
operator|.
name|waitUntilIdle
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|fail
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|mr
operator|!=
literal|null
condition|)
block|{
name|mr
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
DECL|method|createScript (String script)
specifier|private
name|File
name|createScript
parameter_list|(
name|String
name|script
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|scriptFile
init|=
operator|new
name|File
argument_list|(
name|script
argument_list|)
decl_stmt|;
name|UtilTest
operator|.
name|recursiveDelete
argument_list|(
name|scriptFile
argument_list|)
expr_stmt|;
name|FileOutputStream
name|in
init|=
operator|new
name|FileOutputStream
argument_list|(
name|scriptFile
argument_list|)
decl_stmt|;
name|in
operator|.
name|write
argument_list|(
operator|(
literal|"cat> /dev/null 2>&1\n"
operator|+
literal|"echo $HADOOP_ROOT_LOGGER $HADOOP_CLIENT_OPTS"
operator|)
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
name|Shell
operator|.
name|execCommand
argument_list|(
operator|new
name|String
index|[]
block|{
literal|"chmod"
block|,
literal|"+x"
block|,
name|scriptFile
operator|.
name|getAbsolutePath
argument_list|()
block|}
argument_list|)
expr_stmt|;
return|return
name|scriptFile
return|;
block|}
DECL|method|writeInputFile (FileSystem fs, Path dir)
specifier|private
name|void
name|writeInputFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
name|DataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
literal|"part0"
argument_list|)
argument_list|)
decl_stmt|;
name|out
operator|.
name|writeBytes
argument_list|(
name|input
argument_list|)
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Runs the streaming job and validates the output.    * @throws IOException    */
DECL|method|runStreamJobAndValidateEnv ()
specifier|private
name|void
name|runStreamJobAndValidateEnv
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|returnStatus
init|=
operator|-
literal|1
decl_stmt|;
name|boolean
name|mayExit
init|=
literal|false
decl_stmt|;
name|StreamJob
name|job
init|=
operator|new
name|StreamJob
argument_list|(
name|genArgs
argument_list|()
argument_list|,
name|mayExit
argument_list|)
decl_stmt|;
name|returnStatus
operator|=
name|job
operator|.
name|go
argument_list|()
expr_stmt|;
name|assertEquals
argument_list|(
literal|"StreamJob failed."
argument_list|,
literal|0
argument_list|,
name|returnStatus
argument_list|)
expr_stmt|;
comment|// validate environment variables set for the child(script) of java process
name|String
name|env
init|=
name|MapReduceTestUtil
operator|.
name|readOutput
argument_list|(
name|outputPath
argument_list|,
name|mr
operator|.
name|createJobConf
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|logSize
init|=
name|USERLOG_LIMIT_KB
operator|*
literal|1024
decl_stmt|;
name|assertTrue
argument_list|(
literal|"environment set for child is wrong"
argument_list|,
name|env
operator|.
name|contains
argument_list|(
literal|"INFO,TLA"
argument_list|)
operator|&&
name|env
operator|.
name|contains
argument_list|(
literal|"-Dhadoop.tasklog.taskid=attempt_"
argument_list|)
operator|&&
name|env
operator|.
name|contains
argument_list|(
literal|"-Dhadoop.tasklog.totalLogFileSize="
operator|+
name|logSize
argument_list|)
operator|&&
name|env
operator|.
name|contains
argument_list|(
literal|"-Dhadoop.tasklog.iscleanup=false"
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

