begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.tools.rumen
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|rumen
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|JsonEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|JsonGenerator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|JsonFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|codehaus
operator|.
name|jackson
operator|.
name|map
operator|.
name|ObjectMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|*
import|;
end_import

begin_class
DECL|class|TestHistograms
specifier|public
class|class
name|TestHistograms
block|{
comment|/**    * @throws IOException    *     *           There should be files in the directory named by    *           ${test.build.data}/rumen/histogram-test .    *     *           There will be pairs of files, inputXxx.json and goldXxx.json .    *     *           We read the input file as a HistogramRawTestData in json. Then we    *           create a Histogram using the data field, and then a    *           LoggedDiscreteCDF using the percentiles and scale field. Finally,    *           we read the corresponding goldXxx.json as a LoggedDiscreteCDF and    *           deepCompare them.    */
annotation|@
name|Test
DECL|method|testHistograms ()
specifier|public
name|void
name|testHistograms
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
specifier|final
name|FileSystem
name|lfs
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|rootInputDir
init|=
operator|new
name|Path
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
literal|"test.tools.input.dir"
argument_list|,
literal|""
argument_list|)
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|lfs
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|rootInputFile
init|=
operator|new
name|Path
argument_list|(
name|rootInputDir
argument_list|,
literal|"rumen/histogram-tests"
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|tests
init|=
name|lfs
operator|.
name|listStatus
argument_list|(
name|rootInputFile
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|tests
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|Path
name|filePath
init|=
name|tests
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|String
name|fileName
init|=
name|filePath
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileName
operator|.
name|startsWith
argument_list|(
literal|"input"
argument_list|)
condition|)
block|{
name|String
name|testName
init|=
name|fileName
operator|.
name|substring
argument_list|(
literal|"input"
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|goldFilePath
init|=
operator|new
name|Path
argument_list|(
name|rootInputFile
argument_list|,
literal|"gold"
operator|+
name|testName
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Gold file dies not exist"
argument_list|,
name|lfs
operator|.
name|exists
argument_list|(
name|goldFilePath
argument_list|)
argument_list|)
expr_stmt|;
name|LoggedDiscreteCDF
name|newResult
init|=
name|histogramFileToCDF
argument_list|(
name|filePath
argument_list|,
name|lfs
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Testing a Histogram for "
operator|+
name|fileName
argument_list|)
expr_stmt|;
name|FSDataInputStream
name|goldStream
init|=
name|lfs
operator|.
name|open
argument_list|(
name|goldFilePath
argument_list|)
decl_stmt|;
name|JsonObjectMapperParser
argument_list|<
name|LoggedDiscreteCDF
argument_list|>
name|parser
init|=
operator|new
name|JsonObjectMapperParser
argument_list|<
name|LoggedDiscreteCDF
argument_list|>
argument_list|(
name|goldStream
argument_list|,
name|LoggedDiscreteCDF
operator|.
name|class
argument_list|)
decl_stmt|;
try|try
block|{
name|LoggedDiscreteCDF
name|dcdf
init|=
name|parser
operator|.
name|getNext
argument_list|()
decl_stmt|;
name|dcdf
operator|.
name|deepCompare
argument_list|(
name|newResult
argument_list|,
operator|new
name|TreePath
argument_list|(
literal|null
argument_list|,
literal|"<root>"
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeepInequalityException
name|e
parameter_list|)
block|{
name|fail
argument_list|(
name|e
operator|.
name|path
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|parser
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
DECL|method|histogramFileToCDF (Path path, FileSystem fs)
specifier|private
specifier|static
name|LoggedDiscreteCDF
name|histogramFileToCDF
parameter_list|(
name|Path
name|path
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|FSDataInputStream
name|dataStream
init|=
name|fs
operator|.
name|open
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|JsonObjectMapperParser
argument_list|<
name|HistogramRawTestData
argument_list|>
name|parser
init|=
operator|new
name|JsonObjectMapperParser
argument_list|<
name|HistogramRawTestData
argument_list|>
argument_list|(
name|dataStream
argument_list|,
name|HistogramRawTestData
operator|.
name|class
argument_list|)
decl_stmt|;
name|HistogramRawTestData
name|data
decl_stmt|;
try|try
block|{
name|data
operator|=
name|parser
operator|.
name|getNext
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|parser
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|Histogram
name|hist
init|=
operator|new
name|Histogram
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|measurements
init|=
name|data
operator|.
name|getData
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|typeProbeData
init|=
operator|new
name|HistogramRawTestData
argument_list|()
operator|.
name|getData
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"The data attribute of a jackson-reconstructed HistogramRawTestData "
operator|+
literal|" should be a "
operator|+
name|typeProbeData
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|", like a virgin HistogramRawTestData, but it's a "
operator|+
name|measurements
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|measurements
operator|.
name|getClass
argument_list|()
operator|==
name|typeProbeData
operator|.
name|getClass
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|measurements
operator|.
name|size
argument_list|()
condition|;
operator|++
name|j
control|)
block|{
name|hist
operator|.
name|enter
argument_list|(
name|measurements
operator|.
name|get
argument_list|(
name|j
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LoggedDiscreteCDF
name|result
init|=
operator|new
name|LoggedDiscreteCDF
argument_list|()
decl_stmt|;
name|int
index|[]
name|percentiles
init|=
operator|new
name|int
index|[
name|data
operator|.
name|getPercentiles
argument_list|()
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|data
operator|.
name|getPercentiles
argument_list|()
operator|.
name|size
argument_list|()
condition|;
operator|++
name|j
control|)
block|{
name|percentiles
index|[
name|j
index|]
operator|=
name|data
operator|.
name|getPercentiles
argument_list|()
operator|.
name|get
argument_list|(
name|j
argument_list|)
expr_stmt|;
block|}
name|result
operator|.
name|setCDF
argument_list|(
name|hist
argument_list|,
name|percentiles
argument_list|,
name|data
operator|.
name|getScale
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
DECL|method|main (String[] args)
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|()
decl_stmt|;
specifier|final
name|FileSystem
name|lfs
init|=
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|arg
range|:
name|args
control|)
block|{
name|Path
name|filePath
init|=
operator|new
name|Path
argument_list|(
name|arg
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|lfs
argument_list|)
decl_stmt|;
name|String
name|fileName
init|=
name|filePath
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|fileName
operator|.
name|startsWith
argument_list|(
literal|"input"
argument_list|)
condition|)
block|{
name|LoggedDiscreteCDF
name|newResult
init|=
name|histogramFileToCDF
argument_list|(
name|filePath
argument_list|,
name|lfs
argument_list|)
decl_stmt|;
name|String
name|testName
init|=
name|fileName
operator|.
name|substring
argument_list|(
literal|"input"
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|goldFilePath
init|=
operator|new
name|Path
argument_list|(
name|filePath
operator|.
name|getParent
argument_list|()
argument_list|,
literal|"gold"
operator|+
name|testName
argument_list|)
decl_stmt|;
name|ObjectMapper
name|mapper
init|=
operator|new
name|ObjectMapper
argument_list|()
decl_stmt|;
name|JsonFactory
name|factory
init|=
name|mapper
operator|.
name|getJsonFactory
argument_list|()
decl_stmt|;
name|FSDataOutputStream
name|ostream
init|=
name|lfs
operator|.
name|create
argument_list|(
name|goldFilePath
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|JsonGenerator
name|gen
init|=
name|factory
operator|.
name|createJsonGenerator
argument_list|(
name|ostream
argument_list|,
name|JsonEncoding
operator|.
name|UTF8
argument_list|)
decl_stmt|;
name|gen
operator|.
name|useDefaultPrettyPrinter
argument_list|()
expr_stmt|;
name|gen
operator|.
name|writeObject
argument_list|(
name|newResult
argument_list|)
expr_stmt|;
name|gen
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Input file not started with \"input\". File "
operator|+
name|fileName
operator|+
literal|" skipped."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

