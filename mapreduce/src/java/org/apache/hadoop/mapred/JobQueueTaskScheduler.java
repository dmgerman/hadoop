begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.mapred
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|TaskTracker
import|;
end_import

begin_comment
comment|/**  * A {@link TaskScheduler} that keeps jobs in a queue in priority order (FIFO  * by default).  */
end_comment

begin_class
DECL|class|JobQueueTaskScheduler
class|class
name|JobQueueTaskScheduler
extends|extends
name|TaskScheduler
block|{
DECL|field|MIN_CLUSTER_SIZE_FOR_PADDING
specifier|private
specifier|static
specifier|final
name|int
name|MIN_CLUSTER_SIZE_FOR_PADDING
init|=
literal|3
decl_stmt|;
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|JobQueueTaskScheduler
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|jobQueueJobInProgressListener
specifier|protected
name|JobQueueJobInProgressListener
name|jobQueueJobInProgressListener
decl_stmt|;
DECL|field|eagerTaskInitializationListener
specifier|protected
name|EagerTaskInitializationListener
name|eagerTaskInitializationListener
decl_stmt|;
DECL|field|padFraction
specifier|private
name|float
name|padFraction
decl_stmt|;
DECL|method|JobQueueTaskScheduler ()
specifier|public
name|JobQueueTaskScheduler
parameter_list|()
block|{
name|this
operator|.
name|jobQueueJobInProgressListener
operator|=
operator|new
name|JobQueueJobInProgressListener
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|start ()
specifier|public
specifier|synchronized
name|void
name|start
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|start
argument_list|()
expr_stmt|;
name|taskTrackerManager
operator|.
name|addJobInProgressListener
argument_list|(
name|jobQueueJobInProgressListener
argument_list|)
expr_stmt|;
name|eagerTaskInitializationListener
operator|.
name|setTaskTrackerManager
argument_list|(
name|taskTrackerManager
argument_list|)
expr_stmt|;
name|eagerTaskInitializationListener
operator|.
name|start
argument_list|()
expr_stmt|;
name|taskTrackerManager
operator|.
name|addJobInProgressListener
argument_list|(
name|eagerTaskInitializationListener
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|terminate ()
specifier|public
specifier|synchronized
name|void
name|terminate
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|jobQueueJobInProgressListener
operator|!=
literal|null
condition|)
block|{
name|taskTrackerManager
operator|.
name|removeJobInProgressListener
argument_list|(
name|jobQueueJobInProgressListener
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|eagerTaskInitializationListener
operator|!=
literal|null
condition|)
block|{
name|taskTrackerManager
operator|.
name|removeJobInProgressListener
argument_list|(
name|eagerTaskInitializationListener
argument_list|)
expr_stmt|;
name|eagerTaskInitializationListener
operator|.
name|terminate
argument_list|()
expr_stmt|;
block|}
name|super
operator|.
name|terminate
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|setConf (Configuration conf)
specifier|public
specifier|synchronized
name|void
name|setConf
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|super
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|padFraction
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|JTConfig
operator|.
name|JT_TASK_ALLOC_PAD_FRACTION
argument_list|,
literal|0.01f
argument_list|)
expr_stmt|;
name|this
operator|.
name|eagerTaskInitializationListener
operator|=
operator|new
name|EagerTaskInitializationListener
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|assignTasks (TaskTracker taskTracker)
specifier|public
specifier|synchronized
name|List
argument_list|<
name|Task
argument_list|>
name|assignTasks
parameter_list|(
name|TaskTracker
name|taskTracker
parameter_list|)
throws|throws
name|IOException
block|{
name|TaskTrackerStatus
name|taskTrackerStatus
init|=
name|taskTracker
operator|.
name|getStatus
argument_list|()
decl_stmt|;
name|ClusterStatus
name|clusterStatus
init|=
name|taskTrackerManager
operator|.
name|getClusterStatus
argument_list|()
decl_stmt|;
specifier|final
name|int
name|numTaskTrackers
init|=
name|clusterStatus
operator|.
name|getTaskTrackers
argument_list|()
decl_stmt|;
specifier|final
name|int
name|clusterMapCapacity
init|=
name|clusterStatus
operator|.
name|getMaxMapTasks
argument_list|()
decl_stmt|;
specifier|final
name|int
name|clusterReduceCapacity
init|=
name|clusterStatus
operator|.
name|getMaxReduceTasks
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|JobInProgress
argument_list|>
name|jobQueue
init|=
name|jobQueueJobInProgressListener
operator|.
name|getJobQueue
argument_list|()
decl_stmt|;
comment|//
comment|// Get map + reduce counts for the current tracker.
comment|//
specifier|final
name|int
name|trackerMapCapacity
init|=
name|taskTrackerStatus
operator|.
name|getMaxMapSlots
argument_list|()
decl_stmt|;
specifier|final
name|int
name|trackerReduceCapacity
init|=
name|taskTrackerStatus
operator|.
name|getMaxReduceSlots
argument_list|()
decl_stmt|;
specifier|final
name|int
name|trackerRunningMaps
init|=
name|taskTrackerStatus
operator|.
name|countMapTasks
argument_list|()
decl_stmt|;
specifier|final
name|int
name|trackerRunningReduces
init|=
name|taskTrackerStatus
operator|.
name|countReduceTasks
argument_list|()
decl_stmt|;
comment|// Assigned tasks
name|List
argument_list|<
name|Task
argument_list|>
name|assignedTasks
init|=
operator|new
name|ArrayList
argument_list|<
name|Task
argument_list|>
argument_list|()
decl_stmt|;
comment|//
comment|// Compute (running + pending) map and reduce task numbers across pool
comment|//
name|int
name|remainingReduceLoad
init|=
literal|0
decl_stmt|;
name|int
name|remainingMapLoad
init|=
literal|0
decl_stmt|;
synchronized|synchronized
init|(
name|jobQueue
init|)
block|{
for|for
control|(
name|JobInProgress
name|job
range|:
name|jobQueue
control|)
block|{
if|if
condition|(
name|job
operator|.
name|getStatus
argument_list|()
operator|.
name|getRunState
argument_list|()
operator|==
name|JobStatus
operator|.
name|RUNNING
condition|)
block|{
name|remainingMapLoad
operator|+=
operator|(
name|job
operator|.
name|desiredMaps
argument_list|()
operator|-
name|job
operator|.
name|finishedMaps
argument_list|()
operator|)
expr_stmt|;
if|if
condition|(
name|job
operator|.
name|scheduleReduces
argument_list|()
condition|)
block|{
name|remainingReduceLoad
operator|+=
operator|(
name|job
operator|.
name|desiredReduces
argument_list|()
operator|-
name|job
operator|.
name|finishedReduces
argument_list|()
operator|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// Compute the 'load factor' for maps and reduces
name|double
name|mapLoadFactor
init|=
literal|0.0
decl_stmt|;
if|if
condition|(
name|clusterMapCapacity
operator|>
literal|0
condition|)
block|{
name|mapLoadFactor
operator|=
operator|(
name|double
operator|)
name|remainingMapLoad
operator|/
name|clusterMapCapacity
expr_stmt|;
block|}
name|double
name|reduceLoadFactor
init|=
literal|0.0
decl_stmt|;
if|if
condition|(
name|clusterReduceCapacity
operator|>
literal|0
condition|)
block|{
name|reduceLoadFactor
operator|=
operator|(
name|double
operator|)
name|remainingReduceLoad
operator|/
name|clusterReduceCapacity
expr_stmt|;
block|}
comment|//
comment|// In the below steps, we allocate first map tasks (if appropriate),
comment|// and then reduce tasks if appropriate.  We go through all jobs
comment|// in order of job arrival; jobs only get serviced if their
comment|// predecessors are serviced, too.
comment|//
comment|//
comment|// We assign tasks to the current taskTracker if the given machine
comment|// has a workload that's less than the maximum load of that kind of
comment|// task.
comment|// However, if the cluster is close to getting loaded i.e. we don't
comment|// have enough _padding_ for speculative executions etc., we only
comment|// schedule the "highest priority" task i.e. the task from the job
comment|// with the highest priority.
comment|//
specifier|final
name|int
name|trackerCurrentMapCapacity
init|=
name|Math
operator|.
name|min
argument_list|(
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
name|mapLoadFactor
operator|*
name|trackerMapCapacity
argument_list|)
argument_list|,
name|trackerMapCapacity
argument_list|)
decl_stmt|;
name|int
name|availableMapSlots
init|=
name|trackerCurrentMapCapacity
operator|-
name|trackerRunningMaps
decl_stmt|;
name|boolean
name|exceededMapPadding
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|availableMapSlots
operator|>
literal|0
condition|)
block|{
name|exceededMapPadding
operator|=
name|exceededPadding
argument_list|(
literal|true
argument_list|,
name|clusterStatus
argument_list|,
name|trackerMapCapacity
argument_list|)
expr_stmt|;
block|}
name|int
name|numLocalMaps
init|=
literal|0
decl_stmt|;
name|int
name|numNonLocalMaps
init|=
literal|0
decl_stmt|;
name|scheduleMaps
label|:
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|availableMapSlots
condition|;
operator|++
name|i
control|)
block|{
synchronized|synchronized
init|(
name|jobQueue
init|)
block|{
for|for
control|(
name|JobInProgress
name|job
range|:
name|jobQueue
control|)
block|{
if|if
condition|(
name|job
operator|.
name|getStatus
argument_list|()
operator|.
name|getRunState
argument_list|()
operator|!=
name|JobStatus
operator|.
name|RUNNING
condition|)
block|{
continue|continue;
block|}
name|Task
name|t
init|=
literal|null
decl_stmt|;
comment|// Try to schedule a node-local or rack-local Map task
name|t
operator|=
name|job
operator|.
name|obtainNewLocalMapTask
argument_list|(
name|taskTrackerStatus
argument_list|,
name|numTaskTrackers
argument_list|,
name|taskTrackerManager
operator|.
name|getNumberOfUniqueHosts
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|assignedTasks
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
operator|++
name|numLocalMaps
expr_stmt|;
comment|// Don't assign map tasks to the hilt!
comment|// Leave some free slots in the cluster for future task-failures,
comment|// speculative tasks etc. beyond the highest priority job
if|if
condition|(
name|exceededMapPadding
condition|)
block|{
break|break
name|scheduleMaps
break|;
block|}
comment|// Try all jobs again for the next Map task
break|break;
block|}
comment|// Try to schedule a node-local or rack-local Map task
name|t
operator|=
name|job
operator|.
name|obtainNewNonLocalMapTask
argument_list|(
name|taskTrackerStatus
argument_list|,
name|numTaskTrackers
argument_list|,
name|taskTrackerManager
operator|.
name|getNumberOfUniqueHosts
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|assignedTasks
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
operator|++
name|numNonLocalMaps
expr_stmt|;
comment|// We assign at most 1 off-switch or speculative task
comment|// This is to prevent TaskTrackers from stealing local-tasks
comment|// from other TaskTrackers.
break|break
name|scheduleMaps
break|;
block|}
block|}
block|}
block|}
name|int
name|assignedMaps
init|=
name|assignedTasks
operator|.
name|size
argument_list|()
decl_stmt|;
comment|//
comment|// Same thing, but for reduce tasks
comment|// However we _never_ assign more than 1 reduce task per heartbeat
comment|//
specifier|final
name|int
name|trackerCurrentReduceCapacity
init|=
name|Math
operator|.
name|min
argument_list|(
operator|(
name|int
operator|)
name|Math
operator|.
name|ceil
argument_list|(
name|reduceLoadFactor
operator|*
name|trackerReduceCapacity
argument_list|)
argument_list|,
name|trackerReduceCapacity
argument_list|)
decl_stmt|;
specifier|final
name|int
name|availableReduceSlots
init|=
name|Math
operator|.
name|min
argument_list|(
operator|(
name|trackerCurrentReduceCapacity
operator|-
name|trackerRunningReduces
operator|)
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|boolean
name|exceededReducePadding
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|availableReduceSlots
operator|>
literal|0
condition|)
block|{
name|exceededReducePadding
operator|=
name|exceededPadding
argument_list|(
literal|false
argument_list|,
name|clusterStatus
argument_list|,
name|trackerReduceCapacity
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|jobQueue
init|)
block|{
for|for
control|(
name|JobInProgress
name|job
range|:
name|jobQueue
control|)
block|{
if|if
condition|(
name|job
operator|.
name|getStatus
argument_list|()
operator|.
name|getRunState
argument_list|()
operator|!=
name|JobStatus
operator|.
name|RUNNING
operator|||
name|job
operator|.
name|numReduceTasks
operator|==
literal|0
condition|)
block|{
continue|continue;
block|}
name|Task
name|t
init|=
name|job
operator|.
name|obtainNewReduceTask
argument_list|(
name|taskTrackerStatus
argument_list|,
name|numTaskTrackers
argument_list|,
name|taskTrackerManager
operator|.
name|getNumberOfUniqueHosts
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|assignedTasks
operator|.
name|add
argument_list|(
name|t
argument_list|)
expr_stmt|;
break|break;
block|}
comment|// Don't assign reduce tasks to the hilt!
comment|// Leave some free slots in the cluster for future task-failures,
comment|// speculative tasks etc. beyond the highest priority job
if|if
condition|(
name|exceededReducePadding
condition|)
block|{
break|break;
block|}
block|}
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Task assignments for "
operator|+
name|taskTrackerStatus
operator|.
name|getTrackerName
argument_list|()
operator|+
literal|" --> "
operator|+
literal|"["
operator|+
name|mapLoadFactor
operator|+
literal|", "
operator|+
name|trackerMapCapacity
operator|+
literal|", "
operator|+
name|trackerCurrentMapCapacity
operator|+
literal|", "
operator|+
name|trackerRunningMaps
operator|+
literal|"] -> ["
operator|+
operator|(
name|trackerCurrentMapCapacity
operator|-
name|trackerRunningMaps
operator|)
operator|+
literal|", "
operator|+
name|assignedMaps
operator|+
literal|" ("
operator|+
name|numLocalMaps
operator|+
literal|", "
operator|+
name|numNonLocalMaps
operator|+
literal|")] ["
operator|+
name|reduceLoadFactor
operator|+
literal|", "
operator|+
name|trackerReduceCapacity
operator|+
literal|", "
operator|+
name|trackerCurrentReduceCapacity
operator|+
literal|","
operator|+
name|trackerRunningReduces
operator|+
literal|"] -> ["
operator|+
operator|(
name|trackerCurrentReduceCapacity
operator|-
name|trackerRunningReduces
operator|)
operator|+
literal|", "
operator|+
operator|(
name|assignedTasks
operator|.
name|size
argument_list|()
operator|-
name|assignedMaps
operator|)
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return
name|assignedTasks
return|;
block|}
DECL|method|exceededPadding (boolean isMapTask, ClusterStatus clusterStatus, int maxTaskTrackerSlots)
specifier|private
name|boolean
name|exceededPadding
parameter_list|(
name|boolean
name|isMapTask
parameter_list|,
name|ClusterStatus
name|clusterStatus
parameter_list|,
name|int
name|maxTaskTrackerSlots
parameter_list|)
block|{
name|int
name|numTaskTrackers
init|=
name|clusterStatus
operator|.
name|getTaskTrackers
argument_list|()
decl_stmt|;
name|int
name|totalTasks
init|=
operator|(
name|isMapTask
operator|)
condition|?
name|clusterStatus
operator|.
name|getMapTasks
argument_list|()
else|:
name|clusterStatus
operator|.
name|getReduceTasks
argument_list|()
decl_stmt|;
name|int
name|totalTaskCapacity
init|=
name|isMapTask
condition|?
name|clusterStatus
operator|.
name|getMaxMapTasks
argument_list|()
else|:
name|clusterStatus
operator|.
name|getMaxReduceTasks
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|JobInProgress
argument_list|>
name|jobQueue
init|=
name|jobQueueJobInProgressListener
operator|.
name|getJobQueue
argument_list|()
decl_stmt|;
name|boolean
name|exceededPadding
init|=
literal|false
decl_stmt|;
synchronized|synchronized
init|(
name|jobQueue
init|)
block|{
name|int
name|totalNeededTasks
init|=
literal|0
decl_stmt|;
for|for
control|(
name|JobInProgress
name|job
range|:
name|jobQueue
control|)
block|{
if|if
condition|(
name|job
operator|.
name|getStatus
argument_list|()
operator|.
name|getRunState
argument_list|()
operator|!=
name|JobStatus
operator|.
name|RUNNING
operator|||
name|job
operator|.
name|numReduceTasks
operator|==
literal|0
condition|)
block|{
continue|continue;
block|}
comment|//
comment|// Beyond the highest-priority task, reserve a little
comment|// room for failures and speculative executions; don't
comment|// schedule tasks to the hilt.
comment|//
name|totalNeededTasks
operator|+=
name|isMapTask
condition|?
name|job
operator|.
name|desiredMaps
argument_list|()
else|:
name|job
operator|.
name|desiredReduces
argument_list|()
expr_stmt|;
name|int
name|padding
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|numTaskTrackers
operator|>
name|MIN_CLUSTER_SIZE_FOR_PADDING
condition|)
block|{
name|padding
operator|=
name|Math
operator|.
name|min
argument_list|(
name|maxTaskTrackerSlots
argument_list|,
call|(
name|int
call|)
argument_list|(
name|totalNeededTasks
operator|*
name|padFraction
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|totalTasks
operator|+
name|padding
operator|>=
name|totalTaskCapacity
condition|)
block|{
name|exceededPadding
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
block|}
return|return
name|exceededPadding
return|;
block|}
annotation|@
name|Override
DECL|method|getJobs (String queueName)
specifier|public
specifier|synchronized
name|Collection
argument_list|<
name|JobInProgress
argument_list|>
name|getJobs
parameter_list|(
name|String
name|queueName
parameter_list|)
block|{
return|return
name|jobQueueJobInProgressListener
operator|.
name|getJobQueue
argument_list|()
return|;
block|}
block|}
end_class

end_unit

