begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.namenode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|CheckedInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|Checksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LayoutVersion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|LayoutVersion
operator|.
name|Feature
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|HdfsConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
operator|.
name|StorageDirectory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Storage
operator|.
name|StorageState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|InconsistentFSStateException
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|common
operator|.
name|Util
operator|.
name|now
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|FSImage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|EditLogFileInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NNStorage
operator|.
name|NameNodeDirType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
operator|.
name|NNStorage
operator|.
name|NameNodeFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamenodeRegistration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|protocol
operator|.
name|NamenodeProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_comment
comment|/**  * Extension of FSImage for the backup node.  * This class handles the setup of the journaling   * spool on the backup namenode.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|class|BackupImage
specifier|public
class|class
name|BackupImage
extends|extends
name|FSImage
block|{
comment|// Names of the journal spool directory and the spool file
DECL|field|STORAGE_JSPOOL_DIR
specifier|private
specifier|static
specifier|final
name|String
name|STORAGE_JSPOOL_DIR
init|=
literal|"jspool"
decl_stmt|;
DECL|field|STORAGE_JSPOOL_FILE
specifier|private
specifier|static
specifier|final
name|String
name|STORAGE_JSPOOL_FILE
init|=
name|NNStorage
operator|.
name|NameNodeFile
operator|.
name|EDITS_NEW
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|/** Backup input stream for loading edits into memory */
DECL|field|backupInputStream
specifier|private
name|EditLogBackupInputStream
name|backupInputStream
decl_stmt|;
comment|/** Is journal spooling in progress */
DECL|field|jsState
specifier|volatile
name|JSpoolState
name|jsState
decl_stmt|;
DECL|enum|JSpoolState
specifier|static
enum|enum
name|JSpoolState
block|{
DECL|enumConstant|OFF
name|OFF
block|,
DECL|enumConstant|INPROGRESS
name|INPROGRESS
block|,
DECL|enumConstant|WAIT
name|WAIT
block|;   }
comment|/**    */
DECL|method|BackupImage ()
name|BackupImage
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
name|storage
operator|.
name|setDisablePreUpgradableLayoutCheck
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|jsState
operator|=
name|JSpoolState
operator|.
name|OFF
expr_stmt|;
block|}
comment|/**    * Analyze backup storage directories for consistency.<br>    * Recover from incomplete checkpoints if required.<br>    * Read VERSION and fstime files if exist.<br>    * Do not load image or edits.    *    * @param imageDirs list of image directories as URI.    * @param editsDirs list of edits directories URI.    * @throws IOException if the node should shutdown.    */
DECL|method|recoverCreateRead (Collection<URI> imageDirs, Collection<URI> editsDirs)
name|void
name|recoverCreateRead
parameter_list|(
name|Collection
argument_list|<
name|URI
argument_list|>
name|imageDirs
parameter_list|,
name|Collection
argument_list|<
name|URI
argument_list|>
name|editsDirs
parameter_list|)
throws|throws
name|IOException
block|{
name|storage
operator|.
name|setStorageDirectories
argument_list|(
name|imageDirs
argument_list|,
name|editsDirs
argument_list|)
expr_stmt|;
name|storage
operator|.
name|setCheckpointTime
argument_list|(
literal|0L
argument_list|)
expr_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|it
init|=
name|storage
operator|.
name|dirIterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageDirectory
name|sd
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|StorageState
name|curState
decl_stmt|;
try|try
block|{
name|curState
operator|=
name|sd
operator|.
name|analyzeStorage
argument_list|(
name|HdfsConstants
operator|.
name|StartupOption
operator|.
name|REGULAR
argument_list|,
name|storage
argument_list|)
expr_stmt|;
comment|// sd is locked but not opened
switch|switch
condition|(
name|curState
condition|)
block|{
case|case
name|NON_EXISTENT
case|:
comment|// fail if any of the configured storage dirs are inaccessible
throw|throw
operator|new
name|InconsistentFSStateException
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
literal|"checkpoint directory does not exist or is not accessible."
argument_list|)
throw|;
case|case
name|NOT_FORMATTED
case|:
comment|// for backup node all directories may be unformatted initially
name|LOG
operator|.
name|info
argument_list|(
literal|"Storage directory "
operator|+
name|sd
operator|.
name|getRoot
argument_list|()
operator|+
literal|" is not formatted."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Formatting ..."
argument_list|)
expr_stmt|;
name|sd
operator|.
name|clearDirectory
argument_list|()
expr_stmt|;
comment|// create empty current
break|break;
case|case
name|NORMAL
case|:
break|break;
default|default:
comment|// recovery is possible
name|sd
operator|.
name|doRecover
argument_list|(
name|curState
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|curState
operator|!=
name|StorageState
operator|.
name|NOT_FORMATTED
condition|)
block|{
comment|// read and verify consistency with other directories
name|storage
operator|.
name|readProperties
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|sd
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
block|}
comment|/**    * Reset storage directories.    *<p>    * Unlock the storage.    * Rename<code>current</code> to<code>lastcheckpoint.tmp</code>    * and recreate empty<code>current</code>.    * @throws IOException    */
DECL|method|reset ()
specifier|synchronized
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
comment|// reset NameSpace tree
name|FSDirectory
name|fsDir
init|=
name|getFSNamesystem
argument_list|()
operator|.
name|dir
decl_stmt|;
name|fsDir
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// unlock, close and rename storage directories
name|storage
operator|.
name|unlockAll
argument_list|()
expr_stmt|;
comment|// recover from unsuccessful checkpoint if necessary
name|recoverCreateRead
argument_list|(
name|storage
operator|.
name|getImageDirectories
argument_list|()
argument_list|,
name|storage
operator|.
name|getEditsDirectories
argument_list|()
argument_list|)
expr_stmt|;
comment|// rename and recreate
for|for
control|(
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|it
init|=
name|storage
operator|.
name|dirIterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageDirectory
name|sd
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// rename current to lastcheckpoint.tmp
name|storage
operator|.
name|moveCurrent
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Load checkpoint from local files only if the memory state is empty.<br>    * Set new checkpoint time received from the name-node.<br>    * Move<code>lastcheckpoint.tmp</code> to<code>previous.checkpoint</code>.    * @throws IOException    */
DECL|method|loadCheckpoint (CheckpointSignature sig)
name|void
name|loadCheckpoint
parameter_list|(
name|CheckpointSignature
name|sig
parameter_list|)
throws|throws
name|IOException
block|{
comment|// load current image and journal if it is not in memory already
if|if
condition|(
operator|!
name|editLog
operator|.
name|isOpen
argument_list|()
condition|)
name|editLog
operator|.
name|open
argument_list|()
expr_stmt|;
name|FSDirectory
name|fsDir
init|=
name|getFSNamesystem
argument_list|()
operator|.
name|dir
decl_stmt|;
if|if
condition|(
name|fsDir
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|itImage
init|=
name|storage
operator|.
name|dirIterator
argument_list|(
name|NameNodeDirType
operator|.
name|IMAGE
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|itEdits
init|=
name|storage
operator|.
name|dirIterator
argument_list|(
name|NameNodeDirType
operator|.
name|EDITS
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|itImage
operator|.
name|hasNext
argument_list|()
operator|||
operator|!
name|itEdits
operator|.
name|hasNext
argument_list|()
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not locate checkpoint directories"
argument_list|)
throw|;
name|StorageDirectory
name|sdName
init|=
name|itImage
operator|.
name|next
argument_list|()
decl_stmt|;
name|StorageDirectory
name|sdEdits
init|=
name|itEdits
operator|.
name|next
argument_list|()
decl_stmt|;
name|getFSDirectoryRootLock
argument_list|()
operator|.
name|writeLock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// load image under rootDir lock
name|loadFSImage
argument_list|(
name|NNStorage
operator|.
name|getStorageFile
argument_list|(
name|sdName
argument_list|,
name|NameNodeFile
operator|.
name|IMAGE
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|getFSDirectoryRootLock
argument_list|()
operator|.
name|writeUnlock
argument_list|()
expr_stmt|;
block|}
name|loadFSEdits
argument_list|(
name|sdEdits
argument_list|)
expr_stmt|;
block|}
comment|// set storage fields
name|storage
operator|.
name|setStorageInfo
argument_list|(
name|sig
argument_list|)
expr_stmt|;
name|storage
operator|.
name|setImageDigest
argument_list|(
name|sig
operator|.
name|imageDigest
argument_list|)
expr_stmt|;
name|storage
operator|.
name|setCheckpointTime
argument_list|(
name|sig
operator|.
name|checkpointTime
argument_list|)
expr_stmt|;
block|}
comment|/**    * Save meta-data into fsimage files.    * and create empty edits.    */
DECL|method|saveCheckpoint ()
name|void
name|saveCheckpoint
parameter_list|()
throws|throws
name|IOException
block|{
name|saveNamespace
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
DECL|method|getFSDirectoryRootLock ()
specifier|private
name|FSDirectory
name|getFSDirectoryRootLock
parameter_list|()
block|{
return|return
name|getFSNamesystem
argument_list|()
operator|.
name|dir
return|;
block|}
DECL|method|getJSpoolDir (StorageDirectory sd)
specifier|static
name|File
name|getJSpoolDir
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
block|{
return|return
operator|new
name|File
argument_list|(
name|sd
operator|.
name|getRoot
argument_list|()
argument_list|,
name|STORAGE_JSPOOL_DIR
argument_list|)
return|;
block|}
DECL|method|getJSpoolFile (StorageDirectory sd)
specifier|static
name|File
name|getJSpoolFile
parameter_list|(
name|StorageDirectory
name|sd
parameter_list|)
block|{
return|return
operator|new
name|File
argument_list|(
name|getJSpoolDir
argument_list|(
name|sd
argument_list|)
argument_list|,
name|STORAGE_JSPOOL_FILE
argument_list|)
return|;
block|}
comment|/**    * Journal writer journals new meta-data state.    *<ol>    *<li> If Journal Spool state is OFF then journal records (edits)    * are applied directly to meta-data state in memory and are written    * to the edits file(s).</li>    *<li> If Journal Spool state is INPROGRESS then records are only    * written to edits.new file, which is called Spooling.</li>    *<li> Journal Spool state WAIT blocks journaling until the    * Journal Spool reader finalizes merging of the spooled data and    * switches to applying journal to memory.</li>    *</ol>    * @param length length of data.    * @param data serialized journal records.    * @throws IOException    * @see #convergeJournalSpool()    */
DECL|method|journal (int length, byte[] data)
specifier|synchronized
name|void
name|journal
parameter_list|(
name|int
name|length
parameter_list|,
name|byte
index|[]
name|data
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|backupInputStream
operator|.
name|length
argument_list|()
operator|==
literal|0
operator|:
literal|"backup input stream is not empty"
assert|;
try|try
block|{
switch|switch
condition|(
name|jsState
condition|)
block|{
case|case
name|WAIT
case|:
case|case
name|OFF
case|:
comment|// wait until spooling is off
name|waitSpoolEnd
argument_list|()
expr_stmt|;
comment|// update NameSpace in memory
name|backupInputStream
operator|.
name|setBytes
argument_list|(
name|data
argument_list|)
expr_stmt|;
name|FSEditLogLoader
name|logLoader
init|=
operator|new
name|FSEditLogLoader
argument_list|(
name|namesystem
argument_list|)
decl_stmt|;
name|int
name|logVersion
init|=
name|storage
operator|.
name|getLayoutVersion
argument_list|()
decl_stmt|;
name|BufferedInputStream
name|bin
init|=
operator|new
name|BufferedInputStream
argument_list|(
name|backupInputStream
argument_list|)
decl_stmt|;
name|DataInputStream
name|in
init|=
operator|new
name|DataInputStream
argument_list|(
name|bin
argument_list|)
decl_stmt|;
name|Checksum
name|checksum
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|EDITS_CHESKUM
argument_list|,
name|logVersion
argument_list|)
condition|)
block|{
name|checksum
operator|=
name|FSEditLog
operator|.
name|getChecksum
argument_list|()
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
operator|new
name|CheckedInputStream
argument_list|(
name|bin
argument_list|,
name|checksum
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|logLoader
operator|.
name|loadEditRecords
argument_list|(
name|logVersion
argument_list|,
name|in
argument_list|,
name|checksum
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|getFSNamesystem
argument_list|()
operator|.
name|dir
operator|.
name|updateCountForINodeWithQuota
argument_list|()
expr_stmt|;
comment|// inefficient!
break|break;
case|case
name|INPROGRESS
case|:
break|break;
block|}
comment|// write to files
name|editLog
operator|.
name|logEdit
argument_list|(
name|length
argument_list|,
name|data
argument_list|)
expr_stmt|;
name|editLog
operator|.
name|logSync
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|backupInputStream
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
DECL|method|waitSpoolEnd ()
specifier|private
specifier|synchronized
name|void
name|waitSpoolEnd
parameter_list|()
block|{
while|while
condition|(
name|jsState
operator|==
name|JSpoolState
operator|.
name|WAIT
condition|)
block|{
try|try
block|{
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{}
block|}
comment|// now spooling should be off, verifying just in case
assert|assert
name|jsState
operator|==
name|JSpoolState
operator|.
name|OFF
operator|:
literal|"Unexpected JSpool state: "
operator|+
name|jsState
assert|;
block|}
comment|/**    * Start journal spool.    * Switch to writing into edits.new instead of edits.    *    * edits.new for spooling is in separate directory "spool" rather than in    * "current" because the two directories should be independent.    * While spooling a checkpoint can happen and current will first    * move to lastcheckpoint.tmp and then to previous.checkpoint    * spool/edits.new will remain in place during that.    */
DECL|method|startJournalSpool (NamenodeRegistration nnReg)
specifier|synchronized
name|void
name|startJournalSpool
parameter_list|(
name|NamenodeRegistration
name|nnReg
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|jsState
condition|)
block|{
case|case
name|OFF
case|:
break|break;
case|case
name|INPROGRESS
case|:
return|return;
case|case
name|WAIT
case|:
name|waitSpoolEnd
argument_list|()
expr_stmt|;
block|}
comment|// create journal spool directories
for|for
control|(
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|it
init|=
name|storage
operator|.
name|dirIterator
argument_list|(
name|NameNodeDirType
operator|.
name|EDITS
argument_list|)
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageDirectory
name|sd
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|File
name|jsDir
init|=
name|getJSpoolDir
argument_list|(
name|sd
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|jsDir
operator|.
name|exists
argument_list|()
operator|&&
operator|!
name|jsDir
operator|.
name|mkdirs
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mkdirs failed to create "
operator|+
name|jsDir
operator|.
name|getCanonicalPath
argument_list|()
argument_list|)
throw|;
block|}
comment|// create edit file if missing
name|File
name|eFile
init|=
name|storage
operator|.
name|getEditFile
argument_list|(
name|sd
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|eFile
operator|.
name|exists
argument_list|()
condition|)
block|{
name|editLog
operator|.
name|createEditLogFile
argument_list|(
name|eFile
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|editLog
operator|.
name|isOpen
argument_list|()
condition|)
name|editLog
operator|.
name|open
argument_list|()
expr_stmt|;
comment|// create streams pointing to the journal spool files
comment|// subsequent journal records will go directly to the spool
name|editLog
operator|.
name|divertFileStreams
argument_list|(
name|STORAGE_JSPOOL_DIR
operator|+
literal|"/"
operator|+
name|STORAGE_JSPOOL_FILE
argument_list|)
expr_stmt|;
name|setCheckpointState
argument_list|(
name|CheckpointStates
operator|.
name|ROLLED_EDITS
argument_list|)
expr_stmt|;
comment|// set up spooling
if|if
condition|(
name|backupInputStream
operator|==
literal|null
condition|)
name|backupInputStream
operator|=
operator|new
name|EditLogBackupInputStream
argument_list|(
name|nnReg
operator|.
name|getAddress
argument_list|()
argument_list|)
expr_stmt|;
name|jsState
operator|=
name|JSpoolState
operator|.
name|INPROGRESS
expr_stmt|;
block|}
DECL|method|setCheckpointTime (int length, byte[] data)
specifier|synchronized
name|void
name|setCheckpointTime
parameter_list|(
name|int
name|length
parameter_list|,
name|byte
index|[]
name|data
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|backupInputStream
operator|.
name|length
argument_list|()
operator|==
literal|0
operator|:
literal|"backup input stream is not empty"
assert|;
try|try
block|{
comment|// unpack new checkpoint time
name|backupInputStream
operator|.
name|setBytes
argument_list|(
name|data
argument_list|)
expr_stmt|;
name|DataInputStream
name|in
init|=
name|backupInputStream
operator|.
name|getDataInputStream
argument_list|()
decl_stmt|;
name|byte
name|op
init|=
name|in
operator|.
name|readByte
argument_list|()
decl_stmt|;
assert|assert
name|op
operator|==
name|NamenodeProtocol
operator|.
name|JA_CHECKPOINT_TIME
assert|;
name|LongWritable
name|lw
init|=
operator|new
name|LongWritable
argument_list|()
decl_stmt|;
name|lw
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|storage
operator|.
name|setCheckpointTimeInStorage
argument_list|(
name|lw
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backupInputStream
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Merge Journal Spool to memory.<p>    * Journal Spool reader reads journal records from edits.new.    * When it reaches the end of the file it sets {@link JSpoolState} to WAIT.    * This blocks journaling (see {@link #journal(int,byte[])}.    * The reader    *<ul>    *<li> reads remaining journal records if any,</li>    *<li> renames edits.new to edits,</li>    *<li> sets {@link JSpoolState} to OFF,</li>    *<li> and notifies the journaling thread.</li>    *</ul>    * Journaling resumes with applying new journal records to the memory state,    * and writing them into edits file(s).    */
DECL|method|convergeJournalSpool ()
name|void
name|convergeJournalSpool
parameter_list|()
throws|throws
name|IOException
block|{
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|itEdits
init|=
name|storage
operator|.
name|dirIterator
argument_list|(
name|NameNodeDirType
operator|.
name|EDITS
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|itEdits
operator|.
name|hasNext
argument_list|()
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not locate checkpoint directories"
argument_list|)
throw|;
name|StorageDirectory
name|sdEdits
init|=
name|itEdits
operator|.
name|next
argument_list|()
decl_stmt|;
name|int
name|numEdits
init|=
literal|0
decl_stmt|;
name|File
name|jSpoolFile
init|=
name|getJSpoolFile
argument_list|(
name|sdEdits
argument_list|)
decl_stmt|;
name|long
name|startTime
init|=
name|now
argument_list|()
decl_stmt|;
if|if
condition|(
name|jSpoolFile
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// load edits.new
name|EditLogFileInputStream
name|edits
init|=
operator|new
name|EditLogFileInputStream
argument_list|(
name|jSpoolFile
argument_list|)
decl_stmt|;
name|BufferedInputStream
name|bin
init|=
operator|new
name|BufferedInputStream
argument_list|(
name|edits
argument_list|)
decl_stmt|;
name|DataInputStream
name|in
init|=
operator|new
name|DataInputStream
argument_list|(
name|bin
argument_list|)
decl_stmt|;
name|FSEditLogLoader
name|logLoader
init|=
operator|new
name|FSEditLogLoader
argument_list|(
name|namesystem
argument_list|)
decl_stmt|;
name|int
name|logVersion
init|=
name|logLoader
operator|.
name|readLogVersion
argument_list|(
name|in
argument_list|)
decl_stmt|;
name|Checksum
name|checksum
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LayoutVersion
operator|.
name|supports
argument_list|(
name|Feature
operator|.
name|EDITS_CHESKUM
argument_list|,
name|logVersion
argument_list|)
condition|)
block|{
name|checksum
operator|=
name|FSEditLog
operator|.
name|getChecksum
argument_list|()
expr_stmt|;
name|in
operator|=
operator|new
name|DataInputStream
argument_list|(
operator|new
name|CheckedInputStream
argument_list|(
name|bin
argument_list|,
name|checksum
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|numEdits
operator|+=
name|logLoader
operator|.
name|loadEditRecords
argument_list|(
name|logVersion
argument_list|,
name|in
argument_list|,
name|checksum
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// first time reached the end of spool
name|jsState
operator|=
name|JSpoolState
operator|.
name|WAIT
expr_stmt|;
name|numEdits
operator|+=
name|logLoader
operator|.
name|loadEditRecords
argument_list|(
name|logVersion
argument_list|,
name|in
argument_list|,
name|checksum
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|getFSNamesystem
argument_list|()
operator|.
name|dir
operator|.
name|updateCountForINodeWithQuota
argument_list|()
expr_stmt|;
name|edits
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|FSImage
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Edits file "
operator|+
name|jSpoolFile
operator|.
name|getCanonicalPath
argument_list|()
operator|+
literal|" of size "
operator|+
name|jSpoolFile
operator|.
name|length
argument_list|()
operator|+
literal|" edits # "
operator|+
name|numEdits
operator|+
literal|" loaded in "
operator|+
operator|(
name|now
argument_list|()
operator|-
name|startTime
operator|)
operator|/
literal|1000
operator|+
literal|" seconds."
argument_list|)
expr_stmt|;
comment|// rename spool edits.new to edits making it in sync with the active node
comment|// subsequent journal records will go directly to edits
name|editLog
operator|.
name|revertFileStreams
argument_list|(
name|STORAGE_JSPOOL_DIR
operator|+
literal|"/"
operator|+
name|STORAGE_JSPOOL_FILE
argument_list|)
expr_stmt|;
comment|// write version file
name|resetVersion
argument_list|(
literal|false
argument_list|,
name|storage
operator|.
name|getImageDigest
argument_list|()
argument_list|)
expr_stmt|;
comment|// wake up journal writer
synchronized|synchronized
init|(
name|this
init|)
block|{
name|jsState
operator|=
name|JSpoolState
operator|.
name|OFF
expr_stmt|;
name|notifyAll
argument_list|()
expr_stmt|;
block|}
comment|// Rename lastcheckpoint.tmp to previous.checkpoint
for|for
control|(
name|Iterator
argument_list|<
name|StorageDirectory
argument_list|>
name|it
init|=
name|storage
operator|.
name|dirIterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|StorageDirectory
name|sd
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|storage
operator|.
name|moveLastCheckpoint
argument_list|(
name|sd
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

