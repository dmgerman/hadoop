begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.hdfs.server.namenode
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|namenode
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|junit
operator|.
name|framework
operator|.
name|TestCase
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|DF
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSConfigKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DFSUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|HdfsConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|blockmanagement
operator|.
name|DatanodeDescriptor
import|;
end_import

begin_comment
comment|/**  * This tests InterDataNodeProtocol for block handling.   */
end_comment

begin_class
DECL|class|TestNamenodeCapacityReport
specifier|public
class|class
name|TestNamenodeCapacityReport
extends|extends
name|TestCase
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|TestNamenodeCapacityReport
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**    * The following test first creates a file.    * It verifies the block information from a datanode.    * Then, it updates the block with new information and verifies again.     */
DECL|method|testVolumeSize ()
specifier|public
name|void
name|testVolumeSize
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
operator|new
name|HdfsConfiguration
argument_list|()
decl_stmt|;
name|MiniDFSCluster
name|cluster
init|=
literal|null
decl_stmt|;
comment|// Set aside fifth of the total capacity as reserved
name|long
name|reserved
init|=
literal|10000
decl_stmt|;
name|conf
operator|.
name|setLong
argument_list|(
name|DFSConfigKeys
operator|.
name|DFS_DATANODE_DU_RESERVED_KEY
argument_list|,
name|reserved
argument_list|)
expr_stmt|;
try|try
block|{
name|cluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|cluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
specifier|final
name|FSNamesystem
name|namesystem
init|=
name|cluster
operator|.
name|getNamesystem
argument_list|()
decl_stmt|;
comment|// Ensure the data reported for each data node is right
name|ArrayList
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|live
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeDescriptor
argument_list|>
argument_list|()
decl_stmt|;
name|ArrayList
argument_list|<
name|DatanodeDescriptor
argument_list|>
name|dead
init|=
operator|new
name|ArrayList
argument_list|<
name|DatanodeDescriptor
argument_list|>
argument_list|()
decl_stmt|;
name|namesystem
operator|.
name|DFSNodesStatus
argument_list|(
name|live
argument_list|,
name|dead
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|live
operator|.
name|size
argument_list|()
operator|==
literal|1
argument_list|)
expr_stmt|;
name|long
name|used
decl_stmt|,
name|remaining
decl_stmt|,
name|configCapacity
decl_stmt|,
name|nonDFSUsed
decl_stmt|,
name|bpUsed
decl_stmt|;
name|float
name|percentUsed
decl_stmt|,
name|percentRemaining
decl_stmt|,
name|percentBpUsed
decl_stmt|;
for|for
control|(
specifier|final
name|DatanodeDescriptor
name|datanode
range|:
name|live
control|)
block|{
name|used
operator|=
name|datanode
operator|.
name|getDfsUsed
argument_list|()
expr_stmt|;
name|remaining
operator|=
name|datanode
operator|.
name|getRemaining
argument_list|()
expr_stmt|;
name|nonDFSUsed
operator|=
name|datanode
operator|.
name|getNonDfsUsed
argument_list|()
expr_stmt|;
name|configCapacity
operator|=
name|datanode
operator|.
name|getCapacity
argument_list|()
expr_stmt|;
name|percentUsed
operator|=
name|datanode
operator|.
name|getDfsUsedPercent
argument_list|()
expr_stmt|;
name|percentRemaining
operator|=
name|datanode
operator|.
name|getRemainingPercent
argument_list|()
expr_stmt|;
name|bpUsed
operator|=
name|datanode
operator|.
name|getBlockPoolUsed
argument_list|()
expr_stmt|;
name|percentBpUsed
operator|=
name|datanode
operator|.
name|getBlockPoolUsedPercent
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Datanode configCapacity "
operator|+
name|configCapacity
operator|+
literal|" used "
operator|+
name|used
operator|+
literal|" non DFS used "
operator|+
name|nonDFSUsed
operator|+
literal|" remaining "
operator|+
name|remaining
operator|+
literal|" perentUsed "
operator|+
name|percentUsed
operator|+
literal|" percentRemaining "
operator|+
name|percentRemaining
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|configCapacity
operator|==
operator|(
name|used
operator|+
name|remaining
operator|+
name|nonDFSUsed
operator|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|percentUsed
operator|==
name|DFSUtil
operator|.
name|getPercentUsed
argument_list|(
name|used
argument_list|,
name|configCapacity
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|percentRemaining
operator|==
name|DFSUtil
operator|.
name|getPercentRemaining
argument_list|(
name|remaining
argument_list|,
name|configCapacity
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|percentBpUsed
operator|==
name|DFSUtil
operator|.
name|getPercentUsed
argument_list|(
name|bpUsed
argument_list|,
name|configCapacity
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|DF
name|df
init|=
operator|new
name|DF
argument_list|(
operator|new
name|File
argument_list|(
name|cluster
operator|.
name|getDataDirectory
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|)
decl_stmt|;
comment|//
comment|// Currently two data directories are created by the data node
comment|// in the MiniDFSCluster. This results in each data directory having
comment|// capacity equals to the disk capacity of the data directory.
comment|// Hence the capacity reported by the data node is twice the disk space
comment|// the disk capacity
comment|//
comment|// So multiply the disk capacity and reserved space by two
comment|// for accommodating it
comment|//
name|int
name|numOfDataDirs
init|=
literal|2
decl_stmt|;
name|long
name|diskCapacity
init|=
name|numOfDataDirs
operator|*
name|df
operator|.
name|getCapacity
argument_list|()
decl_stmt|;
name|reserved
operator|*=
name|numOfDataDirs
expr_stmt|;
name|configCapacity
operator|=
name|namesystem
operator|.
name|getCapacityTotal
argument_list|()
expr_stmt|;
name|used
operator|=
name|namesystem
operator|.
name|getCapacityUsed
argument_list|()
expr_stmt|;
name|nonDFSUsed
operator|=
name|namesystem
operator|.
name|getNonDfsUsedSpace
argument_list|()
expr_stmt|;
name|remaining
operator|=
name|namesystem
operator|.
name|getCapacityRemaining
argument_list|()
expr_stmt|;
name|percentUsed
operator|=
name|namesystem
operator|.
name|getPercentUsed
argument_list|()
expr_stmt|;
name|percentRemaining
operator|=
name|namesystem
operator|.
name|getPercentRemaining
argument_list|()
expr_stmt|;
name|bpUsed
operator|=
name|namesystem
operator|.
name|getBlockPoolUsedSpace
argument_list|()
expr_stmt|;
name|percentBpUsed
operator|=
name|namesystem
operator|.
name|getPercentBlockPoolUsed
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Data node directory "
operator|+
name|cluster
operator|.
name|getDataDirectory
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Name node diskCapacity "
operator|+
name|diskCapacity
operator|+
literal|" configCapacity "
operator|+
name|configCapacity
operator|+
literal|" reserved "
operator|+
name|reserved
operator|+
literal|" used "
operator|+
name|used
operator|+
literal|" remaining "
operator|+
name|remaining
operator|+
literal|" nonDFSUsed "
operator|+
name|nonDFSUsed
operator|+
literal|" remaining "
operator|+
name|remaining
operator|+
literal|" percentUsed "
operator|+
name|percentUsed
operator|+
literal|" percentRemaining "
operator|+
name|percentRemaining
operator|+
literal|" bpUsed "
operator|+
name|bpUsed
operator|+
literal|" percentBpUsed "
operator|+
name|percentBpUsed
argument_list|)
expr_stmt|;
comment|// Ensure new total capacity reported excludes the reserved space
name|assertTrue
argument_list|(
name|configCapacity
operator|==
name|diskCapacity
operator|-
name|reserved
argument_list|)
expr_stmt|;
comment|// Ensure new total capacity reported excludes the reserved space
name|assertTrue
argument_list|(
name|configCapacity
operator|==
operator|(
name|used
operator|+
name|remaining
operator|+
name|nonDFSUsed
operator|)
argument_list|)
expr_stmt|;
comment|// Ensure percent used is calculated based on used and present capacity
name|assertTrue
argument_list|(
name|percentUsed
operator|==
name|DFSUtil
operator|.
name|getPercentUsed
argument_list|(
name|used
argument_list|,
name|configCapacity
argument_list|)
argument_list|)
expr_stmt|;
comment|// Ensure percent used is calculated based on used and present capacity
name|assertTrue
argument_list|(
name|percentBpUsed
operator|==
name|DFSUtil
operator|.
name|getPercentUsed
argument_list|(
name|bpUsed
argument_list|,
name|configCapacity
argument_list|)
argument_list|)
expr_stmt|;
comment|// Ensure percent used is calculated based on used and present capacity
name|assertTrue
argument_list|(
name|percentRemaining
operator|==
operator|(
operator|(
name|float
operator|)
name|remaining
operator|*
literal|100.0f
operator|)
operator|/
operator|(
name|float
operator|)
name|configCapacity
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

