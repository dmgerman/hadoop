begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.metrics2.sink
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|sink
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Calendar
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TimeZone
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Timer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TimerTask
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadLocalRandom
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|configuration2
operator|.
name|SubsetConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|time
operator|.
name|FastDateFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|RemoteIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|AbstractMetric
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsSink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsTag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|SecurityUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_comment
comment|/**  *<p>This class is a metrics sink that uses  * {@link org.apache.hadoop.fs.FileSystem} to write the metrics logs.  Every  * roll interval a new directory will be created under the path specified by the  *<code>basepath</code> property. All metrics will be logged to a file in the  * current interval's directory in a file named&lt;hostname&gt;.log, where  *&lt;hostname&gt; is the name of the host on which the metrics logging  * process is running. The base path is set by the  *<code>&lt;prefix&gt;.sink.&lt;instance&gt;.basepath</code> property.  The  * time zone used to create the current interval's directory name is GMT.  If  * the<code>basepath</code> property isn't specified, it will default to  *&quot;/tmp&quot;, which is the temp directory on whatever default file  * system is configured for the cluster.</p>  *  *<p>The<code>&lt;prefix&gt;.sink.&lt;instance&gt;.ignore-error</code>  * property controls whether an exception is thrown when an error is encountered  * writing a log file.  The default value is<code>true</code>.  When set to  *<code>false</code>, file errors are quietly swallowed.</p>  *  *<p>The<code>roll-interval</code> property sets the amount of time before  * rolling the directory. The default value is 1 hour. The roll interval may  * not be less than 1 minute. The property's value should be given as  *<i>number unit</i>, where<i>number</i> is an integer value, and  *<i>unit</i> is a valid unit.  Valid units are<i>minute</i>,<i>hour</i>,  * and<i>day</i>.  The units are case insensitive and may be abbreviated or  * plural. If no units are specified, hours are assumed. For example,  *&quot;2&quot;,&quot;2h&quot;,&quot;2 hour&quot;, and  *&quot;2 hours&quot; are all valid ways to specify two hours.</p>  *  *<p>The<code>roll-offset-interval-millis</code> property sets the upper  * bound on a random time interval (in milliseconds) that is used to delay  * before the initial roll.  All subsequent rolls will happen an integer  * number of roll intervals after the initial roll, hence retaining the original  * offset. The purpose of this property is to insert some variance in the roll  * times so that large clusters using this sink on every node don't cause a  * performance impact on HDFS by rolling simultaneously.  The default value is  * 30000 (30s).  When writing to HDFS, as a rule of thumb, the roll offset in  * millis should be no less than the number of sink instances times 5.  *  *<p>The primary use of this class is for logging to HDFS.  As it uses  * {@link org.apache.hadoop.fs.FileSystem} to access the target file system,  * however, it can be used to write to the local file system, Amazon S3, or any  * other supported file system.  The base path for the sink will determine the  * file system used.  An unqualified path will write to the default file system  * set by the configuration.</p>  *  *<p>Not all file systems support the ability to append to files.  In file  * systems without the ability to append to files, only one writer can write to  * a file at a time.  To allow for concurrent writes from multiple daemons on a  * single host, the<code>source</code> property is used to set unique headers  * for the log files.  The property should be set to the name of  * the source daemon, e.g.<i>namenode</i>.  The value of the  *<code>source</code> property should typically be the same as the property's  * prefix.  If this property is not set, the source is taken to be  *<i>unknown</i>.</p>  *  *<p>Instead of appending to an existing file, by default the sink  * will create a new file with a suffix of&quot;.&lt;n&gt;&quot;, where  *<i>n</i> is the next lowest integer that isn't already used in a file name,  * similar to the Hadoop daemon logs.  NOTE: the file with the<b>highest</b>  * sequence number is the<b>newest</b> file, unlike the Hadoop daemon logs.</p>  *  *<p>For file systems that allow append, the sink supports appending to the  * existing file instead. If the<code>allow-append</code> property is set to  * true, the sink will instead append to the existing file on file systems that  * support appends. By default, the<code>allow-append</code> property is  * false.</p>  *  *<p>Note that when writing to HDFS with<code>allow-append</code> set to true,  * there is a minimum acceptable number of data nodes.  If the number of data  * nodes drops below that minimum, the append will succeed, but reading the  * data will fail with an IOException in the DataStreamer class.  The minimum  * number of data nodes required for a successful append is generally 2 or  * 3.</p>  *  *<p>Note also that when writing to HDFS, the file size information is not  * updated until the file is closed (at the end of the interval) even though  * the data is being written successfully. This is a known HDFS limitation that  * exists because of the performance cost of updating the metadata.  See  *<a href="https://issues.apache.org/jira/browse/HDFS-5478">HDFS-5478</a>.</p>  *  *<p>When using this sink in a secure (Kerberos) environment, two additional  * properties must be set:<code>keytab-key</code> and  *<code>principal-key</code>.<code>keytab-key</code> should contain the key by  * which the keytab file can be found in the configuration, for example,  *<code>yarn.nodemanager.keytab</code>.<code>principal-key</code> should  * contain the key by which the principal can be found in the configuration,  * for example,<code>yarn.nodemanager.principal</code>.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|RollingFileSystemSink
specifier|public
class|class
name|RollingFileSystemSink
implements|implements
name|MetricsSink
implements|,
name|Closeable
block|{
DECL|field|BASEPATH_KEY
specifier|private
specifier|static
specifier|final
name|String
name|BASEPATH_KEY
init|=
literal|"basepath"
decl_stmt|;
DECL|field|SOURCE_KEY
specifier|private
specifier|static
specifier|final
name|String
name|SOURCE_KEY
init|=
literal|"source"
decl_stmt|;
DECL|field|IGNORE_ERROR_KEY
specifier|private
specifier|static
specifier|final
name|String
name|IGNORE_ERROR_KEY
init|=
literal|"ignore-error"
decl_stmt|;
DECL|field|DEFAULT_IGNORE_ERROR
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_IGNORE_ERROR
init|=
literal|false
decl_stmt|;
DECL|field|ALLOW_APPEND_KEY
specifier|private
specifier|static
specifier|final
name|String
name|ALLOW_APPEND_KEY
init|=
literal|"allow-append"
decl_stmt|;
DECL|field|DEFAULT_ALLOW_APPEND
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_ALLOW_APPEND
init|=
literal|false
decl_stmt|;
DECL|field|KEYTAB_PROPERTY_KEY
specifier|private
specifier|static
specifier|final
name|String
name|KEYTAB_PROPERTY_KEY
init|=
literal|"keytab-key"
decl_stmt|;
DECL|field|USERNAME_PROPERTY_KEY
specifier|private
specifier|static
specifier|final
name|String
name|USERNAME_PROPERTY_KEY
init|=
literal|"principal-key"
decl_stmt|;
DECL|field|ROLL_INTERVAL_KEY
specifier|private
specifier|static
specifier|final
name|String
name|ROLL_INTERVAL_KEY
init|=
literal|"roll-interval"
decl_stmt|;
DECL|field|DEFAULT_ROLL_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULT_ROLL_INTERVAL
init|=
literal|"1h"
decl_stmt|;
DECL|field|ROLL_OFFSET_INTERVAL_MILLIS_KEY
specifier|private
specifier|static
specifier|final
name|String
name|ROLL_OFFSET_INTERVAL_MILLIS_KEY
init|=
literal|"roll-offset-interval-millis"
decl_stmt|;
DECL|field|DEFAULT_ROLL_OFFSET_INTERVAL_MILLIS
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_ROLL_OFFSET_INTERVAL_MILLIS
init|=
literal|30000
decl_stmt|;
DECL|field|SOURCE_DEFAULT
specifier|private
specifier|static
specifier|final
name|String
name|SOURCE_DEFAULT
init|=
literal|"unknown"
decl_stmt|;
DECL|field|BASEPATH_DEFAULT
specifier|private
specifier|static
specifier|final
name|String
name|BASEPATH_DEFAULT
init|=
literal|"/tmp"
decl_stmt|;
DECL|field|DATE_FORMAT
specifier|private
specifier|static
specifier|final
name|FastDateFormat
name|DATE_FORMAT
init|=
name|FastDateFormat
operator|.
name|getInstance
argument_list|(
literal|"yyyyMMddHHmm"
argument_list|,
name|TimeZone
operator|.
name|getTimeZone
argument_list|(
literal|"GMT"
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|lock
specifier|private
specifier|final
name|Object
name|lock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
DECL|field|initialized
specifier|private
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
DECL|field|properties
specifier|private
name|SubsetConfiguration
name|properties
decl_stmt|;
DECL|field|conf
specifier|private
name|Configuration
name|conf
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|source
specifier|protected
name|String
name|source
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|ignoreError
specifier|protected
name|boolean
name|ignoreError
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|allowAppend
specifier|protected
name|boolean
name|allowAppend
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|basePath
specifier|protected
name|Path
name|basePath
decl_stmt|;
DECL|field|fileSystem
specifier|private
name|FileSystem
name|fileSystem
decl_stmt|;
comment|// The current directory path into which we're writing files
DECL|field|currentDirPath
specifier|private
name|Path
name|currentDirPath
decl_stmt|;
comment|// The path to the current file into which we're writing data
DECL|field|currentFilePath
specifier|private
name|Path
name|currentFilePath
decl_stmt|;
comment|// The stream to which we're currently writing.
DECL|field|currentOutStream
specifier|private
name|PrintStream
name|currentOutStream
decl_stmt|;
comment|// We keep this only to be able to call hsynch() on it.
DECL|field|currentFSOutStream
specifier|private
name|FSDataOutputStream
name|currentFSOutStream
decl_stmt|;
DECL|field|flushTimer
specifier|private
name|Timer
name|flushTimer
decl_stmt|;
comment|// The amount of time between rolls
annotation|@
name|VisibleForTesting
DECL|field|rollIntervalMillis
specifier|protected
name|long
name|rollIntervalMillis
decl_stmt|;
comment|// The maximum amount of random time to add to the initial roll
annotation|@
name|VisibleForTesting
DECL|field|rollOffsetIntervalMillis
specifier|protected
name|long
name|rollOffsetIntervalMillis
decl_stmt|;
comment|// The time for the nextFlush
annotation|@
name|VisibleForTesting
DECL|field|nextFlush
specifier|protected
name|Calendar
name|nextFlush
init|=
literal|null
decl_stmt|;
comment|// This flag when true causes a metrics write to schedule a flush thread to
comment|// run immediately, but only if a flush thread is already scheduled. (It's a
comment|// timing thing.  If the first write forces the flush, it will strand the
comment|// second write.)
annotation|@
name|VisibleForTesting
DECL|field|forceFlush
specifier|protected
specifier|static
name|boolean
name|forceFlush
init|=
literal|false
decl_stmt|;
comment|// This flag is used by the flusher thread to indicate that it has run. Used
comment|// only for testing purposes.
annotation|@
name|VisibleForTesting
DECL|field|hasFlushed
specifier|protected
specifier|static
specifier|volatile
name|boolean
name|hasFlushed
init|=
literal|false
decl_stmt|;
comment|// Use this configuration instead of loading a new one.
annotation|@
name|VisibleForTesting
DECL|field|suppliedConf
specifier|protected
specifier|static
name|Configuration
name|suppliedConf
init|=
literal|null
decl_stmt|;
comment|// Use this file system instead of getting a new one.
annotation|@
name|VisibleForTesting
DECL|field|suppliedFilesystem
specifier|protected
specifier|static
name|FileSystem
name|suppliedFilesystem
init|=
literal|null
decl_stmt|;
comment|/**    * Create an empty instance.  Required for reflection.    */
DECL|method|RollingFileSystemSink ()
specifier|public
name|RollingFileSystemSink
parameter_list|()
block|{   }
comment|/**    * Create an instance for testing.    *    * @param flushIntervalMillis the roll interval in millis    * @param flushOffsetIntervalMillis the roll offset interval in millis    */
annotation|@
name|VisibleForTesting
DECL|method|RollingFileSystemSink (long flushIntervalMillis, long flushOffsetIntervalMillis)
specifier|protected
name|RollingFileSystemSink
parameter_list|(
name|long
name|flushIntervalMillis
parameter_list|,
name|long
name|flushOffsetIntervalMillis
parameter_list|)
block|{
name|this
operator|.
name|rollIntervalMillis
operator|=
name|flushIntervalMillis
expr_stmt|;
name|this
operator|.
name|rollOffsetIntervalMillis
operator|=
name|flushOffsetIntervalMillis
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|init (SubsetConfiguration metrics2Properties)
specifier|public
name|void
name|init
parameter_list|(
name|SubsetConfiguration
name|metrics2Properties
parameter_list|)
block|{
name|properties
operator|=
name|metrics2Properties
expr_stmt|;
name|basePath
operator|=
operator|new
name|Path
argument_list|(
name|properties
operator|.
name|getString
argument_list|(
name|BASEPATH_KEY
argument_list|,
name|BASEPATH_DEFAULT
argument_list|)
argument_list|)
expr_stmt|;
name|source
operator|=
name|properties
operator|.
name|getString
argument_list|(
name|SOURCE_KEY
argument_list|,
name|SOURCE_DEFAULT
argument_list|)
expr_stmt|;
name|ignoreError
operator|=
name|properties
operator|.
name|getBoolean
argument_list|(
name|IGNORE_ERROR_KEY
argument_list|,
name|DEFAULT_IGNORE_ERROR
argument_list|)
expr_stmt|;
name|allowAppend
operator|=
name|properties
operator|.
name|getBoolean
argument_list|(
name|ALLOW_APPEND_KEY
argument_list|,
name|DEFAULT_ALLOW_APPEND
argument_list|)
expr_stmt|;
name|rollOffsetIntervalMillis
operator|=
name|getNonNegative
argument_list|(
name|ROLL_OFFSET_INTERVAL_MILLIS_KEY
argument_list|,
name|DEFAULT_ROLL_OFFSET_INTERVAL_MILLIS
argument_list|)
expr_stmt|;
name|rollIntervalMillis
operator|=
name|getRollInterval
argument_list|()
expr_stmt|;
name|conf
operator|=
name|loadConf
argument_list|()
expr_stmt|;
name|UserGroupInformation
operator|.
name|setConfiguration
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Don't do secure setup if it's not needed.
if|if
condition|(
name|UserGroupInformation
operator|.
name|isSecurityEnabled
argument_list|()
condition|)
block|{
comment|// Validate config so that we don't get an NPE
name|checkIfPropertyExists
argument_list|(
name|KEYTAB_PROPERTY_KEY
argument_list|)
expr_stmt|;
name|checkIfPropertyExists
argument_list|(
name|USERNAME_PROPERTY_KEY
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Login as whoever we're supposed to be and let the hostname be pulled
comment|// from localhost. If security isn't enabled, this does nothing.
name|SecurityUtil
operator|.
name|login
argument_list|(
name|conf
argument_list|,
name|properties
operator|.
name|getString
argument_list|(
name|KEYTAB_PROPERTY_KEY
argument_list|)
argument_list|,
name|properties
operator|.
name|getString
argument_list|(
name|USERNAME_PROPERTY_KEY
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error logging in securely: ["
operator|+
name|ex
operator|.
name|toString
argument_list|()
operator|+
literal|"]"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Initialize the connection to HDFS and create the base directory. Also    * launch the flush thread.    */
DECL|method|initFs ()
specifier|private
name|boolean
name|initFs
parameter_list|()
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|fileSystem
operator|=
name|getFileSystem
argument_list|()
expr_stmt|;
comment|// This step isn't strictly necessary, but it makes debugging issues much
comment|// easier. We try to create the base directory eagerly and fail with
comment|// copious debug info if it fails.
try|try
block|{
name|fileSystem
operator|.
name|mkdirs
argument_list|(
name|basePath
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Failed to create "
operator|+
name|basePath
operator|+
literal|"["
operator|+
name|SOURCE_KEY
operator|+
literal|"="
operator|+
name|source
operator|+
literal|", "
operator|+
name|ALLOW_APPEND_KEY
operator|+
literal|"="
operator|+
name|allowAppend
operator|+
literal|", "
operator|+
name|stringifySecurityProperty
argument_list|(
name|KEYTAB_PROPERTY_KEY
argument_list|)
operator|+
literal|", "
operator|+
name|stringifySecurityProperty
argument_list|(
name|USERNAME_PROPERTY_KEY
argument_list|)
operator|+
literal|"] -- "
operator|+
name|ex
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|success
condition|)
block|{
comment|// If we're permitted to append, check if we actually can
if|if
condition|(
name|allowAppend
condition|)
block|{
name|allowAppend
operator|=
name|checkAppend
argument_list|(
name|fileSystem
argument_list|)
expr_stmt|;
block|}
name|flushTimer
operator|=
operator|new
name|Timer
argument_list|(
literal|"RollingFileSystemSink Flusher"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|setInitialFlushTime
argument_list|(
operator|new
name|Date
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|success
return|;
block|}
comment|/**    * Turn a security property into a nicely formatted set of<i>name=value</i>    * strings, allowing for either the property or the configuration not to be    * set.    *    * @param property the property to stringify    * @return the stringified property    */
DECL|method|stringifySecurityProperty (String property)
specifier|private
name|String
name|stringifySecurityProperty
parameter_list|(
name|String
name|property
parameter_list|)
block|{
name|String
name|securityProperty
decl_stmt|;
if|if
condition|(
name|properties
operator|.
name|containsKey
argument_list|(
name|property
argument_list|)
condition|)
block|{
name|String
name|propertyValue
init|=
name|properties
operator|.
name|getString
argument_list|(
name|property
argument_list|)
decl_stmt|;
name|String
name|confValue
init|=
name|conf
operator|.
name|get
argument_list|(
name|properties
operator|.
name|getString
argument_list|(
name|property
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|confValue
operator|!=
literal|null
condition|)
block|{
name|securityProperty
operator|=
name|property
operator|+
literal|"="
operator|+
name|propertyValue
operator|+
literal|", "
operator|+
name|properties
operator|.
name|getString
argument_list|(
name|property
argument_list|)
operator|+
literal|"="
operator|+
name|confValue
expr_stmt|;
block|}
else|else
block|{
name|securityProperty
operator|=
name|property
operator|+
literal|"="
operator|+
name|propertyValue
operator|+
literal|", "
operator|+
name|properties
operator|.
name|getString
argument_list|(
name|property
argument_list|)
operator|+
literal|"=<NOT SET>"
expr_stmt|;
block|}
block|}
else|else
block|{
name|securityProperty
operator|=
name|property
operator|+
literal|"=<NOT SET>"
expr_stmt|;
block|}
return|return
name|securityProperty
return|;
block|}
comment|/**    * Extract the roll interval from the configuration and return it in    * milliseconds.    *    * @return the roll interval in millis    */
annotation|@
name|VisibleForTesting
DECL|method|getRollInterval ()
specifier|protected
name|long
name|getRollInterval
parameter_list|()
block|{
name|String
name|rollInterval
init|=
name|properties
operator|.
name|getString
argument_list|(
name|ROLL_INTERVAL_KEY
argument_list|,
name|DEFAULT_ROLL_INTERVAL
argument_list|)
decl_stmt|;
name|Pattern
name|pattern
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^\\s*(\\d+)\\s*([A-Za-z]*)\\s*$"
argument_list|)
decl_stmt|;
name|Matcher
name|match
init|=
name|pattern
operator|.
name|matcher
argument_list|(
name|rollInterval
argument_list|)
decl_stmt|;
name|long
name|millis
decl_stmt|;
if|if
condition|(
name|match
operator|.
name|matches
argument_list|()
condition|)
block|{
name|String
name|flushUnit
init|=
name|match
operator|.
name|group
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|int
name|rollIntervalInt
decl_stmt|;
try|try
block|{
name|rollIntervalInt
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|match
operator|.
name|group
argument_list|(
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Unrecognized flush interval: "
operator|+
name|rollInterval
operator|+
literal|". Must be a number followed by an optional "
operator|+
literal|"unit. The unit must be one of: minute, hour, day"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
if|if
condition|(
literal|""
operator|.
name|equals
argument_list|(
name|flushUnit
argument_list|)
condition|)
block|{
name|millis
operator|=
name|TimeUnit
operator|.
name|HOURS
operator|.
name|toMillis
argument_list|(
name|rollIntervalInt
argument_list|)
expr_stmt|;
block|}
else|else
block|{
switch|switch
condition|(
name|flushUnit
operator|.
name|toLowerCase
argument_list|()
condition|)
block|{
case|case
literal|"m"
case|:
case|case
literal|"min"
case|:
case|case
literal|"minute"
case|:
case|case
literal|"minutes"
case|:
name|millis
operator|=
name|TimeUnit
operator|.
name|MINUTES
operator|.
name|toMillis
argument_list|(
name|rollIntervalInt
argument_list|)
expr_stmt|;
break|break;
case|case
literal|"h"
case|:
case|case
literal|"hr"
case|:
case|case
literal|"hour"
case|:
case|case
literal|"hours"
case|:
name|millis
operator|=
name|TimeUnit
operator|.
name|HOURS
operator|.
name|toMillis
argument_list|(
name|rollIntervalInt
argument_list|)
expr_stmt|;
break|break;
case|case
literal|"d"
case|:
case|case
literal|"day"
case|:
case|case
literal|"days"
case|:
name|millis
operator|=
name|TimeUnit
operator|.
name|DAYS
operator|.
name|toMillis
argument_list|(
name|rollIntervalInt
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Unrecognized unit for flush interval: "
operator|+
name|flushUnit
operator|+
literal|". Must be one of: minute, hour, day"
argument_list|)
throw|;
block|}
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Unrecognized flush interval: "
operator|+
name|rollInterval
operator|+
literal|". Must be a number followed by an optional unit."
operator|+
literal|" The unit must be one of: minute, hour, day"
argument_list|)
throw|;
block|}
if|if
condition|(
name|millis
operator|<
literal|60000
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"The flush interval property must be "
operator|+
literal|"at least 1 minute. Value was "
operator|+
name|rollInterval
argument_list|)
throw|;
block|}
return|return
name|millis
return|;
block|}
comment|/**    * Return the property value if it's non-negative and throw an exception if    * it's not.    *    * @param key the property key    * @param defaultValue the default value    */
DECL|method|getNonNegative (String key, int defaultValue)
specifier|private
name|long
name|getNonNegative
parameter_list|(
name|String
name|key
parameter_list|,
name|int
name|defaultValue
parameter_list|)
block|{
name|int
name|flushOffsetIntervalMillis
init|=
name|properties
operator|.
name|getInt
argument_list|(
name|key
argument_list|,
name|defaultValue
argument_list|)
decl_stmt|;
if|if
condition|(
name|flushOffsetIntervalMillis
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"The "
operator|+
name|key
operator|+
literal|" property must be "
operator|+
literal|"non-negative. Value was "
operator|+
name|flushOffsetIntervalMillis
argument_list|)
throw|;
block|}
return|return
name|flushOffsetIntervalMillis
return|;
block|}
comment|/**    * Throw a {@link MetricsException} if the given property is not set.    *    * @param key the key to validate    */
DECL|method|checkIfPropertyExists (String key)
specifier|private
name|void
name|checkIfPropertyExists
parameter_list|(
name|String
name|key
parameter_list|)
block|{
if|if
condition|(
operator|!
name|properties
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Metrics2 configuration is missing "
operator|+
name|key
operator|+
literal|" property"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Return the supplied configuration for testing or otherwise load a new    * configuration.    *    * @return the configuration to use    */
DECL|method|loadConf ()
specifier|private
name|Configuration
name|loadConf
parameter_list|()
block|{
name|Configuration
name|c
decl_stmt|;
if|if
condition|(
name|suppliedConf
operator|!=
literal|null
condition|)
block|{
name|c
operator|=
name|suppliedConf
expr_stmt|;
block|}
else|else
block|{
comment|// The config we're handed in init() isn't the one we want here, so we
comment|// create a new one to pick up the full settings.
name|c
operator|=
operator|new
name|Configuration
argument_list|()
expr_stmt|;
block|}
return|return
name|c
return|;
block|}
comment|/**    * Return the supplied file system for testing or otherwise get a new file    * system.    *    * @return the file system to use    * @throws MetricsException thrown if the file system could not be retrieved    */
DECL|method|getFileSystem ()
specifier|private
name|FileSystem
name|getFileSystem
parameter_list|()
throws|throws
name|MetricsException
block|{
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|suppliedFilesystem
operator|!=
literal|null
condition|)
block|{
name|fs
operator|=
name|suppliedFilesystem
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
operator|new
name|URI
argument_list|(
name|basePath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"The supplied filesystem base path URI"
operator|+
literal|" is not a valid URI: "
operator|+
name|basePath
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error connecting to file system: "
operator|+
name|basePath
operator|+
literal|" ["
operator|+
name|ex
operator|.
name|toString
argument_list|()
operator|+
literal|"]"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
return|return
name|fs
return|;
block|}
comment|/**    * Test whether the file system supports append and return the answer.    *    * @param fs the target file system    */
DECL|method|checkAppend (FileSystem fs)
specifier|private
name|boolean
name|checkAppend
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|boolean
name|canAppend
init|=
literal|true
decl_stmt|;
try|try
block|{
name|fs
operator|.
name|append
argument_list|(
name|basePath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnsupportedOperationException
name|ex
parameter_list|)
block|{
name|canAppend
operator|=
literal|false
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Ignore. The operation is supported.
block|}
return|return
name|canAppend
return|;
block|}
comment|/**    * Check the current directory against the time stamp.  If they're not    * the same, create a new directory and a new log file in that directory.    *    * @throws MetricsException thrown if an error occurs while creating the    * new directory or new log file    */
DECL|method|rollLogDirIfNeeded ()
specifier|private
name|void
name|rollLogDirIfNeeded
parameter_list|()
throws|throws
name|MetricsException
block|{
comment|// Because we're working relative to the clock, we use a Date instead
comment|// of Time.monotonicNow().
name|Date
name|now
init|=
operator|new
name|Date
argument_list|()
decl_stmt|;
comment|// We check whether currentOutStream is null instead of currentDirPath,
comment|// because if currentDirPath is null, then currentOutStream is null, but
comment|// currentOutStream can be null for other reasons.  Same for nextFlush.
if|if
condition|(
operator|(
name|currentOutStream
operator|==
literal|null
operator|)
operator|||
name|now
operator|.
name|after
argument_list|(
name|nextFlush
operator|.
name|getTime
argument_list|()
argument_list|)
condition|)
block|{
comment|// If we're not yet connected to HDFS, create the connection
if|if
condition|(
operator|!
name|initialized
condition|)
block|{
name|initialized
operator|=
name|initFs
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|initialized
condition|)
block|{
comment|// Close the stream. This step could have been handled already by the
comment|// flusher thread, but if it has, the PrintStream will just swallow the
comment|// exception, which is fine.
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|currentDirPath
operator|=
name|findCurrentDirectory
argument_list|(
name|now
argument_list|)
expr_stmt|;
try|try
block|{
name|rollLogDir
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Failed to create new log file"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
comment|// Update the time of the next flush
name|updateFlushTime
argument_list|(
name|now
argument_list|)
expr_stmt|;
comment|// Schedule the next flush at that time
name|scheduleFlush
argument_list|(
name|nextFlush
operator|.
name|getTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|forceFlush
condition|)
block|{
name|scheduleFlush
argument_list|(
operator|new
name|Date
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Use the given time to determine the current directory. The current    * directory will be based on the {@link #rollIntervalMinutes}.    *    * @param now the current time    * @return the current directory    */
DECL|method|findCurrentDirectory (Date now)
specifier|private
name|Path
name|findCurrentDirectory
parameter_list|(
name|Date
name|now
parameter_list|)
block|{
name|long
name|offset
init|=
operator|(
operator|(
name|now
operator|.
name|getTime
argument_list|()
operator|-
name|nextFlush
operator|.
name|getTimeInMillis
argument_list|()
operator|)
operator|/
name|rollIntervalMillis
operator|)
operator|*
name|rollIntervalMillis
decl_stmt|;
name|String
name|currentDir
init|=
name|DATE_FORMAT
operator|.
name|format
argument_list|(
operator|new
name|Date
argument_list|(
name|nextFlush
operator|.
name|getTimeInMillis
argument_list|()
operator|+
name|offset
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|basePath
argument_list|,
name|currentDir
argument_list|)
return|;
block|}
comment|/**    * Schedule the current interval's directory to be flushed. If this ends up    * running after the top of the next interval, it will execute immediately.    *    * @param when the time the thread should run    */
DECL|method|scheduleFlush (Date when)
specifier|private
name|void
name|scheduleFlush
parameter_list|(
name|Date
name|when
parameter_list|)
block|{
comment|// Store the current currentDirPath to close later
specifier|final
name|PrintStream
name|toClose
init|=
name|currentOutStream
decl_stmt|;
name|flushTimer
operator|.
name|schedule
argument_list|(
operator|new
name|TimerTask
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
synchronized|synchronized
init|(
name|lock
init|)
block|{
comment|// This close may have already been done by a putMetrics() call. If it
comment|// has, the PrintStream will swallow the exception, which is fine.
name|toClose
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|hasFlushed
operator|=
literal|true
expr_stmt|;
block|}
block|}
argument_list|,
name|when
argument_list|)
expr_stmt|;
block|}
comment|/**    * Update the {@link #nextFlush} variable to the next flush time. Add    * an integer number of flush intervals, preserving the initial random offset.    *    * @param now the current time    */
annotation|@
name|VisibleForTesting
DECL|method|updateFlushTime (Date now)
specifier|protected
name|void
name|updateFlushTime
parameter_list|(
name|Date
name|now
parameter_list|)
block|{
comment|// In non-initial rounds, add an integer number of intervals to the last
comment|// flush until a time in the future is achieved, thus preserving the
comment|// original random offset.
name|int
name|millis
init|=
call|(
name|int
call|)
argument_list|(
operator|(
operator|(
name|now
operator|.
name|getTime
argument_list|()
operator|-
name|nextFlush
operator|.
name|getTimeInMillis
argument_list|()
operator|)
operator|/
name|rollIntervalMillis
operator|+
literal|1
operator|)
operator|*
name|rollIntervalMillis
argument_list|)
decl_stmt|;
name|nextFlush
operator|.
name|add
argument_list|(
name|Calendar
operator|.
name|MILLISECOND
argument_list|,
name|millis
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the {@link #nextFlush} variable to the initial flush time. The initial    * flush will be an integer number of flush intervals past the beginning of    * the current hour and will have a random offset added, up to    * {@link #rollOffsetIntervalMillis}. The initial flush will be a time in    * past that can be used from which to calculate future flush times.    *    * @param now the current time    */
annotation|@
name|VisibleForTesting
DECL|method|setInitialFlushTime (Date now)
specifier|protected
name|void
name|setInitialFlushTime
parameter_list|(
name|Date
name|now
parameter_list|)
block|{
comment|// Start with the beginning of the current hour
name|nextFlush
operator|=
name|Calendar
operator|.
name|getInstance
argument_list|()
expr_stmt|;
name|nextFlush
operator|.
name|setTime
argument_list|(
name|now
argument_list|)
expr_stmt|;
name|nextFlush
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|MILLISECOND
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|nextFlush
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|SECOND
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|nextFlush
operator|.
name|set
argument_list|(
name|Calendar
operator|.
name|MINUTE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|// In the first round, calculate the first flush as the largest number of
comment|// intervals from the beginning of the current hour that's not in the
comment|// future by:
comment|// 1. Subtract the beginning of the hour from the current time
comment|// 2. Divide by the roll interval and round down to get the number of whole
comment|//    intervals that have passed since the beginning of the hour
comment|// 3. Multiply by the roll interval to get the number of millis between
comment|//    the beginning of the current hour and the beginning of the current
comment|//    interval.
name|int
name|millis
init|=
call|(
name|int
call|)
argument_list|(
operator|(
operator|(
name|now
operator|.
name|getTime
argument_list|()
operator|-
name|nextFlush
operator|.
name|getTimeInMillis
argument_list|()
operator|)
operator|/
name|rollIntervalMillis
operator|)
operator|*
name|rollIntervalMillis
argument_list|)
decl_stmt|;
comment|// Then add some noise to help prevent all the nodes from
comment|// closing their files at the same time.
if|if
condition|(
name|rollOffsetIntervalMillis
operator|>
literal|0
condition|)
block|{
name|millis
operator|+=
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextLong
argument_list|(
name|rollOffsetIntervalMillis
argument_list|)
expr_stmt|;
comment|// If the added time puts us into the future, step back one roll interval
comment|// because the code to increment nextFlush to the next flush expects that
comment|// nextFlush is the next flush from the previous interval.  There wasn't
comment|// a previous interval, so we just fake it with the time in the past that
comment|// would have been the previous interval if there had been one.
comment|//
comment|// It's OK if millis comes out negative.
while|while
condition|(
name|nextFlush
operator|.
name|getTimeInMillis
argument_list|()
operator|+
name|millis
operator|>
name|now
operator|.
name|getTime
argument_list|()
condition|)
block|{
name|millis
operator|-=
name|rollIntervalMillis
expr_stmt|;
block|}
block|}
comment|// Adjust the next flush time by millis to get the time of our ficticious
comment|// previous next flush
name|nextFlush
operator|.
name|add
argument_list|(
name|Calendar
operator|.
name|MILLISECOND
argument_list|,
name|millis
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a new directory based on the current interval and a new log file in    * that directory.    *    * @throws IOException thrown if an error occurs while creating the    * new directory or new log file    */
DECL|method|rollLogDir ()
specifier|private
name|void
name|rollLogDir
parameter_list|()
throws|throws
name|IOException
block|{
name|String
name|fileName
init|=
name|source
operator|+
literal|"-"
operator|+
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
operator|.
name|getHostName
argument_list|()
operator|+
literal|".log"
decl_stmt|;
name|Path
name|targetFile
init|=
operator|new
name|Path
argument_list|(
name|currentDirPath
argument_list|,
name|fileName
argument_list|)
decl_stmt|;
name|fileSystem
operator|.
name|mkdirs
argument_list|(
name|currentDirPath
argument_list|)
expr_stmt|;
if|if
condition|(
name|allowAppend
condition|)
block|{
name|createOrAppendLogFile
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|createLogFile
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a new log file and return the {@link FSDataOutputStream}. If a    * file with the specified path already exists, add a suffix, starting with 1    * and try again. Keep incrementing the suffix until a nonexistent target    * path is found.    *    * Once the file is open, update {@link #currentFSOutStream},    * {@link #currentOutStream}, and {@#link #currentFilePath} are set    * appropriately.    *    * @param initial the target path    * @throws IOException thrown if the call to see if the exists fails    */
DECL|method|createLogFile (Path initial)
specifier|private
name|void
name|createLogFile
parameter_list|(
name|Path
name|initial
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|currentAttempt
init|=
name|initial
decl_stmt|;
comment|// Start at 0 so that if the base filname exists, we start with the suffix
comment|// ".1".
name|int
name|id
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
comment|// First try blindly creating the file. If we fail, it either means
comment|// the file exists, or the operation actually failed.  We do it this way
comment|// because if we check whether the file exists, it might still be created
comment|// by the time we try to create it. Creating first works like a
comment|// test-and-set.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|create
argument_list|(
name|currentAttempt
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
name|currentFilePath
operator|=
name|currentAttempt
expr_stmt|;
break|break;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Now we can check to see if the file exists to know why we failed
if|if
condition|(
name|fileSystem
operator|.
name|exists
argument_list|(
name|currentAttempt
argument_list|)
condition|)
block|{
name|id
operator|=
name|getNextIdToTry
argument_list|(
name|initial
argument_list|,
name|id
argument_list|)
expr_stmt|;
name|currentAttempt
operator|=
operator|new
name|Path
argument_list|(
name|initial
operator|.
name|toString
argument_list|()
operator|+
literal|"."
operator|+
name|id
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|ex
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Return the next ID suffix to use when creating the log file. This method    * will look at the files in the directory, find the one with the highest    * ID suffix, and 1 to that suffix, and return it. This approach saves a full    * linear probe, which matters in the case where there are a large number of    * log files.    *    * @param initial the base file path    * @param lastId the last ID value that was used    * @return the next ID to try    * @throws IOException thrown if there's an issue querying the files in the    * directory    */
DECL|method|getNextIdToTry (Path initial, int lastId)
specifier|private
name|int
name|getNextIdToTry
parameter_list|(
name|Path
name|initial
parameter_list|,
name|int
name|lastId
parameter_list|)
throws|throws
name|IOException
block|{
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|files
init|=
name|fileSystem
operator|.
name|listFiles
argument_list|(
name|currentDirPath
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|String
name|base
init|=
name|initial
operator|.
name|toString
argument_list|()
decl_stmt|;
name|int
name|id
init|=
name|lastId
decl_stmt|;
while|while
condition|(
name|files
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|String
name|file
init|=
name|files
operator|.
name|next
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|file
operator|.
name|startsWith
argument_list|(
name|base
argument_list|)
condition|)
block|{
name|int
name|fileId
init|=
name|extractId
argument_list|(
name|file
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileId
operator|>
name|id
condition|)
block|{
name|id
operator|=
name|fileId
expr_stmt|;
block|}
block|}
block|}
comment|// Return either 1 more than the highest we found or 1 more than the last
comment|// ID used (if no ID was found).
return|return
name|id
operator|+
literal|1
return|;
block|}
comment|/**    * Extract the ID from the suffix of the given file name.    *    * @param file the file name    * @return the ID or -1 if no ID could be extracted    */
DECL|method|extractId (String file)
specifier|private
name|int
name|extractId
parameter_list|(
name|String
name|file
parameter_list|)
block|{
name|int
name|index
init|=
name|file
operator|.
name|lastIndexOf
argument_list|(
literal|"."
argument_list|)
decl_stmt|;
name|int
name|id
init|=
operator|-
literal|1
decl_stmt|;
comment|// A hostname has to have at least 1 character
if|if
condition|(
name|index
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|id
operator|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|file
operator|.
name|substring
argument_list|(
name|index
operator|+
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|ex
parameter_list|)
block|{
comment|// This can happen if there's no suffix, but there is a dot in the
comment|// hostname.  Just ignore it.
block|}
block|}
return|return
name|id
return|;
block|}
comment|/**    * Create a new log file and return the {@link FSDataOutputStream}. If a    * file with the specified path already exists, open the file for append    * instead.    *    * Once the file is open, update {@link #currentFSOutStream},    * {@link #currentOutStream}, and {@#link #currentFilePath}.    *    * @param initial the target path    * @throws IOException thrown if the call to see the append operation fails.    */
DECL|method|createOrAppendLogFile (Path targetFile)
specifier|private
name|void
name|createOrAppendLogFile
parameter_list|(
name|Path
name|targetFile
parameter_list|)
throws|throws
name|IOException
block|{
comment|// First try blindly creating the file. If we fail, it either means
comment|// the file exists, or the operation actually failed.  We do it this way
comment|// because if we check whether the file exists, it might still be created
comment|// by the time we try to create it. Creating first works like a
comment|// test-and-set.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|create
argument_list|(
name|targetFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Try appending instead.  If we fail, if means the file doesn't
comment|// actually exist yet or the operation actually failed.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|append
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex2
parameter_list|)
block|{
comment|// If the original create failed for a legit but transitory
comment|// reason, the append will fail because the file now doesn't exist,
comment|// resulting in a confusing stack trace.  To avoid that, we set
comment|// the cause of the second exception to be the first exception.
comment|// It's still a tiny bit confusing, but it's enough
comment|// information that someone should be able to figure it out.
name|ex2
operator|.
name|initCause
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex2
throw|;
block|}
block|}
name|currentFilePath
operator|=
name|targetFile
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|putMetrics (MetricsRecord record)
specifier|public
name|void
name|putMetrics
parameter_list|(
name|MetricsRecord
name|record
parameter_list|)
block|{
synchronized|synchronized
init|(
name|lock
init|)
block|{
name|rollLogDirIfNeeded
argument_list|()
expr_stmt|;
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%d %s.%s"
argument_list|,
name|record
operator|.
name|timestamp
argument_list|()
argument_list|,
name|record
operator|.
name|context
argument_list|()
argument_list|,
name|record
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|separator
init|=
literal|": "
decl_stmt|;
for|for
control|(
name|MetricsTag
name|tag
range|:
name|record
operator|.
name|tags
argument_list|()
control|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%s%s=%s"
argument_list|,
name|separator
argument_list|,
name|tag
operator|.
name|name
argument_list|()
argument_list|,
name|tag
operator|.
name|value
argument_list|()
argument_list|)
expr_stmt|;
name|separator
operator|=
literal|", "
expr_stmt|;
block|}
for|for
control|(
name|AbstractMetric
name|metric
range|:
name|record
operator|.
name|metrics
argument_list|()
control|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%s%s=%s"
argument_list|,
name|separator
argument_list|,
name|metric
operator|.
name|name
argument_list|()
argument_list|,
name|metric
operator|.
name|value
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|currentOutStream
operator|.
name|println
argument_list|()
expr_stmt|;
comment|// If we don't hflush(), the data may not be written until the file is
comment|// closed. The file won't be closed until the end of the interval *AND*
comment|// another record is received. Calling hflush() makes sure that the data
comment|// is complete at the end of the interval.
try|try
block|{
name|currentFSOutStream
operator|.
name|hflush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Failed flushing the stream"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|checkForErrors
argument_list|(
literal|"Unable to write to log file"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
name|throwMetricsException
argument_list|(
literal|"Unable to write to log file"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|flush ()
specifier|public
name|void
name|flush
parameter_list|()
block|{
synchronized|synchronized
init|(
name|lock
init|)
block|{
comment|// currentOutStream is null if currentFSOutStream is null
if|if
condition|(
name|currentFSOutStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|currentFSOutStream
operator|.
name|hflush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Unable to flush log file"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
block|{
synchronized|synchronized
init|(
name|lock
init|)
block|{
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|close
argument_list|()
expr_stmt|;
try|try
block|{
name|checkForErrors
argument_list|(
literal|"Unable to close log file"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// Null out the streams just in case someone tries to reuse us.
name|currentOutStream
operator|=
literal|null
expr_stmt|;
name|currentFSOutStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, throw a {@link MetricsException}    * if the stream encountered an exception.  The message parameter will be used    * as the new exception's message with the current file name    * ({@link #currentFilePath}) appended to it.    *    * @param message the exception message. The message will have a colon and    * the current file name ({@link #currentFilePath}) appended to it.    * @throws MetricsException thrown if there was an error and the sink isn't    * ignoring errors    */
DECL|method|checkForErrors (String message)
specifier|private
name|void
name|checkForErrors
parameter_list|(
name|String
name|message
parameter_list|)
throws|throws
name|MetricsException
block|{
if|if
condition|(
operator|!
name|ignoreError
operator|&&
name|currentOutStream
operator|.
name|checkError
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
argument_list|)
throw|;
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, wrap the Throwable in a    * {@link MetricsException} and throw it.  The message parameter will be used    * as the new exception's message with the current file name    * ({@link #currentFilePath}) and the Throwable's string representation    * appended to it.    *    * @param message the exception message. The message will have a colon, the    * current file name ({@link #currentFilePath}), and the Throwable's string    * representation (wrapped in square brackets) appended to it.    * @param t the Throwable to wrap    */
DECL|method|throwMetricsException (String message, Throwable t)
specifier|private
name|void
name|throwMetricsException
parameter_list|(
name|String
name|message
parameter_list|,
name|Throwable
name|t
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
operator|+
literal|" ["
operator|+
name|t
operator|.
name|toString
argument_list|()
operator|+
literal|"]"
argument_list|,
name|t
argument_list|)
throw|;
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, throw a new    * {@link MetricsException}.  The message parameter will be used  as the    * new exception's message with the current file name    * ({@link #currentFilePath}) appended to it.    *    * @param message the exception message. The message will have a colon and    * the current file name ({@link #currentFilePath}) appended to it.    */
DECL|method|throwMetricsException (String message)
specifier|private
name|void
name|throwMetricsException
parameter_list|(
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

