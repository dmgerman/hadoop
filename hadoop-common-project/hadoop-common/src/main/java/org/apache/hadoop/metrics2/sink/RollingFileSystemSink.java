begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.metrics2.sink
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|sink
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TimeZone
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|configuration
operator|.
name|SubsetConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|time
operator|.
name|FastDateFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|AbstractMetric
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsSink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsTag
import|;
end_import

begin_comment
comment|/**  * This class is a metrics sink that uses  * {@link org.apache.hadoop.fs.FileSystem} to write the metrics logs.  Every  * hour a new directory will be created under the path specified by the  *<code>basepath</code> property. All metrics will be logged to a file in the  * current hour's directory in a file named&lt;hostname&gt;.log, where  *&lt;hostname&gt; is the name of the host on which the metrics logging  * process is running. The base path is set by the  *<code>&lt;prefix&gt;.sink.&lt;instance&gt;.basepath</code> property.  The  * time zone used to create the current hour's directory name is GMT.  If the  *<code>basepath</code> property isn't specified, it will default to  *&quot;/tmp&quot;, which is the temp directory on whatever default file  * system is configured for the cluster.  *  * The<code>&lt;prefix&gt;.sink.&lt;instance&gt;.ignore-error</code> property  * controls whether an exception is thrown when an error is encountered writing  * a log file.  The default value is<code>true</code>.  When set to  *<code>false</code>, file errors are quietly swallowed.  *  * The primary use of this class is for logging to HDFS.  As it uses  * {@link org.apache.hadoop.fs.FileSystem} to access the target file system,  * however, it can be used to write to the local file system, Amazon S3, or any  * other supported file system.  The base path for the sink will determine the  * file system used.  An unqualified path will write to the default file system  * set by the configuration.  *  * Not all file systems support the ability to append to files.  In file systems  * without the ability to append to files, only one writer can write to a file  * at a time.  To allow for concurrent writes from multiple daemons on a single  * host, the<code>source</code> property should be set to the name of the  * source daemon, e.g.<i>namenode</i>.  The value of the<code>source</code>  * property should typically be the same as the property's prefix.  If this  * property is not set, the source is taken to be<i>unknown</i>.  *  * Instead of appending to an existing file, by default the sink  * will create a new file with a suffix of&quot;.&lt;n&gt;&quet;, where  *<i>n</i> is the next lowest integer that isn't already used in a file name,  * similar to the Hadoop daemon logs.  NOTE: the file with the<b>highest</b>  * sequence number is the<b>newest</b> file, unlike the Hadoop daemon logs.  *  * For file systems that allow append, the sink supports appending to the  * existing file instead. If the<code>allow-append</code> property is set to  * true, the sink will instead append to the existing file on file systems that  * support appends. By default, the<code>allow-append</code> property is  * false.  *  * Note that when writing to HDFS with<code>allow-append</code> set to true,  * there is a minimum acceptable number of data nodes.  If the number of data  * nodes drops below that minimum, the append will succeed, but reading the  * data will fail with an IOException in the DataStreamer class.  The minimum  * number of data nodes required for a successful append is generally 2 or 3.  *  * Note also that when writing to HDFS, the file size information is not updated  * until the file is closed (e.g. at the top of the hour) even though the data  * is being written successfully. This is a known HDFS limitation that exists  * because of the performance cost of updating the metadata.  See  *<a href="https://issues.apache.org/jira/browse/HDFS-5478">HDFS-5478</a>.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|RollingFileSystemSink
specifier|public
class|class
name|RollingFileSystemSink
implements|implements
name|MetricsSink
implements|,
name|Closeable
block|{
DECL|field|BASEPATH_KEY
specifier|private
specifier|static
specifier|final
name|String
name|BASEPATH_KEY
init|=
literal|"basepath"
decl_stmt|;
DECL|field|SOURCE_KEY
specifier|private
specifier|static
specifier|final
name|String
name|SOURCE_KEY
init|=
literal|"source"
decl_stmt|;
DECL|field|IGNORE_ERROR_KEY
specifier|private
specifier|static
specifier|final
name|String
name|IGNORE_ERROR_KEY
init|=
literal|"ignore-error"
decl_stmt|;
DECL|field|ALLOW_APPEND_KEY
specifier|private
specifier|static
specifier|final
name|String
name|ALLOW_APPEND_KEY
init|=
literal|"allow-append"
decl_stmt|;
DECL|field|SOURCE_DEFAULT
specifier|private
specifier|static
specifier|final
name|String
name|SOURCE_DEFAULT
init|=
literal|"unknown"
decl_stmt|;
DECL|field|BASEPATH_DEFAULT
specifier|private
specifier|static
specifier|final
name|String
name|BASEPATH_DEFAULT
init|=
literal|"/tmp"
decl_stmt|;
DECL|field|DATE_FORMAT
specifier|private
specifier|static
specifier|final
name|FastDateFormat
name|DATE_FORMAT
init|=
name|FastDateFormat
operator|.
name|getInstance
argument_list|(
literal|"yyyyMMddHH"
argument_list|,
name|TimeZone
operator|.
name|getTimeZone
argument_list|(
literal|"GMT"
argument_list|)
argument_list|)
decl_stmt|;
DECL|field|source
specifier|private
name|String
name|source
decl_stmt|;
DECL|field|ignoreError
specifier|private
name|boolean
name|ignoreError
decl_stmt|;
DECL|field|allowAppend
specifier|private
name|boolean
name|allowAppend
decl_stmt|;
DECL|field|basePath
specifier|private
name|Path
name|basePath
decl_stmt|;
DECL|field|fileSystem
specifier|private
name|FileSystem
name|fileSystem
decl_stmt|;
comment|// The current directory path into which we're writing files
DECL|field|currentDirPath
specifier|private
name|Path
name|currentDirPath
decl_stmt|;
comment|// The path to the current file into which we're writing data
DECL|field|currentFilePath
specifier|private
name|Path
name|currentFilePath
decl_stmt|;
comment|// The stream to which we're currently writing.
DECL|field|currentOutStream
specifier|private
name|PrintStream
name|currentOutStream
decl_stmt|;
comment|// We keep this only to be able to call hsynch() on it.
DECL|field|currentFSOutStream
specifier|private
name|FSDataOutputStream
name|currentFSOutStream
decl_stmt|;
annotation|@
name|Override
DECL|method|init (SubsetConfiguration conf)
specifier|public
name|void
name|init
parameter_list|(
name|SubsetConfiguration
name|conf
parameter_list|)
block|{
name|basePath
operator|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|getString
argument_list|(
name|BASEPATH_KEY
argument_list|,
name|BASEPATH_DEFAULT
argument_list|)
argument_list|)
expr_stmt|;
name|source
operator|=
name|conf
operator|.
name|getString
argument_list|(
name|SOURCE_KEY
argument_list|,
name|SOURCE_DEFAULT
argument_list|)
expr_stmt|;
name|ignoreError
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|IGNORE_ERROR_KEY
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|allowAppend
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|ALLOW_APPEND_KEY
argument_list|,
literal|false
argument_list|)
expr_stmt|;
try|try
block|{
name|fileSystem
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
operator|new
name|URI
argument_list|(
name|basePath
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
operator|new
name|Configuration
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"The supplied filesystem base path URI"
operator|+
literal|" is not a valid URI: "
operator|+
name|basePath
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error connecting to file system: "
operator|+
name|basePath
operator|+
literal|" ["
operator|+
name|ex
operator|.
name|toString
argument_list|()
operator|+
literal|"]"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
comment|// If we're permitted to append, check if we actually can
if|if
condition|(
name|allowAppend
condition|)
block|{
name|allowAppend
operator|=
name|checkAppend
argument_list|(
name|fileSystem
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Test whether the file system supports append and return the answer.    * @param fs the target file system    */
DECL|method|checkAppend (FileSystem fs)
specifier|private
name|boolean
name|checkAppend
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|boolean
name|canAppend
init|=
literal|true
decl_stmt|;
try|try
block|{
name|fs
operator|.
name|append
argument_list|(
name|basePath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
if|if
condition|(
name|ex
operator|.
name|getMessage
argument_list|()
operator|.
name|equals
argument_list|(
literal|"Not supported"
argument_list|)
condition|)
block|{
name|canAppend
operator|=
literal|false
expr_stmt|;
block|}
block|}
return|return
name|canAppend
return|;
block|}
comment|/**    * Check the current directory against the time stamp.  If they're not    * the same, create a new directory and a new log file in that directory.    *    * @throws MetricsException thrown if an error occurs while creating the    * new directory or new log file    */
DECL|method|rollLogDirIfNeeded ()
specifier|private
name|void
name|rollLogDirIfNeeded
parameter_list|()
throws|throws
name|MetricsException
block|{
name|String
name|currentDir
init|=
name|DATE_FORMAT
operator|.
name|format
argument_list|(
operator|new
name|Date
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
name|basePath
argument_list|,
name|currentDir
argument_list|)
decl_stmt|;
comment|// We check whether currentOutStream is null instead of currentDirPath,
comment|// because if currentDirPath is null, then currentOutStream is null, but
comment|// currentOutStream can be null for other reasons.
if|if
condition|(
operator|(
name|currentOutStream
operator|==
literal|null
operator|)
operator|||
operator|!
name|path
operator|.
name|equals
argument_list|(
name|currentDirPath
argument_list|)
condition|)
block|{
name|currentDirPath
operator|=
name|path
expr_stmt|;
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|rollLogDir
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Failed to creating new log file"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Create a new directory based on the current hour and a new log file in    * that directory.    *    * @throws IOException thrown if an error occurs while creating the    * new directory or new log file    */
DECL|method|rollLogDir ()
specifier|private
name|void
name|rollLogDir
parameter_list|()
throws|throws
name|IOException
block|{
name|String
name|fileName
init|=
name|source
operator|+
literal|"-"
operator|+
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
operator|.
name|getHostName
argument_list|()
operator|+
literal|".log"
decl_stmt|;
name|Path
name|targetFile
init|=
operator|new
name|Path
argument_list|(
name|currentDirPath
argument_list|,
name|fileName
argument_list|)
decl_stmt|;
name|fileSystem
operator|.
name|mkdirs
argument_list|(
name|currentDirPath
argument_list|)
expr_stmt|;
if|if
condition|(
name|allowAppend
condition|)
block|{
name|createOrAppendLogFile
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|createLogFile
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a new log file and return the {@link FSDataOutputStream}. If a    * file with the specified path already exists, add a suffix, starting with 1    * and try again. Keep incrementing the suffix until a nonexistent target    * path is found.    *    * Once the file is open, update {@link #currentFSOutStream},    * {@link #currentOutStream}, and {@#link #currentFile} are set appropriately.    *    * @param initial the target path    * @throws IOException thrown if the call to see if the exists fails    */
DECL|method|createLogFile (Path initial)
specifier|private
name|void
name|createLogFile
parameter_list|(
name|Path
name|initial
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|currentAttempt
init|=
name|initial
decl_stmt|;
name|int
name|id
init|=
literal|1
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
comment|// First try blindly creating the file. If we fail, it either means
comment|// the file exists, or the operation actually failed.  We do it this way
comment|// because if we check whether the file exists, it might still be created
comment|// by the time we try to create it. Creating first works like a
comment|// test-and-set.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|create
argument_list|(
name|currentAttempt
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
name|currentFilePath
operator|=
name|currentAttempt
expr_stmt|;
break|break;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Now we can check to see if the file exists to know why we failed
if|if
condition|(
name|fileSystem
operator|.
name|exists
argument_list|(
name|currentAttempt
argument_list|)
condition|)
block|{
name|currentAttempt
operator|=
operator|new
name|Path
argument_list|(
name|initial
operator|.
name|toString
argument_list|()
operator|+
literal|"."
operator|+
name|id
argument_list|)
expr_stmt|;
name|id
operator|+=
literal|1
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|ex
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Create a new log file and return the {@link FSDataOutputStream}. If a    * file with the specified path already exists, open the file for append    * instead.    *    * Once the file is open, update {@link #currentFSOutStream},    * {@link #currentOutStream}, and {@#link #currentFile} are set appropriately.    *    * @param initial the target path    * @throws IOException thrown if the call to see the append operation fails.    */
DECL|method|createOrAppendLogFile (Path targetFile)
specifier|private
name|void
name|createOrAppendLogFile
parameter_list|(
name|Path
name|targetFile
parameter_list|)
throws|throws
name|IOException
block|{
comment|// First try blindly creating the file. If we fail, it either means
comment|// the file exists, or the operation actually failed.  We do it this way
comment|// because if we check whether the file exists, it might still be created
comment|// by the time we try to create it. Creating first works like a
comment|// test-and-set.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|create
argument_list|(
name|targetFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Try appending instead.  If we fail, if means the file doesn't
comment|// actually exist yet or the operation actually failed.
try|try
block|{
name|currentFSOutStream
operator|=
name|fileSystem
operator|.
name|append
argument_list|(
name|targetFile
argument_list|)
expr_stmt|;
name|currentOutStream
operator|=
operator|new
name|PrintStream
argument_list|(
name|currentFSOutStream
argument_list|,
literal|true
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex2
parameter_list|)
block|{
comment|// If the original create failed for a legit but transitory
comment|// reason, the append will fail because the file now doesn't exist,
comment|// resulting in a confusing stack trace.  To avoid that, we set
comment|// the cause of the second exception to be the first exception.
comment|// It's still a tiny bit confusing, but it's enough
comment|// information that someone should be able to figure it out.
name|ex2
operator|.
name|initCause
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|ex2
throw|;
block|}
block|}
name|currentFilePath
operator|=
name|targetFile
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|putMetrics (MetricsRecord record)
specifier|public
name|void
name|putMetrics
parameter_list|(
name|MetricsRecord
name|record
parameter_list|)
block|{
name|rollLogDirIfNeeded
argument_list|()
expr_stmt|;
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%d %s.%s"
argument_list|,
name|record
operator|.
name|timestamp
argument_list|()
argument_list|,
name|record
operator|.
name|context
argument_list|()
argument_list|,
name|record
operator|.
name|name
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|separator
init|=
literal|": "
decl_stmt|;
for|for
control|(
name|MetricsTag
name|tag
range|:
name|record
operator|.
name|tags
argument_list|()
control|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%s%s=%s"
argument_list|,
name|separator
argument_list|,
name|tag
operator|.
name|name
argument_list|()
argument_list|,
name|tag
operator|.
name|value
argument_list|()
argument_list|)
expr_stmt|;
name|separator
operator|=
literal|", "
expr_stmt|;
block|}
for|for
control|(
name|AbstractMetric
name|metric
range|:
name|record
operator|.
name|metrics
argument_list|()
control|)
block|{
name|currentOutStream
operator|.
name|printf
argument_list|(
literal|"%s%s=%s"
argument_list|,
name|separator
argument_list|,
name|metric
operator|.
name|name
argument_list|()
argument_list|,
name|metric
operator|.
name|value
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|currentOutStream
operator|.
name|println
argument_list|()
expr_stmt|;
comment|// If we don't hflush(), the data may not be written until the file is
comment|// closed. The file won't be closed until the top of the hour *AND*
comment|// another record is received. Calling hflush() makes sure that the data
comment|// is complete at the top of the hour.
try|try
block|{
name|currentFSOutStream
operator|.
name|hflush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Failed flushing the stream"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
name|checkForErrors
argument_list|(
literal|"Unable to write to log file"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
name|throwMetricsException
argument_list|(
literal|"Unable to write to log file"
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|flush ()
specifier|public
name|void
name|flush
parameter_list|()
block|{
comment|// currentOutStream is null if currentFSOutStream is null
if|if
condition|(
name|currentFSOutStream
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|currentFSOutStream
operator|.
name|hflush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|throwMetricsException
argument_list|(
literal|"Unable to flush log file"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|currentOutStream
operator|!=
literal|null
condition|)
block|{
name|currentOutStream
operator|.
name|close
argument_list|()
expr_stmt|;
try|try
block|{
name|checkForErrors
argument_list|(
literal|"Unable to close log file"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// Null out the streams just in case someone tries to reuse us.
name|currentOutStream
operator|=
literal|null
expr_stmt|;
name|currentFSOutStream
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, throw a {@link MetricsException}    * if the stream encountered an exception.  The message parameter will be used    * as the new exception's message with the current file name    * ({@link #currentFilePath}) appended to it.    *    * @param message the exception message. The message will have the current    * file name ({@link #currentFilePath}) appended to it.    * @throws MetricsException thrown if there was an error and the sink isn't    * ignoring errors    */
DECL|method|checkForErrors (String message)
specifier|private
name|void
name|checkForErrors
parameter_list|(
name|String
name|message
parameter_list|)
throws|throws
name|MetricsException
block|{
if|if
condition|(
operator|!
name|ignoreError
operator|&&
name|currentOutStream
operator|.
name|checkError
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
argument_list|)
throw|;
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, wrap the Throwable in a    * {@link MetricsException} and throw it.  The message parameter will be used    * as the new exception's message with the current file name    * ({@link #currentFilePath}) and the Throwable's string representation    * appended to it.    *    * @param message the exception message. The message will have the current    * file name ({@link #currentFilePath}) and the Throwable's string    * representation appended to it.    * @param t the Throwable to wrap    */
DECL|method|throwMetricsException (String message, Throwable t)
specifier|private
name|void
name|throwMetricsException
parameter_list|(
name|String
name|message
parameter_list|,
name|Throwable
name|t
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
operator|+
literal|" ["
operator|+
name|t
operator|.
name|toString
argument_list|()
operator|+
literal|"]"
argument_list|,
name|t
argument_list|)
throw|;
block|}
block|}
comment|/**    * If the sink isn't set to ignore errors, throw a new    * {@link MetricsException}.  The message parameter will be used  as the    * new exception's message with the current file name    * ({@link #currentFilePath}) appended to it.    *    * @param message the exception message. The message will have the current    * file name ({@link #currentFilePath}) appended to it.    */
DECL|method|throwMetricsException (String message)
specifier|private
name|void
name|throwMetricsException
parameter_list|(
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
operator|!
name|ignoreError
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
name|message
operator|+
literal|": "
operator|+
name|currentFilePath
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

