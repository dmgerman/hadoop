begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.azure
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|NativeAzureFileSystem
operator|.
name|PATH_DELIMITER
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|HttpURLConnection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLDecoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLEncoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|InvalidKeyException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Calendar
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|StorageInterface
operator|.
name|CloudBlobContainerWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|StorageInterface
operator|.
name|CloudBlobDirectoryWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|StorageInterface
operator|.
name|CloudBlobWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|StorageInterface
operator|.
name|CloudBlockBlobWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|StorageInterface
operator|.
name|CloudPageBlobWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|metrics
operator|.
name|AzureFileSystemInstrumentation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|metrics
operator|.
name|BandwidthGaugeUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|metrics
operator|.
name|ErrorMetricUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|metrics
operator|.
name|ResponseReceivedMetricUpdater
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|PermissionStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|eclipse
operator|.
name|jetty
operator|.
name|util
operator|.
name|ajax
operator|.
name|JSON
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|CloudStorageAccount
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|OperationContext
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|RetryExponentialRetry
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|RetryNoRetry
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|StorageCredentials
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|StorageCredentialsAccountAndKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|StorageCredentialsSharedAccessSignature
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|StorageErrorCode
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|StorageException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobListingDetails
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobProperties
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobRequestOptions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobType
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|CloudBlob
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|CopyStatus
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|DeleteSnapshotsOption
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|blob
operator|.
name|ListBlobItem
import|;
end_import

begin_import
import|import
name|com
operator|.
name|microsoft
operator|.
name|azure
operator|.
name|storage
operator|.
name|core
operator|.
name|Utility
import|;
end_import

begin_comment
comment|/**  * Core implementation of Windows Azure Filesystem for Hadoop.  * Provides the bridging logic between Hadoop's abstract filesystem and Azure Storage   *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|VisibleForTesting
DECL|class|AzureNativeFileSystemStore
specifier|public
class|class
name|AzureNativeFileSystemStore
implements|implements
name|NativeFileSystemStore
block|{
comment|/**    * Configuration knob on whether we do block-level MD5 validation on    * upload/download.    */
DECL|field|KEY_CHECK_BLOCK_MD5
specifier|static
specifier|final
name|String
name|KEY_CHECK_BLOCK_MD5
init|=
literal|"fs.azure.check.block.md5"
decl_stmt|;
comment|/**    * Configuration knob on whether we store blob-level MD5 on upload.    */
DECL|field|KEY_STORE_BLOB_MD5
specifier|static
specifier|final
name|String
name|KEY_STORE_BLOB_MD5
init|=
literal|"fs.azure.store.blob.md5"
decl_stmt|;
DECL|field|DEFAULT_STORAGE_EMULATOR_ACCOUNT_NAME
specifier|static
specifier|final
name|String
name|DEFAULT_STORAGE_EMULATOR_ACCOUNT_NAME
init|=
literal|"storageemulator"
decl_stmt|;
DECL|field|STORAGE_EMULATOR_ACCOUNT_NAME_PROPERTY_NAME
specifier|static
specifier|final
name|String
name|STORAGE_EMULATOR_ACCOUNT_NAME_PROPERTY_NAME
init|=
literal|"fs.azure.storage.emulator.account.name"
decl_stmt|;
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AzureNativeFileSystemStore
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|storageInteractionLayer
specifier|private
name|StorageInterface
name|storageInteractionLayer
decl_stmt|;
DECL|field|rootDirectory
specifier|private
name|CloudBlobDirectoryWrapper
name|rootDirectory
decl_stmt|;
DECL|field|container
specifier|private
name|CloudBlobContainerWrapper
name|container
decl_stmt|;
comment|// Constants local to this class.
comment|//
DECL|field|KEY_ACCOUNT_KEYPROVIDER_PREFIX
specifier|private
specifier|static
specifier|final
name|String
name|KEY_ACCOUNT_KEYPROVIDER_PREFIX
init|=
literal|"fs.azure.account.keyprovider."
decl_stmt|;
DECL|field|KEY_ACCOUNT_SAS_PREFIX
specifier|private
specifier|static
specifier|final
name|String
name|KEY_ACCOUNT_SAS_PREFIX
init|=
literal|"fs.azure.sas."
decl_stmt|;
comment|// note: this value is not present in core-default.xml as our real default is
comment|// computed as min(2*cpu,8)
DECL|field|KEY_CONCURRENT_CONNECTION_VALUE_OUT
specifier|private
specifier|static
specifier|final
name|String
name|KEY_CONCURRENT_CONNECTION_VALUE_OUT
init|=
literal|"fs.azure.concurrentRequestCount.out"
decl_stmt|;
DECL|field|KEY_STREAM_MIN_READ_SIZE
specifier|private
specifier|static
specifier|final
name|String
name|KEY_STREAM_MIN_READ_SIZE
init|=
literal|"fs.azure.read.request.size"
decl_stmt|;
DECL|field|KEY_STORAGE_CONNECTION_TIMEOUT
specifier|private
specifier|static
specifier|final
name|String
name|KEY_STORAGE_CONNECTION_TIMEOUT
init|=
literal|"fs.azure.storage.timeout"
decl_stmt|;
DECL|field|KEY_WRITE_BLOCK_SIZE
specifier|private
specifier|static
specifier|final
name|String
name|KEY_WRITE_BLOCK_SIZE
init|=
literal|"fs.azure.write.request.size"
decl_stmt|;
comment|// Property controlling whether to allow reads on blob which are concurrently
comment|// appended out-of-band.
DECL|field|KEY_READ_TOLERATE_CONCURRENT_APPEND
specifier|private
specifier|static
specifier|final
name|String
name|KEY_READ_TOLERATE_CONCURRENT_APPEND
init|=
literal|"fs.azure.io.read.tolerate.concurrent.append"
decl_stmt|;
comment|// Configurable throttling parameter properties. These properties are located
comment|// in the core-site.xml configuration file.
DECL|field|KEY_MIN_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_MIN_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.retry.min.backoff.interval"
decl_stmt|;
DECL|field|KEY_MAX_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_MAX_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.retry.max.backoff.interval"
decl_stmt|;
DECL|field|KEY_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.retry.backoff.interval"
decl_stmt|;
DECL|field|KEY_MAX_IO_RETRIES
specifier|private
specifier|static
specifier|final
name|String
name|KEY_MAX_IO_RETRIES
init|=
literal|"fs.azure.io.retry.max.retries"
decl_stmt|;
DECL|field|KEY_COPYBLOB_MIN_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_COPYBLOB_MIN_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.copyblob.retry.min.backoff.interval"
decl_stmt|;
DECL|field|KEY_COPYBLOB_MAX_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_COPYBLOB_MAX_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.copyblob.retry.max.backoff.interval"
decl_stmt|;
DECL|field|KEY_COPYBLOB_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|String
name|KEY_COPYBLOB_BACKOFF_INTERVAL
init|=
literal|"fs.azure.io.copyblob.retry.backoff.interval"
decl_stmt|;
DECL|field|KEY_COPYBLOB_MAX_IO_RETRIES
specifier|private
specifier|static
specifier|final
name|String
name|KEY_COPYBLOB_MAX_IO_RETRIES
init|=
literal|"fs.azure.io.copyblob.retry.max.retries"
decl_stmt|;
DECL|field|KEY_SELF_THROTTLE_ENABLE
specifier|private
specifier|static
specifier|final
name|String
name|KEY_SELF_THROTTLE_ENABLE
init|=
literal|"fs.azure.selfthrottling.enable"
decl_stmt|;
DECL|field|KEY_SELF_THROTTLE_READ_FACTOR
specifier|private
specifier|static
specifier|final
name|String
name|KEY_SELF_THROTTLE_READ_FACTOR
init|=
literal|"fs.azure.selfthrottling.read.factor"
decl_stmt|;
DECL|field|KEY_SELF_THROTTLE_WRITE_FACTOR
specifier|private
specifier|static
specifier|final
name|String
name|KEY_SELF_THROTTLE_WRITE_FACTOR
init|=
literal|"fs.azure.selfthrottling.write.factor"
decl_stmt|;
DECL|field|KEY_ENABLE_STORAGE_CLIENT_LOGGING
specifier|private
specifier|static
specifier|final
name|String
name|KEY_ENABLE_STORAGE_CLIENT_LOGGING
init|=
literal|"fs.azure.storage.client.logging"
decl_stmt|;
comment|/**    * Configuration keys to identify if WASB needs to run in Secure mode. In Secure mode    * all interactions with Azure storage is performed using SAS uris. There are two sub modes    * within the Secure mode , one is remote SAS key mode where the SAS keys are generated    * from a remote process and local mode where SAS keys are generated within WASB.    */
annotation|@
name|VisibleForTesting
DECL|field|KEY_USE_SECURE_MODE
specifier|public
specifier|static
specifier|final
name|String
name|KEY_USE_SECURE_MODE
init|=
literal|"fs.azure.secure.mode"
decl_stmt|;
comment|/**    * By default the SAS Key mode is expected to run in Romote key mode. This flags sets it    * to run on the local mode.    */
DECL|field|KEY_USE_LOCAL_SAS_KEY_MODE
specifier|public
specifier|static
specifier|final
name|String
name|KEY_USE_LOCAL_SAS_KEY_MODE
init|=
literal|"fs.azure.local.sas.key.mode"
decl_stmt|;
DECL|field|PERMISSION_METADATA_KEY
specifier|private
specifier|static
specifier|final
name|String
name|PERMISSION_METADATA_KEY
init|=
literal|"hdi_permission"
decl_stmt|;
DECL|field|OLD_PERMISSION_METADATA_KEY
specifier|private
specifier|static
specifier|final
name|String
name|OLD_PERMISSION_METADATA_KEY
init|=
literal|"asv_permission"
decl_stmt|;
DECL|field|IS_FOLDER_METADATA_KEY
specifier|private
specifier|static
specifier|final
name|String
name|IS_FOLDER_METADATA_KEY
init|=
literal|"hdi_isfolder"
decl_stmt|;
DECL|field|OLD_IS_FOLDER_METADATA_KEY
specifier|private
specifier|static
specifier|final
name|String
name|OLD_IS_FOLDER_METADATA_KEY
init|=
literal|"asv_isfolder"
decl_stmt|;
DECL|field|VERSION_METADATA_KEY
specifier|static
specifier|final
name|String
name|VERSION_METADATA_KEY
init|=
literal|"hdi_version"
decl_stmt|;
DECL|field|OLD_VERSION_METADATA_KEY
specifier|static
specifier|final
name|String
name|OLD_VERSION_METADATA_KEY
init|=
literal|"asv_version"
decl_stmt|;
DECL|field|FIRST_WASB_VERSION
specifier|static
specifier|final
name|String
name|FIRST_WASB_VERSION
init|=
literal|"2013-01-01"
decl_stmt|;
DECL|field|CURRENT_WASB_VERSION
specifier|static
specifier|final
name|String
name|CURRENT_WASB_VERSION
init|=
literal|"2013-09-01"
decl_stmt|;
DECL|field|LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
specifier|static
specifier|final
name|String
name|LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
init|=
literal|"hdi_tmpupload"
decl_stmt|;
DECL|field|OLD_LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
specifier|static
specifier|final
name|String
name|OLD_LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
init|=
literal|"asv_tmpupload"
decl_stmt|;
comment|/**    * Configuration key to indicate the set of directories in WASB where we    * should store files as page blobs instead of block blobs.    *    * Entries should be plain directory names (i.e. not URIs) with no leading or    * trailing slashes. Delimit the entries with commas.    */
DECL|field|KEY_PAGE_BLOB_DIRECTORIES
specifier|public
specifier|static
specifier|final
name|String
name|KEY_PAGE_BLOB_DIRECTORIES
init|=
literal|"fs.azure.page.blob.dir"
decl_stmt|;
comment|/**    * The set of directories where we should store files as page blobs.    */
DECL|field|pageBlobDirs
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|pageBlobDirs
decl_stmt|;
comment|/**    * Configuration key to indicate the set of directories in WASB where    * we should do atomic folder rename synchronized with createNonRecursive.    */
DECL|field|KEY_ATOMIC_RENAME_DIRECTORIES
specifier|public
specifier|static
specifier|final
name|String
name|KEY_ATOMIC_RENAME_DIRECTORIES
init|=
literal|"fs.azure.atomic.rename.dir"
decl_stmt|;
comment|/**    * Configuration key to enable flat listing of blobs. This config is useful    * only if listing depth is AZURE_UNBOUNDED_DEPTH.    */
DECL|field|KEY_ENABLE_FLAT_LISTING
specifier|public
specifier|static
specifier|final
name|String
name|KEY_ENABLE_FLAT_LISTING
init|=
literal|"fs.azure.flatlist.enable"
decl_stmt|;
comment|/**    * The set of directories where we should apply atomic folder rename    * synchronized with createNonRecursive.    */
DECL|field|atomicRenameDirs
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|atomicRenameDirs
decl_stmt|;
DECL|field|HTTP_SCHEME
specifier|private
specifier|static
specifier|final
name|String
name|HTTP_SCHEME
init|=
literal|"http"
decl_stmt|;
DECL|field|HTTPS_SCHEME
specifier|private
specifier|static
specifier|final
name|String
name|HTTPS_SCHEME
init|=
literal|"https"
decl_stmt|;
DECL|field|WASB_AUTHORITY_DELIMITER
specifier|private
specifier|static
specifier|final
name|String
name|WASB_AUTHORITY_DELIMITER
init|=
literal|"@"
decl_stmt|;
DECL|field|AZURE_ROOT_CONTAINER
specifier|private
specifier|static
specifier|final
name|String
name|AZURE_ROOT_CONTAINER
init|=
literal|"$root"
decl_stmt|;
DECL|field|DEFAULT_CONCURRENT_WRITES
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_CONCURRENT_WRITES
init|=
literal|8
decl_stmt|;
comment|// Concurrent reads reads of data written out of band are disable by default.
comment|//
DECL|field|DEFAULT_READ_TOLERATE_CONCURRENT_APPEND
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_READ_TOLERATE_CONCURRENT_APPEND
init|=
literal|false
decl_stmt|;
comment|// Default block sizes
DECL|field|DEFAULT_DOWNLOAD_BLOCK_SIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_DOWNLOAD_BLOCK_SIZE
init|=
literal|4
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
DECL|field|DEFAULT_UPLOAD_BLOCK_SIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_UPLOAD_BLOCK_SIZE
init|=
literal|4
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|// Retry parameter defaults.
comment|//
DECL|field|DEFAULT_MIN_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MIN_BACKOFF_INTERVAL
init|=
literal|1
operator|*
literal|1000
decl_stmt|;
comment|// 1s
DECL|field|DEFAULT_MAX_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_BACKOFF_INTERVAL
init|=
literal|30
operator|*
literal|1000
decl_stmt|;
comment|// 30s
DECL|field|DEFAULT_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_BACKOFF_INTERVAL
init|=
literal|1
operator|*
literal|1000
decl_stmt|;
comment|// 1s
DECL|field|DEFAULT_MAX_RETRY_ATTEMPTS
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_RETRY_ATTEMPTS
init|=
literal|15
decl_stmt|;
DECL|field|DEFAULT_COPYBLOB_MIN_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_COPYBLOB_MIN_BACKOFF_INTERVAL
init|=
literal|3
operator|*
literal|1000
decl_stmt|;
DECL|field|DEFAULT_COPYBLOB_MAX_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_COPYBLOB_MAX_BACKOFF_INTERVAL
init|=
literal|90
operator|*
literal|1000
decl_stmt|;
DECL|field|DEFAULT_COPYBLOB_BACKOFF_INTERVAL
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_COPYBLOB_BACKOFF_INTERVAL
init|=
literal|30
operator|*
literal|1000
decl_stmt|;
DECL|field|DEFAULT_COPYBLOB_MAX_RETRY_ATTEMPTS
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_COPYBLOB_MAX_RETRY_ATTEMPTS
init|=
literal|15
decl_stmt|;
comment|// Self-throttling defaults. Allowed range = (0,1.0]
comment|// Value of 1.0 means no self-throttling.
comment|// Value of x means process data at factor x of unrestricted rate
DECL|field|DEFAULT_SELF_THROTTLE_ENABLE
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_SELF_THROTTLE_ENABLE
init|=
literal|true
decl_stmt|;
DECL|field|DEFAULT_SELF_THROTTLE_READ_FACTOR
specifier|private
specifier|static
specifier|final
name|float
name|DEFAULT_SELF_THROTTLE_READ_FACTOR
init|=
literal|1.0f
decl_stmt|;
DECL|field|DEFAULT_SELF_THROTTLE_WRITE_FACTOR
specifier|private
specifier|static
specifier|final
name|float
name|DEFAULT_SELF_THROTTLE_WRITE_FACTOR
init|=
literal|1.0f
decl_stmt|;
DECL|field|STORAGE_CONNECTION_TIMEOUT_DEFAULT
specifier|private
specifier|static
specifier|final
name|int
name|STORAGE_CONNECTION_TIMEOUT_DEFAULT
init|=
literal|90
decl_stmt|;
comment|/**    * Default values to control SAS Key mode.    * By default we set the values to false.    */
DECL|field|DEFAULT_USE_SECURE_MODE
specifier|public
specifier|static
specifier|final
name|boolean
name|DEFAULT_USE_SECURE_MODE
init|=
literal|false
decl_stmt|;
DECL|field|DEFAULT_USE_LOCAL_SAS_KEY_MODE
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_USE_LOCAL_SAS_KEY_MODE
init|=
literal|false
decl_stmt|;
comment|/**    * Enable flat listing of blobs as default option. This is useful only if    * listing depth is AZURE_UNBOUNDED_DEPTH.    */
DECL|field|DEFAULT_ENABLE_FLAT_LISTING
specifier|public
specifier|static
specifier|final
name|boolean
name|DEFAULT_ENABLE_FLAT_LISTING
init|=
literal|false
decl_stmt|;
comment|/**    * MEMBER VARIABLES    */
DECL|field|sessionUri
specifier|private
name|URI
name|sessionUri
decl_stmt|;
DECL|field|sessionConfiguration
specifier|private
name|Configuration
name|sessionConfiguration
decl_stmt|;
DECL|field|concurrentWrites
specifier|private
name|int
name|concurrentWrites
init|=
name|DEFAULT_CONCURRENT_WRITES
decl_stmt|;
DECL|field|isAnonymousCredentials
specifier|private
name|boolean
name|isAnonymousCredentials
init|=
literal|false
decl_stmt|;
comment|// Set to true if we are connecting using shared access signatures.
DECL|field|connectingUsingSAS
specifier|private
name|boolean
name|connectingUsingSAS
init|=
literal|false
decl_stmt|;
DECL|field|instrumentation
specifier|private
name|AzureFileSystemInstrumentation
name|instrumentation
decl_stmt|;
DECL|field|bandwidthGaugeUpdater
specifier|private
name|BandwidthGaugeUpdater
name|bandwidthGaugeUpdater
decl_stmt|;
DECL|field|PERMISSION_JSON_SERIALIZER
specifier|private
specifier|final
specifier|static
name|JSON
name|PERMISSION_JSON_SERIALIZER
init|=
name|createPermissionJsonSerializer
argument_list|()
decl_stmt|;
DECL|field|suppressRetryPolicy
specifier|private
name|boolean
name|suppressRetryPolicy
init|=
literal|false
decl_stmt|;
DECL|field|canCreateOrModifyContainer
specifier|private
name|boolean
name|canCreateOrModifyContainer
init|=
literal|false
decl_stmt|;
DECL|field|currentKnownContainerState
specifier|private
name|ContainerState
name|currentKnownContainerState
init|=
name|ContainerState
operator|.
name|Unknown
decl_stmt|;
DECL|field|containerStateLock
specifier|private
specifier|final
name|Object
name|containerStateLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
DECL|field|tolerateOobAppends
specifier|private
name|boolean
name|tolerateOobAppends
init|=
name|DEFAULT_READ_TOLERATE_CONCURRENT_APPEND
decl_stmt|;
DECL|field|downloadBlockSizeBytes
specifier|private
name|int
name|downloadBlockSizeBytes
init|=
name|DEFAULT_DOWNLOAD_BLOCK_SIZE
decl_stmt|;
DECL|field|uploadBlockSizeBytes
specifier|private
name|int
name|uploadBlockSizeBytes
init|=
name|DEFAULT_UPLOAD_BLOCK_SIZE
decl_stmt|;
comment|// Bandwidth throttling exponential back-off parameters
comment|//
DECL|field|minBackoff
specifier|private
name|int
name|minBackoff
decl_stmt|;
comment|// the minimum back-off interval (ms) between retries.
DECL|field|maxBackoff
specifier|private
name|int
name|maxBackoff
decl_stmt|;
comment|// the maximum back-off interval (ms) between retries.
DECL|field|deltaBackoff
specifier|private
name|int
name|deltaBackoff
decl_stmt|;
comment|// the back-off interval (ms) between retries.
DECL|field|maxRetries
specifier|private
name|int
name|maxRetries
decl_stmt|;
comment|// the maximum number of retry attempts.
comment|// Self-throttling parameters
DECL|field|selfThrottlingEnabled
specifier|private
name|boolean
name|selfThrottlingEnabled
decl_stmt|;
DECL|field|selfThrottlingReadFactor
specifier|private
name|float
name|selfThrottlingReadFactor
decl_stmt|;
DECL|field|selfThrottlingWriteFactor
specifier|private
name|float
name|selfThrottlingWriteFactor
decl_stmt|;
DECL|field|testHookOperationContext
specifier|private
name|TestHookOperationContext
name|testHookOperationContext
init|=
literal|null
decl_stmt|;
comment|// Set if we're running against a storage emulator..
DECL|field|isStorageEmulator
specifier|private
name|boolean
name|isStorageEmulator
init|=
literal|false
decl_stmt|;
comment|// Configs controlling WASB SAS key mode.
DECL|field|useSecureMode
specifier|private
name|boolean
name|useSecureMode
init|=
literal|false
decl_stmt|;
DECL|field|useLocalSasKeyMode
specifier|private
name|boolean
name|useLocalSasKeyMode
init|=
literal|false
decl_stmt|;
DECL|field|delegationToken
specifier|private
name|String
name|delegationToken
decl_stmt|;
comment|/** The error message template when container is not accessible. */
DECL|field|NO_ACCESS_TO_CONTAINER_MSG
specifier|static
specifier|final
name|String
name|NO_ACCESS_TO_CONTAINER_MSG
init|=
literal|"No credentials found for "
operator|+
literal|"account %s in the configuration, and its container %s is not "
operator|+
literal|"accessible using anonymous credentials. Please check if the container "
operator|+
literal|"exists first. If it is not publicly available, you have to provide "
operator|+
literal|"account credentials."
decl_stmt|;
comment|/**    * A test hook interface that can modify the operation context we use for    * Azure Storage operations, e.g. to inject errors.    */
annotation|@
name|VisibleForTesting
DECL|interface|TestHookOperationContext
interface|interface
name|TestHookOperationContext
block|{
DECL|method|modifyOperationContext (OperationContext original)
name|OperationContext
name|modifyOperationContext
parameter_list|(
name|OperationContext
name|original
parameter_list|)
function_decl|;
block|}
comment|/**    * Suppress the default retry policy for the Storage, useful in unit tests to    * test negative cases without waiting forever.    */
annotation|@
name|VisibleForTesting
DECL|method|suppressRetryPolicy ()
name|void
name|suppressRetryPolicy
parameter_list|()
block|{
name|suppressRetryPolicy
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Add a test hook to modify the operation context we use for Azure Storage    * operations.    *     * @param testHook    *          The test hook, or null to unset previous hooks.    */
annotation|@
name|VisibleForTesting
DECL|method|addTestHookToOperationContext (TestHookOperationContext testHook)
name|void
name|addTestHookToOperationContext
parameter_list|(
name|TestHookOperationContext
name|testHook
parameter_list|)
block|{
name|this
operator|.
name|testHookOperationContext
operator|=
name|testHook
expr_stmt|;
block|}
comment|/**    * If we're asked by unit tests to not retry, set the retry policy factory in    * the client accordingly.    */
DECL|method|suppressRetryPolicyInClientIfNeeded ()
specifier|private
name|void
name|suppressRetryPolicyInClientIfNeeded
parameter_list|()
block|{
if|if
condition|(
name|suppressRetryPolicy
condition|)
block|{
name|storageInteractionLayer
operator|.
name|setRetryPolicyFactory
argument_list|(
operator|new
name|RetryNoRetry
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Creates a JSON serializer that can serialize a PermissionStatus object into    * the JSON string we want in the blob metadata.    *     * @return The JSON serializer.    */
DECL|method|createPermissionJsonSerializer ()
specifier|private
specifier|static
name|JSON
name|createPermissionJsonSerializer
parameter_list|()
block|{
name|JSON
name|serializer
init|=
operator|new
name|JSON
argument_list|()
decl_stmt|;
name|serializer
operator|.
name|addConvertor
argument_list|(
name|PermissionStatus
operator|.
name|class
argument_list|,
operator|new
name|PermissionStatusJsonSerializer
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|serializer
return|;
block|}
comment|/**    * A converter for PermissionStatus to/from JSON as we want it in the blob    * metadata.    */
DECL|class|PermissionStatusJsonSerializer
specifier|private
specifier|static
class|class
name|PermissionStatusJsonSerializer
implements|implements
name|JSON
operator|.
name|Convertor
block|{
DECL|field|OWNER_TAG
specifier|private
specifier|static
specifier|final
name|String
name|OWNER_TAG
init|=
literal|"owner"
decl_stmt|;
DECL|field|GROUP_TAG
specifier|private
specifier|static
specifier|final
name|String
name|GROUP_TAG
init|=
literal|"group"
decl_stmt|;
DECL|field|PERMISSIONS_TAG
specifier|private
specifier|static
specifier|final
name|String
name|PERMISSIONS_TAG
init|=
literal|"permissions"
decl_stmt|;
annotation|@
name|Override
DECL|method|toJSON (Object obj, JSON.Output out)
specifier|public
name|void
name|toJSON
parameter_list|(
name|Object
name|obj
parameter_list|,
name|JSON
operator|.
name|Output
name|out
parameter_list|)
block|{
name|PermissionStatus
name|permissionStatus
init|=
operator|(
name|PermissionStatus
operator|)
name|obj
decl_stmt|;
comment|// Don't store group as null, just store it as empty string
comment|// (which is FileStatus behavior).
name|String
name|group
init|=
name|permissionStatus
operator|.
name|getGroupName
argument_list|()
operator|==
literal|null
condition|?
literal|""
else|:
name|permissionStatus
operator|.
name|getGroupName
argument_list|()
decl_stmt|;
name|out
operator|.
name|add
argument_list|(
name|OWNER_TAG
argument_list|,
name|permissionStatus
operator|.
name|getUserName
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|add
argument_list|(
name|GROUP_TAG
argument_list|,
name|group
argument_list|)
expr_stmt|;
name|out
operator|.
name|add
argument_list|(
name|PERMISSIONS_TAG
argument_list|,
name|permissionStatus
operator|.
name|getPermission
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|fromJSON (@uppressWarningsR) Map object)
specifier|public
name|Object
name|fromJSON
parameter_list|(
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
name|Map
name|object
parameter_list|)
block|{
return|return
name|PermissionStatusJsonSerializer
operator|.
name|fromJSONMap
argument_list|(
name|object
argument_list|)
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
DECL|method|fromJSONString (String jsonString)
specifier|public
specifier|static
name|PermissionStatus
name|fromJSONString
parameter_list|(
name|String
name|jsonString
parameter_list|)
block|{
comment|// The JSON class can only find out about an object's class (and call me)
comment|// if we store the class name in the JSON string. Since I don't want to
comment|// do that (it's an implementation detail), I just deserialize as a
comment|// the default Map (JSON's default behavior) and parse that.
return|return
name|fromJSONMap
argument_list|(
operator|(
name|Map
operator|)
name|PERMISSION_JSON_SERIALIZER
operator|.
name|fromJSON
argument_list|(
name|jsonString
argument_list|)
argument_list|)
return|;
block|}
DECL|method|fromJSONMap ( @uppressWarningsR) Map object)
specifier|private
specifier|static
name|PermissionStatus
name|fromJSONMap
parameter_list|(
annotation|@
name|SuppressWarnings
argument_list|(
literal|"rawtypes"
argument_list|)
name|Map
name|object
parameter_list|)
block|{
return|return
operator|new
name|PermissionStatus
argument_list|(
operator|(
name|String
operator|)
name|object
operator|.
name|get
argument_list|(
name|OWNER_TAG
argument_list|)
argument_list|,
operator|(
name|String
operator|)
name|object
operator|.
name|get
argument_list|(
name|GROUP_TAG
argument_list|)
argument_list|,
comment|// The initial - below is the Unix file type,
comment|// which FsPermission needs there but ignores.
name|FsPermission
operator|.
name|valueOf
argument_list|(
literal|"-"
operator|+
operator|(
name|String
operator|)
name|object
operator|.
name|get
argument_list|(
name|PERMISSIONS_TAG
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
block|}
annotation|@
name|VisibleForTesting
DECL|method|setAzureStorageInteractionLayer (StorageInterface storageInteractionLayer)
name|void
name|setAzureStorageInteractionLayer
parameter_list|(
name|StorageInterface
name|storageInteractionLayer
parameter_list|)
block|{
name|this
operator|.
name|storageInteractionLayer
operator|=
name|storageInteractionLayer
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getBandwidthGaugeUpdater ()
specifier|public
name|BandwidthGaugeUpdater
name|getBandwidthGaugeUpdater
parameter_list|()
block|{
return|return
name|bandwidthGaugeUpdater
return|;
block|}
comment|/**    * Check if concurrent reads and writes on the same blob are allowed.    *     * @return true if concurrent reads and OOB writes has been configured, false    *         otherwise.    */
DECL|method|isConcurrentOOBAppendAllowed ()
specifier|private
name|boolean
name|isConcurrentOOBAppendAllowed
parameter_list|()
block|{
return|return
name|tolerateOobAppends
return|;
block|}
comment|/**    * Method for the URI and configuration object necessary to create a storage    * session with an Azure session. It parses the scheme to ensure it matches    * the storage protocol supported by this file system.    *     * @param uri - URI for target storage blob.    * @param conf - reference to configuration object.    * @param instrumentation - the metrics source that will keep track of operations here.    *     * @throws IllegalArgumentException if URI or job object is null, or invalid scheme.    */
annotation|@
name|Override
DECL|method|initialize (URI uri, Configuration conf, AzureFileSystemInstrumentation instrumentation)
specifier|public
name|void
name|initialize
parameter_list|(
name|URI
name|uri
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|AzureFileSystemInstrumentation
name|instrumentation
parameter_list|)
throws|throws
name|IllegalArgumentException
throws|,
name|AzureException
throws|,
name|IOException
block|{
if|if
condition|(
literal|null
operator|==
name|instrumentation
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Null instrumentation"
argument_list|)
throw|;
block|}
name|this
operator|.
name|instrumentation
operator|=
name|instrumentation
expr_stmt|;
comment|// Check that URI exists.
comment|//
if|if
condition|(
literal|null
operator|==
name|uri
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Cannot initialize WASB file system, URI is null"
argument_list|)
throw|;
block|}
comment|// Check that configuration object is non-null.
comment|//
if|if
condition|(
literal|null
operator|==
name|conf
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Cannot initialize WASB file system, conf is null"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
name|NativeAzureFileSystem
operator|.
name|SKIP_AZURE_METRICS_PROPERTY_NAME
argument_list|,
literal|false
argument_list|)
condition|)
block|{
comment|//If not skip azure metrics, create bandwidthGaugeUpdater
name|this
operator|.
name|bandwidthGaugeUpdater
operator|=
operator|new
name|BandwidthGaugeUpdater
argument_list|(
name|instrumentation
argument_list|)
expr_stmt|;
block|}
comment|// Incoming parameters validated. Capture the URI and the job configuration
comment|// object.
comment|//
name|sessionUri
operator|=
name|uri
expr_stmt|;
name|sessionConfiguration
operator|=
name|conf
expr_stmt|;
name|useSecureMode
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|KEY_USE_SECURE_MODE
argument_list|,
name|DEFAULT_USE_SECURE_MODE
argument_list|)
expr_stmt|;
name|useLocalSasKeyMode
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|KEY_USE_LOCAL_SAS_KEY_MODE
argument_list|,
name|DEFAULT_USE_LOCAL_SAS_KEY_MODE
argument_list|)
expr_stmt|;
if|if
condition|(
literal|null
operator|==
name|this
operator|.
name|storageInteractionLayer
condition|)
block|{
if|if
condition|(
operator|!
name|useSecureMode
condition|)
block|{
name|this
operator|.
name|storageInteractionLayer
operator|=
operator|new
name|StorageInterfaceImpl
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|storageInteractionLayer
operator|=
operator|new
name|SecureStorageInterfaceImpl
argument_list|(
name|useLocalSasKeyMode
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Configure Azure storage session.
name|configureAzureStorageSession
argument_list|()
expr_stmt|;
comment|// Start an Azure storage session.
comment|//
name|createAzureStorageSession
argument_list|()
expr_stmt|;
comment|// Extract the directories that should contain page blobs
name|pageBlobDirs
operator|=
name|getDirectorySet
argument_list|(
name|KEY_PAGE_BLOB_DIRECTORIES
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Page blob directories:  {}"
argument_list|,
name|setToString
argument_list|(
name|pageBlobDirs
argument_list|)
argument_list|)
expr_stmt|;
comment|// Extract directories that should have atomic rename applied.
name|atomicRenameDirs
operator|=
name|getDirectorySet
argument_list|(
name|KEY_ATOMIC_RENAME_DIRECTORIES
argument_list|)
expr_stmt|;
name|String
name|hbaseRoot
decl_stmt|;
try|try
block|{
comment|// Add to this the hbase root directory, or /hbase is that is not set.
name|hbaseRoot
operator|=
name|verifyAndConvertToStandardFormat
argument_list|(
name|sessionConfiguration
operator|.
name|get
argument_list|(
literal|"hbase.rootdir"
argument_list|,
literal|"hbase"
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|hbaseRoot
operator|!=
literal|null
condition|)
block|{
name|atomicRenameDirs
operator|.
name|add
argument_list|(
name|hbaseRoot
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to initialize HBase root as an atomic rename directory."
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Atomic rename directories: {} "
argument_list|,
name|setToString
argument_list|(
name|atomicRenameDirs
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Helper to format a string for log output from Set<String>    */
DECL|method|setToString (Set<String> set)
specifier|private
name|String
name|setToString
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|set
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|i
init|=
literal|1
decl_stmt|;
for|for
control|(
name|String
name|s
range|:
name|set
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"/"
operator|+
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|!=
name|set
operator|.
name|size
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
block|}
name|i
operator|++
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Method to extract the account name from an Azure URI.    *     * @param uri    *          -- WASB blob URI    * @returns accountName -- the account name for the URI.    * @throws URISyntaxException    *           if the URI does not have an authority it is badly formed.    */
DECL|method|getAccountFromAuthority (URI uri)
specifier|private
name|String
name|getAccountFromAuthority
parameter_list|(
name|URI
name|uri
parameter_list|)
throws|throws
name|URISyntaxException
block|{
comment|// Check to make sure that the authority is valid for the URI.
comment|//
name|String
name|authority
init|=
name|uri
operator|.
name|getRawAuthority
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|authority
condition|)
block|{
comment|// Badly formed or illegal URI.
comment|//
throw|throw
operator|new
name|URISyntaxException
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|,
literal|"Expected URI with a valid authority"
argument_list|)
throw|;
block|}
comment|// Check if authority container the delimiter separating the account name from the
comment|// the container.
comment|//
if|if
condition|(
operator|!
name|authority
operator|.
name|contains
argument_list|(
name|WASB_AUTHORITY_DELIMITER
argument_list|)
condition|)
block|{
return|return
name|authority
return|;
block|}
comment|// Split off the container name and the authority.
comment|//
name|String
index|[]
name|authorityParts
init|=
name|authority
operator|.
name|split
argument_list|(
name|WASB_AUTHORITY_DELIMITER
argument_list|,
literal|2
argument_list|)
decl_stmt|;
comment|// Because the string contains an '@' delimiter, a container must be
comment|// specified.
comment|//
if|if
condition|(
name|authorityParts
operator|.
name|length
operator|<
literal|2
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|authorityParts
index|[
literal|0
index|]
argument_list|)
condition|)
block|{
comment|// Badly formed WASB authority since there is no container.
comment|//
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"URI '%s' has a malformed WASB authority, expected container name. "
operator|+
literal|"Authority takes the form wasb://[<container name>@]<account name>"
argument_list|,
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Return with the account name. It is possible that this name is NULL.
comment|//
return|return
name|authorityParts
index|[
literal|1
index|]
return|;
block|}
comment|/**    * Method to extract the container name from an Azure URI.    *     * @param uri    *          -- WASB blob URI    * @returns containerName -- the container name for the URI. May be null.    * @throws URISyntaxException    *           if the uri does not have an authority it is badly formed.    */
DECL|method|getContainerFromAuthority (URI uri)
specifier|private
name|String
name|getContainerFromAuthority
parameter_list|(
name|URI
name|uri
parameter_list|)
throws|throws
name|URISyntaxException
block|{
comment|// Check to make sure that the authority is valid for the URI.
comment|//
name|String
name|authority
init|=
name|uri
operator|.
name|getRawAuthority
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|authority
condition|)
block|{
comment|// Badly formed or illegal URI.
comment|//
throw|throw
operator|new
name|URISyntaxException
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|,
literal|"Expected URI with a valid authority"
argument_list|)
throw|;
block|}
comment|// The URI has a valid authority. Extract the container name. It is the
comment|// second component of the WASB URI authority.
if|if
condition|(
operator|!
name|authority
operator|.
name|contains
argument_list|(
name|WASB_AUTHORITY_DELIMITER
argument_list|)
condition|)
block|{
comment|// The authority does not have a container name. Use the default container by
comment|// setting the container name to the default Azure root container.
comment|//
return|return
name|AZURE_ROOT_CONTAINER
return|;
block|}
comment|// Split off the container name and the authority.
name|String
index|[]
name|authorityParts
init|=
name|authority
operator|.
name|split
argument_list|(
name|WASB_AUTHORITY_DELIMITER
argument_list|,
literal|2
argument_list|)
decl_stmt|;
comment|// Because the string contains an '@' delimiter, a container must be
comment|// specified.
if|if
condition|(
name|authorityParts
operator|.
name|length
operator|<
literal|2
operator|||
literal|""
operator|.
name|equals
argument_list|(
name|authorityParts
index|[
literal|0
index|]
argument_list|)
condition|)
block|{
comment|// Badly formed WASB authority since there is no container.
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"URI '%s' has a malformed WASB authority, expected container name."
operator|+
literal|"Authority takes the form wasb://[<container name>@]<account name>"
argument_list|,
name|uri
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Set the container name from the first entry for the split parts of the
comment|// authority.
return|return
name|authorityParts
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Get the appropriate return the appropriate scheme for communicating with    * Azure depending on whether wasb or wasbs is specified in the target URI.    *     * return scheme - HTTPS or HTTP as appropriate.    */
DECL|method|getHTTPScheme ()
specifier|private
name|String
name|getHTTPScheme
parameter_list|()
block|{
name|String
name|sessionScheme
init|=
name|sessionUri
operator|.
name|getScheme
argument_list|()
decl_stmt|;
comment|// Check if we're on a secure URI scheme: wasbs or the legacy asvs scheme.
if|if
condition|(
name|sessionScheme
operator|!=
literal|null
operator|&&
operator|(
name|sessionScheme
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"asvs"
argument_list|)
operator|||
name|sessionScheme
operator|.
name|equalsIgnoreCase
argument_list|(
literal|"wasbs"
argument_list|)
operator|)
condition|)
block|{
return|return
name|HTTPS_SCHEME
return|;
block|}
else|else
block|{
comment|// At this point the scheme should be either null or asv or wasb.
comment|// Intentionally I'm not going to validate it though since I don't feel
comment|// it's this method's job to ensure a valid URI scheme for this file
comment|// system.
return|return
name|HTTP_SCHEME
return|;
block|}
block|}
comment|/**    * Set the configuration parameters for this client storage session with    * Azure.    *     * @throws AzureException    */
DECL|method|configureAzureStorageSession ()
specifier|private
name|void
name|configureAzureStorageSession
parameter_list|()
throws|throws
name|AzureException
block|{
comment|// Assertion: Target session URI already should have been captured.
if|if
condition|(
name|sessionUri
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Expected a non-null session URI when configuring storage session"
argument_list|)
throw|;
block|}
comment|// Assertion: A client session already should have been established with
comment|// Azure.
if|if
condition|(
name|storageInteractionLayer
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Cannot configure storage session for URI '%s' "
operator|+
literal|"if storage session has not been established."
argument_list|,
name|sessionUri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
comment|// Determine whether or not reads are allowed concurrent with OOB writes.
name|tolerateOobAppends
operator|=
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_READ_TOLERATE_CONCURRENT_APPEND
argument_list|,
name|DEFAULT_READ_TOLERATE_CONCURRENT_APPEND
argument_list|)
expr_stmt|;
comment|// Retrieve configuration for the minimum stream read and write block size.
comment|//
name|this
operator|.
name|downloadBlockSizeBytes
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_STREAM_MIN_READ_SIZE
argument_list|,
name|DEFAULT_DOWNLOAD_BLOCK_SIZE
argument_list|)
expr_stmt|;
name|this
operator|.
name|uploadBlockSizeBytes
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_WRITE_BLOCK_SIZE
argument_list|,
name|DEFAULT_UPLOAD_BLOCK_SIZE
argument_list|)
expr_stmt|;
comment|// The job may want to specify a timeout to use when engaging the
comment|// storage service. The default is currently 90 seconds. It may
comment|// be necessary to increase this value for long latencies in larger
comment|// jobs. If the timeout specified is greater than zero seconds use
comment|// it, otherwise use the default service client timeout.
name|int
name|storageConnectionTimeout
init|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_STORAGE_CONNECTION_TIMEOUT
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
literal|0
operator|<
name|storageConnectionTimeout
condition|)
block|{
name|storageInteractionLayer
operator|.
name|setTimeoutInMs
argument_list|(
name|storageConnectionTimeout
operator|*
literal|1000
argument_list|)
expr_stmt|;
block|}
comment|// Set the concurrency values equal to the that specified in the
comment|// configuration file. If it does not exist, set it to the default
comment|// value calculated as double the number of CPU cores on the client
comment|// machine. The concurrency value is minimum of double the cores and
comment|// the read/write property.
name|int
name|cpuCores
init|=
literal|2
operator|*
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|availableProcessors
argument_list|()
decl_stmt|;
name|concurrentWrites
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_CONCURRENT_CONNECTION_VALUE_OUT
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|cpuCores
argument_list|,
name|DEFAULT_CONCURRENT_WRITES
argument_list|)
argument_list|)
expr_stmt|;
comment|// Set up the exponential retry policy.
comment|//
name|minBackoff
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_MIN_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_MIN_BACKOFF_INTERVAL
argument_list|)
expr_stmt|;
name|maxBackoff
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_MAX_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_MAX_BACKOFF_INTERVAL
argument_list|)
expr_stmt|;
name|deltaBackoff
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_BACKOFF_INTERVAL
argument_list|)
expr_stmt|;
name|maxRetries
operator|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_MAX_IO_RETRIES
argument_list|,
name|DEFAULT_MAX_RETRY_ATTEMPTS
argument_list|)
expr_stmt|;
name|storageInteractionLayer
operator|.
name|setRetryPolicyFactory
argument_list|(
operator|new
name|RetryExponentialRetry
argument_list|(
name|minBackoff
argument_list|,
name|deltaBackoff
argument_list|,
name|maxBackoff
argument_list|,
name|maxRetries
argument_list|)
argument_list|)
expr_stmt|;
comment|// read the self-throttling config.
name|selfThrottlingEnabled
operator|=
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_SELF_THROTTLE_ENABLE
argument_list|,
name|DEFAULT_SELF_THROTTLE_ENABLE
argument_list|)
expr_stmt|;
name|selfThrottlingReadFactor
operator|=
name|sessionConfiguration
operator|.
name|getFloat
argument_list|(
name|KEY_SELF_THROTTLE_READ_FACTOR
argument_list|,
name|DEFAULT_SELF_THROTTLE_READ_FACTOR
argument_list|)
expr_stmt|;
name|selfThrottlingWriteFactor
operator|=
name|sessionConfiguration
operator|.
name|getFloat
argument_list|(
name|KEY_SELF_THROTTLE_WRITE_FACTOR
argument_list|,
name|DEFAULT_SELF_THROTTLE_WRITE_FACTOR
argument_list|)
expr_stmt|;
name|OperationContext
operator|.
name|setLoggingEnabledByDefault
argument_list|(
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_ENABLE_STORAGE_CLIENT_LOGGING
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"AzureNativeFileSystemStore init. Settings={},{},{},{{},{},{},{}},{{},{},{}}"
argument_list|,
name|concurrentWrites
argument_list|,
name|tolerateOobAppends
argument_list|,
operator|(
operator|(
name|storageConnectionTimeout
operator|>
literal|0
operator|)
condition|?
name|storageConnectionTimeout
else|:
name|STORAGE_CONNECTION_TIMEOUT_DEFAULT
operator|)
argument_list|,
name|minBackoff
argument_list|,
name|deltaBackoff
argument_list|,
name|maxBackoff
argument_list|,
name|maxRetries
argument_list|,
name|selfThrottlingEnabled
argument_list|,
name|selfThrottlingReadFactor
argument_list|,
name|selfThrottlingWriteFactor
argument_list|)
expr_stmt|;
block|}
comment|/**    * Connect to Azure storage using anonymous credentials.    *     * @param uri    *          - URI to target blob (R/O access to public blob)    *     * @throws StorageException    *           raised on errors communicating with Azure storage.    * @throws IOException    *           raised on errors performing I/O or setting up the session.    * @throws URISyntaxException    *           raised on creating mal-formed URI's.    */
DECL|method|connectUsingAnonymousCredentials (final URI uri)
specifier|private
name|void
name|connectUsingAnonymousCredentials
parameter_list|(
specifier|final
name|URI
name|uri
parameter_list|)
throws|throws
name|StorageException
throws|,
name|IOException
throws|,
name|URISyntaxException
block|{
comment|// Use an HTTP scheme since the URI specifies a publicly accessible
comment|// container. Explicitly create a storage URI corresponding to the URI
comment|// parameter for use in creating the service client.
name|String
name|accountName
init|=
name|getAccountFromAuthority
argument_list|(
name|uri
argument_list|)
decl_stmt|;
name|URI
name|storageUri
init|=
operator|new
name|URI
argument_list|(
name|getHTTPScheme
argument_list|()
operator|+
literal|":"
operator|+
name|PATH_DELIMITER
operator|+
name|PATH_DELIMITER
operator|+
name|accountName
argument_list|)
decl_stmt|;
comment|// Create the service client with anonymous credentials.
name|String
name|containerName
init|=
name|getContainerFromAuthority
argument_list|(
name|uri
argument_list|)
decl_stmt|;
name|storageInteractionLayer
operator|.
name|createBlobClient
argument_list|(
name|storageUri
argument_list|)
expr_stmt|;
name|suppressRetryPolicyInClientIfNeeded
argument_list|()
expr_stmt|;
comment|// Capture the container reference.
name|container
operator|=
name|storageInteractionLayer
operator|.
name|getContainerReference
argument_list|(
name|containerName
argument_list|)
expr_stmt|;
name|rootDirectory
operator|=
name|container
operator|.
name|getDirectoryReference
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// Check for container existence, and our ability to access it.
name|boolean
name|canAccess
decl_stmt|;
try|try
block|{
name|canAccess
operator|=
name|container
operator|.
name|exists
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Service returned StorageException when checking existence "
operator|+
literal|"of container {} in account {}"
argument_list|,
name|containerName
argument_list|,
name|accountName
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|canAccess
operator|=
literal|false
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|canAccess
condition|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|String
operator|.
name|format
argument_list|(
name|NO_ACCESS_TO_CONTAINER_MSG
argument_list|,
name|accountName
argument_list|,
name|containerName
argument_list|)
argument_list|)
throw|;
block|}
comment|// Accessing the storage server unauthenticated using
comment|// anonymous credentials.
name|isAnonymousCredentials
operator|=
literal|true
expr_stmt|;
block|}
DECL|method|connectUsingCredentials (String accountName, StorageCredentials credentials, String containerName)
specifier|private
name|void
name|connectUsingCredentials
parameter_list|(
name|String
name|accountName
parameter_list|,
name|StorageCredentials
name|credentials
parameter_list|,
name|String
name|containerName
parameter_list|)
throws|throws
name|URISyntaxException
throws|,
name|StorageException
throws|,
name|AzureException
block|{
name|URI
name|blobEndPoint
decl_stmt|;
if|if
condition|(
name|isStorageEmulatorAccount
argument_list|(
name|accountName
argument_list|)
condition|)
block|{
name|isStorageEmulator
operator|=
literal|true
expr_stmt|;
name|CloudStorageAccount
name|account
init|=
name|CloudStorageAccount
operator|.
name|getDevelopmentStorageAccount
argument_list|()
decl_stmt|;
name|storageInteractionLayer
operator|.
name|createBlobClient
argument_list|(
name|account
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|blobEndPoint
operator|=
operator|new
name|URI
argument_list|(
name|getHTTPScheme
argument_list|()
operator|+
literal|"://"
operator|+
name|accountName
argument_list|)
expr_stmt|;
name|storageInteractionLayer
operator|.
name|createBlobClient
argument_list|(
name|blobEndPoint
argument_list|,
name|credentials
argument_list|)
expr_stmt|;
block|}
name|suppressRetryPolicyInClientIfNeeded
argument_list|()
expr_stmt|;
comment|// Capture the container reference for debugging purposes.
name|container
operator|=
name|storageInteractionLayer
operator|.
name|getContainerReference
argument_list|(
name|containerName
argument_list|)
expr_stmt|;
name|rootDirectory
operator|=
name|container
operator|.
name|getDirectoryReference
argument_list|(
literal|""
argument_list|)
expr_stmt|;
comment|// Can only create container if using account key credentials
name|canCreateOrModifyContainer
operator|=
name|credentials
operator|instanceof
name|StorageCredentialsAccountAndKey
expr_stmt|;
block|}
comment|/**    * Method to set up the Storage Interaction layer in Secure mode.    * @param accountName - Storage account provided in the initializer    * @param containerName - Container name provided in the initializer    * @param sessionUri - URI provided in the initializer    */
DECL|method|connectToAzureStorageInSecureMode (String accountName, String containerName, URI sessionUri)
specifier|private
name|void
name|connectToAzureStorageInSecureMode
parameter_list|(
name|String
name|accountName
parameter_list|,
name|String
name|containerName
parameter_list|,
name|URI
name|sessionUri
parameter_list|)
throws|throws
name|AzureException
throws|,
name|StorageException
throws|,
name|URISyntaxException
block|{
comment|// Assertion: storageInteractionLayer instance has to be a SecureStorageInterfaceImpl
if|if
condition|(
operator|!
operator|(
name|this
operator|.
name|storageInteractionLayer
operator|instanceof
name|SecureStorageInterfaceImpl
operator|)
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"connectToAzureStorageInSASKeyMode() should be called only"
operator|+
literal|" for SecureStorageInterfaceImpl instances"
argument_list|)
throw|;
block|}
operator|(
operator|(
name|SecureStorageInterfaceImpl
operator|)
name|this
operator|.
name|storageInteractionLayer
operator|)
operator|.
name|setStorageAccountName
argument_list|(
name|accountName
argument_list|)
expr_stmt|;
name|container
operator|=
name|storageInteractionLayer
operator|.
name|getContainerReference
argument_list|(
name|containerName
argument_list|)
expr_stmt|;
name|rootDirectory
operator|=
name|container
operator|.
name|getDirectoryReference
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|canCreateOrModifyContainer
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Connect to Azure storage using account key credentials.    */
DECL|method|connectUsingConnectionStringCredentials ( final String accountName, final String containerName, final String accountKey)
specifier|private
name|void
name|connectUsingConnectionStringCredentials
parameter_list|(
specifier|final
name|String
name|accountName
parameter_list|,
specifier|final
name|String
name|containerName
parameter_list|,
specifier|final
name|String
name|accountKey
parameter_list|)
throws|throws
name|InvalidKeyException
throws|,
name|StorageException
throws|,
name|IOException
throws|,
name|URISyntaxException
block|{
comment|// If the account name is "acc.blob.core.windows.net", then the
comment|// rawAccountName is just "acc"
name|String
name|rawAccountName
init|=
name|accountName
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
index|[
literal|0
index|]
decl_stmt|;
name|StorageCredentials
name|credentials
init|=
operator|new
name|StorageCredentialsAccountAndKey
argument_list|(
name|rawAccountName
argument_list|,
name|accountKey
argument_list|)
decl_stmt|;
name|connectUsingCredentials
argument_list|(
name|accountName
argument_list|,
name|credentials
argument_list|,
name|containerName
argument_list|)
expr_stmt|;
block|}
comment|/**    * Connect to Azure storage using shared access signature credentials.    */
DECL|method|connectUsingSASCredentials (final String accountName, final String containerName, final String sas)
specifier|private
name|void
name|connectUsingSASCredentials
parameter_list|(
specifier|final
name|String
name|accountName
parameter_list|,
specifier|final
name|String
name|containerName
parameter_list|,
specifier|final
name|String
name|sas
parameter_list|)
throws|throws
name|InvalidKeyException
throws|,
name|StorageException
throws|,
name|IOException
throws|,
name|URISyntaxException
block|{
name|StorageCredentials
name|credentials
init|=
operator|new
name|StorageCredentialsSharedAccessSignature
argument_list|(
name|sas
argument_list|)
decl_stmt|;
name|connectingUsingSAS
operator|=
literal|true
expr_stmt|;
name|connectUsingCredentials
argument_list|(
name|accountName
argument_list|,
name|credentials
argument_list|,
name|containerName
argument_list|)
expr_stmt|;
block|}
DECL|method|isStorageEmulatorAccount (final String accountName)
specifier|private
name|boolean
name|isStorageEmulatorAccount
parameter_list|(
specifier|final
name|String
name|accountName
parameter_list|)
block|{
return|return
name|accountName
operator|.
name|equalsIgnoreCase
argument_list|(
name|sessionConfiguration
operator|.
name|get
argument_list|(
name|STORAGE_EMULATOR_ACCOUNT_NAME_PROPERTY_NAME
argument_list|,
name|DEFAULT_STORAGE_EMULATOR_ACCOUNT_NAME
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getAccountKeyFromConfiguration (String accountName, Configuration conf)
specifier|public
specifier|static
name|String
name|getAccountKeyFromConfiguration
parameter_list|(
name|String
name|accountName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|KeyProviderException
block|{
name|String
name|key
init|=
literal|null
decl_stmt|;
name|String
name|keyProviderClass
init|=
name|conf
operator|.
name|get
argument_list|(
name|KEY_ACCOUNT_KEYPROVIDER_PREFIX
operator|+
name|accountName
argument_list|)
decl_stmt|;
name|KeyProvider
name|keyProvider
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|keyProviderClass
operator|==
literal|null
condition|)
block|{
comment|// No key provider was provided so use the provided key as is.
name|keyProvider
operator|=
operator|new
name|SimpleKeyProvider
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// create an instance of the key provider class and verify it
comment|// implements KeyProvider
name|Object
name|keyProviderObject
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
init|=
name|conf
operator|.
name|getClassByName
argument_list|(
name|keyProviderClass
argument_list|)
decl_stmt|;
name|keyProviderObject
operator|=
name|clazz
operator|.
name|newInstance
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|KeyProviderException
argument_list|(
literal|"Unable to load key provider class."
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
operator|(
name|keyProviderObject
operator|instanceof
name|KeyProvider
operator|)
condition|)
block|{
throw|throw
operator|new
name|KeyProviderException
argument_list|(
name|keyProviderClass
operator|+
literal|" specified in config is not a valid KeyProvider class."
argument_list|)
throw|;
block|}
name|keyProvider
operator|=
operator|(
name|KeyProvider
operator|)
name|keyProviderObject
expr_stmt|;
block|}
name|key
operator|=
name|keyProvider
operator|.
name|getStorageAccountKey
argument_list|(
name|accountName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
name|key
return|;
block|}
comment|/**    * Establish a session with Azure blob storage based on the target URI. The    * method determines whether or not the URI target contains an explicit    * account or an implicit default cluster-wide account.    *     * @throws AzureException    * @throws IOException    */
DECL|method|createAzureStorageSession ()
specifier|private
name|void
name|createAzureStorageSession
parameter_list|()
throws|throws
name|AzureException
throws|,
name|IOException
block|{
comment|// Make sure this object was properly initialized with references to
comment|// the sessionUri and sessionConfiguration.
if|if
condition|(
literal|null
operator|==
name|sessionUri
operator|||
literal|null
operator|==
name|sessionConfiguration
condition|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
literal|"Filesystem object not initialized properly."
operator|+
literal|"Unable to start session with Azure Storage server."
argument_list|)
throw|;
block|}
comment|// File system object initialized, attempt to establish a session
comment|// with the Azure storage service for the target URI string.
try|try
block|{
comment|// Inspect the URI authority to determine the account and use the account
comment|// to start an Azure blob client session using an account key for the
comment|// the account or anonymously.
comment|// For all URI's do the following checks in order:
comment|// 1. Validate that<account> can be used with the current Hadoop
comment|// cluster by checking it exists in the list of configured accounts
comment|// for the cluster.
comment|// 2. Look up the AccountKey in the list of configured accounts for the
comment|// cluster.
comment|// 3. If there is no AccountKey, assume anonymous public blob access
comment|// when accessing the blob.
comment|//
comment|// If the URI does not specify a container use the default root container
comment|// under the account name.
comment|// Assertion: Container name on the session Uri should be non-null.
if|if
condition|(
name|getContainerFromAuthority
argument_list|(
name|sessionUri
argument_list|)
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Non-null container expected from session URI: %s."
argument_list|,
name|sessionUri
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
comment|// Get the account name.
name|String
name|accountName
init|=
name|getAccountFromAuthority
argument_list|(
name|sessionUri
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|accountName
condition|)
block|{
comment|// Account name is not specified as part of the URI. Throw indicating
comment|// an invalid account name.
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Cannot load WASB file system account name not"
operator|+
literal|" specified in URI: %s."
argument_list|,
name|sessionUri
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AzureException
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
name|instrumentation
operator|.
name|setAccountName
argument_list|(
name|accountName
argument_list|)
expr_stmt|;
name|String
name|containerName
init|=
name|getContainerFromAuthority
argument_list|(
name|sessionUri
argument_list|)
decl_stmt|;
name|instrumentation
operator|.
name|setContainerName
argument_list|(
name|containerName
argument_list|)
expr_stmt|;
comment|// Check whether this is a storage emulator account.
if|if
condition|(
name|isStorageEmulatorAccount
argument_list|(
name|accountName
argument_list|)
condition|)
block|{
comment|// It is an emulator account, connect to it with no credentials.
name|connectUsingCredentials
argument_list|(
name|accountName
argument_list|,
literal|null
argument_list|,
name|containerName
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// If the securemode flag is set, WASB uses SecureStorageInterfaceImpl instance
comment|// to communicate with Azure storage. In SecureStorageInterfaceImpl SAS keys
comment|// are used to communicate with Azure storage, so connectToAzureStorageInSecureMode
comment|// instantiates the default container using a SAS Key.
if|if
condition|(
name|useSecureMode
condition|)
block|{
name|connectToAzureStorageInSecureMode
argument_list|(
name|accountName
argument_list|,
name|containerName
argument_list|,
name|sessionUri
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Check whether we have a shared access signature for that container.
name|String
name|propertyValue
init|=
name|sessionConfiguration
operator|.
name|get
argument_list|(
name|KEY_ACCOUNT_SAS_PREFIX
operator|+
name|containerName
operator|+
literal|"."
operator|+
name|accountName
argument_list|)
decl_stmt|;
if|if
condition|(
name|propertyValue
operator|!=
literal|null
condition|)
block|{
comment|// SAS was found. Connect using that.
name|connectUsingSASCredentials
argument_list|(
name|accountName
argument_list|,
name|containerName
argument_list|,
name|propertyValue
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Check whether the account is configured with an account key.
name|propertyValue
operator|=
name|getAccountKeyFromConfiguration
argument_list|(
name|accountName
argument_list|,
name|sessionConfiguration
argument_list|)
expr_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|propertyValue
argument_list|)
condition|)
block|{
comment|// Account key was found.
comment|// Create the Azure storage session using the account key and container.
name|connectUsingConnectionStringCredentials
argument_list|(
name|getAccountFromAuthority
argument_list|(
name|sessionUri
argument_list|)
argument_list|,
name|getContainerFromAuthority
argument_list|(
name|sessionUri
argument_list|)
argument_list|,
name|propertyValue
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"The account access key is not configured for {}. "
operator|+
literal|"Now try anonymous access."
argument_list|,
name|sessionUri
argument_list|)
expr_stmt|;
name|connectUsingAnonymousCredentials
argument_list|(
name|sessionUri
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting to initialize the Azure File
comment|// System store, re-throw the exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
DECL|enum|ContainerState
specifier|private
enum|enum
name|ContainerState
block|{
comment|/**      * We haven't checked the container state yet.      */
DECL|enumConstant|Unknown
name|Unknown
block|,
comment|/**      * We checked and the container doesn't exist.      */
DECL|enumConstant|DoesntExist
name|DoesntExist
block|,
comment|/**      * The container exists and doesn't have an WASB version stamp on it.      */
DECL|enumConstant|ExistsNoVersion
name|ExistsNoVersion
block|,
comment|/**      * The container exists and has an unsupported WASB version stamped on it.      */
DECL|enumConstant|ExistsAtWrongVersion
name|ExistsAtWrongVersion
block|,
comment|/**      * The container exists and has the proper WASB version stamped on it.      */
DECL|enumConstant|ExistsAtRightVersion
name|ExistsAtRightVersion
block|}
DECL|enum|ContainerAccessType
specifier|private
enum|enum
name|ContainerAccessType
block|{
comment|/**      * We're accessing the container for a pure read operation, e.g. read a      * file.      */
DECL|enumConstant|PureRead
name|PureRead
block|,
comment|/**      * We're accessing the container purely to write something, e.g. write a      * file.      */
DECL|enumConstant|PureWrite
name|PureWrite
block|,
comment|/**      * We're accessing the container to read something then write, e.g. rename a      * file.      */
DECL|enumConstant|ReadThenWrite
name|ReadThenWrite
block|}
comment|/**    * Trims a suffix/prefix from the given string. For example if    * s is given as "/xy" and toTrim is "/", this method returns "xy"    */
DECL|method|trim (String s, String toTrim)
specifier|private
specifier|static
name|String
name|trim
parameter_list|(
name|String
name|s
parameter_list|,
name|String
name|toTrim
parameter_list|)
block|{
return|return
name|StringUtils
operator|.
name|removeEnd
argument_list|(
name|StringUtils
operator|.
name|removeStart
argument_list|(
name|s
argument_list|,
name|toTrim
argument_list|)
argument_list|,
name|toTrim
argument_list|)
return|;
block|}
comment|/**    * Checks if the given rawDir belongs to this account/container, and    * if so returns the canonicalized path for it. Otherwise return null.    */
DECL|method|verifyAndConvertToStandardFormat (String rawDir)
specifier|private
name|String
name|verifyAndConvertToStandardFormat
parameter_list|(
name|String
name|rawDir
parameter_list|)
throws|throws
name|URISyntaxException
block|{
name|URI
name|asUri
init|=
operator|new
name|URI
argument_list|(
name|rawDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|asUri
operator|.
name|getAuthority
argument_list|()
operator|==
literal|null
operator|||
name|asUri
operator|.
name|getAuthority
argument_list|()
operator|.
name|toLowerCase
argument_list|(
name|Locale
operator|.
name|ENGLISH
argument_list|)
operator|.
name|equalsIgnoreCase
argument_list|(
name|sessionUri
operator|.
name|getAuthority
argument_list|()
operator|.
name|toLowerCase
argument_list|(
name|Locale
operator|.
name|ENGLISH
argument_list|)
argument_list|)
condition|)
block|{
comment|// Applies to me.
return|return
name|trim
argument_list|(
name|asUri
operator|.
name|getPath
argument_list|()
argument_list|,
literal|"/"
argument_list|)
return|;
block|}
else|else
block|{
comment|// Doen't apply to me.
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Take a comma-separated list of directories from a configuration variable    * and transform it to a set of directories.    */
DECL|method|getDirectorySet (final String configVar)
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|getDirectorySet
parameter_list|(
specifier|final
name|String
name|configVar
parameter_list|)
throws|throws
name|AzureException
block|{
name|String
index|[]
name|rawDirs
init|=
name|sessionConfiguration
operator|.
name|getStrings
argument_list|(
name|configVar
argument_list|,
operator|new
name|String
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|directorySet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|currentDir
range|:
name|rawDirs
control|)
block|{
name|String
name|myDir
decl_stmt|;
try|try
block|{
name|myDir
operator|=
name|verifyAndConvertToStandardFormat
argument_list|(
name|currentDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"The directory %s specified in the configuration entry %s is not"
operator|+
literal|" a valid URI."
argument_list|,
name|currentDir
argument_list|,
name|configVar
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|myDir
operator|!=
literal|null
condition|)
block|{
name|directorySet
operator|.
name|add
argument_list|(
name|myDir
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|directorySet
return|;
block|}
comment|/**    * Checks if the given key in Azure Storage should be stored as a page    * blob instead of block blob.    */
DECL|method|isPageBlobKey (String key)
specifier|public
name|boolean
name|isPageBlobKey
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
name|isKeyForDirectorySet
argument_list|(
name|key
argument_list|,
name|pageBlobDirs
argument_list|)
return|;
block|}
comment|/**    * Checks if the given key in Azure storage should have synchronized    * atomic folder rename createNonRecursive implemented.    */
annotation|@
name|Override
DECL|method|isAtomicRenameKey (String key)
specifier|public
name|boolean
name|isAtomicRenameKey
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
name|isKeyForDirectorySet
argument_list|(
name|key
argument_list|,
name|atomicRenameDirs
argument_list|)
return|;
block|}
DECL|method|isKeyForDirectorySet (String key, Set<String> dirSet)
specifier|public
name|boolean
name|isKeyForDirectorySet
parameter_list|(
name|String
name|key
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|dirSet
parameter_list|)
block|{
name|String
name|defaultFS
init|=
name|FileSystem
operator|.
name|getDefaultUri
argument_list|(
name|sessionConfiguration
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|dir
range|:
name|dirSet
control|)
block|{
if|if
condition|(
name|dir
operator|.
name|isEmpty
argument_list|()
operator|||
name|key
operator|.
name|startsWith
argument_list|(
name|dir
operator|+
literal|"/"
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Allow for blob directories with paths relative to the default file
comment|// system.
comment|//
try|try
block|{
name|URI
name|uriPageBlobDir
init|=
operator|new
name|URI
argument_list|(
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|uriPageBlobDir
operator|.
name|getAuthority
argument_list|()
condition|)
block|{
comment|// Concatenate the default file system prefix with the relative
comment|// page blob directory path.
comment|//
if|if
condition|(
name|key
operator|.
name|startsWith
argument_list|(
name|trim
argument_list|(
name|defaultFS
argument_list|,
literal|"/"
argument_list|)
operator|+
literal|"/"
operator|+
name|dir
operator|+
literal|"/"
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"URI syntax error creating URI for {}"
argument_list|,
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * This should be called from any method that does any modifications to the    * underlying container: it makes sure to put the WASB current version in the    * container's metadata if it's not already there.    */
DECL|method|checkContainer (ContainerAccessType accessType)
specifier|private
name|ContainerState
name|checkContainer
parameter_list|(
name|ContainerAccessType
name|accessType
parameter_list|)
throws|throws
name|StorageException
throws|,
name|AzureException
block|{
synchronized|synchronized
init|(
name|containerStateLock
init|)
block|{
if|if
condition|(
name|isOkContainerState
argument_list|(
name|accessType
argument_list|)
condition|)
block|{
return|return
name|currentKnownContainerState
return|;
block|}
if|if
condition|(
name|currentKnownContainerState
operator|==
name|ContainerState
operator|.
name|ExistsAtWrongVersion
condition|)
block|{
name|String
name|containerVersion
init|=
name|retrieveVersionAttribute
argument_list|(
name|container
argument_list|)
decl_stmt|;
throw|throw
name|wrongVersionException
argument_list|(
name|containerVersion
argument_list|)
throw|;
block|}
comment|// This means I didn't check it before or it didn't exist or
comment|// we need to stamp the version. Since things may have changed by
comment|// other machines since then, do the check again and don't depend
comment|// on past information.
comment|// Sanity check: we don't expect this at this point.
if|if
condition|(
name|currentKnownContainerState
operator|==
name|ContainerState
operator|.
name|ExistsAtRightVersion
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unexpected state: "
operator|+
name|currentKnownContainerState
argument_list|)
throw|;
block|}
comment|// Download the attributes - doubles as an existence check with just
comment|// one service call
try|try
block|{
name|container
operator|.
name|downloadAttributes
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|Unknown
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|ex
parameter_list|)
block|{
if|if
condition|(
name|ex
operator|.
name|getErrorCode
argument_list|()
operator|.
name|equals
argument_list|(
name|StorageErrorCode
operator|.
name|RESOURCE_NOT_FOUND
operator|.
name|toString
argument_list|()
argument_list|)
condition|)
block|{
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|DoesntExist
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|ex
throw|;
block|}
block|}
if|if
condition|(
name|currentKnownContainerState
operator|==
name|ContainerState
operator|.
name|DoesntExist
condition|)
block|{
comment|// If the container doesn't exist and we intend to write to it,
comment|// create it now.
if|if
condition|(
name|needToCreateContainer
argument_list|(
name|accessType
argument_list|)
condition|)
block|{
name|storeVersionAttribute
argument_list|(
name|container
argument_list|)
expr_stmt|;
name|container
operator|.
name|create
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|ExistsAtRightVersion
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// The container exists, check the version.
name|String
name|containerVersion
init|=
name|retrieveVersionAttribute
argument_list|(
name|container
argument_list|)
decl_stmt|;
if|if
condition|(
name|containerVersion
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|containerVersion
operator|.
name|equals
argument_list|(
name|FIRST_WASB_VERSION
argument_list|)
condition|)
block|{
comment|// It's the version from when WASB was called ASV, just
comment|// fix the version attribute if needed and proceed.
comment|// We should be good otherwise.
if|if
condition|(
name|needToStampVersion
argument_list|(
name|accessType
argument_list|)
condition|)
block|{
name|storeVersionAttribute
argument_list|(
name|container
argument_list|)
expr_stmt|;
name|container
operator|.
name|uploadMetadata
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|containerVersion
operator|.
name|equals
argument_list|(
name|CURRENT_WASB_VERSION
argument_list|)
condition|)
block|{
comment|// Don't know this version - throw.
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|ExistsAtWrongVersion
expr_stmt|;
throw|throw
name|wrongVersionException
argument_list|(
name|containerVersion
argument_list|)
throw|;
block|}
else|else
block|{
comment|// It's our correct version.
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|ExistsAtRightVersion
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// No version info exists.
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|ExistsNoVersion
expr_stmt|;
if|if
condition|(
name|needToStampVersion
argument_list|(
name|accessType
argument_list|)
condition|)
block|{
comment|// Need to stamp the version
name|storeVersionAttribute
argument_list|(
name|container
argument_list|)
expr_stmt|;
name|container
operator|.
name|uploadMetadata
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|currentKnownContainerState
operator|=
name|ContainerState
operator|.
name|ExistsAtRightVersion
expr_stmt|;
block|}
block|}
block|}
return|return
name|currentKnownContainerState
return|;
block|}
block|}
DECL|method|wrongVersionException (String containerVersion)
specifier|private
name|AzureException
name|wrongVersionException
parameter_list|(
name|String
name|containerVersion
parameter_list|)
block|{
return|return
operator|new
name|AzureException
argument_list|(
literal|"The container "
operator|+
name|container
operator|.
name|getName
argument_list|()
operator|+
literal|" is at an unsupported version: "
operator|+
name|containerVersion
operator|+
literal|". Current supported version: "
operator|+
name|FIRST_WASB_VERSION
argument_list|)
return|;
block|}
DECL|method|needToStampVersion (ContainerAccessType accessType)
specifier|private
name|boolean
name|needToStampVersion
parameter_list|(
name|ContainerAccessType
name|accessType
parameter_list|)
block|{
comment|// We need to stamp the version on the container any time we write to
comment|// it and we have the correct credentials to be able to write container
comment|// metadata.
return|return
name|accessType
operator|!=
name|ContainerAccessType
operator|.
name|PureRead
operator|&&
name|canCreateOrModifyContainer
return|;
block|}
DECL|method|needToCreateContainer (ContainerAccessType accessType)
specifier|private
specifier|static
name|boolean
name|needToCreateContainer
parameter_list|(
name|ContainerAccessType
name|accessType
parameter_list|)
block|{
comment|// We need to pro-actively create the container (if it doesn't exist) if
comment|// we're doing a pure write. No need to create it for pure read or read-
comment|// then-write access.
return|return
name|accessType
operator|==
name|ContainerAccessType
operator|.
name|PureWrite
return|;
block|}
comment|// Determines whether we have to pull the container information again
comment|// or we can work based off what we already have.
DECL|method|isOkContainerState (ContainerAccessType accessType)
specifier|private
name|boolean
name|isOkContainerState
parameter_list|(
name|ContainerAccessType
name|accessType
parameter_list|)
block|{
switch|switch
condition|(
name|currentKnownContainerState
condition|)
block|{
case|case
name|Unknown
case|:
comment|// When using SAS, we can't discover container attributes
comment|// so just live with Unknown state and fail later if it
comment|// doesn't exist.
return|return
name|connectingUsingSAS
return|;
case|case
name|DoesntExist
case|:
return|return
literal|false
return|;
comment|// the container could have been created
case|case
name|ExistsAtRightVersion
case|:
return|return
literal|true
return|;
comment|// fine to optimize
case|case
name|ExistsAtWrongVersion
case|:
return|return
literal|false
return|;
case|case
name|ExistsNoVersion
case|:
comment|// If there's no version, it's OK if we don't need to stamp the version
comment|// or we can't anyway even if we wanted to.
return|return
operator|!
name|needToStampVersion
argument_list|(
name|accessType
argument_list|)
return|;
default|default:
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Unknown access type: "
operator|+
name|accessType
argument_list|)
throw|;
block|}
block|}
DECL|method|getUseTransactionalContentMD5 ()
specifier|private
name|boolean
name|getUseTransactionalContentMD5
parameter_list|()
block|{
return|return
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_CHECK_BLOCK_MD5
argument_list|,
literal|true
argument_list|)
return|;
block|}
DECL|method|getUploadOptions ()
specifier|private
name|BlobRequestOptions
name|getUploadOptions
parameter_list|()
block|{
name|BlobRequestOptions
name|options
init|=
operator|new
name|BlobRequestOptions
argument_list|()
decl_stmt|;
name|options
operator|.
name|setStoreBlobContentMD5
argument_list|(
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_STORE_BLOB_MD5
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|setUseTransactionalContentMD5
argument_list|(
name|getUseTransactionalContentMD5
argument_list|()
argument_list|)
expr_stmt|;
name|options
operator|.
name|setConcurrentRequestCount
argument_list|(
name|concurrentWrites
argument_list|)
expr_stmt|;
name|options
operator|.
name|setRetryPolicyFactory
argument_list|(
operator|new
name|RetryExponentialRetry
argument_list|(
name|minBackoff
argument_list|,
name|deltaBackoff
argument_list|,
name|maxBackoff
argument_list|,
name|maxRetries
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|options
return|;
block|}
DECL|method|getDownloadOptions ()
specifier|private
name|BlobRequestOptions
name|getDownloadOptions
parameter_list|()
block|{
name|BlobRequestOptions
name|options
init|=
operator|new
name|BlobRequestOptions
argument_list|()
decl_stmt|;
name|options
operator|.
name|setRetryPolicyFactory
argument_list|(
operator|new
name|RetryExponentialRetry
argument_list|(
name|minBackoff
argument_list|,
name|deltaBackoff
argument_list|,
name|maxBackoff
argument_list|,
name|maxRetries
argument_list|)
argument_list|)
expr_stmt|;
name|options
operator|.
name|setUseTransactionalContentMD5
argument_list|(
name|getUseTransactionalContentMD5
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|options
return|;
block|}
annotation|@
name|Override
DECL|method|storefile (String key, PermissionStatus permissionStatus)
specifier|public
name|DataOutputStream
name|storefile
parameter_list|(
name|String
name|key
parameter_list|,
name|PermissionStatus
name|permissionStatus
parameter_list|)
throws|throws
name|AzureException
block|{
try|try
block|{
comment|// Check if a session exists, if not create a session with the
comment|// Azure storage server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AzureException
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Check if there is an authenticated account associated with the
comment|// file this instance of the WASB file system. If not the file system
comment|// has not been authenticated and all access is anonymous.
if|if
condition|(
operator|!
name|isAuthenticatedAccess
argument_list|()
condition|)
block|{
comment|// Preemptively raise an exception indicating no uploads are
comment|// allowed to anonymous accounts.
throw|throw
operator|new
name|AzureException
argument_list|(
operator|new
name|IOException
argument_list|(
literal|"Uploads to public accounts using anonymous "
operator|+
literal|"access is prohibited."
argument_list|)
argument_list|)
throw|;
block|}
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureWrite
argument_list|)
expr_stmt|;
comment|/**        * Note: Windows Azure Blob Storage does not allow the creation of arbitrary directory        *      paths under the default $root directory.  This is by design to eliminate        *      ambiguity in specifying a implicit blob address. A blob in the $root conatiner        *      cannot include a / in its name and must be careful not to include a trailing        *      '/' when referencing  blobs in the $root container.        *      A '/; in the $root container permits ambiguous blob names as in the following        *      example involving two containers $root and mycontainer:        *                http://myaccount.blob.core.windows.net/$root        *                http://myaccount.blob.core.windows.net/mycontainer        *      If the URL "mycontainer/somefile.txt were allowed in $root then the URL:        *                http://myaccount.blob.core.windows.net/mycontainer/myblob.txt        *      could mean either:        *        (1) container=mycontainer; blob=myblob.txt        *        (2) container=$root; blob=mycontainer/myblob.txt        *         * To avoid this type of ambiguity the Azure blob storage prevents        * arbitrary path under $root. For a simple and more consistent user        * experience it was decided to eliminate the opportunity for creating        * such paths by making the $root container read-only under WASB.         */
comment|// Check that no attempt is made to write to blobs on default
comment|// $root containers.
if|if
condition|(
name|AZURE_ROOT_CONTAINER
operator|.
name|equals
argument_list|(
name|getContainerFromAuthority
argument_list|(
name|sessionUri
argument_list|)
argument_list|)
condition|)
block|{
comment|// Azure containers are restricted to non-root containers.
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Writes to '%s' container for URI '%s' are prohibited, "
operator|+
literal|"only updates on non-root containers permitted."
argument_list|,
name|AZURE_ROOT_CONTAINER
argument_list|,
name|sessionUri
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AzureException
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Get the blob reference from the store's container and
comment|// return it.
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|storePermissionStatus
argument_list|(
name|blob
argument_list|,
name|permissionStatus
argument_list|)
expr_stmt|;
comment|// Create the output stream for the Azure blob.
comment|//
name|OutputStream
name|outputStream
init|=
name|openOutputStream
argument_list|(
name|blob
argument_list|)
decl_stmt|;
name|DataOutputStream
name|dataOutStream
init|=
operator|new
name|SyncableDataOutputStream
argument_list|(
name|outputStream
argument_list|)
decl_stmt|;
return|return
name|dataOutStream
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting to open the blob output stream.
comment|// Re-throw as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Opens a new output stream to the given blob (page or block blob)    * to populate it from scratch with data.    */
DECL|method|openOutputStream (final CloudBlobWrapper blob)
specifier|private
name|OutputStream
name|openOutputStream
parameter_list|(
specifier|final
name|CloudBlobWrapper
name|blob
parameter_list|)
throws|throws
name|StorageException
block|{
if|if
condition|(
name|blob
operator|instanceof
name|CloudPageBlobWrapper
condition|)
block|{
return|return
operator|new
name|PageBlobOutputStream
argument_list|(
operator|(
name|CloudPageBlobWrapper
operator|)
name|blob
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|,
name|sessionConfiguration
argument_list|)
return|;
block|}
else|else
block|{
comment|// Handle both ClouldBlockBlobWrapperImpl and (only for the test code path)
comment|// MockCloudBlockBlobWrapper.
return|return
operator|(
operator|(
name|CloudBlockBlobWrapper
operator|)
name|blob
operator|)
operator|.
name|openOutputStream
argument_list|(
name|getUploadOptions
argument_list|()
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
return|;
block|}
block|}
comment|/**    * Opens a new input stream for the given blob (page or block blob)    * to read its data.    */
DECL|method|openInputStream (CloudBlobWrapper blob)
specifier|private
name|InputStream
name|openInputStream
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
throws|throws
name|StorageException
throws|,
name|IOException
block|{
if|if
condition|(
name|blob
operator|instanceof
name|CloudBlockBlobWrapper
condition|)
block|{
return|return
name|blob
operator|.
name|openInputStream
argument_list|(
name|getDownloadOptions
argument_list|()
argument_list|,
name|getInstrumentedContext
argument_list|(
name|isConcurrentOOBAppendAllowed
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|PageBlobInputStream
argument_list|(
operator|(
name|CloudPageBlobWrapper
operator|)
name|blob
argument_list|,
name|getInstrumentedContext
argument_list|(
name|isConcurrentOOBAppendAllowed
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * Default permission to use when no permission metadata is found.    *     * @return The default permission to use.    */
DECL|method|defaultPermissionNoBlobMetadata ()
specifier|private
specifier|static
name|PermissionStatus
name|defaultPermissionNoBlobMetadata
parameter_list|()
block|{
return|return
operator|new
name|PermissionStatus
argument_list|(
literal|""
argument_list|,
literal|""
argument_list|,
name|FsPermission
operator|.
name|getDefault
argument_list|()
argument_list|)
return|;
block|}
DECL|method|storeMetadataAttribute (CloudBlobWrapper blob, String key, String value)
specifier|private
specifier|static
name|void
name|storeMetadataAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|String
name|key
parameter_list|,
name|String
name|value
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|blob
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|metadata
condition|)
block|{
name|metadata
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|metadata
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|blob
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
block|}
DECL|method|getMetadataAttribute (CloudBlobWrapper blob, String... keyAlternatives)
specifier|private
specifier|static
name|String
name|getMetadataAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|String
modifier|...
name|keyAlternatives
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|blob
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|metadata
condition|)
block|{
return|return
literal|null
return|;
block|}
for|for
control|(
name|String
name|key
range|:
name|keyAlternatives
control|)
block|{
if|if
condition|(
name|metadata
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
return|return
name|metadata
operator|.
name|get
argument_list|(
name|key
argument_list|)
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
DECL|method|removeMetadataAttribute (CloudBlobWrapper blob, String key)
specifier|private
specifier|static
name|void
name|removeMetadataAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|String
name|key
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|blob
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|metadata
operator|!=
literal|null
condition|)
block|{
name|metadata
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|blob
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|storePermissionStatus (CloudBlobWrapper blob, PermissionStatus permissionStatus)
specifier|private
specifier|static
name|void
name|storePermissionStatus
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|PermissionStatus
name|permissionStatus
parameter_list|)
block|{
name|storeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|PERMISSION_METADATA_KEY
argument_list|,
name|PERMISSION_JSON_SERIALIZER
operator|.
name|toJSON
argument_list|(
name|permissionStatus
argument_list|)
argument_list|)
expr_stmt|;
comment|// Remove the old metadata key if present
name|removeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|OLD_PERMISSION_METADATA_KEY
argument_list|)
expr_stmt|;
block|}
DECL|method|getPermissionStatus (CloudBlobWrapper blob)
specifier|private
name|PermissionStatus
name|getPermissionStatus
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
block|{
name|String
name|permissionMetadataValue
init|=
name|getMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|PERMISSION_METADATA_KEY
argument_list|,
name|OLD_PERMISSION_METADATA_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|permissionMetadataValue
operator|!=
literal|null
condition|)
block|{
return|return
name|PermissionStatusJsonSerializer
operator|.
name|fromJSONString
argument_list|(
name|permissionMetadataValue
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|defaultPermissionNoBlobMetadata
argument_list|()
return|;
block|}
block|}
DECL|method|storeFolderAttribute (CloudBlobWrapper blob)
specifier|private
specifier|static
name|void
name|storeFolderAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
block|{
name|storeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|IS_FOLDER_METADATA_KEY
argument_list|,
literal|"true"
argument_list|)
expr_stmt|;
comment|// Remove the old metadata key if present
name|removeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|OLD_IS_FOLDER_METADATA_KEY
argument_list|)
expr_stmt|;
block|}
DECL|method|storeLinkAttribute (CloudBlobWrapper blob, String linkTarget)
specifier|private
specifier|static
name|void
name|storeLinkAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|String
name|linkTarget
parameter_list|)
throws|throws
name|UnsupportedEncodingException
block|{
comment|// We have to URL encode the link attribute as the link URI could
comment|// have URI special characters which unless encoded will result
comment|// in 403 errors from the server. This is due to metadata properties
comment|// being sent in the HTTP header of the request which is in turn used
comment|// on the server side to authorize the request.
name|String
name|encodedLinkTarget
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|linkTarget
operator|!=
literal|null
condition|)
block|{
name|encodedLinkTarget
operator|=
name|URLEncoder
operator|.
name|encode
argument_list|(
name|linkTarget
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
block|}
name|storeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
argument_list|,
name|encodedLinkTarget
argument_list|)
expr_stmt|;
comment|// Remove the old metadata key if present
name|removeMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|OLD_LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
argument_list|)
expr_stmt|;
block|}
DECL|method|getLinkAttributeValue (CloudBlobWrapper blob)
specifier|private
specifier|static
name|String
name|getLinkAttributeValue
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
throws|throws
name|UnsupportedEncodingException
block|{
name|String
name|encodedLinkTarget
init|=
name|getMetadataAttribute
argument_list|(
name|blob
argument_list|,
name|LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
argument_list|,
name|OLD_LINK_BACK_TO_UPLOAD_IN_PROGRESS_METADATA_KEY
argument_list|)
decl_stmt|;
name|String
name|linkTarget
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|encodedLinkTarget
operator|!=
literal|null
condition|)
block|{
name|linkTarget
operator|=
name|URLDecoder
operator|.
name|decode
argument_list|(
name|encodedLinkTarget
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
block|}
return|return
name|linkTarget
return|;
block|}
DECL|method|retrieveFolderAttribute (CloudBlobWrapper blob)
specifier|private
specifier|static
name|boolean
name|retrieveFolderAttribute
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|blob
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
return|return
literal|null
operator|!=
name|metadata
operator|&&
operator|(
name|metadata
operator|.
name|containsKey
argument_list|(
name|IS_FOLDER_METADATA_KEY
argument_list|)
operator|||
name|metadata
operator|.
name|containsKey
argument_list|(
name|OLD_IS_FOLDER_METADATA_KEY
argument_list|)
operator|)
return|;
block|}
DECL|method|storeVersionAttribute (CloudBlobContainerWrapper container)
specifier|private
specifier|static
name|void
name|storeVersionAttribute
parameter_list|(
name|CloudBlobContainerWrapper
name|container
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|container
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|metadata
condition|)
block|{
name|metadata
operator|=
operator|new
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|metadata
operator|.
name|put
argument_list|(
name|VERSION_METADATA_KEY
argument_list|,
name|CURRENT_WASB_VERSION
argument_list|)
expr_stmt|;
if|if
condition|(
name|metadata
operator|.
name|containsKey
argument_list|(
name|OLD_VERSION_METADATA_KEY
argument_list|)
condition|)
block|{
name|metadata
operator|.
name|remove
argument_list|(
name|OLD_VERSION_METADATA_KEY
argument_list|)
expr_stmt|;
block|}
name|container
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
block|}
DECL|method|retrieveVersionAttribute ( CloudBlobContainerWrapper container)
specifier|private
specifier|static
name|String
name|retrieveVersionAttribute
parameter_list|(
name|CloudBlobContainerWrapper
name|container
parameter_list|)
block|{
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|metadata
init|=
name|container
operator|.
name|getMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|metadata
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
elseif|else
if|if
condition|(
name|metadata
operator|.
name|containsKey
argument_list|(
name|VERSION_METADATA_KEY
argument_list|)
condition|)
block|{
return|return
name|metadata
operator|.
name|get
argument_list|(
name|VERSION_METADATA_KEY
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|metadata
operator|.
name|containsKey
argument_list|(
name|OLD_VERSION_METADATA_KEY
argument_list|)
condition|)
block|{
return|return
name|metadata
operator|.
name|get
argument_list|(
name|OLD_VERSION_METADATA_KEY
argument_list|)
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
DECL|method|storeEmptyFolder (String key, PermissionStatus permissionStatus)
specifier|public
name|void
name|storeEmptyFolder
parameter_list|(
name|String
name|key
parameter_list|,
name|PermissionStatus
name|permissionStatus
parameter_list|)
throws|throws
name|AzureException
block|{
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Check if there is an authenticated account associated with the file
comment|// this instance of the WASB file system. If not the file system has not
comment|// been authenticated and all access is anonymous.
if|if
condition|(
operator|!
name|isAuthenticatedAccess
argument_list|()
condition|)
block|{
comment|// Preemptively raise an exception indicating no uploads are
comment|// allowed to anonymous accounts.
throw|throw
operator|new
name|AzureException
argument_list|(
literal|"Uploads to to public accounts using anonymous access is prohibited."
argument_list|)
throw|;
block|}
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureWrite
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|storePermissionStatus
argument_list|(
name|blob
argument_list|,
name|permissionStatus
argument_list|)
expr_stmt|;
name|storeFolderAttribute
argument_list|(
name|blob
argument_list|)
expr_stmt|;
name|openOutputStream
argument_list|(
name|blob
argument_list|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting upload. Re-throw as an Azure
comment|// storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Throwable
name|t
init|=
name|e
operator|.
name|getCause
argument_list|()
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
operator|&&
name|t
operator|instanceof
name|StorageException
condition|)
block|{
name|StorageException
name|se
init|=
operator|(
name|StorageException
operator|)
name|t
decl_stmt|;
comment|// If we got this exception, the blob should have already been created
if|if
condition|(
operator|!
name|se
operator|.
name|getErrorCode
argument_list|()
operator|.
name|equals
argument_list|(
literal|"LeaseIdMissing"
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Stores an empty blob that's linking to the temporary file where're we're    * uploading the initial data.    */
annotation|@
name|Override
DECL|method|storeEmptyLinkFile (String key, String tempBlobKey, PermissionStatus permissionStatus)
specifier|public
name|void
name|storeEmptyLinkFile
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|tempBlobKey
parameter_list|,
name|PermissionStatus
name|permissionStatus
parameter_list|)
throws|throws
name|AzureException
block|{
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
comment|// Check if there is an authenticated account associated with the file
comment|// this instance of the WASB file system. If not the file system has not
comment|// been authenticated and all access is anonymous.
if|if
condition|(
operator|!
name|isAuthenticatedAccess
argument_list|()
condition|)
block|{
comment|// Preemptively raise an exception indicating no uploads are
comment|// allowed to anonymous accounts.
throw|throw
operator|new
name|AzureException
argument_list|(
literal|"Uploads to to public accounts using anonymous access is prohibited."
argument_list|)
throw|;
block|}
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureWrite
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|storePermissionStatus
argument_list|(
name|blob
argument_list|,
name|permissionStatus
argument_list|)
expr_stmt|;
name|storeLinkAttribute
argument_list|(
name|blob
argument_list|,
name|tempBlobKey
argument_list|)
expr_stmt|;
name|openOutputStream
argument_list|(
name|blob
argument_list|)
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting upload. Re-throw as an Azure
comment|// storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * If the blob with the given key exists and has a link in its metadata to a    * temporary file (see storeEmptyLinkFile), this method returns the key to    * that temporary file. Otherwise, returns null.    */
annotation|@
name|Override
DECL|method|getLinkInFileMetadata (String key)
specifier|public
name|String
name|getLinkInFileMetadata
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AzureException
block|{
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureRead
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|blob
operator|.
name|downloadAttributes
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|getLinkAttributeValue
argument_list|(
name|blob
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting download. Re-throw as an Azure
comment|// storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Private method to check for authenticated access.    *     * @ returns boolean -- true if access is credentialed and authenticated and    * false otherwise.    */
DECL|method|isAuthenticatedAccess ()
specifier|private
name|boolean
name|isAuthenticatedAccess
parameter_list|()
throws|throws
name|AzureException
block|{
if|if
condition|(
name|isAnonymousCredentials
condition|)
block|{
comment|// Access to this storage account is unauthenticated.
return|return
literal|false
return|;
block|}
comment|// Access is authenticated.
return|return
literal|true
return|;
block|}
comment|/**    * This private method uses the root directory or the original container to    * list blobs under the directory or container depending on whether the    * original file system object was constructed with a short- or long-form URI.    * If the root directory is non-null the URI in the file constructor was in    * the long form.    *     * @param includeMetadata    *          if set, the listed items will have their metadata populated    *          already.    * @param useFlatBlobListing    *          if set the list is flat, otherwise it is hierarchical.    *    * @returns blobItems : iterable collection of blob items.    * @throws URISyntaxException    *     */
DECL|method|listRootBlobs (boolean includeMetadata, boolean useFlatBlobListing)
specifier|private
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|listRootBlobs
parameter_list|(
name|boolean
name|includeMetadata
parameter_list|,
name|boolean
name|useFlatBlobListing
parameter_list|)
throws|throws
name|StorageException
throws|,
name|URISyntaxException
block|{
return|return
name|rootDirectory
operator|.
name|listBlobs
argument_list|(
literal|null
argument_list|,
name|useFlatBlobListing
argument_list|,
name|includeMetadata
condition|?
name|EnumSet
operator|.
name|of
argument_list|(
name|BlobListingDetails
operator|.
name|METADATA
argument_list|)
else|:
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|BlobListingDetails
operator|.
name|class
argument_list|)
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * This private method uses the root directory or the original container to    * list blobs under the directory or container given a specified prefix for    * the directory depending on whether the original file system object was    * constructed with a short- or long-form URI. If the root directory is    * non-null the URI in the file constructor was in the long form.    *     * @param aPrefix    *          : string name representing the prefix of containing blobs.    * @param includeMetadata    *          if set, the listed items will have their metadata populated    *          already.    * @param useFlatBlobListing    *          if set the list is flat, otherwise it is hierarchical.    *     * @returns blobItems : iterable collection of blob items.    * @throws URISyntaxException    *     */
DECL|method|listRootBlobs (String aPrefix, boolean includeMetadata, boolean useFlatBlobListing)
specifier|private
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|listRootBlobs
parameter_list|(
name|String
name|aPrefix
parameter_list|,
name|boolean
name|includeMetadata
parameter_list|,
name|boolean
name|useFlatBlobListing
parameter_list|)
throws|throws
name|StorageException
throws|,
name|URISyntaxException
block|{
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|list
init|=
name|rootDirectory
operator|.
name|listBlobs
argument_list|(
name|aPrefix
argument_list|,
name|useFlatBlobListing
argument_list|,
name|includeMetadata
condition|?
name|EnumSet
operator|.
name|of
argument_list|(
name|BlobListingDetails
operator|.
name|METADATA
argument_list|)
else|:
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|BlobListingDetails
operator|.
name|class
argument_list|)
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|list
return|;
block|}
comment|/**    * This private method uses the root directory or the original container to    * list blobs under the directory or container given a specified prefix for    * the directory depending on whether the original file system object was    * constructed with a short- or long-form URI. It also uses the specified flat    * or hierarchical option, listing details options, request options, and    * operation context.    *     * @param aPrefix    *          string name representing the prefix of containing blobs.    * @param useFlatBlobListing    *          - the list is flat if true, or hierarchical otherwise.    * @param listingDetails    *          - determine whether snapshots, metadata, committed/uncommitted    *          data    * @param options    *          - object specifying additional options for the request. null =    *          default options    * @param opContext    *          - context of the current operation    * @returns blobItems : iterable collection of blob items.    * @throws URISyntaxException    *     */
DECL|method|listRootBlobs (String aPrefix, boolean useFlatBlobListing, EnumSet<BlobListingDetails> listingDetails, BlobRequestOptions options, OperationContext opContext)
specifier|private
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|listRootBlobs
parameter_list|(
name|String
name|aPrefix
parameter_list|,
name|boolean
name|useFlatBlobListing
parameter_list|,
name|EnumSet
argument_list|<
name|BlobListingDetails
argument_list|>
name|listingDetails
parameter_list|,
name|BlobRequestOptions
name|options
parameter_list|,
name|OperationContext
name|opContext
parameter_list|)
throws|throws
name|StorageException
throws|,
name|URISyntaxException
block|{
name|CloudBlobDirectoryWrapper
name|directory
init|=
name|this
operator|.
name|container
operator|.
name|getDirectoryReference
argument_list|(
name|aPrefix
argument_list|)
decl_stmt|;
return|return
name|directory
operator|.
name|listBlobs
argument_list|(
literal|null
argument_list|,
name|useFlatBlobListing
argument_list|,
name|listingDetails
argument_list|,
name|options
argument_list|,
name|opContext
argument_list|)
return|;
block|}
comment|/**    * This private method uses the root directory or the original container to    * get the block blob reference depending on whether the original file system    * object was constructed with a short- or long-form URI. If the root    * directory is non-null the URI in the file constructor was in the long form.    *     * @param aKey    *          : a key used to query Azure for the block blob.    * @returns blob : a reference to the Azure block blob corresponding to the    *          key.    * @throws URISyntaxException    *     */
DECL|method|getBlobReference (String aKey)
specifier|private
name|CloudBlobWrapper
name|getBlobReference
parameter_list|(
name|String
name|aKey
parameter_list|)
throws|throws
name|StorageException
throws|,
name|URISyntaxException
block|{
name|CloudBlobWrapper
name|blob
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isPageBlobKey
argument_list|(
name|aKey
argument_list|)
condition|)
block|{
name|blob
operator|=
name|this
operator|.
name|container
operator|.
name|getPageBlobReference
argument_list|(
name|aKey
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|blob
operator|=
name|this
operator|.
name|container
operator|.
name|getBlockBlobReference
argument_list|(
name|aKey
argument_list|)
expr_stmt|;
name|blob
operator|.
name|setStreamMinimumReadSizeInBytes
argument_list|(
name|downloadBlockSizeBytes
argument_list|)
expr_stmt|;
name|blob
operator|.
name|setWriteBlockSizeInBytes
argument_list|(
name|uploadBlockSizeBytes
argument_list|)
expr_stmt|;
block|}
return|return
name|blob
return|;
block|}
comment|/**    * This private method normalizes the key by stripping the container name from    * the path and returns a path relative to the root directory of the    * container.    *     * @param keyUri    *          - adjust this key to a path relative to the root directory    *     * @returns normKey    */
DECL|method|normalizeKey (URI keyUri)
specifier|private
name|String
name|normalizeKey
parameter_list|(
name|URI
name|keyUri
parameter_list|)
block|{
name|String
name|normKey
decl_stmt|;
comment|// Strip the container name from the path and return the path
comment|// relative to the root directory of the container.
name|int
name|parts
init|=
name|isStorageEmulator
condition|?
literal|4
else|:
literal|3
decl_stmt|;
name|normKey
operator|=
name|keyUri
operator|.
name|getPath
argument_list|()
operator|.
name|split
argument_list|(
literal|"/"
argument_list|,
name|parts
argument_list|)
index|[
operator|(
name|parts
operator|-
literal|1
operator|)
index|]
expr_stmt|;
comment|// Return the fixed key.
return|return
name|normKey
return|;
block|}
comment|/**    * This private method normalizes the key by stripping the container name from    * the path and returns a path relative to the root directory of the    * container.    *     * @param blob    *          - adjust the key to this blob to a path relative to the root    *          directory    *     * @returns normKey    */
DECL|method|normalizeKey (CloudBlobWrapper blob)
specifier|private
name|String
name|normalizeKey
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|)
block|{
return|return
name|normalizeKey
argument_list|(
name|blob
operator|.
name|getUri
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * This private method normalizes the key by stripping the container name from    * the path and returns a path relative to the root directory of the    * container.    *     * @param directory    *          - adjust the key to this directory to a path relative to the root    *          directory    *     * @returns normKey    */
DECL|method|normalizeKey (CloudBlobDirectoryWrapper directory)
specifier|private
name|String
name|normalizeKey
parameter_list|(
name|CloudBlobDirectoryWrapper
name|directory
parameter_list|)
block|{
name|String
name|dirKey
init|=
name|normalizeKey
argument_list|(
name|directory
operator|.
name|getUri
argument_list|()
argument_list|)
decl_stmt|;
comment|// Strip the last delimiter
if|if
condition|(
name|dirKey
operator|.
name|endsWith
argument_list|(
name|PATH_DELIMITER
argument_list|)
condition|)
block|{
name|dirKey
operator|=
name|dirKey
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|dirKey
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return
name|dirKey
return|;
block|}
comment|/**    * Default method to creates a new OperationContext for the Azure Storage    * operation that has listeners hooked to it that will update the metrics for    * this file system. This method does not bind to receive send request    * callbacks by default.    *     * @return The OperationContext object to use.    */
DECL|method|getInstrumentedContext ()
specifier|private
name|OperationContext
name|getInstrumentedContext
parameter_list|()
block|{
comment|// Default is to not bind to receive send callback events.
return|return
name|getInstrumentedContext
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Creates a new OperationContext for the Azure Storage operation that has    * listeners hooked to it that will update the metrics for this file system.    *     * @param bindConcurrentOOBIo    *          - bind to intercept send request call backs to handle OOB I/O.    *     * @return The OperationContext object to use.    */
DECL|method|getInstrumentedContext (boolean bindConcurrentOOBIo)
specifier|private
name|OperationContext
name|getInstrumentedContext
parameter_list|(
name|boolean
name|bindConcurrentOOBIo
parameter_list|)
block|{
name|OperationContext
name|operationContext
init|=
operator|new
name|OperationContext
argument_list|()
decl_stmt|;
if|if
condition|(
name|selfThrottlingEnabled
condition|)
block|{
name|SelfThrottlingIntercept
operator|.
name|hook
argument_list|(
name|operationContext
argument_list|,
name|selfThrottlingReadFactor
argument_list|,
name|selfThrottlingWriteFactor
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bandwidthGaugeUpdater
operator|!=
literal|null
condition|)
block|{
comment|//bandwidthGaugeUpdater is null when we config to skip azure metrics
name|ResponseReceivedMetricUpdater
operator|.
name|hook
argument_list|(
name|operationContext
argument_list|,
name|instrumentation
argument_list|,
name|bandwidthGaugeUpdater
argument_list|)
expr_stmt|;
block|}
comment|// Bind operation context to receive send request callbacks on this operation.
comment|// If reads concurrent to OOB writes are allowed, the interception will reset
comment|// the conditional header on all Azure blob storage read requests.
if|if
condition|(
name|bindConcurrentOOBIo
condition|)
block|{
name|SendRequestIntercept
operator|.
name|bind
argument_list|(
name|operationContext
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|testHookOperationContext
operator|!=
literal|null
condition|)
block|{
name|operationContext
operator|=
name|testHookOperationContext
operator|.
name|modifyOperationContext
argument_list|(
name|operationContext
argument_list|)
expr_stmt|;
block|}
name|ErrorMetricUpdater
operator|.
name|hook
argument_list|(
name|operationContext
argument_list|,
name|instrumentation
argument_list|)
expr_stmt|;
comment|// Return the operation context.
return|return
name|operationContext
return|;
block|}
annotation|@
name|Override
DECL|method|retrieveMetadata (String key)
specifier|public
name|FileMetadata
name|retrieveMetadata
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Attempts to check status may occur before opening any streams so first,
comment|// check if a session exists, if not create a session with the Azure storage
comment|// server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Retrieving metadata for {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureRead
argument_list|)
operator|==
name|ContainerState
operator|.
name|DoesntExist
condition|)
block|{
comment|// The container doesn't exist, so spare some service calls and just
comment|// return null now.
return|return
literal|null
return|;
block|}
comment|// Handle the degenerate cases where the key does not exist or the
comment|// key is a container.
if|if
condition|(
name|key
operator|.
name|equals
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
comment|// The key refers to root directory of container.
comment|// Set the modification time for root to zero.
return|return
operator|new
name|FileMetadata
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|defaultPermissionNoBlobMetadata
argument_list|()
argument_list|,
name|BlobMaterialization
operator|.
name|Implicit
argument_list|)
return|;
block|}
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|// Download attributes and return file metadata only if the blob
comment|// exists.
if|if
condition|(
literal|null
operator|!=
name|blob
operator|&&
name|blob
operator|.
name|exists
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found {} as an explicit blob. Checking if it's a file or folder."
argument_list|,
name|key
argument_list|)
expr_stmt|;
comment|// The blob exists, so capture the metadata from the blob
comment|// properties.
name|blob
operator|.
name|downloadAttributes
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|BlobProperties
name|properties
init|=
name|blob
operator|.
name|getProperties
argument_list|()
decl_stmt|;
if|if
condition|(
name|retrieveFolderAttribute
argument_list|(
name|blob
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} is a folder blob."
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
operator|new
name|FileMetadata
argument_list|(
name|key
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|,
name|BlobMaterialization
operator|.
name|Explicit
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} is a normal blob."
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
operator|new
name|FileMetadata
argument_list|(
name|key
argument_list|,
comment|// Always return denormalized key with metadata.
name|getDataLength
argument_list|(
name|blob
argument_list|,
name|properties
argument_list|)
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|// There is no file with that key name, but maybe it is a folder.
comment|// Query the underlying folder/container to list the blobs stored
comment|// there under that key.
comment|//
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|objects
init|=
name|listRootBlobs
argument_list|(
name|key
argument_list|,
literal|true
argument_list|,
name|EnumSet
operator|.
name|of
argument_list|(
name|BlobListingDetails
operator|.
name|METADATA
argument_list|)
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
decl_stmt|;
comment|// Check if the directory/container has the blob items.
for|for
control|(
name|ListBlobItem
name|blobItem
range|:
name|objects
control|)
block|{
if|if
condition|(
name|blobItem
operator|instanceof
name|CloudBlockBlobWrapper
operator|||
name|blobItem
operator|instanceof
name|CloudPageBlobWrapper
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found blob as a directory-using this file under it to infer its properties {}"
argument_list|,
name|blobItem
operator|.
name|getUri
argument_list|()
argument_list|)
expr_stmt|;
name|blob
operator|=
operator|(
name|CloudBlobWrapper
operator|)
name|blobItem
expr_stmt|;
comment|// The key specifies a directory. Create a FileMetadata object which
comment|// specifies as such.
name|BlobProperties
name|properties
init|=
name|blob
operator|.
name|getProperties
argument_list|()
decl_stmt|;
return|return
operator|new
name|FileMetadata
argument_list|(
name|key
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|,
name|BlobMaterialization
operator|.
name|Implicit
argument_list|)
return|;
block|}
block|}
comment|// Return to caller with a null metadata object.
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw the exception as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|retrieve (String key)
specifier|public
name|DataInputStream
name|retrieve
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AzureException
throws|,
name|IOException
block|{
try|try
block|{
comment|// Check if a session exists, if not create a session with the
comment|// Azure storage server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureRead
argument_list|)
expr_stmt|;
comment|// Get blob reference and open the input buffer stream.
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|// Return a data input stream.
name|DataInputStream
name|inDataStream
init|=
operator|new
name|DataInputStream
argument_list|(
name|openInputStream
argument_list|(
name|blob
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|inDataStream
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|retrieve (String key, long startByteOffset)
specifier|public
name|DataInputStream
name|retrieve
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|startByteOffset
parameter_list|)
throws|throws
name|AzureException
throws|,
name|IOException
block|{
try|try
block|{
comment|// Check if a session exists, if not create a session with the
comment|// Azure storage server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureRead
argument_list|)
expr_stmt|;
comment|// Get blob reference and open the input buffer stream.
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|// Open input stream and seek to the start offset.
name|InputStream
name|in
init|=
name|blob
operator|.
name|openInputStream
argument_list|(
name|getDownloadOptions
argument_list|()
argument_list|,
name|getInstrumentedContext
argument_list|(
name|isConcurrentOOBAppendAllowed
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
comment|// Create a data input stream.
name|DataInputStream
name|inDataStream
init|=
operator|new
name|DataInputStream
argument_list|(
name|in
argument_list|)
decl_stmt|;
comment|// Skip bytes and ignore return value. This is okay
comment|// because if you try to skip too far you will be positioned
comment|// at the end and reads will not return data.
name|inDataStream
operator|.
name|skip
argument_list|(
name|startByteOffset
argument_list|)
expr_stmt|;
return|return
name|inDataStream
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|list (String prefix, final int maxListingCount, final int maxListingDepth)
specifier|public
name|PartialListing
name|list
parameter_list|(
name|String
name|prefix
parameter_list|,
specifier|final
name|int
name|maxListingCount
parameter_list|,
specifier|final
name|int
name|maxListingDepth
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|list
argument_list|(
name|prefix
argument_list|,
name|maxListingCount
argument_list|,
name|maxListingDepth
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|list (String prefix, final int maxListingCount, final int maxListingDepth, String priorLastKey)
specifier|public
name|PartialListing
name|list
parameter_list|(
name|String
name|prefix
parameter_list|,
specifier|final
name|int
name|maxListingCount
parameter_list|,
specifier|final
name|int
name|maxListingDepth
parameter_list|,
name|String
name|priorLastKey
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|list
argument_list|(
name|prefix
argument_list|,
name|PATH_DELIMITER
argument_list|,
name|maxListingCount
argument_list|,
name|maxListingDepth
argument_list|,
name|priorLastKey
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|listAll (String prefix, final int maxListingCount, final int maxListingDepth, String priorLastKey)
specifier|public
name|PartialListing
name|listAll
parameter_list|(
name|String
name|prefix
parameter_list|,
specifier|final
name|int
name|maxListingCount
parameter_list|,
specifier|final
name|int
name|maxListingDepth
parameter_list|,
name|String
name|priorLastKey
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|list
argument_list|(
name|prefix
argument_list|,
literal|null
argument_list|,
name|maxListingCount
argument_list|,
name|maxListingDepth
argument_list|,
name|priorLastKey
argument_list|)
return|;
block|}
comment|/**    * Searches the given list of {@link FileMetadata} objects for a directory    * with the given key.    *     * @param list    *          The list to search.    * @param key    *          The key to search for.    * @return The wanted directory, or null if not found.    */
DECL|method|getFileMetadataInList ( final Iterable<FileMetadata> list, String key)
specifier|private
specifier|static
name|FileMetadata
name|getFileMetadataInList
parameter_list|(
specifier|final
name|Iterable
argument_list|<
name|FileMetadata
argument_list|>
name|list
parameter_list|,
name|String
name|key
parameter_list|)
block|{
for|for
control|(
name|FileMetadata
name|current
range|:
name|list
control|)
block|{
if|if
condition|(
name|current
operator|.
name|getKey
argument_list|()
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
return|return
name|current
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
DECL|method|list (String prefix, String delimiter, final int maxListingCount, final int maxListingDepth, String priorLastKey)
specifier|private
name|PartialListing
name|list
parameter_list|(
name|String
name|prefix
parameter_list|,
name|String
name|delimiter
parameter_list|,
specifier|final
name|int
name|maxListingCount
parameter_list|,
specifier|final
name|int
name|maxListingDepth
parameter_list|,
name|String
name|priorLastKey
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|PureRead
argument_list|)
expr_stmt|;
if|if
condition|(
literal|0
operator|<
name|prefix
operator|.
name|length
argument_list|()
operator|&&
operator|!
name|prefix
operator|.
name|endsWith
argument_list|(
name|PATH_DELIMITER
argument_list|)
condition|)
block|{
name|prefix
operator|+=
name|PATH_DELIMITER
expr_stmt|;
block|}
comment|// Enable flat listing option only if depth is unbounded and config
comment|// KEY_ENABLE_FLAT_LISTING is enabled.
name|boolean
name|enableFlatListing
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|maxListingDepth
operator|<
literal|0
operator|&&
name|sessionConfiguration
operator|.
name|getBoolean
argument_list|(
name|KEY_ENABLE_FLAT_LISTING
argument_list|,
name|DEFAULT_ENABLE_FLAT_LISTING
argument_list|)
condition|)
block|{
name|enableFlatListing
operator|=
literal|true
expr_stmt|;
block|}
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|objects
decl_stmt|;
if|if
condition|(
name|prefix
operator|.
name|equals
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|objects
operator|=
name|listRootBlobs
argument_list|(
literal|true
argument_list|,
name|enableFlatListing
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|objects
operator|=
name|listRootBlobs
argument_list|(
name|prefix
argument_list|,
literal|true
argument_list|,
name|enableFlatListing
argument_list|)
expr_stmt|;
block|}
name|ArrayList
argument_list|<
name|FileMetadata
argument_list|>
name|fileMetadata
init|=
operator|new
name|ArrayList
argument_list|<
name|FileMetadata
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|ListBlobItem
name|blobItem
range|:
name|objects
control|)
block|{
comment|// Check that the maximum listing count is not exhausted.
comment|//
if|if
condition|(
literal|0
operator|<
name|maxListingCount
operator|&&
name|fileMetadata
operator|.
name|size
argument_list|()
operator|>=
name|maxListingCount
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|blobItem
operator|instanceof
name|CloudBlockBlobWrapper
operator|||
name|blobItem
operator|instanceof
name|CloudPageBlobWrapper
condition|)
block|{
name|String
name|blobKey
init|=
literal|null
decl_stmt|;
name|CloudBlobWrapper
name|blob
init|=
operator|(
name|CloudBlobWrapper
operator|)
name|blobItem
decl_stmt|;
name|BlobProperties
name|properties
init|=
name|blob
operator|.
name|getProperties
argument_list|()
decl_stmt|;
comment|// Determine format of the blob name depending on whether an absolute
comment|// path is being used or not.
name|blobKey
operator|=
name|normalizeKey
argument_list|(
name|blob
argument_list|)
expr_stmt|;
name|FileMetadata
name|metadata
decl_stmt|;
if|if
condition|(
name|retrieveFolderAttribute
argument_list|(
name|blob
argument_list|)
condition|)
block|{
name|metadata
operator|=
operator|new
name|FileMetadata
argument_list|(
name|blobKey
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|,
name|BlobMaterialization
operator|.
name|Explicit
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metadata
operator|=
operator|new
name|FileMetadata
argument_list|(
name|blobKey
argument_list|,
name|getDataLength
argument_list|(
name|blob
argument_list|,
name|properties
argument_list|)
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Add the metadata to the list, but remove any existing duplicate
comment|// entries first that we may have added by finding nested files.
name|FileMetadata
name|existing
init|=
name|getFileMetadataInList
argument_list|(
name|fileMetadata
argument_list|,
name|blobKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|existing
operator|!=
literal|null
condition|)
block|{
name|fileMetadata
operator|.
name|remove
argument_list|(
name|existing
argument_list|)
expr_stmt|;
block|}
name|fileMetadata
operator|.
name|add
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|blobItem
operator|instanceof
name|CloudBlobDirectoryWrapper
condition|)
block|{
name|CloudBlobDirectoryWrapper
name|directory
init|=
operator|(
name|CloudBlobDirectoryWrapper
operator|)
name|blobItem
decl_stmt|;
comment|// Determine format of directory name depending on whether an absolute
comment|// path is being used or not.
comment|//
name|String
name|dirKey
init|=
name|normalizeKey
argument_list|(
name|directory
argument_list|)
decl_stmt|;
comment|// Strip the last /
if|if
condition|(
name|dirKey
operator|.
name|endsWith
argument_list|(
name|PATH_DELIMITER
argument_list|)
condition|)
block|{
name|dirKey
operator|=
name|dirKey
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|dirKey
operator|.
name|length
argument_list|()
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// Reached the targeted listing depth. Return metadata for the
comment|// directory using default permissions.
comment|//
comment|// Note: Something smarter should be done about permissions. Maybe
comment|// inherit the permissions of the first non-directory blob.
comment|// Also, getting a proper value for last-modified is tricky.
name|FileMetadata
name|directoryMetadata
init|=
operator|new
name|FileMetadata
argument_list|(
name|dirKey
argument_list|,
literal|0
argument_list|,
name|defaultPermissionNoBlobMetadata
argument_list|()
argument_list|,
name|BlobMaterialization
operator|.
name|Implicit
argument_list|)
decl_stmt|;
comment|// Add the directory metadata to the list only if it's not already
comment|// there.
if|if
condition|(
name|getFileMetadataInList
argument_list|(
name|fileMetadata
argument_list|,
name|dirKey
argument_list|)
operator|==
literal|null
condition|)
block|{
name|fileMetadata
operator|.
name|add
argument_list|(
name|directoryMetadata
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|enableFlatListing
condition|)
block|{
comment|// Currently at a depth of one, decrement the listing depth for
comment|// sub-directories.
name|buildUpList
argument_list|(
name|directory
argument_list|,
name|fileMetadata
argument_list|,
name|maxListingCount
argument_list|,
name|maxListingDepth
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Note: Original code indicated that this may be a hack.
name|priorLastKey
operator|=
literal|null
expr_stmt|;
name|PartialListing
name|listing
init|=
operator|new
name|PartialListing
argument_list|(
name|priorLastKey
argument_list|,
name|fileMetadata
operator|.
name|toArray
argument_list|(
operator|new
name|FileMetadata
index|[]
block|{}
argument_list|)
argument_list|,
literal|0
operator|==
name|fileMetadata
operator|.
name|size
argument_list|()
condition|?
operator|new
name|String
index|[]
block|{}
else|:
operator|new
name|String
index|[]
block|{
name|prefix
block|}
argument_list|)
decl_stmt|;
return|return
name|listing
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw as an Azure storage exception.
comment|//
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Build up a metadata list of blobs in an Azure blob directory. This method    * uses a in-order first traversal of blob directory structures to maintain    * the sorted order of the blob names.    *     * @param aCloudBlobDirectory Azure blob directory    * @param aFileMetadataList a list of file metadata objects for each    *                          non-directory blob.    * @param maxListingCount maximum length of the built up list.    */
DECL|method|buildUpList (CloudBlobDirectoryWrapper aCloudBlobDirectory, ArrayList<FileMetadata> aFileMetadataList, final int maxListingCount, final int maxListingDepth)
specifier|private
name|void
name|buildUpList
parameter_list|(
name|CloudBlobDirectoryWrapper
name|aCloudBlobDirectory
parameter_list|,
name|ArrayList
argument_list|<
name|FileMetadata
argument_list|>
name|aFileMetadataList
parameter_list|,
specifier|final
name|int
name|maxListingCount
parameter_list|,
specifier|final
name|int
name|maxListingDepth
parameter_list|)
throws|throws
name|Exception
block|{
comment|// Push the blob directory onto the stack.
comment|//
name|AzureLinkedStack
argument_list|<
name|Iterator
argument_list|<
name|ListBlobItem
argument_list|>
argument_list|>
name|dirIteratorStack
init|=
operator|new
name|AzureLinkedStack
argument_list|<
name|Iterator
argument_list|<
name|ListBlobItem
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|blobItems
init|=
name|aCloudBlobDirectory
operator|.
name|listBlobs
argument_list|(
literal|null
argument_list|,
literal|false
argument_list|,
name|EnumSet
operator|.
name|of
argument_list|(
name|BlobListingDetails
operator|.
name|METADATA
argument_list|)
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|ListBlobItem
argument_list|>
name|blobItemIterator
init|=
name|blobItems
operator|.
name|iterator
argument_list|()
decl_stmt|;
if|if
condition|(
literal|0
operator|==
name|maxListingDepth
operator|||
literal|0
operator|==
name|maxListingCount
condition|)
block|{
comment|// Recurrence depth and listing count are already exhausted. Return
comment|// immediately.
return|return;
block|}
comment|// The directory listing depth is unbounded if the maximum listing depth
comment|// is negative.
specifier|final
name|boolean
name|isUnboundedDepth
init|=
operator|(
name|maxListingDepth
operator|<
literal|0
operator|)
decl_stmt|;
comment|// Reset the current directory listing depth.
name|int
name|listingDepth
init|=
literal|1
decl_stmt|;
comment|// Loop until all directories have been traversed in-order. Loop only
comment|// the following conditions are satisfied:
comment|// (1) The stack is not empty, and
comment|// (2) maxListingCount> 0 implies that the number of items in the
comment|// metadata list is less than the max listing count.
while|while
condition|(
literal|null
operator|!=
name|blobItemIterator
operator|&&
operator|(
name|maxListingCount
operator|<=
literal|0
operator|||
name|aFileMetadataList
operator|.
name|size
argument_list|()
operator|<
name|maxListingCount
operator|)
condition|)
block|{
while|while
condition|(
name|blobItemIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
comment|// Check if the count of items on the list exhausts the maximum
comment|// listing count.
comment|//
if|if
condition|(
literal|0
operator|<
name|maxListingCount
operator|&&
name|aFileMetadataList
operator|.
name|size
argument_list|()
operator|>=
name|maxListingCount
condition|)
block|{
break|break;
block|}
name|ListBlobItem
name|blobItem
init|=
name|blobItemIterator
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// Add the file metadata to the list if this is not a blob
comment|// directory item.
comment|//
if|if
condition|(
name|blobItem
operator|instanceof
name|CloudBlockBlobWrapper
operator|||
name|blobItem
operator|instanceof
name|CloudPageBlobWrapper
condition|)
block|{
name|String
name|blobKey
init|=
literal|null
decl_stmt|;
name|CloudBlobWrapper
name|blob
init|=
operator|(
name|CloudBlobWrapper
operator|)
name|blobItem
decl_stmt|;
name|BlobProperties
name|properties
init|=
name|blob
operator|.
name|getProperties
argument_list|()
decl_stmt|;
comment|// Determine format of the blob name depending on whether an absolute
comment|// path is being used or not.
name|blobKey
operator|=
name|normalizeKey
argument_list|(
name|blob
argument_list|)
expr_stmt|;
name|FileMetadata
name|metadata
decl_stmt|;
if|if
condition|(
name|retrieveFolderAttribute
argument_list|(
name|blob
argument_list|)
condition|)
block|{
name|metadata
operator|=
operator|new
name|FileMetadata
argument_list|(
name|blobKey
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|,
name|BlobMaterialization
operator|.
name|Explicit
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|metadata
operator|=
operator|new
name|FileMetadata
argument_list|(
name|blobKey
argument_list|,
name|getDataLength
argument_list|(
name|blob
argument_list|,
name|properties
argument_list|)
argument_list|,
name|properties
operator|.
name|getLastModified
argument_list|()
operator|.
name|getTime
argument_list|()
argument_list|,
name|getPermissionStatus
argument_list|(
name|blob
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Add the directory metadata to the list only if it's not already
comment|// there.
name|FileMetadata
name|existing
init|=
name|getFileMetadataInList
argument_list|(
name|aFileMetadataList
argument_list|,
name|blobKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|existing
operator|!=
literal|null
condition|)
block|{
name|aFileMetadataList
operator|.
name|remove
argument_list|(
name|existing
argument_list|)
expr_stmt|;
block|}
name|aFileMetadataList
operator|.
name|add
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|blobItem
operator|instanceof
name|CloudBlobDirectoryWrapper
condition|)
block|{
name|CloudBlobDirectoryWrapper
name|directory
init|=
operator|(
name|CloudBlobDirectoryWrapper
operator|)
name|blobItem
decl_stmt|;
comment|// This is a directory blob, push the current iterator onto
comment|// the stack of iterators and start iterating through the current
comment|// directory.
if|if
condition|(
name|isUnboundedDepth
operator|||
name|maxListingDepth
operator|>
name|listingDepth
condition|)
block|{
comment|// Push the current directory on the stack and increment the listing
comment|// depth.
name|dirIteratorStack
operator|.
name|push
argument_list|(
name|blobItemIterator
argument_list|)
expr_stmt|;
operator|++
name|listingDepth
expr_stmt|;
comment|// The current blob item represents the new directory. Get
comment|// an iterator for this directory and continue by iterating through
comment|// this directory.
name|blobItems
operator|=
name|directory
operator|.
name|listBlobs
argument_list|(
literal|null
argument_list|,
literal|false
argument_list|,
name|EnumSet
operator|.
name|noneOf
argument_list|(
name|BlobListingDetails
operator|.
name|class
argument_list|)
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|blobItemIterator
operator|=
name|blobItems
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Determine format of directory name depending on whether an
comment|// absolute path is being used or not.
name|String
name|dirKey
init|=
name|normalizeKey
argument_list|(
name|directory
argument_list|)
decl_stmt|;
if|if
condition|(
name|getFileMetadataInList
argument_list|(
name|aFileMetadataList
argument_list|,
name|dirKey
argument_list|)
operator|==
literal|null
condition|)
block|{
comment|// Reached the targeted listing depth. Return metadata for the
comment|// directory using default permissions.
comment|//
comment|// Note: Something smarter should be done about permissions. Maybe
comment|// inherit the permissions of the first non-directory blob.
comment|// Also, getting a proper value for last-modified is tricky.
comment|//
name|FileMetadata
name|directoryMetadata
init|=
operator|new
name|FileMetadata
argument_list|(
name|dirKey
argument_list|,
literal|0
argument_list|,
name|defaultPermissionNoBlobMetadata
argument_list|()
argument_list|,
name|BlobMaterialization
operator|.
name|Implicit
argument_list|)
decl_stmt|;
comment|// Add the directory metadata to the list.
name|aFileMetadataList
operator|.
name|add
argument_list|(
name|directoryMetadata
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// Traversal of directory tree
comment|// Check if the iterator stack is empty. If it is set the next blob
comment|// iterator to null. This will act as a terminator for the for-loop.
comment|// Otherwise pop the next iterator from the stack and continue looping.
comment|//
if|if
condition|(
name|dirIteratorStack
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|blobItemIterator
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
comment|// Pop the next directory item from the stack and decrement the
comment|// depth.
name|blobItemIterator
operator|=
name|dirIteratorStack
operator|.
name|pop
argument_list|()
expr_stmt|;
operator|--
name|listingDepth
expr_stmt|;
comment|// Assertion: Listing depth should not be less than zero.
if|if
condition|(
name|listingDepth
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Non-negative listing depth expected"
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Return the actual data length of the blob with the specified properties.    * If it is a page blob, you can't rely on the length from the properties    * argument and you must get it from the file. Otherwise, you can.    */
DECL|method|getDataLength (CloudBlobWrapper blob, BlobProperties properties)
specifier|private
name|long
name|getDataLength
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|BlobProperties
name|properties
parameter_list|)
throws|throws
name|AzureException
block|{
if|if
condition|(
name|blob
operator|instanceof
name|CloudPageBlobWrapper
condition|)
block|{
try|try
block|{
return|return
name|PageBlobInputStream
operator|.
name|getPageBlobDataSize
argument_list|(
operator|(
name|CloudPageBlobWrapper
operator|)
name|blob
argument_list|,
name|getInstrumentedContext
argument_list|(
name|isConcurrentOOBAppendAllowed
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
literal|"Unexpected exception getting page blob actual data size."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
return|return
name|properties
operator|.
name|getLength
argument_list|()
return|;
block|}
comment|/**    * Deletes the given blob, taking special care that if we get a    * blob-not-found exception upon retrying the operation, we just    * swallow the error since what most probably happened is that    * the first operation succeeded on the server.    * @param blob The blob to delete.    * @param lease Azure blob lease, or null if no lease is to be used.    * @throws StorageException    */
DECL|method|safeDelete (CloudBlobWrapper blob, SelfRenewingLease lease)
specifier|private
name|void
name|safeDelete
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|SelfRenewingLease
name|lease
parameter_list|)
throws|throws
name|StorageException
block|{
name|OperationContext
name|operationContext
init|=
name|getInstrumentedContext
argument_list|()
decl_stmt|;
try|try
block|{
name|blob
operator|.
name|delete
argument_list|(
name|operationContext
argument_list|,
name|lease
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Encountered Storage Exception for delete on Blob: {}, Exception Details: {} Error Code: {}"
argument_list|,
name|blob
operator|.
name|getUri
argument_list|()
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
operator|.
name|getErrorCode
argument_list|()
argument_list|)
expr_stmt|;
comment|// On exception, check that if:
comment|// 1. It's a BlobNotFound exception AND
comment|// 2. It got there after one-or-more retries THEN
comment|// we swallow the exception.
if|if
condition|(
name|e
operator|.
name|getErrorCode
argument_list|()
operator|!=
literal|null
operator|&&
name|e
operator|.
name|getErrorCode
argument_list|()
operator|.
name|equals
argument_list|(
literal|"BlobNotFound"
argument_list|)
operator|&&
name|operationContext
operator|.
name|getRequestResults
argument_list|()
operator|.
name|size
argument_list|()
operator|>
literal|1
operator|&&
name|operationContext
operator|.
name|getRequestResults
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getException
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Swallowing delete exception on retry: {}"
argument_list|,
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|lease
operator|!=
literal|null
condition|)
block|{
name|lease
operator|.
name|free
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * API implementation to delete a blob in the back end azure storage.    */
annotation|@
name|Override
DECL|method|delete (String key, SelfRenewingLease lease)
specifier|public
name|boolean
name|delete
parameter_list|(
name|String
name|key
parameter_list|,
name|SelfRenewingLease
name|lease
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
operator|==
name|ContainerState
operator|.
name|DoesntExist
condition|)
block|{
comment|// Container doesn't exist, no need to do anything
return|return
literal|true
return|;
block|}
comment|// Get the blob reference and delete it.
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|blob
operator|.
name|exists
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
condition|)
block|{
name|safeDelete
argument_list|(
name|blob
argument_list|,
name|lease
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * API implementation to delete a blob in the back end azure storage.    */
annotation|@
name|Override
DECL|method|delete (String key)
specifier|public
name|boolean
name|delete
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|delete
argument_list|(
name|key
argument_list|,
literal|null
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|Throwable
name|t
init|=
name|e
operator|.
name|getCause
argument_list|()
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
operator|&&
name|t
operator|instanceof
name|StorageException
condition|)
block|{
name|StorageException
name|se
init|=
operator|(
name|StorageException
operator|)
name|t
decl_stmt|;
if|if
condition|(
name|se
operator|.
name|getErrorCode
argument_list|()
operator|.
name|equals
argument_list|(
operator|(
literal|"LeaseIdMissing"
operator|)
argument_list|)
condition|)
block|{
name|SelfRenewingLease
name|lease
init|=
literal|null
decl_stmt|;
try|try
block|{
name|lease
operator|=
name|acquireLease
argument_list|(
name|key
argument_list|)
expr_stmt|;
return|return
name|delete
argument_list|(
name|key
argument_list|,
name|lease
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AzureException
name|e3
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got unexpected exception trying to acquire lease on "
operator|+
name|key
operator|+
literal|"."
operator|+
name|e3
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|e3
throw|;
block|}
finally|finally
block|{
try|try
block|{
if|if
condition|(
name|lease
operator|!=
literal|null
condition|)
block|{
name|lease
operator|.
name|free
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e4
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to free lease on "
operator|+
name|key
argument_list|,
name|e4
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
annotation|@
name|Override
DECL|method|rename (String srcKey, String dstKey)
specifier|public
name|void
name|rename
parameter_list|(
name|String
name|srcKey
parameter_list|,
name|String
name|dstKey
parameter_list|)
throws|throws
name|IOException
block|{
name|rename
argument_list|(
name|srcKey
argument_list|,
name|dstKey
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|rename (String srcKey, String dstKey, boolean acquireLease, SelfRenewingLease existingLease)
specifier|public
name|void
name|rename
parameter_list|(
name|String
name|srcKey
parameter_list|,
name|String
name|dstKey
parameter_list|,
name|boolean
name|acquireLease
parameter_list|,
name|SelfRenewingLease
name|existingLease
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving {} to {}"
argument_list|,
name|srcKey
argument_list|,
name|dstKey
argument_list|)
expr_stmt|;
if|if
condition|(
name|acquireLease
operator|&&
name|existingLease
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot acquire new lease if one already exists."
argument_list|)
throw|;
block|}
name|CloudBlobWrapper
name|srcBlob
init|=
literal|null
decl_stmt|;
name|CloudBlobWrapper
name|dstBlob
init|=
literal|null
decl_stmt|;
name|SelfRenewingLease
name|lease
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// Attempts rename may occur before opening any streams so first,
comment|// check if a session exists, if not create a session with the Azure
comment|// storage server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
expr_stmt|;
comment|// Get the source blob and assert its existence. If the source key
comment|// needs to be normalized then normalize it.
comment|//
name|srcBlob
operator|=
name|getBlobReference
argument_list|(
name|srcKey
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|srcBlob
operator|.
name|exists
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
literal|"Source blob "
operator|+
name|srcKey
operator|+
literal|" does not exist."
argument_list|)
throw|;
block|}
comment|/**        * Conditionally get a lease on the source blob to prevent other writers        * from changing it. This is used for correctness in HBase when log files        * are renamed. It generally should do no harm other than take a little        * more time for other rename scenarios. When the HBase master renames a        * log file folder, the lease locks out other writers.  This        * prevents a region server that the master thinks is dead, but is still        * alive, from committing additional updates.  This is different than        * when HBase runs on HDFS, where the region server recovers the lease        * on a log file, to gain exclusive access to it, before it splits it.        */
if|if
condition|(
name|acquireLease
condition|)
block|{
name|lease
operator|=
name|srcBlob
operator|.
name|acquireLease
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|existingLease
operator|!=
literal|null
condition|)
block|{
name|lease
operator|=
name|existingLease
expr_stmt|;
block|}
comment|// Get the destination blob. The destination key always needs to be
comment|// normalized.
comment|//
name|dstBlob
operator|=
name|getBlobReference
argument_list|(
name|dstKey
argument_list|)
expr_stmt|;
comment|// Rename the source blob to the destination blob by copying it to
comment|// the destination blob then deleting it.
comment|//
comment|// Copy blob operation in Azure storage is very costly. It will be highly
comment|// likely throttled during Azure storage gc. Short term fix will be using
comment|// a more intensive exponential retry policy when the cluster is getting
comment|// throttled.
try|try
block|{
name|dstBlob
operator|.
name|startCopyFromBlob
argument_list|(
name|srcBlob
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|se
parameter_list|)
block|{
if|if
condition|(
name|se
operator|.
name|getHttpStatusCode
argument_list|()
operator|==
name|HttpURLConnection
operator|.
name|HTTP_UNAVAILABLE
condition|)
block|{
name|int
name|copyBlobMinBackoff
init|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_COPYBLOB_MIN_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_COPYBLOB_MIN_BACKOFF_INTERVAL
argument_list|)
decl_stmt|;
name|int
name|copyBlobMaxBackoff
init|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_COPYBLOB_MAX_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_COPYBLOB_MAX_BACKOFF_INTERVAL
argument_list|)
decl_stmt|;
name|int
name|copyBlobDeltaBackoff
init|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_COPYBLOB_BACKOFF_INTERVAL
argument_list|,
name|DEFAULT_COPYBLOB_BACKOFF_INTERVAL
argument_list|)
decl_stmt|;
name|int
name|copyBlobMaxRetries
init|=
name|sessionConfiguration
operator|.
name|getInt
argument_list|(
name|KEY_COPYBLOB_MAX_IO_RETRIES
argument_list|,
name|DEFAULT_COPYBLOB_MAX_RETRY_ATTEMPTS
argument_list|)
decl_stmt|;
name|BlobRequestOptions
name|options
init|=
operator|new
name|BlobRequestOptions
argument_list|()
decl_stmt|;
name|options
operator|.
name|setRetryPolicyFactory
argument_list|(
operator|new
name|RetryExponentialRetry
argument_list|(
name|copyBlobMinBackoff
argument_list|,
name|copyBlobDeltaBackoff
argument_list|,
name|copyBlobMaxBackoff
argument_list|,
name|copyBlobMaxRetries
argument_list|)
argument_list|)
expr_stmt|;
name|dstBlob
operator|.
name|startCopyFromBlob
argument_list|(
name|srcBlob
argument_list|,
name|options
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|se
throw|;
block|}
block|}
name|waitForCopyToComplete
argument_list|(
name|dstBlob
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|safeDelete
argument_list|(
name|srcBlob
argument_list|,
name|lease
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getHttpStatusCode
argument_list|()
operator|==
name|HttpURLConnection
operator|.
name|HTTP_UNAVAILABLE
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Rename: CopyBlob: StorageException: ServerBusy: Retry complete, will attempt client side copy for page blob"
argument_list|)
expr_stmt|;
name|InputStream
name|ipStream
init|=
literal|null
decl_stmt|;
name|OutputStream
name|opStream
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|srcBlob
operator|.
name|getProperties
argument_list|()
operator|.
name|getBlobType
argument_list|()
operator|==
name|BlobType
operator|.
name|PAGE_BLOB
condition|)
block|{
name|ipStream
operator|=
name|openInputStream
argument_list|(
name|srcBlob
argument_list|)
expr_stmt|;
name|opStream
operator|=
name|openOutputStream
argument_list|(
name|dstBlob
argument_list|)
expr_stmt|;
name|byte
index|[]
name|buffer
init|=
operator|new
name|byte
index|[
name|PageBlobFormatHelpers
operator|.
name|PAGE_SIZE
index|]
decl_stmt|;
name|int
name|len
decl_stmt|;
while|while
condition|(
operator|(
name|len
operator|=
name|ipStream
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
operator|)
operator|!=
operator|-
literal|1
condition|)
block|{
name|opStream
operator|.
name|write
argument_list|(
name|buffer
argument_list|,
literal|0
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
name|opStream
operator|.
name|flush
argument_list|()
expr_stmt|;
name|opStream
operator|.
name|close
argument_list|()
expr_stmt|;
name|ipStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|safeDelete
argument_list|(
name|srcBlob
argument_list|,
name|lease
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|se
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Rename: CopyBlob: StorageException: Failed"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|AzureException
argument_list|(
name|se
argument_list|)
throw|;
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|ipStream
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeStream
argument_list|(
name|opStream
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
comment|// Re-throw exception as an Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
DECL|method|waitForCopyToComplete (CloudBlobWrapper blob, OperationContext opContext)
specifier|private
name|void
name|waitForCopyToComplete
parameter_list|(
name|CloudBlobWrapper
name|blob
parameter_list|,
name|OperationContext
name|opContext
parameter_list|)
block|{
name|boolean
name|copyInProgress
init|=
literal|true
decl_stmt|;
while|while
condition|(
name|copyInProgress
condition|)
block|{
try|try
block|{
name|blob
operator|.
name|downloadAttributes
argument_list|(
name|opContext
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|se
parameter_list|)
block|{       }
comment|// test for null because mocked filesystem doesn't know about copystates yet.
name|copyInProgress
operator|=
operator|(
name|blob
operator|.
name|getCopyState
argument_list|()
operator|!=
literal|null
operator|&&
name|blob
operator|.
name|getCopyState
argument_list|()
operator|.
name|getStatus
argument_list|()
operator|==
name|CopyStatus
operator|.
name|PENDING
operator|)
expr_stmt|;
if|if
condition|(
name|copyInProgress
condition|)
block|{
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|//ignore
block|}
block|}
block|}
block|}
comment|/**    * Checks whether an explicit file/folder exists.    * This is used by redo of atomic rename.    * There was a bug(apache jira HADOOP-12780) during atomic rename if    * process crashes after an inner directory has been renamed but still    * there are file under that directory to be renamed then after the    * process comes again it tries to redo the renames. It checks whether    * the directory exists or not by calling filesystem.exist.    * But filesystem.Exists will treat that directory as implicit directory    * and return true as file exists under that directory. So It will try    * try to rename that directory and will fail as the corresponding blob    * does not exist. So this method explicitly checks for the blob.    */
annotation|@
name|Override
DECL|method|explicitFileExists (String key)
specifier|public
name|boolean
name|explicitFileExists
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AzureException
block|{
name|CloudBlobWrapper
name|blob
decl_stmt|;
try|try
block|{
name|blob
operator|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
literal|null
operator|!=
name|blob
operator|&&
name|blob
operator|.
name|exists
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|StorageException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Changes the permission status on the given key.    */
annotation|@
name|Override
DECL|method|changePermissionStatus (String key, PermissionStatus newPermission)
specifier|public
name|void
name|changePermissionStatus
parameter_list|(
name|String
name|key
parameter_list|,
name|PermissionStatus
name|newPermission
parameter_list|)
throws|throws
name|AzureException
block|{
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|blob
operator|.
name|downloadAttributes
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
name|storePermissionStatus
argument_list|(
name|blob
argument_list|,
name|newPermission
argument_list|)
expr_stmt|;
name|blob
operator|.
name|uploadMetadata
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|purge (String prefix)
specifier|public
name|void
name|purge
parameter_list|(
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
comment|// Attempts to purge may occur before opening any streams so first,
comment|// check if a session exists, if not create a session with the Azure
comment|// storage server.
if|if
condition|(
literal|null
operator|==
name|storageInteractionLayer
condition|)
block|{
specifier|final
name|String
name|errMsg
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Storage session expected for URI '%s' but does not exist."
argument_list|,
name|sessionUri
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|AssertionError
argument_list|(
name|errMsg
argument_list|)
throw|;
block|}
if|if
condition|(
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
operator|==
name|ContainerState
operator|.
name|DoesntExist
condition|)
block|{
comment|// Container doesn't exist, no need to do anything.
return|return;
block|}
comment|// Get all blob items with the given prefix from the container and delete
comment|// them.
name|Iterable
argument_list|<
name|ListBlobItem
argument_list|>
name|objects
init|=
name|listRootBlobs
argument_list|(
name|prefix
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
decl_stmt|;
for|for
control|(
name|ListBlobItem
name|blobItem
range|:
name|objects
control|)
block|{
operator|(
operator|(
name|CloudBlob
operator|)
name|blobItem
operator|)
operator|.
name|delete
argument_list|(
name|DeleteSnapshotsOption
operator|.
name|NONE
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Re-throw as an Azure storage exception.
comment|//
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get a lease on the blob identified by key. This lease will be renewed    * indefinitely by a background thread.    */
annotation|@
name|Override
DECL|method|acquireLease (String key)
specifier|public
name|SelfRenewingLease
name|acquireLease
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AzureException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"acquiring lease on {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
return|return
name|blob
operator|.
name|acquireLease
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting to get lease. Re-throw as an
comment|// Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|updateFolderLastModifiedTime (String key, Date lastModified, SelfRenewingLease folderLease)
specifier|public
name|void
name|updateFolderLastModifiedTime
parameter_list|(
name|String
name|key
parameter_list|,
name|Date
name|lastModified
parameter_list|,
name|SelfRenewingLease
name|folderLease
parameter_list|)
throws|throws
name|AzureException
block|{
try|try
block|{
name|checkContainer
argument_list|(
name|ContainerAccessType
operator|.
name|ReadThenWrite
argument_list|)
expr_stmt|;
name|CloudBlobWrapper
name|blob
init|=
name|getBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//setLastModified function is not available in 2.0.0 version. blob.uploadProperties automatically updates last modified
comment|//timestamp to current time
name|blob
operator|.
name|uploadProperties
argument_list|(
name|getInstrumentedContext
argument_list|()
argument_list|,
name|folderLease
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// Caught exception while attempting to update the properties. Re-throw as an
comment|// Azure storage exception.
throw|throw
operator|new
name|AzureException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|updateFolderLastModifiedTime (String key, SelfRenewingLease folderLease)
specifier|public
name|void
name|updateFolderLastModifiedTime
parameter_list|(
name|String
name|key
parameter_list|,
name|SelfRenewingLease
name|folderLease
parameter_list|)
throws|throws
name|AzureException
block|{
specifier|final
name|Calendar
name|lastModifiedCalendar
init|=
name|Calendar
operator|.
name|getInstance
argument_list|(
name|Utility
operator|.
name|LOCALE_US
argument_list|)
decl_stmt|;
name|lastModifiedCalendar
operator|.
name|setTimeZone
argument_list|(
name|Utility
operator|.
name|UTC_ZONE
argument_list|)
expr_stmt|;
name|Date
name|lastModified
init|=
name|lastModifiedCalendar
operator|.
name|getTime
argument_list|()
decl_stmt|;
name|updateFolderLastModifiedTime
argument_list|(
name|key
argument_list|,
name|lastModified
argument_list|,
name|folderLease
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|dump ()
specifier|public
name|void
name|dump
parameter_list|()
throws|throws
name|IOException
block|{   }
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|bandwidthGaugeUpdater
operator|!=
literal|null
condition|)
block|{
name|bandwidthGaugeUpdater
operator|.
name|close
argument_list|()
expr_stmt|;
name|bandwidthGaugeUpdater
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|// Finalizer to ensure complete shutdown
annotation|@
name|Override
DECL|method|finalize ()
specifier|protected
name|void
name|finalize
parameter_list|()
throws|throws
name|Throwable
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"finalize() called"
argument_list|)
expr_stmt|;
name|close
argument_list|()
expr_stmt|;
name|super
operator|.
name|finalize
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|retrieveAppendStream (String key, int bufferSize)
specifier|public
name|DataOutputStream
name|retrieveAppendStream
parameter_list|(
name|String
name|key
parameter_list|,
name|int
name|bufferSize
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|isPageBlobKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Append not supported for Page Blobs"
argument_list|)
throw|;
block|}
name|CloudBlobWrapper
name|blob
init|=
name|this
operator|.
name|container
operator|.
name|getBlockBlobReference
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|BlockBlobAppendStream
name|appendStream
init|=
operator|new
name|BlockBlobAppendStream
argument_list|(
operator|(
name|CloudBlockBlobWrapper
operator|)
name|blob
argument_list|,
name|key
argument_list|,
name|bufferSize
argument_list|,
name|getInstrumentedContext
argument_list|()
argument_list|)
decl_stmt|;
name|appendStream
operator|.
name|initialize
argument_list|()
expr_stmt|;
return|return
operator|new
name|DataOutputStream
argument_list|(
name|appendStream
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|AzureException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

