begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.azure
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assume
operator|.
name|assumeNotNull
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|azure
operator|.
name|AzureException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Time
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_comment
comment|/**  * Write data into a page blob and verify you can read back all of it  * or just a part of it.  */
end_comment

begin_class
DECL|class|TestReadAndSeekPageBlobAfterWrite
specifier|public
class|class
name|TestReadAndSeekPageBlobAfterWrite
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|TestReadAndSeekPageBlobAfterWrite
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|fs
specifier|private
name|FileSystem
name|fs
decl_stmt|;
DECL|field|testAccount
specifier|private
name|AzureBlobStorageTestAccount
name|testAccount
decl_stmt|;
DECL|field|randomData
specifier|private
name|byte
index|[]
name|randomData
decl_stmt|;
comment|// Page blob physical page size
DECL|field|PAGE_SIZE
specifier|private
specifier|static
specifier|final
name|int
name|PAGE_SIZE
init|=
name|PageBlobFormatHelpers
operator|.
name|PAGE_SIZE
decl_stmt|;
comment|// Size of data on page (excluding header)
DECL|field|PAGE_DATA_SIZE
specifier|private
specifier|static
specifier|final
name|int
name|PAGE_DATA_SIZE
init|=
name|PAGE_SIZE
operator|-
name|PageBlobFormatHelpers
operator|.
name|PAGE_HEADER_SIZE
decl_stmt|;
DECL|field|MAX_BYTES
specifier|private
specifier|static
specifier|final
name|int
name|MAX_BYTES
init|=
literal|33554432
decl_stmt|;
comment|// maximum bytes in a file that we'll test
DECL|field|MAX_PAGES
specifier|private
specifier|static
specifier|final
name|int
name|MAX_PAGES
init|=
name|MAX_BYTES
operator|/
name|PAGE_SIZE
decl_stmt|;
comment|// maximum number of pages we'll test
DECL|field|rand
specifier|private
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
comment|// A key with a prefix under /pageBlobs, which for the test file system will
comment|// force use of a page blob.
DECL|field|KEY
specifier|private
specifier|static
specifier|final
name|String
name|KEY
init|=
literal|"/pageBlobs/file.dat"
decl_stmt|;
DECL|field|PATH
specifier|private
specifier|static
specifier|final
name|Path
name|PATH
init|=
operator|new
name|Path
argument_list|(
name|KEY
argument_list|)
decl_stmt|;
comment|// path of page blob file to read and write
DECL|method|createTestAccount ()
specifier|protected
name|AzureBlobStorageTestAccount
name|createTestAccount
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|AzureBlobStorageTestAccount
operator|.
name|create
argument_list|()
return|;
block|}
annotation|@
name|Before
DECL|method|setUp ()
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|testAccount
operator|=
name|createTestAccount
argument_list|()
expr_stmt|;
if|if
condition|(
name|testAccount
operator|!=
literal|null
condition|)
block|{
name|fs
operator|=
name|testAccount
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
block|}
name|assumeNotNull
argument_list|(
name|testAccount
argument_list|)
expr_stmt|;
comment|// Make sure we are using an integral number of pages.
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|MAX_BYTES
operator|%
name|PAGE_SIZE
argument_list|)
expr_stmt|;
comment|// load an in-memory array of random data
name|randomData
operator|=
operator|new
name|byte
index|[
name|PAGE_SIZE
operator|*
name|MAX_PAGES
index|]
expr_stmt|;
name|rand
operator|.
name|nextBytes
argument_list|(
name|randomData
argument_list|)
expr_stmt|;
block|}
annotation|@
name|After
DECL|method|tearDown ()
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|testAccount
operator|!=
literal|null
condition|)
block|{
name|testAccount
operator|.
name|cleanup
argument_list|()
expr_stmt|;
name|testAccount
operator|=
literal|null
expr_stmt|;
name|fs
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Make sure the file name (key) is a page blob file name. If anybody changes that,    * we need to come back and update this test class.    */
annotation|@
name|Test
DECL|method|testIsPageBlobFileName ()
specifier|public
name|void
name|testIsPageBlobFileName
parameter_list|()
block|{
name|AzureNativeFileSystemStore
name|store
init|=
operator|(
operator|(
name|NativeAzureFileSystem
operator|)
name|fs
operator|)
operator|.
name|getStore
argument_list|()
decl_stmt|;
name|String
index|[]
name|a
init|=
name|KEY
operator|.
name|split
argument_list|(
literal|"/"
argument_list|)
decl_stmt|;
name|String
name|key2
init|=
name|a
index|[
literal|1
index|]
operator|+
literal|"/"
decl_stmt|;
name|assertTrue
argument_list|(
name|store
operator|.
name|isPageBlobKey
argument_list|(
name|key2
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * For a set of different file sizes, write some random data to a page blob,    * read it back, and compare that what was read is the same as what was written.    */
annotation|@
name|Test
DECL|method|testReadAfterWriteRandomData ()
specifier|public
name|void
name|testReadAfterWriteRandomData
parameter_list|()
throws|throws
name|IOException
block|{
comment|// local shorthand
specifier|final
name|int
name|PDS
init|=
name|PAGE_DATA_SIZE
decl_stmt|;
comment|// Test for sizes at and near page boundaries
name|int
index|[]
name|dataSizes
init|=
block|{
comment|// on first page
literal|0
block|,
literal|1
block|,
literal|2
block|,
literal|3
block|,
comment|// Near first physical page boundary (because the implementation
comment|// stores PDS + the page header size bytes on each page).
name|PDS
operator|-
literal|1
block|,
name|PDS
block|,
name|PDS
operator|+
literal|1
block|,
name|PDS
operator|+
literal|2
block|,
name|PDS
operator|+
literal|3
block|,
comment|// near second physical page boundary
operator|(
literal|2
operator|*
name|PDS
operator|)
operator|-
literal|1
block|,
operator|(
literal|2
operator|*
name|PDS
operator|)
block|,
operator|(
literal|2
operator|*
name|PDS
operator|)
operator|+
literal|1
block|,
operator|(
literal|2
operator|*
name|PDS
operator|)
operator|+
literal|2
block|,
operator|(
literal|2
operator|*
name|PDS
operator|)
operator|+
literal|3
block|,
comment|// near tenth physical page boundary
operator|(
literal|10
operator|*
name|PDS
operator|)
operator|-
literal|1
block|,
operator|(
literal|10
operator|*
name|PDS
operator|)
block|,
operator|(
literal|10
operator|*
name|PDS
operator|)
operator|+
literal|1
block|,
operator|(
literal|10
operator|*
name|PDS
operator|)
operator|+
literal|2
block|,
operator|(
literal|10
operator|*
name|PDS
operator|)
operator|+
literal|3
block|,
comment|// test one big size,>> 4MB (an internal buffer size in the code)
name|MAX_BYTES
block|}
decl_stmt|;
for|for
control|(
name|int
name|i
range|:
name|dataSizes
control|)
block|{
name|testReadAfterWriteRandomData
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|testReadAfterWriteRandomData (int size)
specifier|private
name|void
name|testReadAfterWriteRandomData
parameter_list|(
name|int
name|size
parameter_list|)
throws|throws
name|IOException
block|{
name|writeRandomData
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|readRandomDataAndVerify
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
comment|/**    * Read "size" bytes of data and verify that what was read and what was written    * are the same.    */
DECL|method|readRandomDataAndVerify (int size)
specifier|private
name|void
name|readRandomDataAndVerify
parameter_list|(
name|int
name|size
parameter_list|)
throws|throws
name|AzureException
throws|,
name|IOException
block|{
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|size
index|]
decl_stmt|;
name|FSDataInputStream
name|stream
init|=
name|fs
operator|.
name|open
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
name|int
name|bytesRead
init|=
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|)
decl_stmt|;
name|stream
operator|.
name|close
argument_list|()
expr_stmt|;
name|assertEquals
argument_list|(
name|bytesRead
argument_list|,
name|size
argument_list|)
expr_stmt|;
comment|// compare the data read to the data written
name|assertTrue
argument_list|(
name|comparePrefix
argument_list|(
name|randomData
argument_list|,
name|b
argument_list|,
name|size
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// return true if the beginning "size" values of the arrays are the same
DECL|method|comparePrefix (byte[] a, byte[] b, int size)
specifier|private
name|boolean
name|comparePrefix
parameter_list|(
name|byte
index|[]
name|a
parameter_list|,
name|byte
index|[]
name|b
parameter_list|,
name|int
name|size
parameter_list|)
block|{
if|if
condition|(
name|a
operator|.
name|length
operator|<
name|size
operator|||
name|b
operator|.
name|length
operator|<
name|size
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|a
index|[
name|i
index|]
operator|!=
name|b
index|[
name|i
index|]
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|// Write a specified amount of random data to the file path for this test class.
DECL|method|writeRandomData (int size)
specifier|private
name|void
name|writeRandomData
parameter_list|(
name|int
name|size
parameter_list|)
throws|throws
name|IOException
block|{
name|OutputStream
name|output
init|=
name|fs
operator|.
name|create
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
name|output
operator|.
name|write
argument_list|(
name|randomData
argument_list|,
literal|0
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**    * Write data to a page blob, open it, seek, and then read a range of data.    * Then compare that the data read from that range is the same as the data originally written.    */
annotation|@
name|Test
DECL|method|testPageBlobSeekAndReadAfterWrite ()
specifier|public
name|void
name|testPageBlobSeekAndReadAfterWrite
parameter_list|()
throws|throws
name|IOException
block|{
name|writeRandomData
argument_list|(
name|PAGE_SIZE
operator|*
name|MAX_PAGES
argument_list|)
expr_stmt|;
name|int
name|recordSize
init|=
literal|100
decl_stmt|;
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|recordSize
index|]
decl_stmt|;
name|FSDataInputStream
name|stream
init|=
name|fs
operator|.
name|open
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
comment|// Seek to a boundary around the middle of the 6th page
name|int
name|seekPosition
init|=
literal|5
operator|*
name|PAGE_SIZE
operator|+
literal|250
decl_stmt|;
name|stream
operator|.
name|seek
argument_list|(
name|seekPosition
argument_list|)
expr_stmt|;
comment|// Read a record's worth of bytes and verify results
name|int
name|bytesRead
init|=
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|)
decl_stmt|;
name|verifyReadRandomData
argument_list|(
name|b
argument_list|,
name|bytesRead
argument_list|,
name|seekPosition
argument_list|,
name|recordSize
argument_list|)
expr_stmt|;
comment|// Seek to another spot and read a record greater than a page
name|seekPosition
operator|=
literal|10
operator|*
name|PAGE_SIZE
operator|+
literal|250
expr_stmt|;
name|stream
operator|.
name|seek
argument_list|(
name|seekPosition
argument_list|)
expr_stmt|;
name|recordSize
operator|=
literal|1000
expr_stmt|;
name|b
operator|=
operator|new
name|byte
index|[
name|recordSize
index|]
expr_stmt|;
name|bytesRead
operator|=
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|verifyReadRandomData
argument_list|(
name|b
argument_list|,
name|bytesRead
argument_list|,
name|seekPosition
argument_list|,
name|recordSize
argument_list|)
expr_stmt|;
comment|// Read the last 100 bytes of the file
name|recordSize
operator|=
literal|100
expr_stmt|;
name|seekPosition
operator|=
name|PAGE_SIZE
operator|*
name|MAX_PAGES
operator|-
name|recordSize
expr_stmt|;
name|stream
operator|.
name|seek
argument_list|(
name|seekPosition
argument_list|)
expr_stmt|;
name|b
operator|=
operator|new
name|byte
index|[
name|recordSize
index|]
expr_stmt|;
name|bytesRead
operator|=
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|verifyReadRandomData
argument_list|(
name|b
argument_list|,
name|bytesRead
argument_list|,
name|seekPosition
argument_list|,
name|recordSize
argument_list|)
expr_stmt|;
comment|// Read past the end of the file and we should get only partial data.
name|recordSize
operator|=
literal|100
expr_stmt|;
name|seekPosition
operator|=
name|PAGE_SIZE
operator|*
name|MAX_PAGES
operator|-
name|recordSize
operator|+
literal|50
expr_stmt|;
name|stream
operator|.
name|seek
argument_list|(
name|seekPosition
argument_list|)
expr_stmt|;
name|b
operator|=
operator|new
name|byte
index|[
name|recordSize
index|]
expr_stmt|;
name|bytesRead
operator|=
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|50
argument_list|,
name|bytesRead
argument_list|)
expr_stmt|;
comment|// compare last 50 bytes written with those read
name|byte
index|[]
name|tail
init|=
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|randomData
argument_list|,
name|seekPosition
argument_list|,
name|randomData
operator|.
name|length
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|comparePrefix
argument_list|(
name|tail
argument_list|,
name|b
argument_list|,
literal|50
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Verify that reading a record of data after seeking gives the expected data.
DECL|method|verifyReadRandomData (byte[] b, int bytesRead, int seekPosition, int recordSize)
specifier|private
name|void
name|verifyReadRandomData
parameter_list|(
name|byte
index|[]
name|b
parameter_list|,
name|int
name|bytesRead
parameter_list|,
name|int
name|seekPosition
parameter_list|,
name|int
name|recordSize
parameter_list|)
block|{
name|byte
index|[]
name|originalRecordData
init|=
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|randomData
argument_list|,
name|seekPosition
argument_list|,
name|seekPosition
operator|+
name|recordSize
operator|+
literal|1
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
name|recordSize
argument_list|,
name|bytesRead
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|comparePrefix
argument_list|(
name|originalRecordData
argument_list|,
name|b
argument_list|,
name|recordSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Test many small flushed writes interspersed with periodic hflush calls.
comment|// For manual testing, increase NUM_WRITES to a large number.
comment|// The goal for a long-running manual test is to make sure that it finishes
comment|// and the close() call does not time out. It also facilitates debugging into
comment|// hflush/hsync.
annotation|@
name|Test
DECL|method|testManySmallWritesWithHFlush ()
specifier|public
name|void
name|testManySmallWritesWithHFlush
parameter_list|()
throws|throws
name|IOException
block|{
name|writeAndReadOneFile
argument_list|(
literal|50
argument_list|,
literal|100
argument_list|,
literal|20
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write a total of numWrites * recordLength data to a file, read it back,    * and check to make sure what was read is the same as what was written.    * The syncInterval is the number of writes after which to call hflush to    * force the data to storage.    */
DECL|method|writeAndReadOneFile (int numWrites, int recordLength, int syncInterval)
specifier|private
name|void
name|writeAndReadOneFile
parameter_list|(
name|int
name|numWrites
parameter_list|,
name|int
name|recordLength
parameter_list|,
name|int
name|syncInterval
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|int
name|NUM_WRITES
init|=
name|numWrites
decl_stmt|;
specifier|final
name|int
name|RECORD_LENGTH
init|=
name|recordLength
decl_stmt|;
specifier|final
name|int
name|SYNC_INTERVAL
init|=
name|syncInterval
decl_stmt|;
comment|// A lower bound on the minimum time we think it will take to do
comment|// a write to Azure storage.
specifier|final
name|long
name|MINIMUM_EXPECTED_TIME
init|=
literal|20
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Writing "
operator|+
name|NUM_WRITES
operator|*
name|RECORD_LENGTH
operator|+
literal|" bytes to "
operator|+
name|PATH
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|FSDataOutputStream
name|output
init|=
name|fs
operator|.
name|create
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
name|int
name|writesSinceHFlush
init|=
literal|0
decl_stmt|;
try|try
block|{
comment|// Do a flush and hflush to exercise case for empty write queue in PageBlobOutputStream,
comment|// to test concurrent execution gates.
name|output
operator|.
name|flush
argument_list|()
expr_stmt|;
name|output
operator|.
name|hflush
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|NUM_WRITES
condition|;
name|i
operator|++
control|)
block|{
name|output
operator|.
name|write
argument_list|(
name|randomData
argument_list|,
name|i
operator|*
name|RECORD_LENGTH
argument_list|,
name|RECORD_LENGTH
argument_list|)
expr_stmt|;
name|writesSinceHFlush
operator|++
expr_stmt|;
name|output
operator|.
name|flush
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|i
operator|%
name|SYNC_INTERVAL
operator|)
operator|==
literal|0
condition|)
block|{
name|long
name|start
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|output
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|writesSinceHFlush
operator|=
literal|0
expr_stmt|;
name|long
name|end
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
comment|// A true, round-trip synchronous flush to Azure must take
comment|// a significant amount of time or we are not syncing to storage correctly.
name|LOG
operator|.
name|debug
argument_list|(
literal|"hflush duration = "
operator|+
operator|(
name|end
operator|-
name|start
operator|)
operator|+
literal|" msec."
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"hflush duration of %d, less than minimum expected of %d"
argument_list|,
name|end
operator|-
name|start
argument_list|,
name|MINIMUM_EXPECTED_TIME
argument_list|)
argument_list|,
name|end
operator|-
name|start
operator|>=
name|MINIMUM_EXPECTED_TIME
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|long
name|start
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
name|long
name|end
init|=
name|Time
operator|.
name|monotonicNow
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"close duration = "
operator|+
operator|(
name|end
operator|-
name|start
operator|)
operator|+
literal|" msec."
argument_list|)
expr_stmt|;
if|if
condition|(
name|writesSinceHFlush
operator|>
literal|0
condition|)
block|{
name|assertTrue
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"close duration with>= 1 pending write is %d, less than minimum expected of %d"
argument_list|,
name|end
operator|-
name|start
argument_list|,
name|MINIMUM_EXPECTED_TIME
argument_list|)
argument_list|,
name|end
operator|-
name|start
operator|>=
name|MINIMUM_EXPECTED_TIME
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Read the data back and check it.
name|FSDataInputStream
name|stream
init|=
name|fs
operator|.
name|open
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
name|int
name|SIZE
init|=
name|NUM_WRITES
operator|*
name|RECORD_LENGTH
decl_stmt|;
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|SIZE
index|]
decl_stmt|;
try|try
block|{
name|stream
operator|.
name|seek
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|stream
operator|.
name|read
argument_list|(
name|b
argument_list|,
literal|0
argument_list|,
name|SIZE
argument_list|)
expr_stmt|;
name|verifyReadRandomData
argument_list|(
name|b
argument_list|,
name|SIZE
argument_list|,
literal|0
argument_list|,
name|SIZE
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|stream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// delete the file
name|fs
operator|.
name|delete
argument_list|(
name|PATH
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// Test writing to a large file repeatedly as a stress test.
comment|// Set the repetitions to a larger number for manual testing
comment|// for a longer stress run.
annotation|@
name|Test
DECL|method|testLargeFileStress ()
specifier|public
name|void
name|testLargeFileStress
parameter_list|()
throws|throws
name|IOException
block|{
name|int
name|numWrites
init|=
literal|32
decl_stmt|;
name|int
name|recordSize
init|=
literal|1024
operator|*
literal|1024
decl_stmt|;
name|int
name|syncInterval
init|=
literal|10
decl_stmt|;
name|int
name|repetitions
init|=
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|repetitions
condition|;
name|i
operator|++
control|)
block|{
name|writeAndReadOneFile
argument_list|(
name|numWrites
argument_list|,
name|recordSize
argument_list|,
name|syncInterval
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Write to a file repeatedly to verify that it extends.
comment|// The page blob file should start out at 128MB and finish at 256MB.
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|300000
argument_list|)
DECL|method|testFileSizeExtension ()
specifier|public
name|void
name|testFileSizeExtension
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|int
name|writeSize
init|=
literal|1024
operator|*
literal|1024
decl_stmt|;
specifier|final
name|int
name|numWrites
init|=
literal|129
decl_stmt|;
specifier|final
name|byte
name|dataByte
init|=
literal|5
decl_stmt|;
name|byte
index|[]
name|data
init|=
operator|new
name|byte
index|[
name|writeSize
index|]
decl_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|data
argument_list|,
name|dataByte
argument_list|)
expr_stmt|;
name|FSDataOutputStream
name|output
init|=
name|fs
operator|.
name|create
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numWrites
condition|;
name|i
operator|++
control|)
block|{
name|output
operator|.
name|write
argument_list|(
name|data
argument_list|)
expr_stmt|;
name|output
operator|.
name|hflush
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"total writes = "
operator|+
operator|(
name|i
operator|+
literal|1
operator|)
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|output
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// Show that we wrote more than the default page blob file size.
name|assertTrue
argument_list|(
name|numWrites
operator|*
name|writeSize
operator|>
name|PageBlobOutputStream
operator|.
name|PAGE_BLOB_MIN_SIZE
argument_list|)
expr_stmt|;
comment|// Verify we can list the new size. That will prove we expanded the file.
name|FileStatus
index|[]
name|status
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|PATH
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|status
index|[
literal|0
index|]
operator|.
name|getLen
argument_list|()
operator|==
name|numWrites
operator|*
name|writeSize
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Total bytes written to "
operator|+
name|PATH
operator|+
literal|" = "
operator|+
name|status
index|[
literal|0
index|]
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|PATH
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

