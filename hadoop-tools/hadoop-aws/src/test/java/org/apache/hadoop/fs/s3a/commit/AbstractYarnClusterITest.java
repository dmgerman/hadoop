begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a.commit
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|LocalDateTime
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|format
operator|.
name|DateTimeFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|rules
operator|.
name|TemporaryFolder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonConfigurationKeys
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|files
operator|.
name|SuccessData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|v2
operator|.
name|MiniMRYarnCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|v2
operator|.
name|jobhistory
operator|.
name|JHAdminConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|conf
operator|.
name|YarnConfiguration
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkNotNull
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
operator|.
name|assume
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
operator|.
name|deployService
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
operator|.
name|getTestPropertyBool
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
operator|.
name|prepareTestConfiguration
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
operator|.
name|terminateService
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
operator|.
name|FS_S3A_COMMITTER_STAGING_TMP_PATH
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
operator|.
name|FS_S3A_COMMITTER_STAGING_UNIQUE_FILENAMES
import|;
end_import

begin_comment
comment|/**  * Full integration test MR jobs.  *  * This is all done on shared static mini YARN and (optionally) HDFS clusters,  * set up before any of the tests methods run.  *  * To isolate tests properly for parallel test runs, that static state  * needs to be stored in the final classes implementing the tests, and  * exposed to the base class, with the setup clusters in the  * specific test suites creating the clusters with unique names.  *  * This is "hard" to do in Java, unlike, say, Scala.  *  * Note: this turns out not to be the root cause of ordering problems  * with the Terasort tests (that is hard coded use of a file in the local FS),  * but this design here does make it clear that the before and after class  * operations are explicitly called in the subclasses.  * If two subclasses of this class are instantiated in the same JVM, in order,  * they are guaranteed to be isolated.  *  */
end_comment

begin_class
DECL|class|AbstractYarnClusterITest
specifier|public
specifier|abstract
class|class
name|AbstractYarnClusterITest
extends|extends
name|AbstractCommitITest
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|AbstractYarnClusterITest
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|TEST_FILE_COUNT
specifier|private
specifier|static
specifier|final
name|int
name|TEST_FILE_COUNT
init|=
literal|1
decl_stmt|;
DECL|field|SCALE_TEST_FILE_COUNT
specifier|private
specifier|static
specifier|final
name|int
name|SCALE_TEST_FILE_COUNT
init|=
literal|10
decl_stmt|;
DECL|field|SCALE_TEST_KEYS
specifier|public
specifier|static
specifier|final
name|int
name|SCALE_TEST_KEYS
init|=
literal|100
decl_stmt|;
DECL|field|BASE_TEST_KEYS
specifier|public
specifier|static
specifier|final
name|int
name|BASE_TEST_KEYS
init|=
literal|10
decl_stmt|;
DECL|field|NO_OF_NODEMANAGERS
specifier|public
specifier|static
specifier|final
name|int
name|NO_OF_NODEMANAGERS
init|=
literal|2
decl_stmt|;
DECL|field|scaleTest
specifier|private
name|boolean
name|scaleTest
decl_stmt|;
comment|/**    * The static cluster binding with the lifecycle of this test; served    * through instance-level methods for sharing across methods in the    * suite.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"StaticNonFinalField"
argument_list|)
DECL|field|clusterBinding
specifier|private
specifier|static
name|ClusterBinding
name|clusterBinding
decl_stmt|;
annotation|@
name|AfterClass
DECL|method|teardownClusters ()
specifier|public
specifier|static
name|void
name|teardownClusters
parameter_list|()
throws|throws
name|IOException
block|{
name|terminateCluster
argument_list|(
name|clusterBinding
argument_list|)
expr_stmt|;
name|clusterBinding
operator|=
literal|null
expr_stmt|;
block|}
comment|/**    * This is the cluster binding which every subclass must create.    */
DECL|class|ClusterBinding
specifier|protected
specifier|static
specifier|final
class|class
name|ClusterBinding
block|{
DECL|field|clusterName
specifier|private
name|String
name|clusterName
decl_stmt|;
DECL|field|hdfs
specifier|private
specifier|final
name|MiniDFSClusterService
name|hdfs
decl_stmt|;
DECL|field|yarn
specifier|private
specifier|final
name|MiniMRYarnCluster
name|yarn
decl_stmt|;
DECL|method|ClusterBinding ( final String clusterName, final MiniDFSClusterService hdfs, final MiniMRYarnCluster yarn)
specifier|public
name|ClusterBinding
parameter_list|(
specifier|final
name|String
name|clusterName
parameter_list|,
specifier|final
name|MiniDFSClusterService
name|hdfs
parameter_list|,
specifier|final
name|MiniMRYarnCluster
name|yarn
parameter_list|)
block|{
name|this
operator|.
name|clusterName
operator|=
name|clusterName
expr_stmt|;
name|this
operator|.
name|hdfs
operator|=
name|hdfs
expr_stmt|;
name|this
operator|.
name|yarn
operator|=
name|checkNotNull
argument_list|(
name|yarn
argument_list|)
expr_stmt|;
block|}
DECL|method|getHdfs ()
specifier|public
name|MiniDFSClusterService
name|getHdfs
parameter_list|()
block|{
return|return
name|hdfs
return|;
block|}
comment|/**      * Get the cluster FS, which will either be HDFS or the local FS.      * @return a filesystem.      * @throws IOException failure      */
DECL|method|getClusterFS ()
specifier|public
name|FileSystem
name|getClusterFS
parameter_list|()
throws|throws
name|IOException
block|{
name|MiniDFSClusterService
name|miniCluster
init|=
name|getHdfs
argument_list|()
decl_stmt|;
return|return
name|miniCluster
operator|!=
literal|null
condition|?
name|miniCluster
operator|.
name|getClusterFS
argument_list|()
else|:
name|FileSystem
operator|.
name|getLocal
argument_list|(
name|yarn
operator|.
name|getConfig
argument_list|()
argument_list|)
return|;
block|}
DECL|method|getYarn ()
specifier|public
name|MiniMRYarnCluster
name|getYarn
parameter_list|()
block|{
return|return
name|yarn
return|;
block|}
DECL|method|getConf ()
specifier|public
name|Configuration
name|getConf
parameter_list|()
block|{
return|return
name|getYarn
argument_list|()
operator|.
name|getConfig
argument_list|()
return|;
block|}
DECL|method|getClusterName ()
specifier|public
name|String
name|getClusterName
parameter_list|()
block|{
return|return
name|clusterName
return|;
block|}
DECL|method|terminate ()
specifier|public
name|void
name|terminate
parameter_list|()
block|{
name|terminateService
argument_list|(
name|getYarn
argument_list|()
argument_list|)
expr_stmt|;
name|terminateService
argument_list|(
name|getHdfs
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create the cluster binding.    * The configuration will be patched by propagating down options    * from the maven build (S3Guard binding etc) and turning off unwanted    * YARN features.    *    * If an HDFS cluster is requested,    * the HDFS and YARN clusters will share the same configuration, so    * the HDFS cluster binding is implicitly propagated to YARN.    * If one is not requested, the local filesystem is used as the cluster FS.    * @param conf configuration to start with.    * @param useHDFS should an HDFS cluster be instantiated.    * @return the cluster binding.    * @throws IOException failure.    */
DECL|method|createCluster ( final JobConf conf, final boolean useHDFS)
specifier|protected
specifier|static
name|ClusterBinding
name|createCluster
parameter_list|(
specifier|final
name|JobConf
name|conf
parameter_list|,
specifier|final
name|boolean
name|useHDFS
parameter_list|)
throws|throws
name|IOException
block|{
name|prepareTestConfiguration
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|JHAdminConfig
operator|.
name|MR_HISTORY_CLEANER_ENABLE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setLong
argument_list|(
name|CommonConfigurationKeys
operator|.
name|FS_DU_INTERVAL_KEY
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
comment|// minicluster tests overreact to not enough disk space.
name|conf
operator|.
name|setBoolean
argument_list|(
name|YarnConfiguration
operator|.
name|NM_DISK_HEALTH_CHECK_ENABLE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|YarnConfiguration
operator|.
name|NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE
argument_list|,
literal|100
argument_list|)
expr_stmt|;
comment|// create a unique cluster name based on the current time in millis.
name|String
name|timestamp
init|=
name|LocalDateTime
operator|.
name|now
argument_list|()
operator|.
name|format
argument_list|(
name|DateTimeFormatter
operator|.
name|ofPattern
argument_list|(
literal|"yyyy-MM-dd-HH.mm.ss.SS"
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|clusterName
init|=
literal|"yarn-"
operator|+
name|timestamp
decl_stmt|;
name|MiniDFSClusterService
name|miniDFSClusterService
init|=
name|useHDFS
condition|?
name|deployService
argument_list|(
name|conf
argument_list|,
operator|new
name|MiniDFSClusterService
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
name|MiniMRYarnCluster
name|yarnCluster
init|=
name|deployService
argument_list|(
name|conf
argument_list|,
operator|new
name|MiniMRYarnCluster
argument_list|(
name|clusterName
argument_list|,
name|NO_OF_NODEMANAGERS
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|ClusterBinding
argument_list|(
name|clusterName
argument_list|,
name|miniDFSClusterService
argument_list|,
name|yarnCluster
argument_list|)
return|;
block|}
comment|/**    * Terminate the cluster if it is not null.    * @param cluster the cluster    */
DECL|method|terminateCluster (ClusterBinding cluster)
specifier|protected
specifier|static
name|void
name|terminateCluster
parameter_list|(
name|ClusterBinding
name|cluster
parameter_list|)
block|{
if|if
condition|(
name|cluster
operator|!=
literal|null
condition|)
block|{
name|cluster
operator|.
name|terminate
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Get the cluster binding for this subclass.    * @return the cluster binding    */
DECL|method|getClusterBinding ()
specifier|protected
name|ClusterBinding
name|getClusterBinding
parameter_list|()
block|{
return|return
name|clusterBinding
return|;
block|}
DECL|method|getYarn ()
specifier|protected
name|MiniMRYarnCluster
name|getYarn
parameter_list|()
block|{
return|return
name|getClusterBinding
argument_list|()
operator|.
name|getYarn
argument_list|()
return|;
block|}
comment|/**    * Get the cluster filesystem -hdfs or local.    * @return the filesystem shared across the yarn nodes.    */
DECL|method|getClusterFS ()
specifier|protected
name|FileSystem
name|getClusterFS
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getClusterBinding
argument_list|()
operator|.
name|getClusterFS
argument_list|()
return|;
block|}
comment|/**    * We stage work into a temporary directory rather than directly under    * the user's home directory, as that is often rejected by CI test    * runners.    */
annotation|@
name|Rule
DECL|field|stagingFilesDir
specifier|public
specifier|final
name|TemporaryFolder
name|stagingFilesDir
init|=
operator|new
name|TemporaryFolder
argument_list|()
decl_stmt|;
comment|/**    * The name of the committer as returned by    * {@link AbstractS3ACommitter#getName()}    * and used for committer construction.    */
DECL|method|committerName ()
specifier|protected
specifier|abstract
name|String
name|committerName
parameter_list|()
function_decl|;
comment|/**    * binding on demand rather than in a BeforeClass static method.    * Subclasses can override this to change the binding options.    * @return the cluster binding    */
DECL|method|demandCreateClusterBinding ()
specifier|protected
name|ClusterBinding
name|demandCreateClusterBinding
parameter_list|()
throws|throws
name|Exception
block|{
return|return
name|createCluster
argument_list|(
operator|new
name|JobConf
argument_list|()
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|setup ()
specifier|public
name|void
name|setup
parameter_list|()
throws|throws
name|Exception
block|{
name|super
operator|.
name|setup
argument_list|()
expr_stmt|;
name|scaleTest
operator|=
name|getTestPropertyBool
argument_list|(
name|getConfiguration
argument_list|()
argument_list|,
name|KEY_SCALE_TESTS_ENABLED
argument_list|,
name|DEFAULT_SCALE_TESTS_ENABLED
argument_list|)
expr_stmt|;
if|if
condition|(
name|getClusterBinding
argument_list|()
operator|==
literal|null
condition|)
block|{
name|clusterBinding
operator|=
name|demandCreateClusterBinding
argument_list|()
expr_stmt|;
block|}
name|assertNotNull
argument_list|(
literal|"cluster is not bound"
argument_list|,
name|getClusterBinding
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getTestTimeoutMillis ()
specifier|protected
name|int
name|getTestTimeoutMillis
parameter_list|()
block|{
return|return
name|SCALE_TEST_TIMEOUT_SECONDS
operator|*
literal|1000
return|;
block|}
comment|/**    * Create a job configuration.    * This creates a new job conf from the yarn    * cluster configuration then calls    * {@link #applyCustomConfigOptions(JobConf)} to allow it to be customized.    * @return the new job configuration.    * @throws IOException failure    */
DECL|method|newJobConf ()
specifier|protected
name|JobConf
name|newJobConf
parameter_list|()
throws|throws
name|IOException
block|{
name|JobConf
name|jobConf
init|=
operator|new
name|JobConf
argument_list|(
name|getYarn
argument_list|()
operator|.
name|getConfig
argument_list|()
argument_list|)
decl_stmt|;
name|jobConf
operator|.
name|addResource
argument_list|(
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|applyCustomConfigOptions
argument_list|(
name|jobConf
argument_list|)
expr_stmt|;
return|return
name|jobConf
return|;
block|}
DECL|method|createJob (Configuration jobConf)
specifier|protected
name|Job
name|createJob
parameter_list|(
name|Configuration
name|jobConf
parameter_list|)
throws|throws
name|IOException
block|{
name|Job
name|mrJob
init|=
name|Job
operator|.
name|getInstance
argument_list|(
name|jobConf
argument_list|,
name|getMethodName
argument_list|()
argument_list|)
decl_stmt|;
name|patchConfigurationForCommitter
argument_list|(
name|mrJob
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|mrJob
return|;
block|}
comment|/**    * Patch the (job) configuration for this committer.    * @param jobConf configuration to patch    * @return a configuration which will run this configuration.    */
DECL|method|patchConfigurationForCommitter ( final Configuration jobConf)
specifier|protected
name|Configuration
name|patchConfigurationForCommitter
parameter_list|(
specifier|final
name|Configuration
name|jobConf
parameter_list|)
block|{
name|jobConf
operator|.
name|setBoolean
argument_list|(
name|FS_S3A_COMMITTER_STAGING_UNIQUE_FILENAMES
argument_list|,
name|isUniqueFilenames
argument_list|()
argument_list|)
expr_stmt|;
name|bindCommitter
argument_list|(
name|jobConf
argument_list|,
name|CommitConstants
operator|.
name|S3A_COMMITTER_FACTORY
argument_list|,
name|committerName
argument_list|()
argument_list|)
expr_stmt|;
comment|// pass down the scale test flag
name|jobConf
operator|.
name|setBoolean
argument_list|(
name|KEY_SCALE_TESTS_ENABLED
argument_list|,
name|isScaleTest
argument_list|()
argument_list|)
expr_stmt|;
comment|// and fix the commit dir to the local FS across all workers.
name|String
name|staging
init|=
name|stagingFilesDir
operator|.
name|getRoot
argument_list|()
operator|.
name|getAbsolutePath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Staging temp dir is {}"
argument_list|,
name|staging
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|set
argument_list|(
name|FS_S3A_COMMITTER_STAGING_TMP_PATH
argument_list|,
name|staging
argument_list|)
expr_stmt|;
return|return
name|jobConf
return|;
block|}
comment|/**    * Get the file count for the test.    * @return the number of mappers to create.    */
DECL|method|getTestFileCount ()
specifier|public
name|int
name|getTestFileCount
parameter_list|()
block|{
return|return
name|isScaleTest
argument_list|()
condition|?
name|SCALE_TEST_FILE_COUNT
else|:
name|TEST_FILE_COUNT
return|;
block|}
comment|/**    * Override point to let implementations tune the MR Job conf.    * @param jobConf configuration    */
DECL|method|applyCustomConfigOptions (JobConf jobConf)
specifier|protected
name|void
name|applyCustomConfigOptions
parameter_list|(
name|JobConf
name|jobConf
parameter_list|)
throws|throws
name|IOException
block|{    }
comment|/**    * Override point for any committer specific validation operations;    * called after the base assertions have all passed.    * @param destPath destination of work    * @param successData loaded success data    * @throws Exception failure    */
DECL|method|customPostExecutionValidation (Path destPath, SuccessData successData)
specifier|protected
name|void
name|customPostExecutionValidation
parameter_list|(
name|Path
name|destPath
parameter_list|,
name|SuccessData
name|successData
parameter_list|)
throws|throws
name|Exception
block|{    }
comment|/**    * Assume that scale tests are enabled.    */
DECL|method|requireScaleTestsEnabled ()
specifier|protected
name|void
name|requireScaleTestsEnabled
parameter_list|()
block|{
name|assume
argument_list|(
literal|"Scale test disabled: to enable set property "
operator|+
name|KEY_SCALE_TESTS_ENABLED
argument_list|,
name|isScaleTest
argument_list|()
argument_list|)
expr_stmt|;
block|}
DECL|method|isScaleTest ()
specifier|public
name|boolean
name|isScaleTest
parameter_list|()
block|{
return|return
name|scaleTest
return|;
block|}
DECL|method|isUniqueFilenames ()
specifier|public
name|boolean
name|isUniqueFilenames
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
block|}
end_class

end_unit

