begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a.s3guard
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
package|;
end_package

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|DynamoDB
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|ProvisionedThroughputDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|FixMethodOrder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|internal
operator|.
name|AssumptionViolatedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|runners
operator|.
name|MethodSorters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|contract
operator|.
name|ContractTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|AWSServiceThrottledException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AStorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Statistic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|scale
operator|.
name|AbstractITestS3AMetadataStoreScale
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|GenericTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|LambdaTestUtils
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|MetadataStoreTestBase
operator|.
name|basicFileStatus
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assume
operator|.
name|*
import|;
end_import

begin_comment
comment|/**  * Scale test for DynamoDBMetadataStore.  *  * The throttle tests aren't quite trying to verify that throttling can  * be recovered from, because that makes for very slow tests: you have  * to overload the system and them have them back of until they finally complete.  * Instead  */
end_comment

begin_class
annotation|@
name|FixMethodOrder
argument_list|(
name|MethodSorters
operator|.
name|NAME_ASCENDING
argument_list|)
DECL|class|ITestDynamoDBMetadataStoreScale
specifier|public
class|class
name|ITestDynamoDBMetadataStoreScale
extends|extends
name|AbstractITestS3AMetadataStoreScale
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ITestDynamoDBMetadataStoreScale
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|BATCH_SIZE
specifier|private
specifier|static
specifier|final
name|long
name|BATCH_SIZE
init|=
literal|25
decl_stmt|;
comment|/**    * IO Units for batch size; this sets the size to use for IO capacity.    * Value: {@value}.    */
DECL|field|MAXIMUM_READ_CAPACITY
specifier|private
specifier|static
specifier|final
name|long
name|MAXIMUM_READ_CAPACITY
init|=
literal|10
decl_stmt|;
DECL|field|MAXIMUM_WRITE_CAPACITY
specifier|private
specifier|static
specifier|final
name|long
name|MAXIMUM_WRITE_CAPACITY
init|=
literal|15
decl_stmt|;
DECL|field|ddbms
specifier|private
name|DynamoDBMetadataStore
name|ddbms
decl_stmt|;
DECL|field|ddb
specifier|private
name|DynamoDB
name|ddb
decl_stmt|;
DECL|field|table
specifier|private
name|Table
name|table
decl_stmt|;
DECL|field|tableName
specifier|private
name|String
name|tableName
decl_stmt|;
comment|/** was the provisioning changed in test_001_limitCapacity()? */
DECL|field|isOverProvisionedForTest
specifier|private
name|boolean
name|isOverProvisionedForTest
decl_stmt|;
DECL|field|originalCapacity
specifier|private
name|ProvisionedThroughputDescription
name|originalCapacity
decl_stmt|;
DECL|field|THREADS
specifier|private
specifier|static
specifier|final
name|int
name|THREADS
init|=
literal|40
decl_stmt|;
DECL|field|OPERATIONS_PER_THREAD
specifier|private
specifier|static
specifier|final
name|int
name|OPERATIONS_PER_THREAD
init|=
literal|50
decl_stmt|;
comment|/**    * Create the metadata store. The table and region are determined from    * the attributes of the FS used in the tests.    * @return a new metadata store instance    * @throws IOException failure to instantiate    * @throws AssumptionViolatedException if the FS isn't running S3Guard + DDB/    */
annotation|@
name|Override
DECL|method|createMetadataStore ()
specifier|public
name|MetadataStore
name|createMetadataStore
parameter_list|()
throws|throws
name|IOException
block|{
name|S3AFileSystem
name|fs
init|=
name|getFileSystem
argument_list|()
decl_stmt|;
name|assumeTrue
argument_list|(
literal|"S3Guard is disabled for "
operator|+
name|fs
operator|.
name|getUri
argument_list|()
argument_list|,
name|fs
operator|.
name|hasMetadataStore
argument_list|()
argument_list|)
expr_stmt|;
name|MetadataStore
name|store
init|=
name|fs
operator|.
name|getMetadataStore
argument_list|()
decl_stmt|;
name|assumeTrue
argument_list|(
literal|"Metadata store for "
operator|+
name|fs
operator|.
name|getUri
argument_list|()
operator|+
literal|" is "
operator|+
name|store
operator|+
literal|" -not DynamoDBMetadataStore"
argument_list|,
name|store
operator|instanceof
name|DynamoDBMetadataStore
argument_list|)
expr_stmt|;
name|DDBCapacities
name|capacities
init|=
name|DDBCapacities
operator|.
name|extractCapacities
argument_list|(
name|store
operator|.
name|getDiagnostics
argument_list|()
argument_list|)
decl_stmt|;
name|assumeTrue
argument_list|(
literal|"DBB table is on-demand"
argument_list|,
operator|!
name|capacities
operator|.
name|isOnDemandTable
argument_list|()
argument_list|)
expr_stmt|;
name|DynamoDBMetadataStore
name|fsStore
init|=
operator|(
name|DynamoDBMetadataStore
operator|)
name|store
decl_stmt|;
name|Configuration
name|conf
init|=
operator|new
name|Configuration
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|tableName
operator|=
name|fsStore
operator|.
name|getTableName
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Null/Empty tablename in "
operator|+
name|fsStore
argument_list|,
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|region
init|=
name|fsStore
operator|.
name|getRegion
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Null/Empty region in "
operator|+
name|fsStore
argument_list|,
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|region
argument_list|)
argument_list|)
expr_stmt|;
comment|// create a new metastore configured to fail fast if throttling
comment|// happens.
name|conf
operator|.
name|set
argument_list|(
name|S3GUARD_DDB_TABLE_NAME_KEY
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|S3GUARD_DDB_REGION_KEY
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|S3GUARD_DDB_THROTTLE_RETRY_INTERVAL
argument_list|,
literal|"50ms"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|S3GUARD_DDB_MAX_RETRIES
argument_list|,
literal|"2"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|MAX_ERROR_RETRIES
argument_list|,
literal|"1"
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|S3GUARD_DDB_BACKGROUND_SLEEP_MSEC_KEY
argument_list|,
literal|"5ms"
argument_list|)
expr_stmt|;
name|DynamoDBMetadataStore
name|ms
init|=
operator|new
name|DynamoDBMetadataStore
argument_list|()
decl_stmt|;
name|ms
operator|.
name|initialize
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// wire up the owner FS so that we can make assertions about throttle
comment|// events
name|ms
operator|.
name|bindToOwnerFilesystem
argument_list|(
name|fs
argument_list|)
expr_stmt|;
return|return
name|ms
return|;
block|}
annotation|@
name|Override
DECL|method|setup ()
specifier|public
name|void
name|setup
parameter_list|()
throws|throws
name|Exception
block|{
name|super
operator|.
name|setup
argument_list|()
expr_stmt|;
name|ddbms
operator|=
operator|(
name|DynamoDBMetadataStore
operator|)
name|createMetadataStore
argument_list|()
expr_stmt|;
name|tableName
operator|=
name|ddbms
operator|.
name|getTableName
argument_list|()
expr_stmt|;
name|assertNotNull
argument_list|(
literal|"table has no name"
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
name|ddb
operator|=
name|ddbms
operator|.
name|getDynamoDB
argument_list|()
expr_stmt|;
name|table
operator|=
name|ddb
operator|.
name|getTable
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
name|originalCapacity
operator|=
name|table
operator|.
name|describe
argument_list|()
operator|.
name|getProvisionedThroughput
argument_list|()
expr_stmt|;
comment|// If you set the same provisioned I/O as already set it throws an
comment|// exception, avoid that.
name|isOverProvisionedForTest
operator|=
operator|(
name|originalCapacity
operator|.
name|getReadCapacityUnits
argument_list|()
operator|>
name|MAXIMUM_READ_CAPACITY
operator|||
name|originalCapacity
operator|.
name|getWriteCapacityUnits
argument_list|()
operator|>
name|MAXIMUM_WRITE_CAPACITY
operator|)
expr_stmt|;
name|assumeFalse
argument_list|(
literal|"Table has too much capacity: "
operator|+
name|originalCapacity
operator|.
name|toString
argument_list|()
argument_list|,
name|isOverProvisionedForTest
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|teardown ()
specifier|public
name|void
name|teardown
parameter_list|()
throws|throws
name|Exception
block|{
name|IOUtils
operator|.
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|ddbms
argument_list|)
expr_stmt|;
name|super
operator|.
name|teardown
argument_list|()
expr_stmt|;
block|}
comment|/**    * The subclass expects the superclass to be throttled; sometimes it is.    */
annotation|@
name|Test
annotation|@
name|Override
DECL|method|test_020_Moves ()
specifier|public
name|void
name|test_020_Moves
parameter_list|()
throws|throws
name|Throwable
block|{
name|ThrottleTracker
name|tracker
init|=
operator|new
name|ThrottleTracker
argument_list|()
decl_stmt|;
try|try
block|{
comment|// if this doesn't throttle, all is well.
name|super
operator|.
name|test_020_Moves
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AWSServiceThrottledException
name|ex
parameter_list|)
block|{
comment|// if the service was throttled, we ex;ect the exception text
name|GenericTestUtils
operator|.
name|assertExceptionContains
argument_list|(
name|DynamoDBMetadataStore
operator|.
name|HINT_DDB_IOPS_TOO_LOW
argument_list|,
name|ex
argument_list|,
literal|"Expected throttling message"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Statistics {}"
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Though the AWS SDK claims in documentation to handle retries and    * exponential backoff, we have witnessed    * com.amazonaws...dynamodbv2.model.ProvisionedThroughputExceededException    * (Status Code: 400; Error Code: ProvisionedThroughputExceededException)    * Hypothesis:    * Happens when the size of a batched write is bigger than the number of    * provisioned write units.  This test ensures we handle the case    * correctly, retrying w/ smaller batch instead of surfacing exceptions.    */
annotation|@
name|Test
DECL|method|test_030_BatchedWrite ()
specifier|public
name|void
name|test_030_BatchedWrite
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|int
name|iterations
init|=
literal|15
decl_stmt|;
specifier|final
name|ArrayList
argument_list|<
name|PathMetadata
argument_list|>
name|toCleanup
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|toCleanup
operator|.
name|ensureCapacity
argument_list|(
name|THREADS
operator|*
name|iterations
argument_list|)
expr_stmt|;
comment|// Fail if someone changes a constant we depend on
name|assertTrue
argument_list|(
literal|"Maximum batch size must big enough to run this test"
argument_list|,
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
operator|>=
name|BATCH_SIZE
argument_list|)
expr_stmt|;
comment|// We know the dynamodb metadata store will expand a put of a path
comment|// of depth N into a batch of N writes (all ancestors are written
comment|// separately up to the root).  (Ab)use this for an easy way to write
comment|// a batch of stuff that is bigger than the provisioned write units
try|try
block|{
name|describe
argument_list|(
literal|"Running %d iterations of batched put, size %d"
argument_list|,
name|iterations
argument_list|,
name|BATCH_SIZE
argument_list|)
expr_stmt|;
name|ThrottleTracker
name|result
init|=
name|execute
argument_list|(
literal|"prune"
argument_list|,
literal|1
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|ThrottleTracker
name|tracker
init|=
operator|new
name|ThrottleTracker
argument_list|()
decl_stmt|;
name|long
name|pruneItems
init|=
literal|0
decl_stmt|;
for|for
control|(
name|long
name|i
init|=
literal|0
init|;
name|i
operator|<
name|iterations
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|longPath
init|=
name|pathOfDepth
argument_list|(
name|BATCH_SIZE
argument_list|,
name|String
operator|.
name|valueOf
argument_list|(
name|i
argument_list|)
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
name|basicFileStatus
argument_list|(
name|longPath
argument_list|,
literal|0
argument_list|,
literal|false
argument_list|,
literal|12345
argument_list|,
literal|12345
argument_list|)
decl_stmt|;
name|PathMetadata
name|pm
init|=
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|toCleanup
init|)
block|{
name|toCleanup
operator|.
name|add
argument_list|(
name|pm
argument_list|)
expr_stmt|;
block|}
name|ddbms
operator|.
name|put
argument_list|(
name|pm
argument_list|)
expr_stmt|;
name|pruneItems
operator|++
expr_stmt|;
if|if
condition|(
name|pruneItems
operator|==
name|BATCH_SIZE
condition|)
block|{
name|describe
argument_list|(
literal|"pruning files"
argument_list|)
expr_stmt|;
name|ddbms
operator|.
name|prune
argument_list|(
name|Long
operator|.
name|MAX_VALUE
comment|/* all files */
argument_list|)
expr_stmt|;
name|pruneItems
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|tracker
operator|.
name|probe
argument_list|()
condition|)
block|{
comment|// fail fast
break|break;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|assertNotEquals
argument_list|(
literal|"No batch retries in "
operator|+
name|result
argument_list|,
literal|0
argument_list|,
name|result
operator|.
name|batchThrottles
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|describe
argument_list|(
literal|"Cleaning up table %s"
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
for|for
control|(
name|PathMetadata
name|pm
range|:
name|toCleanup
control|)
block|{
name|cleanupMetadata
argument_list|(
name|ddbms
argument_list|,
name|pm
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Test Get throttling including using    * {@link MetadataStore#get(Path, boolean)},    * as that stresses more of the code.    */
annotation|@
name|Test
DECL|method|test_040_get ()
specifier|public
name|void
name|test_040_get
parameter_list|()
throws|throws
name|Throwable
block|{
comment|// attempt to create many many get requests in parallel.
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
literal|"s3a://example.org/get"
argument_list|)
decl_stmt|;
name|S3AFileStatus
name|status
init|=
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
literal|"alice"
argument_list|)
decl_stmt|;
name|PathMetadata
name|metadata
init|=
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|)
decl_stmt|;
name|ddbms
operator|.
name|put
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
try|try
block|{
name|execute
argument_list|(
literal|"get"
argument_list|,
name|OPERATIONS_PER_THREAD
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|get
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|retryingDelete
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Ask for the version marker, which is where table init can be overloaded.    */
annotation|@
name|Test
DECL|method|test_050_getVersionMarkerItem ()
specifier|public
name|void
name|test_050_getVersionMarkerItem
parameter_list|()
throws|throws
name|Throwable
block|{
name|execute
argument_list|(
literal|"get"
argument_list|,
name|OPERATIONS_PER_THREAD
operator|*
literal|2
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|getVersionMarkerItem
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cleanup with an extra bit of retry logic around it, in case things    * are still over the limit.    * @param path path    */
DECL|method|retryingDelete (final Path path)
specifier|private
name|void
name|retryingDelete
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|)
block|{
try|try
block|{
name|ddbms
operator|.
name|getInvoker
argument_list|()
operator|.
name|retry
argument_list|(
literal|"Delete "
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|delete
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to delete {}: "
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Test
DECL|method|test_060_list ()
specifier|public
name|void
name|test_060_list
parameter_list|()
throws|throws
name|Throwable
block|{
comment|// attempt to create many many get requests in parallel.
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
literal|"s3a://example.org/list"
argument_list|)
decl_stmt|;
name|S3AFileStatus
name|status
init|=
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
literal|"alice"
argument_list|)
decl_stmt|;
name|PathMetadata
name|metadata
init|=
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|)
decl_stmt|;
name|ddbms
operator|.
name|put
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
try|try
block|{
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|execute
argument_list|(
literal|"list"
argument_list|,
name|OPERATIONS_PER_THREAD
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|listChildren
argument_list|(
name|parent
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|retryingDelete
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Test
DECL|method|test_070_putDirMarker ()
specifier|public
name|void
name|test_070_putDirMarker
parameter_list|()
throws|throws
name|Throwable
block|{
comment|// attempt to create many many get requests in parallel.
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
literal|"s3a://example.org/putDirMarker"
argument_list|)
decl_stmt|;
name|S3AFileStatus
name|status
init|=
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
literal|"alice"
argument_list|)
decl_stmt|;
name|PathMetadata
name|metadata
init|=
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|)
decl_stmt|;
name|ddbms
operator|.
name|put
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
name|DirListingMetadata
name|children
init|=
name|ddbms
operator|.
name|listChildren
argument_list|(
name|path
operator|.
name|getParent
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|execute
argument_list|(
literal|"list"
argument_list|,
name|OPERATIONS_PER_THREAD
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|put
argument_list|(
name|children
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|retryingDelete
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Test
DECL|method|test_080_fullPathsToPut ()
specifier|public
name|void
name|test_080_fullPathsToPut
parameter_list|()
throws|throws
name|Throwable
block|{
comment|// attempt to create many many get requests in parallel.
name|Path
name|base
init|=
operator|new
name|Path
argument_list|(
literal|"s3a://example.org/test_080_fullPathsToPut"
argument_list|)
decl_stmt|;
name|Path
name|child
init|=
operator|new
name|Path
argument_list|(
name|base
argument_list|,
literal|"child"
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|pms
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|ddbms
operator|.
name|put
argument_list|(
operator|new
name|PathMetadata
argument_list|(
name|makeDirStatus
argument_list|(
name|base
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|ddbms
operator|.
name|put
argument_list|(
operator|new
name|PathMetadata
argument_list|(
name|makeDirStatus
argument_list|(
name|child
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|ddbms
operator|.
name|getInvoker
argument_list|()
operator|.
name|retry
argument_list|(
literal|"set up directory tree"
argument_list|,
name|base
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|put
argument_list|(
name|pms
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|DDBPathMetadata
name|dirData
init|=
name|ddbms
operator|.
name|get
argument_list|(
name|child
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|execute
argument_list|(
literal|"list"
argument_list|,
name|OPERATIONS_PER_THREAD
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ddbms
operator|.
name|fullPathsToPut
argument_list|(
name|dirData
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|retryingDelete
argument_list|(
name|base
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Test
DECL|method|test_900_instrumentation ()
specifier|public
name|void
name|test_900_instrumentation
parameter_list|()
throws|throws
name|Throwable
block|{
name|describe
argument_list|(
literal|"verify the owner FS gets updated after throttling events"
argument_list|)
expr_stmt|;
comment|// we rely on the FS being shared
name|S3AFileSystem
name|fs
init|=
name|getFileSystem
argument_list|()
decl_stmt|;
name|String
name|fsSummary
init|=
name|fs
operator|.
name|toString
argument_list|()
decl_stmt|;
name|S3AStorageStatistics
name|statistics
init|=
name|fs
operator|.
name|getStorageStatistics
argument_list|()
decl_stmt|;
for|for
control|(
name|StorageStatistics
operator|.
name|LongStatistic
name|statistic
range|:
name|statistics
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"{}"
argument_list|,
name|statistic
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|String
name|retryKey
init|=
name|Statistic
operator|.
name|S3GUARD_METADATASTORE_RETRY
operator|.
name|getSymbol
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"No increment of "
operator|+
name|retryKey
operator|+
literal|" in "
operator|+
name|fsSummary
argument_list|,
name|statistics
operator|.
name|getLong
argument_list|(
name|retryKey
argument_list|)
operator|>
literal|0
argument_list|)
expr_stmt|;
name|String
name|throttledKey
init|=
name|Statistic
operator|.
name|S3GUARD_METADATASTORE_THROTTLED
operator|.
name|getSymbol
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"No increment of "
operator|+
name|throttledKey
operator|+
literal|" in "
operator|+
name|fsSummary
argument_list|,
name|statistics
operator|.
name|getLong
argument_list|(
name|throttledKey
argument_list|)
operator|>
literal|0
argument_list|)
expr_stmt|;
block|}
comment|/**    * Execute a set of operations in parallel, collect throttling statistics    * and return them.    * This execution will complete as soon as throttling is detected.    * This ensures that the tests do not run for longer than they should.    * @param operation string for messages.    * @param operationsPerThread number of times per thread to invoke the action.    * @param expectThrottling is throttling expected (and to be asserted on?)    * @param action action to invoke.    * @return the throttle statistics    */
DECL|method|execute (String operation, int operationsPerThread, final boolean expectThrottling, LambdaTestUtils.VoidCallable action)
specifier|public
name|ThrottleTracker
name|execute
parameter_list|(
name|String
name|operation
parameter_list|,
name|int
name|operationsPerThread
parameter_list|,
specifier|final
name|boolean
name|expectThrottling
parameter_list|,
name|LambdaTestUtils
operator|.
name|VoidCallable
name|action
parameter_list|)
throws|throws
name|Exception
block|{
specifier|final
name|ContractTestUtils
operator|.
name|NanoTimer
name|timer
init|=
operator|new
name|ContractTestUtils
operator|.
name|NanoTimer
argument_list|()
decl_stmt|;
specifier|final
name|ThrottleTracker
name|tracker
init|=
operator|new
name|ThrottleTracker
argument_list|()
decl_stmt|;
specifier|final
name|ExecutorService
name|executorService
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|THREADS
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Callable
argument_list|<
name|ExecutionOutcome
argument_list|>
argument_list|>
name|tasks
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|THREADS
argument_list|)
decl_stmt|;
specifier|final
name|AtomicInteger
name|throttleExceptions
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|THREADS
condition|;
name|i
operator|++
control|)
block|{
name|tasks
operator|.
name|add
argument_list|(
parameter_list|()
lambda|->
block|{
specifier|final
name|ExecutionOutcome
name|outcome
init|=
operator|new
name|ExecutionOutcome
argument_list|()
decl_stmt|;
specifier|final
name|ContractTestUtils
operator|.
name|NanoTimer
name|t
init|=
operator|new
name|ContractTestUtils
operator|.
name|NanoTimer
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|operationsPerThread
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|tracker
operator|.
name|isThrottlingDetected
argument_list|()
condition|)
block|{
name|outcome
operator|.
name|skipped
operator|=
literal|true
expr_stmt|;
return|return
name|outcome
return|;
block|}
try|try
block|{
name|action
operator|.
name|call
argument_list|()
expr_stmt|;
name|outcome
operator|.
name|completed
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AWSServiceThrottledException
name|e
parameter_list|)
block|{
comment|// this is possibly OK
name|LOG
operator|.
name|info
argument_list|(
literal|"Operation [{}] raised a throttled exception "
operator|+
name|e
argument_list|,
name|j
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|throttleExceptions
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// consider it completed
name|outcome
operator|.
name|throttleExceptions
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|outcome
operator|.
name|throttled
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to execute {}"
argument_list|,
name|operation
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|outcome
operator|.
name|exceptions
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
break|break;
block|}
name|tracker
operator|.
name|probe
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Thread completed {} with in {} ms with outcome {}: {}"
argument_list|,
name|operation
argument_list|,
name|t
operator|.
name|elapsedTimeMs
argument_list|()
argument_list|,
name|outcome
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
return|return
name|outcome
return|;
block|}
argument_list|)
expr_stmt|;
block|}
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|ExecutionOutcome
argument_list|>
argument_list|>
name|futures
init|=
name|executorService
operator|.
name|invokeAll
argument_list|(
name|tasks
argument_list|,
name|getTestTimeoutMillis
argument_list|()
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|long
name|elapsedMs
init|=
name|timer
operator|.
name|elapsedTimeMs
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Completed {} with {}"
argument_list|,
name|operation
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"time to execute: {} millis"
argument_list|,
name|elapsedMs
argument_list|)
expr_stmt|;
for|for
control|(
name|Future
argument_list|<
name|ExecutionOutcome
argument_list|>
name|future
range|:
name|futures
control|)
block|{
name|assertTrue
argument_list|(
literal|"Future timed out"
argument_list|,
name|future
operator|.
name|isDone
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|tracker
operator|.
name|probe
argument_list|()
expr_stmt|;
if|if
condition|(
name|expectThrottling
condition|)
block|{
name|tracker
operator|.
name|assertThrottlingDetected
argument_list|()
expr_stmt|;
block|}
for|for
control|(
name|Future
argument_list|<
name|ExecutionOutcome
argument_list|>
name|future
range|:
name|futures
control|)
block|{
name|ExecutionOutcome
name|outcome
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|outcome
operator|.
name|exceptions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
name|outcome
operator|.
name|exceptions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|outcome
operator|.
name|skipped
condition|)
block|{
name|assertEquals
argument_list|(
literal|"Future did not complete all operations"
argument_list|,
name|operationsPerThread
argument_list|,
name|outcome
operator|.
name|completed
operator|+
name|outcome
operator|.
name|throttled
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|tracker
return|;
block|}
comment|/**    * Attempt to delete metadata, suppressing any errors, and retrying on    * throttle events just in case some are still surfacing.    * @param ms store    * @param pm path to clean up    */
DECL|method|cleanupMetadata (MetadataStore ms, PathMetadata pm)
specifier|private
name|void
name|cleanupMetadata
parameter_list|(
name|MetadataStore
name|ms
parameter_list|,
name|PathMetadata
name|pm
parameter_list|)
block|{
name|Path
name|path
init|=
name|pm
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
decl_stmt|;
try|try
block|{
name|ddbms
operator|.
name|getInvoker
argument_list|()
operator|.
name|retry
argument_list|(
literal|"clean up"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|ms
operator|.
name|forgetMetadata
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Ignore.
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring error while cleaning up {} in database"
argument_list|,
name|path
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|pathOfDepth (long n, @Nullable String fileSuffix)
specifier|private
name|Path
name|pathOfDepth
parameter_list|(
name|long
name|n
parameter_list|,
annotation|@
name|Nullable
name|String
name|fileSuffix
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|long
name|i
init|=
literal|0
init|;
name|i
operator|<
name|n
condition|;
name|i
operator|++
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|i
operator|==
literal|0
condition|?
literal|"/"
operator|+
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
else|:
literal|"lvl"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|==
name|n
operator|-
literal|1
operator|&&
name|fileSuffix
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|fileSuffix
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|getFileSystem
argument_list|()
operator|.
name|getUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Something to track throttles.    * The constructor sets the counters to the current count in the    * DDB table; a call to {@link #reset()} will set it to the latest values.    * The {@link #probe()} will pick up the latest values to compare them with    * the original counts.    */
DECL|class|ThrottleTracker
specifier|private
class|class
name|ThrottleTracker
block|{
DECL|field|writeThrottleEventOrig
specifier|private
name|long
name|writeThrottleEventOrig
init|=
name|ddbms
operator|.
name|getWriteThrottleEventCount
argument_list|()
decl_stmt|;
DECL|field|readThrottleEventOrig
specifier|private
name|long
name|readThrottleEventOrig
init|=
name|ddbms
operator|.
name|getReadThrottleEventCount
argument_list|()
decl_stmt|;
DECL|field|batchWriteThrottleCountOrig
specifier|private
name|long
name|batchWriteThrottleCountOrig
init|=
name|ddbms
operator|.
name|getBatchWriteCapacityExceededCount
argument_list|()
decl_stmt|;
DECL|field|readThrottles
specifier|private
name|long
name|readThrottles
decl_stmt|;
DECL|field|writeThrottles
specifier|private
name|long
name|writeThrottles
decl_stmt|;
DECL|field|batchThrottles
specifier|private
name|long
name|batchThrottles
decl_stmt|;
DECL|method|ThrottleTracker ()
name|ThrottleTracker
parameter_list|()
block|{
name|reset
argument_list|()
expr_stmt|;
block|}
comment|/**      * Reset the counters.      */
DECL|method|reset ()
specifier|private
specifier|synchronized
name|void
name|reset
parameter_list|()
block|{
name|writeThrottleEventOrig
operator|=
name|ddbms
operator|.
name|getWriteThrottleEventCount
argument_list|()
expr_stmt|;
name|readThrottleEventOrig
operator|=
name|ddbms
operator|.
name|getReadThrottleEventCount
argument_list|()
expr_stmt|;
name|batchWriteThrottleCountOrig
operator|=
name|ddbms
operator|.
name|getBatchWriteCapacityExceededCount
argument_list|()
expr_stmt|;
block|}
comment|/**      * Update the latest throttle count; synchronized.      * @return true if throttling has been detected.      */
DECL|method|probe ()
specifier|private
specifier|synchronized
name|boolean
name|probe
parameter_list|()
block|{
name|readThrottles
operator|=
name|ddbms
operator|.
name|getReadThrottleEventCount
argument_list|()
operator|-
name|readThrottleEventOrig
expr_stmt|;
name|writeThrottles
operator|=
name|ddbms
operator|.
name|getWriteThrottleEventCount
argument_list|()
operator|-
name|writeThrottleEventOrig
expr_stmt|;
name|batchThrottles
operator|=
name|ddbms
operator|.
name|getBatchWriteCapacityExceededCount
argument_list|()
operator|-
name|batchWriteThrottleCountOrig
expr_stmt|;
return|return
name|isThrottlingDetected
argument_list|()
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|String
operator|.
name|format
argument_list|(
literal|"Tracker with read throttle events = %d;"
operator|+
literal|" write events = %d;"
operator|+
literal|" batch throttles = %d"
argument_list|,
name|readThrottles
argument_list|,
name|writeThrottles
argument_list|,
name|batchThrottles
argument_list|)
return|;
block|}
comment|/**      * Assert that throttling has been detected.      */
DECL|method|assertThrottlingDetected ()
name|void
name|assertThrottlingDetected
parameter_list|()
block|{
name|assertTrue
argument_list|(
literal|"No throttling detected in "
operator|+
name|this
operator|+
literal|" against "
operator|+
name|ddbms
operator|.
name|toString
argument_list|()
argument_list|,
name|isThrottlingDetected
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**      * Has there been any throttling on an operation?      * @return true iff read, write or batch operations were throttled.      */
DECL|method|isThrottlingDetected ()
specifier|private
name|boolean
name|isThrottlingDetected
parameter_list|()
block|{
return|return
name|readThrottles
operator|>
literal|0
operator|||
name|writeThrottles
operator|>
literal|0
operator|||
name|batchThrottles
operator|>
literal|0
return|;
block|}
block|}
comment|/**    * Outcome of a thread's execution operation.    */
DECL|class|ExecutionOutcome
specifier|private
specifier|static
class|class
name|ExecutionOutcome
block|{
DECL|field|completed
specifier|private
name|int
name|completed
decl_stmt|;
DECL|field|throttled
specifier|private
name|int
name|throttled
decl_stmt|;
DECL|field|skipped
specifier|private
name|boolean
name|skipped
decl_stmt|;
DECL|field|exceptions
specifier|private
specifier|final
name|List
argument_list|<
name|Exception
argument_list|>
name|exceptions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
DECL|field|throttleExceptions
specifier|private
specifier|final
name|List
argument_list|<
name|Exception
argument_list|>
name|throttleExceptions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"ExecutionOutcome{"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"completed="
argument_list|)
operator|.
name|append
argument_list|(
name|completed
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", skipped="
argument_list|)
operator|.
name|append
argument_list|(
name|skipped
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", throttled="
argument_list|)
operator|.
name|append
argument_list|(
name|throttled
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", exception count="
argument_list|)
operator|.
name|append
argument_list|(
name|exceptions
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

