begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a.select
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|select
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|examples
operator|.
name|WordCount
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|impl
operator|.
name|FutureIOSupport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|impl
operator|.
name|WrappedIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ATestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|files
operator|.
name|SuccessData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|staging
operator|.
name|StagingCommitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IntWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|FileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DurationInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|conf
operator|.
name|YarnConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|MiniYARNCluster
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
operator|.
name|FS_S3A_COMMITTER_NAME
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
operator|.
name|FS_S3A_COMMITTER_STAGING_UNIQUE_FILENAMES
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|select
operator|.
name|SelectConstants
operator|.
name|*
import|;
end_import

begin_comment
comment|/**  * Run an MR job with a select query.  * This is the effective end-to-end test which verifies:  *<ol>  *<li>Passing of select parameters through an MR job conf.</li>  *<li>Automatic pick-up of these parameter through TextInputFormat's use  *   of the mapreduce.lib.input.LineRecordReaderLineRecordReader.</li>  *<li>Issuing of S3 Select queries in mapper processes.</li>  *<li>Projection of columns in a select.</li>  *<li>Ability to switch to the Passthrough decompressor in an MR job.</li>  *<li>Saving of results through the S3A Staging committer.</li>  *<li>Basic validation of results.</li>  *</ol>  * This makes it the most complex of the MR jobs in the hadoop-aws test suite.  *  * The query used is  * {@link ITestS3SelectLandsat#SELECT_PROCESSING_LEVEL_NO_LIMIT},  * which lists the processing level of all records in the source file,  * and counts the number in each one by way of the normal word-count  * routines.  * This works because the SQL is projecting only the processing level.  *  * The result becomes something like (with tabs between fields):  *<pre>  * L1GT   370231  * L1T    689526  *</pre>  */
end_comment

begin_class
DECL|class|ITestS3SelectMRJob
specifier|public
class|class
name|ITestS3SelectMRJob
extends|extends
name|AbstractS3SelectTest
block|{
DECL|field|conf
specifier|private
specifier|final
name|Configuration
name|conf
init|=
operator|new
name|YarnConfiguration
argument_list|()
decl_stmt|;
DECL|field|fs
specifier|private
name|S3AFileSystem
name|fs
decl_stmt|;
DECL|field|yarnCluster
specifier|private
name|MiniYARNCluster
name|yarnCluster
decl_stmt|;
DECL|field|rootPath
specifier|private
name|Path
name|rootPath
decl_stmt|;
annotation|@
name|Override
DECL|method|setup ()
specifier|public
name|void
name|setup
parameter_list|()
throws|throws
name|Exception
block|{
name|super
operator|.
name|setup
argument_list|()
expr_stmt|;
name|fs
operator|=
name|S3ATestUtils
operator|.
name|createTestFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|rootPath
operator|=
name|path
argument_list|(
literal|"ITestS3SelectMRJob"
argument_list|)
expr_stmt|;
name|Path
name|workingDir
init|=
name|path
argument_list|(
literal|"working"
argument_list|)
decl_stmt|;
name|fs
operator|.
name|setWorkingDirectory
argument_list|(
name|workingDir
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
operator|new
name|Path
argument_list|(
name|rootPath
argument_list|,
literal|"input/"
argument_list|)
argument_list|)
expr_stmt|;
name|yarnCluster
operator|=
operator|new
name|MiniYARNCluster
argument_list|(
literal|"ITestS3SelectMRJob"
argument_list|,
comment|// testName
literal|1
argument_list|,
comment|// number of node managers
literal|1
argument_list|,
comment|// number of local log dirs per node manager
literal|1
argument_list|)
expr_stmt|;
comment|// number of hdfs dirs per node manager
name|yarnCluster
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|yarnCluster
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|teardown ()
specifier|public
name|void
name|teardown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|yarnCluster
operator|!=
literal|null
condition|)
block|{
name|yarnCluster
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
name|super
operator|.
name|teardown
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Test
DECL|method|testLandsatSelect ()
specifier|public
name|void
name|testLandsatSelect
parameter_list|()
throws|throws
name|Exception
block|{
specifier|final
name|Path
name|input
init|=
name|getLandsatGZ
argument_list|()
decl_stmt|;
specifier|final
name|Path
name|output
init|=
name|path
argument_list|(
literal|"testLandsatSelect"
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|fs
operator|.
name|getUri
argument_list|()
argument_list|,
name|fs
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|Job
name|job
init|=
name|Job
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|,
literal|"process level count"
argument_list|)
decl_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|WordCount
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|WordCount
operator|.
name|TokenizerMapper
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setCombinerClass
argument_list|(
name|WordCount
operator|.
name|IntSumReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|WordCount
operator|.
name|IntSumReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputKeyClass
argument_list|(
name|Text
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputValueClass
argument_list|(
name|IntWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|FileInputFormat
operator|.
name|addInputPath
argument_list|(
name|job
argument_list|,
name|input
argument_list|)
expr_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|output
argument_list|)
expr_stmt|;
comment|// job with use the staging committer
specifier|final
name|JobConf
name|jobConf
init|=
operator|(
name|JobConf
operator|)
name|job
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|jobConf
operator|.
name|set
argument_list|(
name|FS_S3A_COMMITTER_NAME
argument_list|,
name|StagingCommitter
operator|.
name|NAME
argument_list|)
expr_stmt|;
name|jobConf
operator|.
name|setBoolean
argument_list|(
name|FS_S3A_COMMITTER_STAGING_UNIQUE_FILENAMES
argument_list|,
literal|false
argument_list|)
expr_stmt|;
specifier|final
name|String
name|query
init|=
name|ITestS3SelectLandsat
operator|.
name|SELECT_PROCESSING_LEVEL_NO_LIMIT
decl_stmt|;
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|SELECT_SQL
argument_list|,
name|query
argument_list|)
expr_stmt|;
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|SELECT_INPUT_COMPRESSION
argument_list|,
name|COMPRESSION_OPT_GZIP
argument_list|)
expr_stmt|;
comment|// input settings
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|SELECT_INPUT_FORMAT
argument_list|,
name|SELECT_FORMAT_CSV
argument_list|)
expr_stmt|;
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|CSV_INPUT_HEADER
argument_list|,
name|CSV_HEADER_OPT_USE
argument_list|)
expr_stmt|;
comment|// output
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|SELECT_OUTPUT_FORMAT
argument_list|,
name|SELECT_FORMAT_CSV
argument_list|)
expr_stmt|;
name|inputMust
argument_list|(
name|jobConf
argument_list|,
name|CSV_OUTPUT_QUOTE_FIELDS
argument_list|,
name|CSV_OUTPUT_QUOTE_FIELDS_AS_NEEEDED
argument_list|)
expr_stmt|;
comment|// disable the gzip codec, so that the record readers do not
comment|// get confused
name|enablePassthroughCodec
argument_list|(
name|jobConf
argument_list|,
literal|".gz"
argument_list|)
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|"SQL "
operator|+
name|query
argument_list|)
init|)
block|{
name|int
name|exitCode
init|=
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|true
argument_list|)
condition|?
literal|0
else|:
literal|1
decl_stmt|;
name|assertEquals
argument_list|(
literal|"Returned error code."
argument_list|,
literal|0
argument_list|,
name|exitCode
argument_list|)
expr_stmt|;
block|}
comment|// log the success info
name|Path
name|successPath
init|=
operator|new
name|Path
argument_list|(
name|output
argument_list|,
literal|"_SUCCESS"
argument_list|)
decl_stmt|;
name|SuccessData
name|success
init|=
name|SuccessData
operator|.
name|load
argument_list|(
name|fs
argument_list|,
name|successPath
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Job _SUCCESS\n{}"
argument_list|,
name|success
argument_list|)
expr_stmt|;
comment|// process the results by ver
comment|//
name|LOG
operator|.
name|info
argument_list|(
literal|"Results for query \n{}"
argument_list|,
name|query
argument_list|)
expr_stmt|;
specifier|final
name|AtomicLong
name|parts
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|S3AUtils
operator|.
name|applyLocatedFiles
argument_list|(
name|fs
operator|.
name|listFiles
argument_list|(
name|output
argument_list|,
literal|false
argument_list|)
argument_list|,
parameter_list|(
name|status
parameter_list|)
lambda|->
block|{
name|Path
name|path
init|=
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
comment|// ignore _SUCCESS, any temp files in subdirectories...
if|if
condition|(
name|path
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"part-"
argument_list|)
condition|)
block|{
name|parts
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|String
name|result
init|=
name|readStringFromFile
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"{}\n{}"
argument_list|,
name|path
argument_list|,
name|result
argument_list|)
expr_stmt|;
name|String
index|[]
name|lines
init|=
name|result
operator|.
name|split
argument_list|(
literal|"\n"
argument_list|,
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|l
init|=
name|lines
operator|.
name|length
decl_stmt|;
comment|// add a bit of slack here in case some new processing
comment|// option was added.
name|assertTrue
argument_list|(
literal|"Wrong number of lines ("
operator|+
name|l
operator|+
literal|") in "
operator|+
name|result
argument_list|,
name|l
operator|>
literal|0
operator|&&
name|l
operator|<
literal|15
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"More part files created than expected"
argument_list|,
literal|1
argument_list|,
name|parts
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Read a file; using Async IO for completeness and to see how    * well the async IO works in practice.    * Summary: checked exceptions cripple Async operations.    */
DECL|method|readStringFromFile (Path path)
specifier|private
name|String
name|readStringFromFile
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|bytesLen
init|=
operator|(
name|int
operator|)
name|fs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|byte
index|[]
name|buffer
init|=
operator|new
name|byte
index|[
name|bytesLen
index|]
decl_stmt|;
return|return
name|FutureIOSupport
operator|.
name|awaitFuture
argument_list|(
name|fs
operator|.
name|openFile
argument_list|(
name|path
argument_list|)
operator|.
name|build
argument_list|()
operator|.
name|thenApply
argument_list|(
name|in
lambda|->
block|{
try|try
block|{
name|IOUtils
operator|.
name|readFully
argument_list|(
name|in
argument_list|,
name|buffer
argument_list|,
literal|0
argument_list|,
name|bytesLen
argument_list|)
expr_stmt|;
return|return
operator|new
name|String
argument_list|(
name|buffer
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|WrappedIOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

