begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a.s3guard
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonClientException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|AmazonDynamoDB
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|BatchWriteItemOutcome
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|DynamoDB
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|Item
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|ItemCollection
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|PrimaryKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|PutItemOutcome
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|QueryOutcome
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|ScanOutcome
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|TableWriteItems
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|spec
operator|.
name|GetItemSpec
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|spec
operator|.
name|QuerySpec
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|document
operator|.
name|utils
operator|.
name|ValueMap
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|CreateTableRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|ProvisionedThroughput
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|ProvisionedThroughputDescription
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|ResourceInUseException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|ResourceNotFoundException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|TableDescription
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|dynamodbv2
operator|.
name|model
operator|.
name|WriteRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Invoker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Retries
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AInstrumentation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ARetryPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Tristate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicies
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
operator|.
name|translateException
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|PathMetadataDynamoDBTranslation
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|S3Guard
operator|.
name|*
import|;
end_import

begin_comment
comment|/**  * DynamoDBMetadataStore is a {@link MetadataStore} that persists  * file system metadata to DynamoDB.  *  * The current implementation uses a schema consisting of a single table.  The  * name of the table can be configured by config key  * {@link org.apache.hadoop.fs.s3a.Constants#S3GUARD_DDB_TABLE_NAME_KEY}.  * By default, it matches the name of the S3 bucket.  Each item in the table  * represents a single directory or file.  Its path is split into separate table  * attributes:  *<ul>  *<li> parent (absolute path of the parent, with bucket name inserted as  * first path component).</li>  *<li> child (path of that specific child, relative to parent).</li>  *<li> optional boolean attribute tracking whether the path is a directory.  *      Absence or a false value indicates the path is a file.</li>  *<li> optional long attribute revealing modification time of file.  *      This attribute is meaningful only to file items.</li>  *<li> optional long attribute revealing file length.  *      This attribute is meaningful only to file items.</li>  *<li> optional long attribute revealing block size of the file.  *      This attribute is meaningful only to file items.</li>  *</ul>  *  * The DynamoDB partition key is the parent, and the range key is the child.  *  * To allow multiple buckets to share the same DynamoDB table, the bucket  * name is treated as the root directory.  *  * For example, assume the consistent store contains metadata representing this  * file system structure:  *  *<pre>  * s3a://bucket/dir1  * |-- dir2  * |   |-- file1  * |   `-- file2  * `-- dir3  *     |-- dir4  *     |   `-- file3  *     |-- dir5  *     |   `-- file4  *     `-- dir6  *</pre>  *  * This is persisted to a single DynamoDB table as:  *  *<pre>  * =========================================================================  * | parent                 | child | is_dir | mod_time | len |     ...    |  * =========================================================================  * | /bucket                | dir1  | true   |          |     |            |  * | /bucket/dir1           | dir2  | true   |          |     |            |  * | /bucket/dir1           | dir3  | true   |          |     |            |  * | /bucket/dir1/dir2      | file1 |        |   100    | 111 |            |  * | /bucket/dir1/dir2      | file2 |        |   200    | 222 |            |  * | /bucket/dir1/dir3      | dir4  | true   |          |     |            |  * | /bucket/dir1/dir3      | dir5  | true   |          |     |            |  * | /bucket/dir1/dir3/dir4 | file3 |        |   300    | 333 |            |  * | /bucket/dir1/dir3/dir5 | file4 |        |   400    | 444 |            |  * | /bucket/dir1/dir3      | dir6  | true   |          |     |            |  * =========================================================================  *</pre>  *  * This choice of schema is efficient for read access patterns.  * {@link #get(Path)} can be served from a single item lookup.  * {@link #listChildren(Path)} can be served from a query against all rows  * matching the parent (the partition key) and the returned list is guaranteed  * to be sorted by child (the range key).  Tracking whether or not a path is a  * directory helps prevent unnecessary queries during traversal of an entire  * sub-tree.  *  * Some mutating operations, notably {@link #deleteSubtree(Path)} and  * {@link #move(Collection, Collection)}, are less efficient with this schema.  * They require mutating multiple items in the DynamoDB table.  *  * By default, DynamoDB access is performed within the same AWS region as  * the S3 bucket that hosts the S3A instance.  During initialization, it checks  * the location of the S3 bucket and creates a DynamoDB client connected to the  * same region. The region may also be set explicitly by setting the config  * parameter {@code fs.s3a.s3guard.ddb.region} to the corresponding region.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|DynamoDBMetadataStore
specifier|public
class|class
name|DynamoDBMetadataStore
implements|implements
name|MetadataStore
block|{
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|DynamoDBMetadataStore
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** parent/child name to use in the version marker. */
DECL|field|VERSION_MARKER
specifier|public
specifier|static
specifier|final
name|String
name|VERSION_MARKER
init|=
literal|"../VERSION"
decl_stmt|;
comment|/** Current version number. */
DECL|field|VERSION
specifier|public
specifier|static
specifier|final
name|int
name|VERSION
init|=
literal|100
decl_stmt|;
comment|/** Error: version marker not found in table. */
DECL|field|E_NO_VERSION_MARKER
specifier|public
specifier|static
specifier|final
name|String
name|E_NO_VERSION_MARKER
init|=
literal|"S3Guard table lacks version marker."
decl_stmt|;
comment|/** Error: version mismatch. */
DECL|field|E_INCOMPATIBLE_VERSION
specifier|public
specifier|static
specifier|final
name|String
name|E_INCOMPATIBLE_VERSION
init|=
literal|"Database table is from an incompatible S3Guard version."
decl_stmt|;
comment|/** Initial delay for retries when batched operations get throttled by    * DynamoDB. Value is {@value} msec. */
DECL|field|MIN_RETRY_SLEEP_MSEC
specifier|public
specifier|static
specifier|final
name|long
name|MIN_RETRY_SLEEP_MSEC
init|=
literal|100
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|DESCRIPTION
specifier|static
specifier|final
name|String
name|DESCRIPTION
init|=
literal|"S3Guard metadata store in DynamoDB"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|READ_CAPACITY
specifier|static
specifier|final
name|String
name|READ_CAPACITY
init|=
literal|"read-capacity"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|WRITE_CAPACITY
specifier|static
specifier|final
name|String
name|WRITE_CAPACITY
init|=
literal|"write-capacity"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|STATUS
specifier|static
specifier|final
name|String
name|STATUS
init|=
literal|"status"
decl_stmt|;
annotation|@
name|VisibleForTesting
DECL|field|TABLE
specifier|static
specifier|final
name|String
name|TABLE
init|=
literal|"table"
decl_stmt|;
DECL|field|deleteTrackingValueMap
specifier|private
specifier|static
name|ValueMap
name|deleteTrackingValueMap
init|=
operator|new
name|ValueMap
argument_list|()
operator|.
name|withBoolean
argument_list|(
literal|":false"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
DECL|field|dynamoDB
specifier|private
name|DynamoDB
name|dynamoDB
decl_stmt|;
DECL|field|region
specifier|private
name|String
name|region
decl_stmt|;
DECL|field|table
specifier|private
name|Table
name|table
decl_stmt|;
DECL|field|tableName
specifier|private
name|String
name|tableName
decl_stmt|;
DECL|field|conf
specifier|private
name|Configuration
name|conf
decl_stmt|;
DECL|field|username
specifier|private
name|String
name|username
decl_stmt|;
DECL|field|dataAccessRetryPolicy
specifier|private
name|RetryPolicy
name|dataAccessRetryPolicy
decl_stmt|;
DECL|field|instrumentation
specifier|private
name|S3AInstrumentation
operator|.
name|S3GuardInstrumentation
name|instrumentation
decl_stmt|;
comment|/** Owner FS: only valid if configured with an owner FS. */
DECL|field|owner
specifier|private
name|S3AFileSystem
name|owner
decl_stmt|;
comment|/** Invoker for IO. Until configured properly, use try-once. */
DECL|field|invoker
specifier|private
name|Invoker
name|invoker
init|=
operator|new
name|Invoker
argument_list|(
name|RetryPolicies
operator|.
name|TRY_ONCE_THEN_FAIL
argument_list|,
name|Invoker
operator|.
name|NO_OP
argument_list|)
decl_stmt|;
comment|/** Data access can have its own policies. */
DECL|field|dataAccess
specifier|private
name|Invoker
name|dataAccess
decl_stmt|;
comment|/**    * Total limit on the number of throttle events after which    * we stop warning in the log. Keeps the noise down.    */
DECL|field|THROTTLE_EVENT_LOG_LIMIT
specifier|private
specifier|static
specifier|final
name|int
name|THROTTLE_EVENT_LOG_LIMIT
init|=
literal|100
decl_stmt|;
comment|/**    * Count of the total number of throttle events; used to crank back logging.    */
DECL|field|throttleEventCount
specifier|private
name|AtomicInteger
name|throttleEventCount
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|/**    * A utility function to create DynamoDB instance.    * @param conf the file system configuration    * @param s3Region region of the associated S3 bucket (if any).    * @return DynamoDB instance.    * @throws IOException I/O error.    */
DECL|method|createDynamoDB (Configuration conf, String s3Region)
specifier|private
specifier|static
name|DynamoDB
name|createDynamoDB
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
name|s3Region
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|conf
argument_list|)
expr_stmt|;
specifier|final
name|Class
argument_list|<
name|?
extends|extends
name|DynamoDBClientFactory
argument_list|>
name|cls
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|S3GUARD_DDB_CLIENT_FACTORY_IMPL
argument_list|,
name|S3GUARD_DDB_CLIENT_FACTORY_IMPL_DEFAULT
argument_list|,
name|DynamoDBClientFactory
operator|.
name|class
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating DynamoDB client {} with S3 region {}"
argument_list|,
name|cls
argument_list|,
name|s3Region
argument_list|)
expr_stmt|;
specifier|final
name|AmazonDynamoDB
name|dynamoDBClient
init|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|cls
argument_list|,
name|conf
argument_list|)
operator|.
name|createDynamoDBClient
argument_list|(
name|s3Region
argument_list|)
decl_stmt|;
return|return
operator|new
name|DynamoDB
argument_list|(
name|dynamoDBClient
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|initialize (FileSystem fs)
specifier|public
name|void
name|initialize
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|fs
argument_list|,
literal|"Null filesystem"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|fs
operator|instanceof
name|S3AFileSystem
argument_list|,
literal|"DynamoDBMetadataStore only supports S3A filesystem."
argument_list|)
expr_stmt|;
name|owner
operator|=
operator|(
name|S3AFileSystem
operator|)
name|fs
expr_stmt|;
name|instrumentation
operator|=
name|owner
operator|.
name|getInstrumentation
argument_list|()
operator|.
name|getS3GuardInstrumentation
argument_list|()
expr_stmt|;
specifier|final
name|String
name|bucket
init|=
name|owner
operator|.
name|getBucket
argument_list|()
decl_stmt|;
name|conf
operator|=
name|owner
operator|.
name|getConf
argument_list|()
expr_stmt|;
name|String
name|confRegion
init|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|S3GUARD_DDB_REGION_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|confRegion
argument_list|)
condition|)
block|{
name|region
operator|=
name|confRegion
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overriding S3 region with configured DynamoDB region: {}"
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|region
operator|=
name|owner
operator|.
name|getBucketLocation
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Inferring DynamoDB region from S3 bucket: {}"
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
name|username
operator|=
name|owner
operator|.
name|getUsername
argument_list|()
expr_stmt|;
name|dynamoDB
operator|=
name|createDynamoDB
argument_list|(
name|conf
argument_list|,
name|region
argument_list|)
expr_stmt|;
comment|// use the bucket as the DynamoDB table name if not specified in config
name|tableName
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|S3GUARD_DDB_TABLE_NAME_KEY
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
name|initDataAccessRetries
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// set up a full retry policy
name|invoker
operator|=
operator|new
name|Invoker
argument_list|(
operator|new
name|S3ARetryPolicy
argument_list|(
name|conf
argument_list|)
argument_list|,
name|this
operator|::
name|retryEvent
argument_list|)
expr_stmt|;
name|initTable
argument_list|()
expr_stmt|;
name|instrumentation
operator|.
name|initialized
argument_list|()
expr_stmt|;
block|}
comment|/**    * Performs one-time initialization of the metadata store via configuration.    *    * This initialization depends on the configuration object to get AWS    * credentials, DynamoDBFactory implementation class, DynamoDB endpoints,    * DynamoDB table names etc. After initialization, this metadata store does    * not explicitly relate to any S3 bucket, which be nonexistent.    *    * This is used to operate the metadata store directly beyond the scope of the    * S3AFileSystem integration, e.g. command line tools.    * Generally, callers should use {@link #initialize(FileSystem)}    * with an initialized {@code S3AFileSystem} instance.    *    * Without a filesystem to act as a reference point, the configuration itself    * must declare the table name and region in the    * {@link Constants#S3GUARD_DDB_TABLE_NAME_KEY} and    * {@link Constants#S3GUARD_DDB_REGION_KEY} respectively.    *    * @see #initialize(FileSystem)    * @throws IOException if there is an error    * @throws IllegalArgumentException if the configuration is incomplete    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|initialize (Configuration config)
specifier|public
name|void
name|initialize
parameter_list|(
name|Configuration
name|config
parameter_list|)
throws|throws
name|IOException
block|{
name|conf
operator|=
name|config
expr_stmt|;
comment|// use the bucket as the DynamoDB table name if not specified in config
name|tableName
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|S3GUARD_DDB_TABLE_NAME_KEY
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|tableName
argument_list|)
argument_list|,
literal|"No DynamoDB table name configured"
argument_list|)
expr_stmt|;
name|region
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|S3GUARD_DDB_REGION_KEY
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|region
argument_list|)
argument_list|,
literal|"No DynamoDB region configured"
argument_list|)
expr_stmt|;
name|dynamoDB
operator|=
name|createDynamoDB
argument_list|(
name|conf
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|username
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|initDataAccessRetries
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|initTable
argument_list|()
expr_stmt|;
block|}
comment|/**    * Set retry policy. This is driven by the value of    * {@link Constants#S3GUARD_DDB_MAX_RETRIES} with an exponential backoff    * between each attempt of {@link #MIN_RETRY_SLEEP_MSEC} milliseconds.    * @param config configuration for data access    */
DECL|method|initDataAccessRetries (Configuration config)
specifier|private
name|void
name|initDataAccessRetries
parameter_list|(
name|Configuration
name|config
parameter_list|)
block|{
name|int
name|maxRetries
init|=
name|config
operator|.
name|getInt
argument_list|(
name|S3GUARD_DDB_MAX_RETRIES
argument_list|,
name|S3GUARD_DDB_MAX_RETRIES_DEFAULT
argument_list|)
decl_stmt|;
name|dataAccessRetryPolicy
operator|=
name|RetryPolicies
operator|.
name|exponentialBackoffRetry
argument_list|(
name|maxRetries
argument_list|,
name|MIN_RETRY_SLEEP_MSEC
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
name|dataAccess
operator|=
operator|new
name|Invoker
argument_list|(
name|dataAccessRetryPolicy
argument_list|,
name|this
operator|::
name|retryEvent
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|delete (Path path)
specifier|public
name|void
name|delete
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|innerDelete
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|forgetMetadata (Path path)
specifier|public
name|void
name|forgetMetadata
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|innerDelete
argument_list|(
name|path
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Inner delete option, action based on the {@code tombstone} flag.    * No tombstone: delete the entry. Tombstone: create a tombstone entry.    * There is no check as to whether the entry exists in the table first.    * @param path path to delete    * @param tombstone flag to create a tombstone marker    * @throws IOException I/O error.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerDelete (final Path path, boolean tombstone)
specifier|private
name|void
name|innerDelete
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
name|boolean
name|tombstone
parameter_list|)
throws|throws
name|IOException
block|{
name|checkPath
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting from table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|)
expr_stmt|;
comment|// deleting nonexistent item consumes 1 write capacity; skip it
if|if
condition|(
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skip deleting root directory as it does not exist in table"
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// the policy on whether repeating delete operations is based
comment|// on that of S3A itself
name|boolean
name|idempotent
init|=
name|S3AFileSystem
operator|.
name|DELETE_CONSIDERED_IDEMPOTENT
decl_stmt|;
if|if
condition|(
name|tombstone
condition|)
block|{
name|Item
name|item
init|=
name|PathMetadataDynamoDBTranslation
operator|.
name|pathMetadataToItem
argument_list|(
name|PathMetadata
operator|.
name|tombstone
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"Put tombstone"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
name|idempotent
argument_list|,
parameter_list|()
lambda|->
name|table
operator|.
name|putItem
argument_list|(
name|item
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|PrimaryKey
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"Delete key"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
name|idempotent
argument_list|,
parameter_list|()
lambda|->
name|table
operator|.
name|deleteItem
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|deleteSubtree (Path path)
specifier|public
name|void
name|deleteSubtree
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|checkPath
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting subtree from table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|)
expr_stmt|;
specifier|final
name|PathMetadata
name|meta
init|=
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|meta
operator|==
literal|null
operator|||
name|meta
operator|.
name|isDeleted
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Subtree path {} does not exist; this will be a no-op"
argument_list|,
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|DescendantsIterator
name|desc
init|=
operator|new
name|DescendantsIterator
argument_list|(
name|this
argument_list|,
name|meta
argument_list|)
init|;
name|desc
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|innerDelete
argument_list|(
name|desc
operator|.
name|next
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|getConsistentItem (PrimaryKey key)
specifier|private
name|Item
name|getConsistentItem
parameter_list|(
name|PrimaryKey
name|key
parameter_list|)
block|{
specifier|final
name|GetItemSpec
name|spec
init|=
operator|new
name|GetItemSpec
argument_list|()
operator|.
name|withPrimaryKey
argument_list|(
name|key
argument_list|)
operator|.
name|withConsistentRead
argument_list|(
literal|true
argument_list|)
decl_stmt|;
comment|// strictly consistent read
return|return
name|table
operator|.
name|getItem
argument_list|(
name|spec
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|get (Path path)
specifier|public
name|PathMetadata
name|get
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|path
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|get (Path path, boolean wantEmptyDirectoryFlag)
specifier|public
name|PathMetadata
name|get
parameter_list|(
name|Path
name|path
parameter_list|,
name|boolean
name|wantEmptyDirectoryFlag
parameter_list|)
throws|throws
name|IOException
block|{
name|checkPath
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Get from table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|)
expr_stmt|;
return|return
name|Invoker
operator|.
name|once
argument_list|(
literal|"get"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
name|innerGet
argument_list|(
name|path
argument_list|,
name|wantEmptyDirectoryFlag
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Inner get operation, as invoked in the retry logic.    * @param path the path to get    * @param wantEmptyDirectoryFlag Set to true to give a hint to the    *   MetadataStore that it should try to compute the empty directory flag.    * @return metadata for {@code path}, {@code null} if not found    * @throws IOException IO problem    * @throws AmazonClientException dynamo DB level problem    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|innerGet (Path path, boolean wantEmptyDirectoryFlag)
specifier|private
name|PathMetadata
name|innerGet
parameter_list|(
name|Path
name|path
parameter_list|,
name|boolean
name|wantEmptyDirectoryFlag
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|PathMetadata
name|meta
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
comment|// Root does not persist in the table
name|meta
operator|=
operator|new
name|PathMetadata
argument_list|(
name|makeDirStatus
argument_list|(
name|username
argument_list|,
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
specifier|final
name|Item
name|item
init|=
name|getConsistentItem
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|meta
operator|=
name|itemToPathMetadata
argument_list|(
name|item
argument_list|,
name|username
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Get from table {} in region {} returning for {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|,
name|meta
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|wantEmptyDirectoryFlag
operator|&&
name|meta
operator|!=
literal|null
condition|)
block|{
specifier|final
name|FileStatus
name|status
init|=
name|meta
operator|.
name|getFileStatus
argument_list|()
decl_stmt|;
comment|// for directory, we query its direct children to determine isEmpty bit
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
specifier|final
name|QuerySpec
name|spec
init|=
operator|new
name|QuerySpec
argument_list|()
operator|.
name|withHashKey
argument_list|(
name|pathToParentKeyAttribute
argument_list|(
name|path
argument_list|)
argument_list|)
operator|.
name|withConsistentRead
argument_list|(
literal|true
argument_list|)
operator|.
name|withFilterExpression
argument_list|(
name|IS_DELETED
operator|+
literal|" = :false"
argument_list|)
operator|.
name|withValueMap
argument_list|(
name|deleteTrackingValueMap
argument_list|)
decl_stmt|;
specifier|final
name|ItemCollection
argument_list|<
name|QueryOutcome
argument_list|>
name|items
init|=
name|table
operator|.
name|query
argument_list|(
name|spec
argument_list|)
decl_stmt|;
name|boolean
name|hasChildren
init|=
name|items
operator|.
name|iterator
argument_list|()
operator|.
name|hasNext
argument_list|()
decl_stmt|;
comment|// When this class has support for authoritative
comment|// (fully-cached) directory listings, we may also be able to answer
comment|// TRUE here.  Until then, we don't know if we have full listing or
comment|// not, thus the UNKNOWN here:
name|meta
operator|.
name|setIsEmptyDirectory
argument_list|(
name|hasChildren
condition|?
name|Tristate
operator|.
name|FALSE
else|:
name|Tristate
operator|.
name|UNKNOWN
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|meta
return|;
block|}
comment|/**    * Make a FileStatus object for a directory at given path.  The FileStatus    * only contains what S3A needs, and omits mod time since S3A uses its own    * implementation which returns current system time.    * @param owner  username of owner    * @param path   path to dir    * @return new FileStatus    */
DECL|method|makeDirStatus (String owner, Path path)
specifier|private
name|FileStatus
name|makeDirStatus
parameter_list|(
name|String
name|owner
parameter_list|,
name|Path
name|path
parameter_list|)
block|{
return|return
operator|new
name|FileStatus
argument_list|(
literal|0
argument_list|,
literal|true
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
literal|null
argument_list|,
name|owner
argument_list|,
literal|null
argument_list|,
name|path
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|listChildren (final Path path)
specifier|public
name|DirListingMetadata
name|listChildren
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|checkPath
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Listing table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|)
expr_stmt|;
comment|// find the children in the table
return|return
name|Invoker
operator|.
name|once
argument_list|(
literal|"listChildren"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
block|{
specifier|final
name|QuerySpec
name|spec
init|=
operator|new
name|QuerySpec
argument_list|()
operator|.
name|withHashKey
argument_list|(
name|pathToParentKeyAttribute
argument_list|(
name|path
argument_list|)
argument_list|)
operator|.
name|withConsistentRead
argument_list|(
literal|true
argument_list|)
decl_stmt|;
comment|// strictly consistent read
specifier|final
name|ItemCollection
argument_list|<
name|QueryOutcome
argument_list|>
name|items
init|=
name|table
operator|.
name|query
argument_list|(
name|spec
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|metas
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Item
name|item
range|:
name|items
control|)
block|{
name|PathMetadata
name|meta
init|=
name|itemToPathMetadata
argument_list|(
name|item
argument_list|,
name|username
argument_list|)
decl_stmt|;
name|metas
operator|.
name|add
argument_list|(
name|meta
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|trace
argument_list|(
literal|"Listing table {} in region {} for {} returning {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|path
argument_list|,
name|metas
argument_list|)
expr_stmt|;
return|return
operator|(
name|metas
operator|.
name|isEmpty
argument_list|()
operator|&&
name|get
argument_list|(
name|path
argument_list|)
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
operator|new
name|DirListingMetadata
argument_list|(
name|path
argument_list|,
name|metas
argument_list|,
literal|false
argument_list|)
return|;
block|}
argument_list|)
return|;
block|}
comment|/**    * build the list of all parent entries.    * @param pathsToCreate paths to create    * @return the full ancestry paths    */
DECL|method|completeAncestry ( Collection<PathMetadata> pathsToCreate)
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|completeAncestry
parameter_list|(
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|pathsToCreate
parameter_list|)
block|{
comment|// Key on path to allow fast lookup
name|Map
argument_list|<
name|Path
argument_list|,
name|PathMetadata
argument_list|>
name|ancestry
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|PathMetadata
name|meta
range|:
name|pathsToCreate
control|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|meta
operator|!=
literal|null
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|meta
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
break|break;
block|}
name|ancestry
operator|.
name|put
argument_list|(
name|path
argument_list|,
name|meta
argument_list|)
expr_stmt|;
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|parent
operator|.
name|isRoot
argument_list|()
operator|&&
operator|!
name|ancestry
operator|.
name|containsKey
argument_list|(
name|parent
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"auto-create ancestor path {} for child path {}"
argument_list|,
name|parent
argument_list|,
name|path
argument_list|)
expr_stmt|;
specifier|final
name|FileStatus
name|status
init|=
name|makeDirStatus
argument_list|(
name|parent
argument_list|,
name|username
argument_list|)
decl_stmt|;
name|ancestry
operator|.
name|put
argument_list|(
name|parent
argument_list|,
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|,
name|Tristate
operator|.
name|FALSE
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|parent
operator|=
name|parent
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|ancestry
operator|.
name|values
argument_list|()
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|move (Collection<Path> pathsToDelete, Collection<PathMetadata> pathsToCreate)
specifier|public
name|void
name|move
parameter_list|(
name|Collection
argument_list|<
name|Path
argument_list|>
name|pathsToDelete
parameter_list|,
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|pathsToCreate
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|pathsToDelete
operator|==
literal|null
operator|&&
name|pathsToCreate
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving paths of table {} in region {}: {} paths to delete and {}"
operator|+
literal|" paths to create"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|pathsToDelete
operator|==
literal|null
condition|?
literal|0
else|:
name|pathsToDelete
operator|.
name|size
argument_list|()
argument_list|,
name|pathsToCreate
operator|==
literal|null
condition|?
literal|0
else|:
name|pathsToCreate
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"move: pathsToDelete = {}, pathsToCreate = {}"
argument_list|,
name|pathsToDelete
argument_list|,
name|pathsToCreate
argument_list|)
expr_stmt|;
comment|// In DynamoDBMetadataStore implementation, we assume that if a path
comment|// exists, all its ancestors will also exist in the table.
comment|// Following code is to maintain this invariant by putting all ancestor
comment|// directories of the paths to create.
comment|// ancestor paths that are not explicitly added to paths to create
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|newItems
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|pathsToCreate
operator|!=
literal|null
condition|)
block|{
name|newItems
operator|.
name|addAll
argument_list|(
name|completeAncestry
argument_list|(
name|pathsToCreate
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|pathsToDelete
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Path
name|meta
range|:
name|pathsToDelete
control|)
block|{
name|newItems
operator|.
name|add
argument_list|(
name|PathMetadata
operator|.
name|tombstone
argument_list|(
name|meta
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|Invoker
operator|.
name|once
argument_list|(
literal|"move"
argument_list|,
name|tableName
argument_list|,
parameter_list|()
lambda|->
name|processBatchWriteRequest
argument_list|(
literal|null
argument_list|,
name|pathMetadataToItem
argument_list|(
name|newItems
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Helper method to issue a batch write request to DynamoDB.    *    * The retry logic here is limited to repeating the write operations    * until all items have been written; there is no other attempt    * at recovery/retry. Throttling is handled internally.    * @param keysToDelete primary keys to be deleted; can be null    * @param itemsToPut new items to be put; can be null    */
annotation|@
name|Retries
operator|.
name|OnceRaw
argument_list|(
literal|"Outstanding batch items are updated with backoff"
argument_list|)
DECL|method|processBatchWriteRequest (PrimaryKey[] keysToDelete, Item[] itemsToPut)
specifier|private
name|void
name|processBatchWriteRequest
parameter_list|(
name|PrimaryKey
index|[]
name|keysToDelete
parameter_list|,
name|Item
index|[]
name|itemsToPut
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|int
name|totalToDelete
init|=
operator|(
name|keysToDelete
operator|==
literal|null
condition|?
literal|0
else|:
name|keysToDelete
operator|.
name|length
operator|)
decl_stmt|;
specifier|final
name|int
name|totalToPut
init|=
operator|(
name|itemsToPut
operator|==
literal|null
condition|?
literal|0
else|:
name|itemsToPut
operator|.
name|length
operator|)
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|count
operator|<
name|totalToDelete
operator|+
name|totalToPut
condition|)
block|{
specifier|final
name|TableWriteItems
name|writeItems
init|=
operator|new
name|TableWriteItems
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|int
name|numToDelete
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|keysToDelete
operator|!=
literal|null
operator|&&
name|count
operator|<
name|totalToDelete
condition|)
block|{
name|numToDelete
operator|=
name|Math
operator|.
name|min
argument_list|(
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
argument_list|,
name|totalToDelete
operator|-
name|count
argument_list|)
expr_stmt|;
name|writeItems
operator|.
name|withPrimaryKeysToDelete
argument_list|(
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|keysToDelete
argument_list|,
name|count
argument_list|,
name|count
operator|+
name|numToDelete
argument_list|)
argument_list|)
expr_stmt|;
name|count
operator|+=
name|numToDelete
expr_stmt|;
block|}
if|if
condition|(
name|numToDelete
operator|<
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
operator|&&
name|itemsToPut
operator|!=
literal|null
operator|&&
name|count
operator|<
name|totalToDelete
operator|+
name|totalToPut
condition|)
block|{
specifier|final
name|int
name|numToPut
init|=
name|Math
operator|.
name|min
argument_list|(
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
operator|-
name|numToDelete
argument_list|,
name|totalToDelete
operator|+
name|totalToPut
operator|-
name|count
argument_list|)
decl_stmt|;
specifier|final
name|int
name|index
init|=
name|count
operator|-
name|totalToDelete
decl_stmt|;
name|writeItems
operator|.
name|withItemsToPut
argument_list|(
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|itemsToPut
argument_list|,
name|index
argument_list|,
name|index
operator|+
name|numToPut
argument_list|)
argument_list|)
expr_stmt|;
name|count
operator|+=
name|numToPut
expr_stmt|;
block|}
name|BatchWriteItemOutcome
name|res
init|=
name|dynamoDB
operator|.
name|batchWriteItem
argument_list|(
name|writeItems
argument_list|)
decl_stmt|;
comment|// Check for unprocessed keys in case of exceeding provisioned throughput
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|WriteRequest
argument_list|>
argument_list|>
name|unprocessed
init|=
name|res
operator|.
name|getUnprocessedItems
argument_list|()
decl_stmt|;
name|int
name|retryCount
init|=
literal|0
decl_stmt|;
while|while
condition|(
operator|!
name|unprocessed
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|retryBackoff
argument_list|(
name|retryCount
operator|++
argument_list|)
expr_stmt|;
name|res
operator|=
name|dynamoDB
operator|.
name|batchWriteItemUnprocessed
argument_list|(
name|unprocessed
argument_list|)
expr_stmt|;
name|unprocessed
operator|=
name|res
operator|.
name|getUnprocessedItems
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Put the current thread to sleep to implement exponential backoff    * depending on retryCount.  If max retries are exceeded, throws an    * exception instead.    * @param retryCount number of retries so far    * @throws IOException when max retryCount is exceeded.    */
DECL|method|retryBackoff (int retryCount)
specifier|private
name|void
name|retryBackoff
parameter_list|(
name|int
name|retryCount
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
comment|// Our RetryPolicy ignores everything but retryCount here.
name|RetryPolicy
operator|.
name|RetryAction
name|action
init|=
name|dataAccessRetryPolicy
operator|.
name|shouldRetry
argument_list|(
literal|null
argument_list|,
name|retryCount
argument_list|,
literal|0
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|action
operator|.
name|action
operator|==
name|RetryPolicy
operator|.
name|RetryAction
operator|.
name|RetryDecision
operator|.
name|FAIL
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Max retries exceeded (%d) for DynamoDB. This may be"
operator|+
literal|" because write threshold of DynamoDB is set too low."
argument_list|,
name|retryCount
argument_list|)
argument_list|)
throw|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Sleeping {} msec before next retry"
argument_list|,
name|action
operator|.
name|delayMillis
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|action
operator|.
name|delayMillis
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|IOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unexpected exception"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|put (PathMetadata meta)
specifier|public
name|void
name|put
parameter_list|(
name|PathMetadata
name|meta
parameter_list|)
throws|throws
name|IOException
block|{
comment|// For a deeply nested path, this method will automatically create the full
comment|// ancestry and save respective item in DynamoDB table.
comment|// So after put operation, we maintain the invariant that if a path exists,
comment|// all its ancestors will also exist in the table.
comment|// For performance purpose, we generate the full paths to put and use batch
comment|// write item request to save the items.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Saving to table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|meta
argument_list|)
expr_stmt|;
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|wrapper
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|wrapper
operator|.
name|add
argument_list|(
name|meta
argument_list|)
expr_stmt|;
name|put
argument_list|(
name|wrapper
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|put (Collection<PathMetadata> metas)
specifier|public
name|void
name|put
parameter_list|(
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|metas
parameter_list|)
throws|throws
name|IOException
block|{
name|Item
index|[]
name|items
init|=
name|pathMetadataToItem
argument_list|(
name|completeAncestry
argument_list|(
name|metas
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Saving batch of {} items to table {}, region {}"
argument_list|,
name|items
operator|.
name|length
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|processBatchWriteRequest
argument_list|(
literal|null
argument_list|,
name|items
argument_list|)
expr_stmt|;
block|}
comment|/**    * Helper method to get full path of ancestors that are nonexistent in table.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|fullPathsToPut (PathMetadata meta)
specifier|private
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|fullPathsToPut
parameter_list|(
name|PathMetadata
name|meta
parameter_list|)
throws|throws
name|IOException
block|{
name|checkPathMetadata
argument_list|(
name|meta
argument_list|)
expr_stmt|;
specifier|final
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|metasToPut
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// root path is not persisted
if|if
condition|(
operator|!
name|meta
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|isRoot
argument_list|()
condition|)
block|{
name|metasToPut
operator|.
name|add
argument_list|(
name|meta
argument_list|)
expr_stmt|;
block|}
comment|// put all its ancestors if not present; as an optimization we return at its
comment|// first existent ancestor
name|Path
name|path
init|=
name|meta
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
while|while
condition|(
name|path
operator|!=
literal|null
operator|&&
operator|!
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
specifier|final
name|Item
name|item
init|=
name|getConsistentItem
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|itemExists
argument_list|(
name|item
argument_list|)
condition|)
block|{
specifier|final
name|FileStatus
name|status
init|=
name|makeDirStatus
argument_list|(
name|path
argument_list|,
name|username
argument_list|)
decl_stmt|;
name|metasToPut
operator|.
name|add
argument_list|(
operator|new
name|PathMetadata
argument_list|(
name|status
argument_list|,
name|Tristate
operator|.
name|FALSE
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|path
operator|=
name|path
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
else|else
block|{
break|break;
block|}
block|}
return|return
name|metasToPut
return|;
block|}
DECL|method|itemExists (Item item)
specifier|private
name|boolean
name|itemExists
parameter_list|(
name|Item
name|item
parameter_list|)
block|{
if|if
condition|(
name|item
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|item
operator|.
name|hasAttribute
argument_list|(
name|IS_DELETED
argument_list|)
operator|&&
name|item
operator|.
name|getBoolean
argument_list|(
name|IS_DELETED
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|/** Create a directory FileStatus using current system time as mod time. */
DECL|method|makeDirStatus (Path f, String owner)
specifier|static
name|FileStatus
name|makeDirStatus
parameter_list|(
name|Path
name|f
parameter_list|,
name|String
name|owner
parameter_list|)
block|{
return|return
operator|new
name|FileStatus
argument_list|(
literal|0
argument_list|,
literal|true
argument_list|,
literal|1
argument_list|,
literal|0
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
literal|0
argument_list|,
literal|null
argument_list|,
name|owner
argument_list|,
name|owner
argument_list|,
name|f
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    * There is retry around building the list of paths to update, but    * the call to {@link #processBatchWriteRequest(PrimaryKey[], Item[])}    * is only tried once.    * @param meta Directory listing metadata.    * @throws IOException IO problem    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
argument_list|(
literal|"retry(listFullPaths); once(batchWrite)"
argument_list|)
DECL|method|put (DirListingMetadata meta)
specifier|public
name|void
name|put
parameter_list|(
name|DirListingMetadata
name|meta
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Saving to table {} in region {}: {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|meta
argument_list|)
expr_stmt|;
comment|// directory path
name|Path
name|path
init|=
name|meta
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|PathMetadata
name|p
init|=
operator|new
name|PathMetadata
argument_list|(
name|makeDirStatus
argument_list|(
name|path
argument_list|,
name|username
argument_list|)
argument_list|,
name|meta
operator|.
name|isEmpty
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// First add any missing ancestors...
specifier|final
name|Collection
argument_list|<
name|PathMetadata
argument_list|>
name|metasToPut
init|=
name|invoker
operator|.
name|retry
argument_list|(
literal|"paths to put"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|fullPathsToPut
argument_list|(
name|p
argument_list|)
argument_list|)
decl_stmt|;
comment|// next add all children of the directory
name|metasToPut
operator|.
name|addAll
argument_list|(
name|meta
operator|.
name|getListing
argument_list|()
argument_list|)
expr_stmt|;
name|Invoker
operator|.
name|once
argument_list|(
literal|"put"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
name|processBatchWriteRequest
argument_list|(
literal|null
argument_list|,
name|pathMetadataToItem
argument_list|(
name|metasToPut
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|close ()
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|instrumentation
operator|!=
literal|null
condition|)
block|{
name|instrumentation
operator|.
name|storeClosed
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|dynamoDB
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Shutting down {}"
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|dynamoDB
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|dynamoDB
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|destroy ()
specifier|public
name|void
name|destroy
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|table
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"In destroy(): no table to delete"
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Deleting DynamoDB table {} in region {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|dynamoDB
argument_list|,
literal|"Not connected to DynamoDB"
argument_list|)
expr_stmt|;
try|try
block|{
name|table
operator|.
name|delete
argument_list|()
expr_stmt|;
name|table
operator|.
name|waitForDelete
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ResourceNotFoundException
name|rnfe
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"ResourceNotFoundException while deleting DynamoDB table {} in "
operator|+
literal|"region {}.  This may indicate that the table does not exist, "
operator|+
literal|"or has been deleted by another concurrent thread or process."
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting for DynamoDB table {} being deleted"
argument_list|,
name|tableName
argument_list|,
name|ie
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Table "
operator|+
name|tableName
operator|+
literal|" in region "
operator|+
name|region
operator|+
literal|" has not been deleted"
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"destroy"
argument_list|,
name|tableName
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|expiredFiles (long modTime, String keyPrefix)
specifier|private
name|ItemCollection
argument_list|<
name|ScanOutcome
argument_list|>
name|expiredFiles
parameter_list|(
name|long
name|modTime
parameter_list|,
name|String
name|keyPrefix
parameter_list|)
block|{
name|String
name|filterExpression
init|=
literal|"mod_time< :mod_time and begins_with(parent, :parent)"
decl_stmt|;
name|String
name|projectionExpression
init|=
literal|"parent,child"
decl_stmt|;
name|ValueMap
name|map
init|=
operator|new
name|ValueMap
argument_list|()
operator|.
name|withLong
argument_list|(
literal|":mod_time"
argument_list|,
name|modTime
argument_list|)
operator|.
name|withString
argument_list|(
literal|":parent"
argument_list|,
name|keyPrefix
argument_list|)
decl_stmt|;
return|return
name|table
operator|.
name|scan
argument_list|(
name|filterExpression
argument_list|,
name|projectionExpression
argument_list|,
literal|null
argument_list|,
name|map
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
argument_list|(
literal|"once(batchWrite)"
argument_list|)
DECL|method|prune (long modTime)
specifier|public
name|void
name|prune
parameter_list|(
name|long
name|modTime
parameter_list|)
throws|throws
name|IOException
block|{
name|prune
argument_list|(
name|modTime
argument_list|,
literal|"/"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
argument_list|(
literal|"once(batchWrite)"
argument_list|)
DECL|method|prune (long modTime, String keyPrefix)
specifier|public
name|void
name|prune
parameter_list|(
name|long
name|modTime
parameter_list|,
name|String
name|keyPrefix
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|itemCount
init|=
literal|0
decl_stmt|;
try|try
block|{
name|Collection
argument_list|<
name|Path
argument_list|>
name|deletionBatch
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
argument_list|)
decl_stmt|;
name|int
name|delay
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|S3GUARD_DDB_BACKGROUND_SLEEP_MSEC_KEY
argument_list|,
name|S3GUARD_DDB_BACKGROUND_SLEEP_MSEC_DEFAULT
argument_list|)
decl_stmt|;
for|for
control|(
name|Item
name|item
range|:
name|expiredFiles
argument_list|(
name|modTime
argument_list|,
name|keyPrefix
argument_list|)
control|)
block|{
name|PathMetadata
name|md
init|=
name|PathMetadataDynamoDBTranslation
operator|.
name|itemToPathMetadata
argument_list|(
name|item
argument_list|,
name|username
argument_list|)
decl_stmt|;
name|Path
name|path
init|=
name|md
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|deletionBatch
operator|.
name|add
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|itemCount
operator|++
expr_stmt|;
if|if
condition|(
name|deletionBatch
operator|.
name|size
argument_list|()
operator|==
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|delay
argument_list|)
expr_stmt|;
name|processBatchWriteRequest
argument_list|(
name|pathToKey
argument_list|(
name|deletionBatch
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|deletionBatch
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|deletionBatch
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|delay
argument_list|)
expr_stmt|;
name|processBatchWriteRequest
argument_list|(
name|pathToKey
argument_list|(
name|deletionBatch
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Pruning was interrupted"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Finished pruning {} items in batches of {}"
argument_list|,
name|itemCount
argument_list|,
name|S3GUARD_DDB_BATCH_WRITE_REQUEST_LIMIT
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|'{'
operator|+
literal|"region="
operator|+
name|region
operator|+
literal|", tableName="
operator|+
name|tableName
operator|+
literal|'}'
return|;
block|}
comment|/**    * Create a table if it does not exist and wait for it to become active.    *    * If a table with the intended name already exists, then it uses that table.    * Otherwise, it will automatically create the table if the config    * {@link org.apache.hadoop.fs.s3a.Constants#S3GUARD_DDB_TABLE_CREATE_KEY} is    * enabled. The DynamoDB table creation API is asynchronous.  This method wait    * for the table to become active after sending the creation request, so    * overall, this method is synchronous, and the table is guaranteed to exist    * after this method returns successfully.    *    * @throws IOException if table does not exist and auto-creation is disabled;    * or table is being deleted, or any other I/O exception occurred.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|initTable ()
name|void
name|initTable
parameter_list|()
throws|throws
name|IOException
block|{
name|table
operator|=
name|dynamoDB
operator|.
name|getTable
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
try|try
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Binding to table {}"
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
name|TableDescription
name|description
init|=
name|table
operator|.
name|describe
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Table state: {}"
argument_list|,
name|description
argument_list|)
expr_stmt|;
specifier|final
name|String
name|status
init|=
name|description
operator|.
name|getTableStatus
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|status
condition|)
block|{
case|case
literal|"CREATING"
case|:
case|case
literal|"UPDATING"
case|:
name|LOG
operator|.
name|debug
argument_list|(
literal|"Table {} in region {} is being created/updated. This may"
operator|+
literal|" indicate that the table is being operated by another "
operator|+
literal|"concurrent thread or process. Waiting for active..."
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|waitForTableActive
argument_list|(
name|table
argument_list|)
expr_stmt|;
break|break;
case|case
literal|"DELETING"
case|:
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"DynamoDB table "
operator|+
literal|"'"
operator|+
name|tableName
operator|+
literal|"' is being "
operator|+
literal|"deleted in region "
operator|+
name|region
argument_list|)
throw|;
case|case
literal|"ACTIVE"
case|:
break|break;
default|default:
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unknown DynamoDB table status "
operator|+
name|status
operator|+
literal|": tableName='"
operator|+
name|tableName
operator|+
literal|"', region="
operator|+
name|region
argument_list|)
throw|;
block|}
specifier|final
name|Item
name|versionMarker
init|=
name|getVersionMarkerItem
argument_list|()
decl_stmt|;
name|verifyVersionCompatibility
argument_list|(
name|tableName
argument_list|,
name|versionMarker
argument_list|)
expr_stmt|;
name|Long
name|created
init|=
name|extractCreationTimeFromMarker
argument_list|(
name|versionMarker
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using existing DynamoDB table {} in region {} created {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
operator|(
name|created
operator|!=
literal|null
operator|)
condition|?
operator|new
name|Date
argument_list|(
name|created
argument_list|)
else|:
literal|null
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ResourceNotFoundException
name|rnfe
parameter_list|)
block|{
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
name|S3GUARD_DDB_TABLE_CREATE_KEY
argument_list|,
literal|false
argument_list|)
condition|)
block|{
specifier|final
name|ProvisionedThroughput
name|capacity
init|=
operator|new
name|ProvisionedThroughput
argument_list|(
name|conf
operator|.
name|getLong
argument_list|(
name|S3GUARD_DDB_TABLE_CAPACITY_READ_KEY
argument_list|,
name|S3GUARD_DDB_TABLE_CAPACITY_READ_DEFAULT
argument_list|)
argument_list|,
name|conf
operator|.
name|getLong
argument_list|(
name|S3GUARD_DDB_TABLE_CAPACITY_WRITE_KEY
argument_list|,
name|S3GUARD_DDB_TABLE_CAPACITY_WRITE_DEFAULT
argument_list|)
argument_list|)
decl_stmt|;
name|createTable
argument_list|(
name|capacity
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|(
name|FileNotFoundException
operator|)
operator|new
name|FileNotFoundException
argument_list|(
literal|"DynamoDB table '"
operator|+
name|tableName
operator|+
literal|"' does not "
operator|+
literal|"exist in region "
operator|+
name|region
operator|+
literal|"; auto-creation is turned off"
argument_list|)
operator|.
name|initCause
argument_list|(
name|rnfe
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"initTable"
argument_list|,
name|tableName
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get the version mark item in the existing DynamoDB table.    *    * As the version marker item may be created by another concurrent thread or    * process, we sleep and retry a limited times before we fail to get it.    * This does not include handling any failure other than "item not found",    * so this method is tagged as "OnceRaw"    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|getVersionMarkerItem ()
specifier|private
name|Item
name|getVersionMarkerItem
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|PrimaryKey
name|versionMarkerKey
init|=
name|createVersionMarkerPrimaryKey
argument_list|(
name|VERSION_MARKER
argument_list|)
decl_stmt|;
name|int
name|retryCount
init|=
literal|0
decl_stmt|;
name|Item
name|versionMarker
init|=
name|table
operator|.
name|getItem
argument_list|(
name|versionMarkerKey
argument_list|)
decl_stmt|;
while|while
condition|(
name|versionMarker
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|RetryPolicy
operator|.
name|RetryAction
name|action
init|=
name|dataAccessRetryPolicy
operator|.
name|shouldRetry
argument_list|(
literal|null
argument_list|,
name|retryCount
argument_list|,
literal|0
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|action
operator|.
name|action
operator|==
name|RetryPolicy
operator|.
name|RetryAction
operator|.
name|RetryDecision
operator|.
name|FAIL
condition|)
block|{
break|break;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Sleeping {} ms before next retry"
argument_list|,
name|action
operator|.
name|delayMillis
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|action
operator|.
name|delayMillis
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"initTable: Unexpected exception"
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|retryCount
operator|++
expr_stmt|;
name|versionMarker
operator|=
name|table
operator|.
name|getItem
argument_list|(
name|versionMarkerKey
argument_list|)
expr_stmt|;
block|}
return|return
name|versionMarker
return|;
block|}
comment|/**    * Verify that a table version is compatible with this S3Guard client.    * @param tableName name of the table (for error messages)    * @param versionMarker the version marker retrieved from the table    * @throws IOException on any incompatibility    */
annotation|@
name|VisibleForTesting
DECL|method|verifyVersionCompatibility (String tableName, Item versionMarker)
specifier|static
name|void
name|verifyVersionCompatibility
parameter_list|(
name|String
name|tableName
parameter_list|,
name|Item
name|versionMarker
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|versionMarker
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Table {} contains no version marker"
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|E_NO_VERSION_MARKER
operator|+
literal|" Table: "
operator|+
name|tableName
argument_list|)
throw|;
block|}
else|else
block|{
specifier|final
name|int
name|version
init|=
name|extractVersionFromMarker
argument_list|(
name|versionMarker
argument_list|)
decl_stmt|;
if|if
condition|(
name|VERSION
operator|!=
name|version
condition|)
block|{
comment|// version mismatch. Unless/until there is support for
comment|// upgrading versions, treat this as an incompatible change
comment|// and fail.
throw|throw
operator|new
name|IOException
argument_list|(
name|E_INCOMPATIBLE_VERSION
operator|+
literal|" Table "
operator|+
name|tableName
operator|+
literal|" Expected version "
operator|+
name|VERSION
operator|+
literal|" actual "
operator|+
name|version
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Wait for table being active.    * @param t table to block on.    * @throws IOException IO problems    * @throws InterruptedIOException if the wait was interrupted    * @throws IllegalArgumentException if an exception was raised in the waiter    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|waitForTableActive (Table t)
specifier|private
name|void
name|waitForTableActive
parameter_list|(
name|Table
name|t
parameter_list|)
throws|throws
name|InterruptedIOException
block|{
try|try
block|{
name|t
operator|.
name|waitForActive
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting for table {} in region {} active"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"DynamoDB table '"
operator|+
name|tableName
operator|+
literal|"' is not active yet in region "
operator|+
name|region
argument_list|)
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create a table, wait for it to become active, then add the version    * marker.    * @param capacity capacity to provision    * @throws IOException on any failure.    * @throws InterruptedIOException if the wait was interrupted    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|createTable (ProvisionedThroughput capacity)
specifier|private
name|void
name|createTable
parameter_list|(
name|ProvisionedThroughput
name|capacity
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating non-existent DynamoDB table {} in region {}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
name|table
operator|=
name|dynamoDB
operator|.
name|createTable
argument_list|(
operator|new
name|CreateTableRequest
argument_list|()
operator|.
name|withTableName
argument_list|(
name|tableName
argument_list|)
operator|.
name|withKeySchema
argument_list|(
name|keySchema
argument_list|()
argument_list|)
operator|.
name|withAttributeDefinitions
argument_list|(
name|attributeDefinitions
argument_list|()
argument_list|)
operator|.
name|withProvisionedThroughput
argument_list|(
name|capacity
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Awaiting table becoming active"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ResourceInUseException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"ResourceInUseException while creating DynamoDB table {} "
operator|+
literal|"in region {}.  This may indicate that the table was "
operator|+
literal|"created by another concurrent thread or process."
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
name|waitForTableActive
argument_list|(
name|table
argument_list|)
expr_stmt|;
specifier|final
name|Item
name|marker
init|=
name|createVersionMarker
argument_list|(
name|VERSION_MARKER
argument_list|,
name|VERSION
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|putItem
argument_list|(
name|marker
argument_list|)
expr_stmt|;
block|}
comment|/**    * PUT a single item to the table.    * @param item item to put    * @return the outcome.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|putItem (Item item)
name|PutItemOutcome
name|putItem
parameter_list|(
name|Item
name|item
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Putting item {}"
argument_list|,
name|item
argument_list|)
expr_stmt|;
return|return
name|table
operator|.
name|putItem
argument_list|(
name|item
argument_list|)
return|;
block|}
comment|/**    * Provision the table with given read and write capacity units.    * Call will fail if the table is busy, or the new values match the current    * ones.    * @param readCapacity read units    * @param writeCapacity write units    * @throws IOException on a failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|provisionTable (Long readCapacity, Long writeCapacity)
name|void
name|provisionTable
parameter_list|(
name|Long
name|readCapacity
parameter_list|,
name|Long
name|writeCapacity
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ProvisionedThroughput
name|toProvision
init|=
operator|new
name|ProvisionedThroughput
argument_list|()
operator|.
name|withReadCapacityUnits
argument_list|(
name|readCapacity
argument_list|)
operator|.
name|withWriteCapacityUnits
argument_list|(
name|writeCapacity
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"ProvisionTable"
argument_list|,
name|tableName
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
specifier|final
name|ProvisionedThroughputDescription
name|p
init|=
name|table
operator|.
name|updateTable
argument_list|(
name|toProvision
argument_list|)
operator|.
name|getProvisionedThroughput
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Provision table {} in region {}: readCapacityUnits={}, "
operator|+
literal|"writeCapacityUnits={}"
argument_list|,
name|tableName
argument_list|,
name|region
argument_list|,
name|p
operator|.
name|getReadCapacityUnits
argument_list|()
argument_list|,
name|p
operator|.
name|getWriteCapacityUnits
argument_list|()
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Retries
operator|.
name|RetryTranslated
annotation|@
name|VisibleForTesting
DECL|method|provisionTableBlocking (Long readCapacity, Long writeCapacity)
name|void
name|provisionTableBlocking
parameter_list|(
name|Long
name|readCapacity
parameter_list|,
name|Long
name|writeCapacity
parameter_list|)
throws|throws
name|IOException
block|{
name|provisionTable
argument_list|(
name|readCapacity
argument_list|,
name|writeCapacity
argument_list|)
expr_stmt|;
name|waitForTableActive
argument_list|(
name|table
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getTable ()
name|Table
name|getTable
parameter_list|()
block|{
return|return
name|table
return|;
block|}
DECL|method|getRegion ()
name|String
name|getRegion
parameter_list|()
block|{
return|return
name|region
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getDynamoDB ()
name|DynamoDB
name|getDynamoDB
parameter_list|()
block|{
return|return
name|dynamoDB
return|;
block|}
comment|/**    * Validates a path object; it must be absolute, have an s3a:/// scheme    * and contain a host (bucket) component.    * @param path path to check    * @return the path passed in    */
DECL|method|checkPath (Path path)
specifier|private
name|Path
name|checkPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|path
operator|.
name|isAbsolute
argument_list|()
argument_list|,
literal|"Path %s is not absolute"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|URI
name|uri
init|=
name|path
operator|.
name|toUri
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|uri
operator|.
name|getScheme
argument_list|()
argument_list|,
literal|"Path %s missing scheme"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|uri
operator|.
name|getScheme
argument_list|()
operator|.
name|equals
argument_list|(
name|Constants
operator|.
name|FS_S3A
argument_list|)
argument_list|,
literal|"Path %s scheme must be %s"
argument_list|,
name|path
argument_list|,
name|Constants
operator|.
name|FS_S3A
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|StringUtils
operator|.
name|isEmpty
argument_list|(
name|uri
operator|.
name|getHost
argument_list|()
argument_list|)
argument_list|,
literal|"Path %s"
operator|+
literal|" is missing bucket."
argument_list|,
name|path
argument_list|)
expr_stmt|;
return|return
name|path
return|;
block|}
comment|/**    * Validates a path meta-data object.    */
DECL|method|checkPathMetadata (PathMetadata meta)
specifier|private
specifier|static
name|void
name|checkPathMetadata
parameter_list|(
name|PathMetadata
name|meta
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|meta
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|meta
operator|.
name|getFileStatus
argument_list|()
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|meta
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|getDiagnostics ()
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|getDiagnostics
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|map
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|table
operator|!=
literal|null
condition|)
block|{
name|TableDescription
name|desc
init|=
name|getTableDescription
argument_list|(
literal|true
argument_list|)
decl_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"name"
argument_list|,
name|desc
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|STATUS
argument_list|,
name|desc
operator|.
name|getTableStatus
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"ARN"
argument_list|,
name|desc
operator|.
name|getTableArn
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"size"
argument_list|,
name|desc
operator|.
name|getTableSizeBytes
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|TABLE
argument_list|,
name|desc
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|ProvisionedThroughputDescription
name|throughput
init|=
name|desc
operator|.
name|getProvisionedThroughput
argument_list|()
decl_stmt|;
name|map
operator|.
name|put
argument_list|(
name|READ_CAPACITY
argument_list|,
name|throughput
operator|.
name|getReadCapacityUnits
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|WRITE_CAPACITY
argument_list|,
name|throughput
operator|.
name|getWriteCapacityUnits
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|TABLE
argument_list|,
name|desc
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|MetadataStoreCapabilities
operator|.
name|PERSISTS_AUTHORITATIVE_BIT
argument_list|,
name|Boolean
operator|.
name|toString
argument_list|(
literal|false
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|map
operator|.
name|put
argument_list|(
literal|"name"
argument_list|,
literal|"DynamoDB Metadata Store"
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|TABLE
argument_list|,
literal|"none"
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|STATUS
argument_list|,
literal|"undefined"
argument_list|)
expr_stmt|;
block|}
name|map
operator|.
name|put
argument_list|(
literal|"description"
argument_list|,
name|DESCRIPTION
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"region"
argument_list|,
name|region
argument_list|)
expr_stmt|;
if|if
condition|(
name|dataAccessRetryPolicy
operator|!=
literal|null
condition|)
block|{
name|map
operator|.
name|put
argument_list|(
literal|"retryPolicy"
argument_list|,
name|dataAccessRetryPolicy
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|map
return|;
block|}
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|getTableDescription (boolean forceUpdate)
specifier|private
name|TableDescription
name|getTableDescription
parameter_list|(
name|boolean
name|forceUpdate
parameter_list|)
block|{
name|TableDescription
name|desc
init|=
name|table
operator|.
name|getDescription
argument_list|()
decl_stmt|;
if|if
condition|(
name|desc
operator|==
literal|null
operator|||
name|forceUpdate
condition|)
block|{
name|desc
operator|=
name|table
operator|.
name|describe
argument_list|()
expr_stmt|;
block|}
return|return
name|desc
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|updateParameters (Map<String, String> parameters)
specifier|public
name|void
name|updateParameters
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|table
argument_list|,
literal|"Not initialized"
argument_list|)
expr_stmt|;
name|TableDescription
name|desc
init|=
name|getTableDescription
argument_list|(
literal|true
argument_list|)
decl_stmt|;
name|ProvisionedThroughputDescription
name|current
init|=
name|desc
operator|.
name|getProvisionedThroughput
argument_list|()
decl_stmt|;
name|long
name|currentRead
init|=
name|current
operator|.
name|getReadCapacityUnits
argument_list|()
decl_stmt|;
name|long
name|newRead
init|=
name|getLongParam
argument_list|(
name|parameters
argument_list|,
name|S3GUARD_DDB_TABLE_CAPACITY_READ_KEY
argument_list|,
name|currentRead
argument_list|)
decl_stmt|;
name|long
name|currentWrite
init|=
name|current
operator|.
name|getWriteCapacityUnits
argument_list|()
decl_stmt|;
name|long
name|newWrite
init|=
name|getLongParam
argument_list|(
name|parameters
argument_list|,
name|S3GUARD_DDB_TABLE_CAPACITY_WRITE_KEY
argument_list|,
name|currentWrite
argument_list|)
decl_stmt|;
if|if
condition|(
name|newRead
operator|!=
name|currentRead
operator|||
name|newWrite
operator|!=
name|currentWrite
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Current table capacity is read: {}, write: {}"
argument_list|,
name|currentRead
argument_list|,
name|currentWrite
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Changing capacity of table to read: {}, write: {}"
argument_list|,
name|newRead
argument_list|,
name|newWrite
argument_list|)
expr_stmt|;
name|provisionTableBlocking
argument_list|(
name|newRead
argument_list|,
name|newWrite
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Table capacity unchanged at read: {}, write: {}"
argument_list|,
name|newRead
argument_list|,
name|newWrite
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|getLongParam (Map<String, String> parameters, String key, long defVal)
specifier|private
name|long
name|getLongParam
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|parameters
parameter_list|,
name|String
name|key
parameter_list|,
name|long
name|defVal
parameter_list|)
block|{
name|String
name|k
init|=
name|parameters
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|k
operator|!=
literal|null
condition|)
block|{
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|k
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|defVal
return|;
block|}
block|}
comment|/**    * Callback from {@link Invoker} when an operation is retried.    * @param text text of the operation    * @param ex exception    * @param attempts number of attempts    * @param idempotent is the method idempotent    */
DECL|method|retryEvent ( String text, IOException ex, int attempts, boolean idempotent)
name|void
name|retryEvent
parameter_list|(
name|String
name|text
parameter_list|,
name|IOException
name|ex
parameter_list|,
name|int
name|attempts
parameter_list|,
name|boolean
name|idempotent
parameter_list|)
block|{
if|if
condition|(
name|S3AUtils
operator|.
name|isThrottleException
argument_list|(
name|ex
argument_list|)
condition|)
block|{
comment|// throttled
if|if
condition|(
name|instrumentation
operator|!=
literal|null
condition|)
block|{
name|instrumentation
operator|.
name|throttled
argument_list|()
expr_stmt|;
block|}
name|int
name|eventCount
init|=
name|throttleEventCount
operator|.
name|addAndGet
argument_list|(
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|attempts
operator|==
literal|1
operator|&&
name|eventCount
operator|<
name|THROTTLE_EVENT_LOG_LIMIT
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"DynamoDB IO limits reached in {};"
operator|+
literal|" consider increasing capacity: {}"
argument_list|,
name|text
argument_list|,
name|ex
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Throttled"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// user has been warned already, log at debug only.
name|LOG
operator|.
name|debug
argument_list|(
literal|"DynamoDB IO limits reached in {};"
operator|+
literal|" consider increasing capacity: {}"
argument_list|,
name|text
argument_list|,
name|ex
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|attempts
operator|==
literal|1
condition|)
block|{
comment|// not throttled. Log on the first attempt only
name|LOG
operator|.
name|info
argument_list|(
literal|"Retrying {}: {}"
argument_list|,
name|text
argument_list|,
name|ex
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Retrying {}"
argument_list|,
name|text
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|instrumentation
operator|!=
literal|null
condition|)
block|{
comment|// note a retry
name|instrumentation
operator|.
name|retrying
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|owner
operator|!=
literal|null
condition|)
block|{
name|owner
operator|.
name|metastoreOperationRetried
argument_list|(
name|ex
argument_list|,
name|attempts
argument_list|,
name|idempotent
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

