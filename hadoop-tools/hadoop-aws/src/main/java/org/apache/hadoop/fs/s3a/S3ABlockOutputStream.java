begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonClientException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressEvent
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressEventType
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CompleteMultipartUploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PartETag
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Futures
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListenableFuture
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListeningExecutorService
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|MoreExecutors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicies
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Statistic
operator|.
name|*
import|;
end_import

begin_comment
comment|/**  * Upload files/parts directly via different buffering mechanisms:  * including memory and disk.  *  * If the stream is closed and no update has started, then the upload  * is instead done as a single PUT operation.  *  * Unstable: statistics and error handling might evolve.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|class|S3ABlockOutputStream
class|class
name|S3ABlockOutputStream
extends|extends
name|OutputStream
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|S3ABlockOutputStream
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** Owner FileSystem. */
DECL|field|fs
specifier|private
specifier|final
name|S3AFileSystem
name|fs
decl_stmt|;
comment|/** Object being uploaded. */
DECL|field|key
specifier|private
specifier|final
name|String
name|key
decl_stmt|;
comment|/** Size of all blocks. */
DECL|field|blockSize
specifier|private
specifier|final
name|int
name|blockSize
decl_stmt|;
comment|/** Callback for progress. */
DECL|field|progressListener
specifier|private
specifier|final
name|ProgressListener
name|progressListener
decl_stmt|;
DECL|field|executorService
specifier|private
specifier|final
name|ListeningExecutorService
name|executorService
decl_stmt|;
comment|/**    * Retry policy for multipart commits; not all AWS SDK versions retry that.    */
DECL|field|retryPolicy
specifier|private
specifier|final
name|RetryPolicy
name|retryPolicy
init|=
name|RetryPolicies
operator|.
name|retryUpToMaximumCountWithProportionalSleep
argument_list|(
literal|5
argument_list|,
literal|2000
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
comment|/**    * Factory for blocks.    */
DECL|field|blockFactory
specifier|private
specifier|final
name|S3ADataBlocks
operator|.
name|BlockFactory
name|blockFactory
decl_stmt|;
comment|/** Preallocated byte buffer for writing single characters. */
DECL|field|singleCharWrite
specifier|private
specifier|final
name|byte
index|[]
name|singleCharWrite
init|=
operator|new
name|byte
index|[
literal|1
index|]
decl_stmt|;
comment|/** Multipart upload details; null means none started. */
DECL|field|multiPartUpload
specifier|private
name|MultiPartUpload
name|multiPartUpload
decl_stmt|;
comment|/** Closed flag. */
DECL|field|closed
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/** Current data block. Null means none currently active */
DECL|field|activeBlock
specifier|private
name|S3ADataBlocks
operator|.
name|DataBlock
name|activeBlock
decl_stmt|;
comment|/** Count of blocks uploaded. */
DECL|field|blockCount
specifier|private
name|long
name|blockCount
init|=
literal|0
decl_stmt|;
comment|/** Statistics to build up. */
DECL|field|statistics
specifier|private
specifier|final
name|S3AInstrumentation
operator|.
name|OutputStreamStatistics
name|statistics
decl_stmt|;
comment|/**    * Write operation helper; encapsulation of the filesystem operations.    */
DECL|field|writeOperationHelper
specifier|private
specifier|final
name|S3AFileSystem
operator|.
name|WriteOperationHelper
name|writeOperationHelper
decl_stmt|;
comment|/**    * An S3A output stream which uploads partitions in a separate pool of    * threads; different {@link S3ADataBlocks.BlockFactory}    * instances can control where data is buffered.    *    * @param fs S3AFilesystem    * @param key S3 object to work on.    * @param executorService the executor service to use to schedule work    * @param progress report progress in order to prevent timeouts. If    * this object implements {@code ProgressListener} then it will be    * directly wired up to the AWS client, so receive detailed progress    * information.    * @param blockSize size of a single block.    * @param blockFactory factory for creating stream destinations    * @param statistics stats for this stream    * @param writeOperationHelper state of the write operation.    * @throws IOException on any problem    */
DECL|method|S3ABlockOutputStream (S3AFileSystem fs, String key, ExecutorService executorService, Progressable progress, long blockSize, S3ADataBlocks.BlockFactory blockFactory, S3AInstrumentation.OutputStreamStatistics statistics, S3AFileSystem.WriteOperationHelper writeOperationHelper)
name|S3ABlockOutputStream
parameter_list|(
name|S3AFileSystem
name|fs
parameter_list|,
name|String
name|key
parameter_list|,
name|ExecutorService
name|executorService
parameter_list|,
name|Progressable
name|progress
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|S3ADataBlocks
operator|.
name|BlockFactory
name|blockFactory
parameter_list|,
name|S3AInstrumentation
operator|.
name|OutputStreamStatistics
name|statistics
parameter_list|,
name|S3AFileSystem
operator|.
name|WriteOperationHelper
name|writeOperationHelper
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|key
operator|=
name|key
expr_stmt|;
name|this
operator|.
name|blockFactory
operator|=
name|blockFactory
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
operator|(
name|int
operator|)
name|blockSize
expr_stmt|;
name|this
operator|.
name|statistics
operator|=
name|statistics
expr_stmt|;
name|this
operator|.
name|writeOperationHelper
operator|=
name|writeOperationHelper
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|blockSize
operator|>=
name|Constants
operator|.
name|MULTIPART_MIN_SIZE
argument_list|,
literal|"Block size is too small: %d"
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
name|this
operator|.
name|executorService
operator|=
name|MoreExecutors
operator|.
name|listeningDecorator
argument_list|(
name|executorService
argument_list|)
expr_stmt|;
name|this
operator|.
name|multiPartUpload
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|progressListener
operator|=
operator|(
name|progress
operator|instanceof
name|ProgressListener
operator|)
condition|?
operator|(
name|ProgressListener
operator|)
name|progress
else|:
operator|new
name|ProgressableListener
argument_list|(
name|progress
argument_list|)
expr_stmt|;
comment|// create that first block. This guarantees that an open + close sequence
comment|// writes a 0-byte entry.
name|createBlockIfNeeded
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initialized S3ABlockOutputStream for {}"
operator|+
literal|" output to {}"
argument_list|,
name|writeOperationHelper
argument_list|,
name|activeBlock
argument_list|)
expr_stmt|;
block|}
comment|/**    * Demand create a destination block.    * @return the active block; null if there isn't one.    * @throws IOException on any failure to create    */
DECL|method|createBlockIfNeeded ()
specifier|private
specifier|synchronized
name|S3ADataBlocks
operator|.
name|DataBlock
name|createBlockIfNeeded
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|activeBlock
operator|==
literal|null
condition|)
block|{
name|blockCount
operator|++
expr_stmt|;
if|if
condition|(
name|blockCount
operator|>=
name|Constants
operator|.
name|MAX_MULTIPART_COUNT
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Number of partitions in stream exceeds limit for S3: "
operator|+
name|Constants
operator|.
name|MAX_MULTIPART_COUNT
operator|+
literal|" write may fail."
argument_list|)
expr_stmt|;
block|}
name|activeBlock
operator|=
name|blockFactory
operator|.
name|create
argument_list|(
name|blockCount
argument_list|,
name|this
operator|.
name|blockSize
argument_list|,
name|statistics
argument_list|)
expr_stmt|;
block|}
return|return
name|activeBlock
return|;
block|}
comment|/**    * Synchronized accessor to the active block.    * @return the active block; null if there isn't one.    */
DECL|method|getActiveBlock ()
specifier|private
specifier|synchronized
name|S3ADataBlocks
operator|.
name|DataBlock
name|getActiveBlock
parameter_list|()
block|{
return|return
name|activeBlock
return|;
block|}
comment|/**    * Predicate to query whether or not there is an active block.    * @return true if there is an active block.    */
DECL|method|hasActiveBlock ()
specifier|private
specifier|synchronized
name|boolean
name|hasActiveBlock
parameter_list|()
block|{
return|return
name|activeBlock
operator|!=
literal|null
return|;
block|}
comment|/**    * Clear the active block.    */
DECL|method|clearActiveBlock ()
specifier|private
name|void
name|clearActiveBlock
parameter_list|()
block|{
if|if
condition|(
name|activeBlock
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Clearing active block"
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|this
init|)
block|{
name|activeBlock
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Check for the filesystem being open.    * @throws IOException if the filesystem is closed.    */
DECL|method|checkOpen ()
name|void
name|checkOpen
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Filesystem "
operator|+
name|writeOperationHelper
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
block|}
comment|/**    * The flush operation does not trigger an upload; that awaits    * the next block being full. What it does do is call {@code flush() }    * on the current block, leaving it to choose how to react.    * @throws IOException Any IO problem.    */
annotation|@
name|Override
DECL|method|flush ()
specifier|public
specifier|synchronized
name|void
name|flush
parameter_list|()
throws|throws
name|IOException
block|{
name|checkOpen
argument_list|()
expr_stmt|;
name|S3ADataBlocks
operator|.
name|DataBlock
name|dataBlock
init|=
name|getActiveBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|dataBlock
operator|!=
literal|null
condition|)
block|{
name|dataBlock
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Writes a byte to the destination. If this causes the buffer to reach    * its limit, the actual upload is submitted to the threadpool.    * @param b the int of which the lowest byte is written    * @throws IOException on any problem    */
annotation|@
name|Override
DECL|method|write (int b)
specifier|public
specifier|synchronized
name|void
name|write
parameter_list|(
name|int
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|singleCharWrite
index|[
literal|0
index|]
operator|=
operator|(
name|byte
operator|)
name|b
expr_stmt|;
name|write
argument_list|(
name|singleCharWrite
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Writes a range of bytes from to the memory buffer. If this causes the    * buffer to reach its limit, the actual upload is submitted to the    * threadpool and the remainder of the array is written to memory    * (recursively).    * @param source byte array containing    * @param offset offset in array where to start    * @param len number of bytes to be written    * @throws IOException on any problem    */
annotation|@
name|Override
DECL|method|write (byte[] source, int offset, int len)
specifier|public
specifier|synchronized
name|void
name|write
parameter_list|(
name|byte
index|[]
name|source
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|len
parameter_list|)
throws|throws
name|IOException
block|{
name|S3ADataBlocks
operator|.
name|validateWriteArgs
argument_list|(
name|source
argument_list|,
name|offset
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|checkOpen
argument_list|()
expr_stmt|;
if|if
condition|(
name|len
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
init|=
name|createBlockIfNeeded
argument_list|()
decl_stmt|;
name|int
name|written
init|=
name|block
operator|.
name|write
argument_list|(
name|source
argument_list|,
name|offset
argument_list|,
name|len
argument_list|)
decl_stmt|;
name|int
name|remainingCapacity
init|=
name|block
operator|.
name|remainingCapacity
argument_list|()
decl_stmt|;
if|if
condition|(
name|written
operator|<
name|len
condition|)
block|{
comment|// not everything was written âthe block has run out
comment|// of capacity
comment|// Trigger an upload then process the remainder.
name|LOG
operator|.
name|debug
argument_list|(
literal|"writing more data than block has capacity -triggering upload"
argument_list|)
expr_stmt|;
name|uploadCurrentBlock
argument_list|()
expr_stmt|;
comment|// tail recursion is mildly expensive, but given buffer sizes must be MB.
comment|// it's unlikely to recurse very deeply.
name|this
operator|.
name|write
argument_list|(
name|source
argument_list|,
name|offset
operator|+
name|written
argument_list|,
name|len
operator|-
name|written
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|remainingCapacity
operator|==
literal|0
condition|)
block|{
comment|// the whole buffer is done, trigger an upload
name|uploadCurrentBlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Start an asynchronous upload of the current block.    * @throws IOException Problems opening the destination for upload    * or initializing the upload.    */
DECL|method|uploadCurrentBlock ()
specifier|private
specifier|synchronized
name|void
name|uploadCurrentBlock
parameter_list|()
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkState
argument_list|(
name|hasActiveBlock
argument_list|()
argument_list|,
literal|"No active block"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Writing block # {}"
argument_list|,
name|blockCount
argument_list|)
expr_stmt|;
if|if
condition|(
name|multiPartUpload
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initiating Multipart upload"
argument_list|)
expr_stmt|;
name|multiPartUpload
operator|=
operator|new
name|MultiPartUpload
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|multiPartUpload
operator|.
name|uploadBlockAsync
argument_list|(
name|getActiveBlock
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// set the block to null, so the next write will create a new block.
name|clearActiveBlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Close the stream.    *    * This will not return until the upload is complete    * or the attempt to perform the upload has failed.    * Exceptions raised in this method are indicative that the write has    * failed and data is at risk of being lost.    * @throws IOException on any failure.    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
comment|// already closed
name|LOG
operator|.
name|debug
argument_list|(
literal|"Ignoring close() as stream is already closed"
argument_list|)
expr_stmt|;
return|return;
block|}
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
init|=
name|getActiveBlock
argument_list|()
decl_stmt|;
name|boolean
name|hasBlock
init|=
name|hasActiveBlock
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"{}: Closing block #{}: current block= {}"
argument_list|,
name|this
argument_list|,
name|blockCount
argument_list|,
name|hasBlock
condition|?
name|block
else|:
literal|"(none)"
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|multiPartUpload
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|hasBlock
condition|)
block|{
comment|// no uploads of data have taken place, put the single block up.
comment|// This must happen even if there is no data, so that 0 byte files
comment|// are created.
name|putObject
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// there has already been at least one block scheduled for upload;
comment|// put up the current then wait
if|if
condition|(
name|hasBlock
operator|&&
name|block
operator|.
name|hasData
argument_list|()
condition|)
block|{
comment|//send last part
name|uploadCurrentBlock
argument_list|()
expr_stmt|;
block|}
comment|// wait for the partial uploads to finish
specifier|final
name|List
argument_list|<
name|PartETag
argument_list|>
name|partETags
init|=
name|multiPartUpload
operator|.
name|waitForAllPartUploads
argument_list|()
decl_stmt|;
comment|// then complete the operation
name|multiPartUpload
operator|.
name|complete
argument_list|(
name|partETags
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Upload complete for {}"
argument_list|,
name|writeOperationHelper
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|writeOperationHelper
operator|.
name|writeFailed
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
finally|finally
block|{
name|closeAll
argument_list|(
name|LOG
argument_list|,
name|block
argument_list|,
name|blockFactory
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Statistics: {}"
argument_list|,
name|statistics
argument_list|)
expr_stmt|;
name|closeAll
argument_list|(
name|LOG
argument_list|,
name|statistics
argument_list|)
expr_stmt|;
name|clearActiveBlock
argument_list|()
expr_stmt|;
block|}
comment|// All end of write operations, including deleting fake parent directories
name|writeOperationHelper
operator|.
name|writeSuccessful
argument_list|()
expr_stmt|;
block|}
comment|/**    * Upload the current block as a single PUT request; if the buffer    * is empty a 0-byte PUT will be invoked, as it is needed to create an    * entry at the far end.    * @throws IOException any problem.    */
DECL|method|putObject ()
specifier|private
name|void
name|putObject
parameter_list|()
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Executing regular upload for {}"
argument_list|,
name|writeOperationHelper
argument_list|)
expr_stmt|;
specifier|final
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
init|=
name|getActiveBlock
argument_list|()
decl_stmt|;
name|int
name|size
init|=
name|block
operator|.
name|dataSize
argument_list|()
decl_stmt|;
specifier|final
name|S3ADataBlocks
operator|.
name|BlockUploadData
name|uploadData
init|=
name|block
operator|.
name|startUpload
argument_list|()
decl_stmt|;
specifier|final
name|PutObjectRequest
name|putObjectRequest
init|=
name|uploadData
operator|.
name|hasFile
argument_list|()
condition|?
name|writeOperationHelper
operator|.
name|newPutRequest
argument_list|(
name|uploadData
operator|.
name|getFile
argument_list|()
argument_list|)
else|:
name|writeOperationHelper
operator|.
name|newPutRequest
argument_list|(
name|uploadData
operator|.
name|getUploadStream
argument_list|()
argument_list|,
name|size
argument_list|)
decl_stmt|;
name|fs
operator|.
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|long
name|transferQueueTime
init|=
name|now
argument_list|()
decl_stmt|;
name|BlockUploadProgress
name|callback
init|=
operator|new
name|BlockUploadProgress
argument_list|(
name|block
argument_list|,
name|progressListener
argument_list|,
name|transferQueueTime
argument_list|)
decl_stmt|;
name|putObjectRequest
operator|.
name|setGeneralProgressListener
argument_list|(
name|callback
argument_list|)
expr_stmt|;
name|statistics
operator|.
name|blockUploadQueued
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|ListenableFuture
argument_list|<
name|PutObjectResult
argument_list|>
name|putObjectResult
init|=
name|executorService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|PutObjectResult
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|PutObjectResult
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|PutObjectResult
name|result
decl_stmt|;
try|try
block|{
comment|// the putObject call automatically closes the input
comment|// stream afterwards.
name|result
operator|=
name|writeOperationHelper
operator|.
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeAll
argument_list|(
name|LOG
argument_list|,
name|uploadData
argument_list|,
name|block
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
block|}
argument_list|)
decl_stmt|;
name|clearActiveBlock
argument_list|()
expr_stmt|;
comment|//wait for completion
try|try
block|{
name|putObjectResult
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted object upload"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|ee
parameter_list|)
block|{
throw|throw
name|extractException
argument_list|(
literal|"regular upload"
argument_list|,
name|key
argument_list|,
name|ee
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"S3ABlockOutputStream{"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|writeOperationHelper
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", blockSize="
argument_list|)
operator|.
name|append
argument_list|(
name|blockSize
argument_list|)
expr_stmt|;
comment|// unsynced access; risks consistency in exchange for no risk of deadlock.
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
init|=
name|activeBlock
decl_stmt|;
if|if
condition|(
name|block
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", activeBlock="
argument_list|)
operator|.
name|append
argument_list|(
name|block
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
DECL|method|incrementWriteOperations ()
specifier|private
name|void
name|incrementWriteOperations
parameter_list|()
block|{
name|fs
operator|.
name|incrementWriteOperations
argument_list|()
expr_stmt|;
block|}
comment|/**    * Current time in milliseconds.    * @return time    */
DECL|method|now ()
specifier|private
name|long
name|now
parameter_list|()
block|{
return|return
name|System
operator|.
name|currentTimeMillis
argument_list|()
return|;
block|}
comment|/**    * Get the statistics for this stream.    * @return stream statistics    */
DECL|method|getStatistics ()
name|S3AInstrumentation
operator|.
name|OutputStreamStatistics
name|getStatistics
parameter_list|()
block|{
return|return
name|statistics
return|;
block|}
comment|/**    * Multiple partition upload.    */
DECL|class|MultiPartUpload
specifier|private
class|class
name|MultiPartUpload
block|{
DECL|field|uploadId
specifier|private
specifier|final
name|String
name|uploadId
decl_stmt|;
DECL|field|partETagsFutures
specifier|private
specifier|final
name|List
argument_list|<
name|ListenableFuture
argument_list|<
name|PartETag
argument_list|>
argument_list|>
name|partETagsFutures
decl_stmt|;
DECL|method|MultiPartUpload ()
name|MultiPartUpload
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|uploadId
operator|=
name|writeOperationHelper
operator|.
name|initiateMultiPartUpload
argument_list|()
expr_stmt|;
name|this
operator|.
name|partETagsFutures
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|2
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initiated multi-part upload for {} with "
operator|+
literal|"id '{}'"
argument_list|,
name|writeOperationHelper
argument_list|,
name|uploadId
argument_list|)
expr_stmt|;
block|}
comment|/**      * Upload a block of data.      * This will take the block      * @param block block to upload      * @throws IOException upload failure      */
DECL|method|uploadBlockAsync (final S3ADataBlocks.DataBlock block)
specifier|private
name|void
name|uploadBlockAsync
parameter_list|(
specifier|final
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Queueing upload of {}"
argument_list|,
name|block
argument_list|)
expr_stmt|;
specifier|final
name|int
name|size
init|=
name|block
operator|.
name|dataSize
argument_list|()
decl_stmt|;
specifier|final
name|S3ADataBlocks
operator|.
name|BlockUploadData
name|uploadData
init|=
name|block
operator|.
name|startUpload
argument_list|()
decl_stmt|;
specifier|final
name|int
name|currentPartNumber
init|=
name|partETagsFutures
operator|.
name|size
argument_list|()
operator|+
literal|1
decl_stmt|;
specifier|final
name|UploadPartRequest
name|request
init|=
name|writeOperationHelper
operator|.
name|newUploadPartRequest
argument_list|(
name|uploadId
argument_list|,
name|currentPartNumber
argument_list|,
name|size
argument_list|,
name|uploadData
operator|.
name|getUploadStream
argument_list|()
argument_list|,
name|uploadData
operator|.
name|getFile
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|transferQueueTime
init|=
name|now
argument_list|()
decl_stmt|;
name|BlockUploadProgress
name|callback
init|=
operator|new
name|BlockUploadProgress
argument_list|(
name|block
argument_list|,
name|progressListener
argument_list|,
name|transferQueueTime
argument_list|)
decl_stmt|;
name|request
operator|.
name|setGeneralProgressListener
argument_list|(
name|callback
argument_list|)
expr_stmt|;
name|statistics
operator|.
name|blockUploadQueued
argument_list|(
name|block
operator|.
name|dataSize
argument_list|()
argument_list|)
expr_stmt|;
name|ListenableFuture
argument_list|<
name|PartETag
argument_list|>
name|partETagFuture
init|=
name|executorService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|PartETag
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|PartETag
name|call
parameter_list|()
throws|throws
name|Exception
block|{
comment|// this is the queued upload operation
name|LOG
operator|.
name|debug
argument_list|(
literal|"Uploading part {} for id '{}'"
argument_list|,
name|currentPartNumber
argument_list|,
name|uploadId
argument_list|)
expr_stmt|;
comment|// do the upload
name|PartETag
name|partETag
decl_stmt|;
try|try
block|{
name|partETag
operator|=
name|fs
operator|.
name|uploadPart
argument_list|(
name|request
argument_list|)
operator|.
name|getPartETag
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Completed upload of {} to part {}"
argument_list|,
name|block
argument_list|,
name|partETag
operator|.
name|getETag
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Stream statistics of {}"
argument_list|,
name|statistics
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// close the stream and block
name|closeAll
argument_list|(
name|LOG
argument_list|,
name|uploadData
argument_list|,
name|block
argument_list|)
expr_stmt|;
block|}
return|return
name|partETag
return|;
block|}
block|}
argument_list|)
decl_stmt|;
name|partETagsFutures
operator|.
name|add
argument_list|(
name|partETagFuture
argument_list|)
expr_stmt|;
block|}
comment|/**      * Block awaiting all outstanding uploads to complete.      * @return list of results      * @throws IOException IO Problems      */
DECL|method|waitForAllPartUploads ()
specifier|private
name|List
argument_list|<
name|PartETag
argument_list|>
name|waitForAllPartUploads
parameter_list|()
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Waiting for {} uploads to complete"
argument_list|,
name|partETagsFutures
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
return|return
name|Futures
operator|.
name|allAsList
argument_list|(
name|partETagsFutures
argument_list|)
operator|.
name|get
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted partUpload"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|ee
parameter_list|)
block|{
comment|//there is no way of recovering so abort
comment|//cancel all partUploads
name|LOG
operator|.
name|debug
argument_list|(
literal|"While waiting for upload completion"
argument_list|,
name|ee
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cancelling futures"
argument_list|)
expr_stmt|;
for|for
control|(
name|ListenableFuture
argument_list|<
name|PartETag
argument_list|>
name|future
range|:
name|partETagsFutures
control|)
block|{
name|future
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
comment|//abort multipartupload
name|this
operator|.
name|abort
argument_list|()
expr_stmt|;
throw|throw
name|extractException
argument_list|(
literal|"Multi-part upload with id '"
operator|+
name|uploadId
operator|+
literal|"' to "
operator|+
name|key
argument_list|,
name|key
argument_list|,
name|ee
argument_list|)
throw|;
block|}
block|}
comment|/**      * This completes a multipart upload.      * Sometimes it fails; here retries are handled to avoid losing all data      * on a transient failure.      * @param partETags list of partial uploads      * @throws IOException on any problem      */
DECL|method|complete (List<PartETag> partETags)
specifier|private
name|CompleteMultipartUploadResult
name|complete
parameter_list|(
name|List
argument_list|<
name|PartETag
argument_list|>
name|partETags
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|retryCount
init|=
literal|0
decl_stmt|;
name|AmazonClientException
name|lastException
decl_stmt|;
name|String
name|operation
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Completing multi-part upload for key '%s',"
operator|+
literal|" id '%s' with %s partitions "
argument_list|,
name|key
argument_list|,
name|uploadId
argument_list|,
name|partETags
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
do|do
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|operation
argument_list|)
expr_stmt|;
return|return
name|writeOperationHelper
operator|.
name|completeMultipartUpload
argument_list|(
name|uploadId
argument_list|,
name|partETags
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|lastException
operator|=
name|e
expr_stmt|;
name|statistics
operator|.
name|exceptionInMultipartComplete
argument_list|()
expr_stmt|;
block|}
block|}
do|while
condition|(
name|shouldRetry
argument_list|(
name|operation
argument_list|,
name|lastException
argument_list|,
name|retryCount
operator|++
argument_list|)
condition|)
do|;
comment|// this point is only reached if the operation failed more than
comment|// the allowed retry count
throw|throw
name|translateException
argument_list|(
name|operation
argument_list|,
name|key
argument_list|,
name|lastException
argument_list|)
throw|;
block|}
comment|/**      * Abort a multi-part upload. Retries are attempted on failures.      * IOExceptions are caught; this is expected to be run as a cleanup process.      */
DECL|method|abort ()
specifier|public
name|void
name|abort
parameter_list|()
block|{
name|int
name|retryCount
init|=
literal|0
decl_stmt|;
name|AmazonClientException
name|lastException
decl_stmt|;
name|fs
operator|.
name|incrementStatistic
argument_list|(
name|OBJECT_MULTIPART_UPLOAD_ABORTED
argument_list|)
expr_stmt|;
name|String
name|operation
init|=
name|String
operator|.
name|format
argument_list|(
literal|"Aborting multi-part upload for '%s', id '%s"
argument_list|,
name|writeOperationHelper
argument_list|,
name|uploadId
argument_list|)
decl_stmt|;
do|do
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|operation
argument_list|)
expr_stmt|;
name|writeOperationHelper
operator|.
name|abortMultipartUpload
argument_list|(
name|uploadId
argument_list|)
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|lastException
operator|=
name|e
expr_stmt|;
name|statistics
operator|.
name|exceptionInMultipartAbort
argument_list|()
expr_stmt|;
block|}
block|}
do|while
condition|(
name|shouldRetry
argument_list|(
name|operation
argument_list|,
name|lastException
argument_list|,
name|retryCount
operator|++
argument_list|)
condition|)
do|;
comment|// this point is only reached if the operation failed more than
comment|// the allowed retry count
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to abort multipart upload, you may need to purge  "
operator|+
literal|"uploaded parts"
argument_list|,
name|lastException
argument_list|)
expr_stmt|;
block|}
comment|/**      * Predicate to determine whether a failed operation should      * be attempted again.      * If a retry is advised, the exception is automatically logged and      * the filesystem statistic {@link Statistic#IGNORED_ERRORS} incremented.      * The method then sleeps for the sleep time suggested by the sleep policy;      * if the sleep is interrupted then {@code Thread.interrupted()} is set      * to indicate the thread was interrupted; then false is returned.      *      * @param operation operation for log message      * @param e exception raised.      * @param retryCount  number of retries already attempted      * @return true if another attempt should be made      */
DECL|method|shouldRetry (String operation, AmazonClientException e, int retryCount)
specifier|private
name|boolean
name|shouldRetry
parameter_list|(
name|String
name|operation
parameter_list|,
name|AmazonClientException
name|e
parameter_list|,
name|int
name|retryCount
parameter_list|)
block|{
try|try
block|{
name|RetryPolicy
operator|.
name|RetryAction
name|retryAction
init|=
name|retryPolicy
operator|.
name|shouldRetry
argument_list|(
name|e
argument_list|,
name|retryCount
argument_list|,
literal|0
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|boolean
name|retry
init|=
name|retryAction
operator|==
name|RetryPolicy
operator|.
name|RetryAction
operator|.
name|RETRY
decl_stmt|;
if|if
condition|(
name|retry
condition|)
block|{
name|fs
operator|.
name|incrementStatistic
argument_list|(
name|IGNORED_ERRORS
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Retrying {} after exception "
argument_list|,
name|operation
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|retryAction
operator|.
name|delayMillis
argument_list|)
expr_stmt|;
block|}
return|return
name|retry
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ex
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignored
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
block|}
comment|/**    * The upload progress listener registered for events returned    * during the upload of a single block.    * It updates statistics and handles the end of the upload.    * Transfer failures are logged at WARN.    */
DECL|class|BlockUploadProgress
specifier|private
specifier|final
class|class
name|BlockUploadProgress
implements|implements
name|ProgressListener
block|{
DECL|field|block
specifier|private
specifier|final
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
decl_stmt|;
DECL|field|nextListener
specifier|private
specifier|final
name|ProgressListener
name|nextListener
decl_stmt|;
DECL|field|transferQueueTime
specifier|private
specifier|final
name|long
name|transferQueueTime
decl_stmt|;
DECL|field|transferStartTime
specifier|private
name|long
name|transferStartTime
decl_stmt|;
comment|/**      * Track the progress of a single block upload.      * @param block block to monitor      * @param nextListener optional next progress listener      * @param transferQueueTime time the block was transferred      * into the queue      */
DECL|method|BlockUploadProgress (S3ADataBlocks.DataBlock block, ProgressListener nextListener, long transferQueueTime)
specifier|private
name|BlockUploadProgress
parameter_list|(
name|S3ADataBlocks
operator|.
name|DataBlock
name|block
parameter_list|,
name|ProgressListener
name|nextListener
parameter_list|,
name|long
name|transferQueueTime
parameter_list|)
block|{
name|this
operator|.
name|block
operator|=
name|block
expr_stmt|;
name|this
operator|.
name|transferQueueTime
operator|=
name|transferQueueTime
expr_stmt|;
name|this
operator|.
name|nextListener
operator|=
name|nextListener
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|progressChanged (ProgressEvent progressEvent)
specifier|public
name|void
name|progressChanged
parameter_list|(
name|ProgressEvent
name|progressEvent
parameter_list|)
block|{
name|ProgressEventType
name|eventType
init|=
name|progressEvent
operator|.
name|getEventType
argument_list|()
decl_stmt|;
name|long
name|bytesTransferred
init|=
name|progressEvent
operator|.
name|getBytesTransferred
argument_list|()
decl_stmt|;
name|int
name|size
init|=
name|block
operator|.
name|dataSize
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|eventType
condition|)
block|{
case|case
name|REQUEST_BYTE_TRANSFER_EVENT
case|:
comment|// bytes uploaded
name|statistics
operator|.
name|bytesTransferred
argument_list|(
name|bytesTransferred
argument_list|)
expr_stmt|;
break|break;
case|case
name|TRANSFER_PART_STARTED_EVENT
case|:
name|transferStartTime
operator|=
name|now
argument_list|()
expr_stmt|;
name|statistics
operator|.
name|blockUploadStarted
argument_list|(
name|transferStartTime
operator|-
name|transferQueueTime
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
break|break;
case|case
name|TRANSFER_PART_COMPLETED_EVENT
case|:
name|statistics
operator|.
name|blockUploadCompleted
argument_list|(
name|now
argument_list|()
operator|-
name|transferStartTime
argument_list|,
name|size
argument_list|)
expr_stmt|;
break|break;
case|case
name|TRANSFER_PART_FAILED_EVENT
case|:
name|statistics
operator|.
name|blockUploadFailed
argument_list|(
name|now
argument_list|()
operator|-
name|transferStartTime
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Transfer failure of block {}"
argument_list|,
name|block
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// nothing
block|}
if|if
condition|(
name|nextListener
operator|!=
literal|null
condition|)
block|{
name|nextListener
operator|.
name|progressChanged
argument_list|(
name|progressEvent
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Bridge from AWS {@code ProgressListener} to Hadoop {@link Progressable}.    */
DECL|class|ProgressableListener
specifier|private
specifier|static
class|class
name|ProgressableListener
implements|implements
name|ProgressListener
block|{
DECL|field|progress
specifier|private
specifier|final
name|Progressable
name|progress
decl_stmt|;
DECL|method|ProgressableListener (Progressable progress)
specifier|public
name|ProgressableListener
parameter_list|(
name|Progressable
name|progress
parameter_list|)
block|{
name|this
operator|.
name|progress
operator|=
name|progress
expr_stmt|;
block|}
DECL|method|progressChanged (ProgressEvent progressEvent)
specifier|public
name|void
name|progressChanged
parameter_list|(
name|ProgressEvent
name|progressEvent
parameter_list|)
block|{
if|if
condition|(
name|progress
operator|!=
literal|null
condition|)
block|{
name|progress
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

