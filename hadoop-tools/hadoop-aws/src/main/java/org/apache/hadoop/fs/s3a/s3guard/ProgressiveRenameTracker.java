begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a.s3guard
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3ObjectAttributes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|StoreContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DurationInfo
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|checkArgument
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|S3Guard
operator|.
name|addMoveAncestors
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|S3Guard
operator|.
name|addMoveDir
import|;
end_import

begin_comment
comment|/**  * This rename tracker progressively updates the metadata store  * as it proceeds, during the parallelized copy operation.  *<p>  * Algorithm  *<ol>  *<li>  *     As {@code RenameTracker.fileCopied()} callbacks  *     are raised, the metastore is updated with the new file entry.  *</li>  *<li>  *     Including parent entries, as appropriate.  *</li>  *<li>  *     All directories which have been created are tracked locally,  *     to avoid needing to read the store; this is a thread-safe structure.  *</li>  *<li>  *    The actual update is performed out of any synchronized block.  *</li>  *<li>  *     When deletes are executed, the store is also updated.  *</li>  *<li>  *     And at the completion of a successful rename, the source directory  *     is also removed.  *</li>  *</ol>  *<pre>  *  *</pre>  */
end_comment

begin_class
DECL|class|ProgressiveRenameTracker
specifier|public
class|class
name|ProgressiveRenameTracker
extends|extends
name|RenameTracker
block|{
comment|/**    * The collection of paths to delete; this is added as individual files    * are renamed.    *<p>    * The metastore is only updated with these entries after the DELETE    * call containing these paths succeeds.    *<p>    * If the DELETE fails; the filesystem will use    * {@code MultiObjectDeleteSupport} to remove all successfully deleted    * entries from the metastore.    */
DECL|field|pathsToDelete
specifier|private
specifier|final
name|Collection
argument_list|<
name|Path
argument_list|>
name|pathsToDelete
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
DECL|method|ProgressiveRenameTracker ( final StoreContext storeContext, final MetadataStore metadataStore, final Path sourceRoot, final Path dest, final BulkOperationState operationState)
specifier|public
name|ProgressiveRenameTracker
parameter_list|(
specifier|final
name|StoreContext
name|storeContext
parameter_list|,
specifier|final
name|MetadataStore
name|metadataStore
parameter_list|,
specifier|final
name|Path
name|sourceRoot
parameter_list|,
specifier|final
name|Path
name|dest
parameter_list|,
specifier|final
name|BulkOperationState
name|operationState
parameter_list|)
block|{
name|super
argument_list|(
literal|"ProgressiveRenameTracker"
argument_list|,
name|storeContext
argument_list|,
name|metadataStore
argument_list|,
name|sourceRoot
argument_list|,
name|dest
argument_list|,
name|operationState
argument_list|)
expr_stmt|;
block|}
comment|/**    * When a file is copied, any ancestors    * are calculated and then the store is updated with    * the destination entries.    *<p>    * The source entries are added to the {@link #pathsToDelete} list.    * @param sourcePath path of source    * @param sourceAttributes status of source.    * @param destAttributes destination attributes    * @param destPath destination path.    * @param blockSize block size.    * @param addAncestors should ancestors be added?    * @throws IOException failure    */
annotation|@
name|Override
DECL|method|fileCopied ( final Path sourcePath, final S3ObjectAttributes sourceAttributes, final S3ObjectAttributes destAttributes, final Path destPath, final long blockSize, final boolean addAncestors)
specifier|public
name|void
name|fileCopied
parameter_list|(
specifier|final
name|Path
name|sourcePath
parameter_list|,
specifier|final
name|S3ObjectAttributes
name|sourceAttributes
parameter_list|,
specifier|final
name|S3ObjectAttributes
name|destAttributes
parameter_list|,
specifier|final
name|Path
name|destPath
parameter_list|,
specifier|final
name|long
name|blockSize
parameter_list|,
specifier|final
name|boolean
name|addAncestors
parameter_list|)
throws|throws
name|IOException
block|{
comment|// build the list of entries to add in a synchronized block.
specifier|final
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|entriesToAdd
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updating store with copied file {}"
argument_list|,
name|sourcePath
argument_list|)
expr_stmt|;
name|MetadataStore
name|store
init|=
name|getMetadataStore
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|checkArgument
argument_list|(
operator|!
name|pathsToDelete
operator|.
name|contains
argument_list|(
name|sourcePath
argument_list|)
argument_list|,
literal|"File being renamed is already processed %s"
argument_list|,
name|destPath
argument_list|)
expr_stmt|;
comment|// create the file metadata and update the lists
comment|// the pathsToDelete field is incremented with the new source path,
comment|// for deletion after the DELETE operation succeeds;
comment|// the entriesToAdd variable is filled in with all entries
comment|// to add within this method
name|S3Guard
operator|.
name|addMoveFile
argument_list|(
name|store
argument_list|,
name|pathsToDelete
argument_list|,
name|entriesToAdd
argument_list|,
name|sourcePath
argument_list|,
name|destPath
argument_list|,
name|sourceAttributes
operator|.
name|getLen
argument_list|()
argument_list|,
name|blockSize
argument_list|,
name|getOwner
argument_list|()
argument_list|,
name|destAttributes
operator|.
name|getETag
argument_list|()
argument_list|,
name|destAttributes
operator|.
name|getVersionId
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"New metastore entry : {}"
argument_list|,
name|entriesToAdd
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|addAncestors
condition|)
block|{
comment|// add all new ancestors to the lists
name|addMoveAncestors
argument_list|(
name|store
argument_list|,
name|pathsToDelete
argument_list|,
name|entriesToAdd
argument_list|,
name|getSourceRoot
argument_list|()
argument_list|,
name|sourcePath
argument_list|,
name|destPath
argument_list|,
name|getOwner
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// outside the lock, the entriesToAdd variable has all the new entries to
comment|// create. ...so update the store.
comment|// no entries are deleted at this point.
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"Adding new metastore entries"
argument_list|)
init|)
block|{
name|store
operator|.
name|move
argument_list|(
literal|null
argument_list|,
name|entriesToAdd
argument_list|,
name|getOperationState
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * A directory marker has been added.    * Add the new entry and record the source path as another entry to delete.    * @param sourcePath status of source.    * @param destPath destination path.    * @param addAncestors should ancestors be added?    * @throws IOException failure.    */
annotation|@
name|Override
DECL|method|directoryMarkerCopied ( final Path sourcePath, final Path destPath, final boolean addAncestors)
specifier|public
name|void
name|directoryMarkerCopied
parameter_list|(
specifier|final
name|Path
name|sourcePath
parameter_list|,
specifier|final
name|Path
name|destPath
parameter_list|,
specifier|final
name|boolean
name|addAncestors
parameter_list|)
throws|throws
name|IOException
block|{
comment|// this list is created on demand.
specifier|final
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|entriesToAdd
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|MetadataStore
name|store
init|=
name|getMetadataStore
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
name|addMoveDir
argument_list|(
name|store
argument_list|,
name|pathsToDelete
argument_list|,
name|entriesToAdd
argument_list|,
name|sourcePath
argument_list|,
name|destPath
argument_list|,
name|getOwner
argument_list|()
argument_list|)
expr_stmt|;
comment|// Ancestor directories may not be listed, so we explicitly add them
if|if
condition|(
name|addAncestors
condition|)
block|{
name|addMoveAncestors
argument_list|(
name|store
argument_list|,
name|pathsToDelete
argument_list|,
name|entriesToAdd
argument_list|,
name|getSourceRoot
argument_list|()
argument_list|,
name|sourcePath
argument_list|,
name|destPath
argument_list|,
name|getOwner
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// outside the lock, the entriesToAdd list has all new files to create.
comment|// ...so update the store.
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"adding %s metastore entries"
argument_list|,
name|entriesToAdd
operator|.
name|size
argument_list|()
argument_list|)
init|)
block|{
name|store
operator|.
name|move
argument_list|(
literal|null
argument_list|,
name|entriesToAdd
argument_list|,
name|getOperationState
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|moveSourceDirectory ()
specifier|public
specifier|synchronized
name|void
name|moveSourceDirectory
parameter_list|()
throws|throws
name|IOException
block|{
comment|// this moves the source directory in the metastore if it has not
comment|// already been processed.
comment|// TODO S3Guard: performance: mark destination dirs as authoritative
if|if
condition|(
operator|!
name|pathsToDelete
operator|.
name|contains
argument_list|(
name|getSourceRoot
argument_list|()
argument_list|)
condition|)
block|{
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|toDelete
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|toAdd
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|addMoveDir
argument_list|(
name|getMetadataStore
argument_list|()
argument_list|,
name|pathsToDelete
argument_list|,
name|toAdd
argument_list|,
name|getSourceRoot
argument_list|()
argument_list|,
name|getDest
argument_list|()
argument_list|,
name|getOwner
argument_list|()
argument_list|)
expr_stmt|;
name|getMetadataStore
argument_list|()
operator|.
name|move
argument_list|(
name|toDelete
argument_list|,
name|toAdd
argument_list|,
name|getOperationState
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * As source objects are deleted, so is the list of entries.    * @param paths path of objects deleted.    * @throws IOException failure.    */
annotation|@
name|Override
DECL|method|sourceObjectsDeleted ( final Collection<Path> paths)
specifier|public
name|void
name|sourceObjectsDeleted
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|Path
argument_list|>
name|paths
parameter_list|)
throws|throws
name|IOException
block|{
comment|// delete the paths from the metastore
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"delete %s metastore entries"
argument_list|,
name|paths
operator|.
name|size
argument_list|()
argument_list|)
init|)
block|{
name|getMetadataStore
argument_list|()
operator|.
name|move
argument_list|(
name|paths
argument_list|,
literal|null
argument_list|,
name|getOperationState
argument_list|()
argument_list|)
expr_stmt|;
name|getMetadataStore
argument_list|()
operator|.
name|deletePaths
argument_list|(
name|paths
argument_list|,
name|getOperationState
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|completeRename ()
specifier|public
specifier|synchronized
name|void
name|completeRename
parameter_list|()
throws|throws
name|IOException
block|{
comment|// and finish off by deleting source directories.
name|sourceObjectsDeleted
argument_list|(
name|pathsToDelete
argument_list|)
expr_stmt|;
name|super
operator|.
name|completeRename
argument_list|()
expr_stmt|;
block|}
block|}
end_class

end_unit

