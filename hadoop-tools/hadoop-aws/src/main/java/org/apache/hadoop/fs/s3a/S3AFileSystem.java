begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|AccessDeniedException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonClientException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonServiceException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|AmazonS3
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|AbortMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CannedAccessControlList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CopyObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|DeleteObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|GetObjectMetadataRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|InitiateMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|InitiateMultipartUploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListMultipartUploadsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListObjectsV2Request
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|MultiObjectDeleteException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|MultipartUpload
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ObjectMetadata
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|S3ObjectSummary
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSEAwsKeyManagementParams
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSECustomerKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Copy
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManager
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManagerConfiguration
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Upload
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|model
operator|.
name|UploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressEvent
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListeningExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|GlobalStorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|InvalidRequestException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalDirAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathIsNotEmptyDirectoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|RemoteIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StreamCapabilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|PutTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|MagicCommitIntegration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|DirListingMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|MetadataStoreListFilesIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|MetadataStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|PathMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|S3Guard
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3native
operator|.
name|S3xLoginHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicies
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|BlockingThreadPoolExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|SemaphoredDelegatingExecutor
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Invoker
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Statistic
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * The core S3A Filesystem implementation.  *  * This subclass is marked as private as code should not be creating it  * directly; use {@link FileSystem#get(Configuration)} and variants to  * create one.  *  * If cast to {@code S3AFileSystem}, extra methods and features may be accessed.  * Consider those private and unstable.  *  * Because it prints some of the state of the instrumentation,  * the output of {@link #toString()} must also be considered unstable.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|S3AFileSystem
specifier|public
class|class
name|S3AFileSystem
extends|extends
name|FileSystem
implements|implements
name|StreamCapabilities
block|{
comment|/**    * Default blocksize as used in blocksize and FS status queries.    */
DECL|field|DEFAULT_BLOCKSIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKSIZE
init|=
literal|32
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|/**    * This declared delete as idempotent.    * This is an "interesting" topic in past Hadoop FS work.    * Essentially: with a single caller, DELETE is idempotent    * but in a shared filesystem, it is is very much not so.    * Here, on the basis that isn't a filesystem with consistency guarantees,    * retryable results in files being deleted.   */
DECL|field|DELETE_CONSIDERED_IDEMPOTENT
specifier|public
specifier|static
specifier|final
name|boolean
name|DELETE_CONSIDERED_IDEMPOTENT
init|=
literal|true
decl_stmt|;
DECL|field|uri
specifier|private
name|URI
name|uri
decl_stmt|;
DECL|field|workingDir
specifier|private
name|Path
name|workingDir
decl_stmt|;
DECL|field|username
specifier|private
name|String
name|username
decl_stmt|;
DECL|field|s3
specifier|private
name|AmazonS3
name|s3
decl_stmt|;
comment|// initial callback policy is fail-once; it's there just to assist
comment|// some mock tests and other codepaths trying to call the low level
comment|// APIs on an uninitialized filesystem.
DECL|field|invoker
specifier|private
name|Invoker
name|invoker
init|=
operator|new
name|Invoker
argument_list|(
name|RetryPolicies
operator|.
name|TRY_ONCE_THEN_FAIL
argument_list|,
name|Invoker
operator|.
name|LOG_EVENT
argument_list|)
decl_stmt|;
DECL|field|onRetry
specifier|private
specifier|final
name|Retried
name|onRetry
init|=
name|this
operator|::
name|operationRetried
decl_stmt|;
DECL|field|bucket
specifier|private
name|String
name|bucket
decl_stmt|;
DECL|field|maxKeys
specifier|private
name|int
name|maxKeys
decl_stmt|;
DECL|field|listing
specifier|private
name|Listing
name|listing
decl_stmt|;
DECL|field|partSize
specifier|private
name|long
name|partSize
decl_stmt|;
DECL|field|enableMultiObjectsDelete
specifier|private
name|boolean
name|enableMultiObjectsDelete
decl_stmt|;
DECL|field|transfers
specifier|private
name|TransferManager
name|transfers
decl_stmt|;
DECL|field|boundedThreadPool
specifier|private
name|ListeningExecutorService
name|boundedThreadPool
decl_stmt|;
DECL|field|unboundedThreadPool
specifier|private
name|ExecutorService
name|unboundedThreadPool
decl_stmt|;
DECL|field|multiPartThreshold
specifier|private
name|long
name|multiPartThreshold
decl_stmt|;
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|S3AFileSystem
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|PROGRESS
specifier|private
specifier|static
specifier|final
name|Logger
name|PROGRESS
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"org.apache.hadoop.fs.s3a.S3AFileSystem.Progress"
argument_list|)
decl_stmt|;
DECL|field|directoryAllocator
specifier|private
name|LocalDirAllocator
name|directoryAllocator
decl_stmt|;
DECL|field|cannedACL
specifier|private
name|CannedAccessControlList
name|cannedACL
decl_stmt|;
DECL|field|serverSideEncryptionAlgorithm
specifier|private
name|S3AEncryptionMethods
name|serverSideEncryptionAlgorithm
decl_stmt|;
DECL|field|instrumentation
specifier|private
name|S3AInstrumentation
name|instrumentation
decl_stmt|;
DECL|field|storageStatistics
specifier|private
specifier|final
name|S3AStorageStatistics
name|storageStatistics
init|=
name|createStorageStatistics
argument_list|()
decl_stmt|;
DECL|field|readAhead
specifier|private
name|long
name|readAhead
decl_stmt|;
DECL|field|inputPolicy
specifier|private
name|S3AInputPolicy
name|inputPolicy
decl_stmt|;
DECL|field|closed
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|metadataStore
specifier|private
name|MetadataStore
name|metadataStore
decl_stmt|;
DECL|field|allowAuthoritative
specifier|private
name|boolean
name|allowAuthoritative
decl_stmt|;
comment|// The maximum number of entries that can be deleted in any call to s3
DECL|field|MAX_ENTRIES_TO_DELETE
specifier|private
specifier|static
specifier|final
name|int
name|MAX_ENTRIES_TO_DELETE
init|=
literal|1000
decl_stmt|;
DECL|field|blockOutputBuffer
specifier|private
name|String
name|blockOutputBuffer
decl_stmt|;
DECL|field|blockFactory
specifier|private
name|S3ADataBlocks
operator|.
name|BlockFactory
name|blockFactory
decl_stmt|;
DECL|field|blockOutputActiveBlocks
specifier|private
name|int
name|blockOutputActiveBlocks
decl_stmt|;
DECL|field|writeHelper
specifier|private
name|WriteOperationHelper
name|writeHelper
decl_stmt|;
DECL|field|useListV1
specifier|private
name|boolean
name|useListV1
decl_stmt|;
DECL|field|committerIntegration
specifier|private
name|MagicCommitIntegration
name|committerIntegration
decl_stmt|;
comment|/** Add any deprecated keys. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|addDeprecatedKeys ()
specifier|private
specifier|static
name|void
name|addDeprecatedKeys
parameter_list|()
block|{
name|Configuration
operator|.
name|addDeprecations
argument_list|(
operator|new
name|Configuration
operator|.
name|DeprecationDelta
index|[]
block|{
comment|// never shipped in an ASF release, but did get into the wild.
operator|new
name|Configuration
operator|.
name|DeprecationDelta
argument_list|(
name|OLD_S3A_SERVER_SIDE_ENCRYPTION_KEY
argument_list|,
name|SERVER_SIDE_ENCRYPTION_KEY
argument_list|)
block|}
argument_list|)
expr_stmt|;
name|Configuration
operator|.
name|reloadExistingConfigurations
argument_list|()
expr_stmt|;
block|}
static|static
block|{
name|addDeprecatedKeys
argument_list|()
expr_stmt|;
block|}
comment|/** Called after a new FileSystem instance is constructed.    * @param name a uri whose authority section names the host, port, etc.    *   for this FileSystem    * @param originalConf the configuration to use for the FS. The    * bucket-specific options are patched over the base ones before any use is    * made of the config.    */
DECL|method|initialize (URI name, Configuration originalConf)
specifier|public
name|void
name|initialize
parameter_list|(
name|URI
name|name
parameter_list|,
name|Configuration
name|originalConf
parameter_list|)
throws|throws
name|IOException
block|{
name|setUri
argument_list|(
name|name
argument_list|)
expr_stmt|;
comment|// get the host; this is guaranteed to be non-null, non-empty
name|bucket
operator|=
name|name
operator|.
name|getHost
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initializing S3AFileSystem for {}"
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
comment|// clone the configuration into one with propagated bucket options
name|Configuration
name|conf
init|=
name|propagateBucketOptions
argument_list|(
name|originalConf
argument_list|,
name|bucket
argument_list|)
decl_stmt|;
name|patchSecurityCredentialProviders
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|super
operator|.
name|initialize
argument_list|(
name|name
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
try|try
block|{
name|instrumentation
operator|=
operator|new
name|S3AInstrumentation
argument_list|(
name|name
argument_list|)
expr_stmt|;
comment|// Username is the current user at the time the FS was instantiated.
name|username
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|workingDir
operator|=
operator|new
name|Path
argument_list|(
literal|"/user"
argument_list|,
name|username
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|this
operator|.
name|uri
argument_list|,
name|this
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
expr_stmt|;
name|Class
argument_list|<
name|?
extends|extends
name|S3ClientFactory
argument_list|>
name|s3ClientFactoryClass
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|S3_CLIENT_FACTORY_IMPL
argument_list|,
name|DEFAULT_S3_CLIENT_FACTORY_IMPL
argument_list|,
name|S3ClientFactory
operator|.
name|class
argument_list|)
decl_stmt|;
name|s3
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|s3ClientFactoryClass
argument_list|,
name|conf
argument_list|)
operator|.
name|createS3Client
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|invoker
operator|=
operator|new
name|Invoker
argument_list|(
operator|new
name|S3ARetryPolicy
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|onRetry
argument_list|)
expr_stmt|;
name|writeHelper
operator|=
operator|new
name|WriteOperationHelper
argument_list|(
name|this
argument_list|,
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|maxKeys
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_PAGING_KEYS
argument_list|,
name|DEFAULT_MAX_PAGING_KEYS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|listing
operator|=
operator|new
name|Listing
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MULTIPART_SIZE
argument_list|,
name|DEFAULT_MULTIPART_SIZE
argument_list|)
expr_stmt|;
name|multiPartThreshold
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MIN_MULTIPART_THRESHOLD
argument_list|,
name|DEFAULT_MIN_MULTIPART_THRESHOLD
argument_list|)
expr_stmt|;
comment|//check but do not store the block size
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|enableMultiObjectsDelete
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|ENABLE_MULTI_DELETE
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|readAhead
operator|=
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|READAHEAD_RANGE
argument_list|,
name|DEFAULT_READAHEAD_RANGE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|int
name|maxThreads
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MAX_THREADS
argument_list|,
name|DEFAULT_MAX_THREADS
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxThreads
operator|<
literal|2
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|MAX_THREADS
operator|+
literal|" must be at least 2: forcing to 2."
argument_list|)
expr_stmt|;
name|maxThreads
operator|=
literal|2
expr_stmt|;
block|}
name|int
name|totalTasks
init|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_TOTAL_TASKS
argument_list|,
name|DEFAULT_MAX_TOTAL_TASKS
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|long
name|keepAliveTime
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|KEEPALIVE_TIME
argument_list|,
name|DEFAULT_KEEPALIVE_TIME
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|boundedThreadPool
operator|=
name|BlockingThreadPoolExecutorService
operator|.
name|newInstance
argument_list|(
name|maxThreads
argument_list|,
name|maxThreads
operator|+
name|totalTasks
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"s3a-transfer-shared"
argument_list|)
expr_stmt|;
name|unboundedThreadPool
operator|=
operator|new
name|ThreadPoolExecutor
argument_list|(
name|maxThreads
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|LinkedBlockingQueue
argument_list|<
name|Runnable
argument_list|>
argument_list|()
argument_list|,
name|BlockingThreadPoolExecutorService
operator|.
name|newDaemonThreadFactory
argument_list|(
literal|"s3a-transfer-unbounded"
argument_list|)
argument_list|)
expr_stmt|;
name|int
name|listVersion
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|LIST_VERSION
argument_list|,
name|DEFAULT_LIST_VERSION
argument_list|)
decl_stmt|;
if|if
condition|(
name|listVersion
argument_list|<
literal|1
operator|||
name|listVersion
argument_list|>
literal|2
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Configured fs.s3a.list.version {} is invalid, forcing "
operator|+
literal|"version 2"
argument_list|,
name|listVersion
argument_list|)
expr_stmt|;
block|}
name|useListV1
operator|=
operator|(
name|listVersion
operator|==
literal|1
operator|)
expr_stmt|;
name|initTransferManager
argument_list|()
expr_stmt|;
name|initCannedAcls
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|verifyBucketExists
argument_list|()
expr_stmt|;
name|serverSideEncryptionAlgorithm
operator|=
name|getEncryptionAlgorithm
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|inputPolicy
operator|=
name|S3AInputPolicy
operator|.
name|getPolicy
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|INPUT_FADVISE
argument_list|,
name|INPUT_FADV_NORMAL
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Input fadvise policy = {}"
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
name|boolean
name|magicCommitterEnabled
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|CommitConstants
operator|.
name|MAGIC_COMMITTER_ENABLED
argument_list|,
name|CommitConstants
operator|.
name|DEFAULT_MAGIC_COMMITTER_ENABLED
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Filesystem support for magic committers {} enabled"
argument_list|,
name|magicCommitterEnabled
condition|?
literal|"is"
else|:
literal|"is not"
argument_list|)
expr_stmt|;
name|committerIntegration
operator|=
operator|new
name|MagicCommitIntegration
argument_list|(
name|this
argument_list|,
name|magicCommitterEnabled
argument_list|)
expr_stmt|;
name|boolean
name|blockUploadEnabled
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|FAST_UPLOAD
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|blockUploadEnabled
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The \"slow\" output stream is no longer supported"
argument_list|)
expr_stmt|;
block|}
name|blockOutputBuffer
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|FAST_UPLOAD_BUFFER
argument_list|,
name|DEFAULT_FAST_UPLOAD_BUFFER
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|ensureOutputParameterInRange
argument_list|(
name|MULTIPART_SIZE
argument_list|,
name|partSize
argument_list|)
expr_stmt|;
name|blockFactory
operator|=
name|S3ADataBlocks
operator|.
name|createFactory
argument_list|(
name|this
argument_list|,
name|blockOutputBuffer
argument_list|)
expr_stmt|;
name|blockOutputActiveBlocks
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
name|DEFAULT_FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using S3ABlockOutputStream with buffer = {}; block={};"
operator|+
literal|" queue limit={}"
argument_list|,
name|blockOutputBuffer
argument_list|,
name|partSize
argument_list|,
name|blockOutputActiveBlocks
argument_list|)
expr_stmt|;
name|setMetadataStore
argument_list|(
name|S3Guard
operator|.
name|getMetadataStore
argument_list|(
name|this
argument_list|)
argument_list|)
expr_stmt|;
name|allowAuthoritative
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|METADATASTORE_AUTHORITATIVE
argument_list|,
name|DEFAULT_METADATASTORE_AUTHORITATIVE
argument_list|)
expr_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using metadata store {}, authoritative={}"
argument_list|,
name|getMetadataStore
argument_list|()
argument_list|,
name|allowAuthoritative
argument_list|)
expr_stmt|;
block|}
name|initMultipartUploads
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"initializing "
argument_list|,
operator|new
name|Path
argument_list|(
name|name
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create the storage statistics or bind to an existing one.    * @return a storage statistics instance.    */
DECL|method|createStorageStatistics ()
specifier|protected
specifier|static
name|S3AStorageStatistics
name|createStorageStatistics
parameter_list|()
block|{
return|return
operator|(
name|S3AStorageStatistics
operator|)
name|GlobalStorageStatistics
operator|.
name|INSTANCE
operator|.
name|put
argument_list|(
name|S3AStorageStatistics
operator|.
name|NAME
argument_list|,
parameter_list|()
lambda|->
operator|new
name|S3AStorageStatistics
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Verify that the bucket exists. This does not check permissions,    * not even read access.    * Retry policy: retrying, translated.    * @throws FileNotFoundException the bucket is absent    * @throws IOException any other problem talking to S3    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|verifyBucketExists ()
specifier|protected
name|void
name|verifyBucketExists
parameter_list|()
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
if|if
condition|(
operator|!
name|invoker
operator|.
name|retry
argument_list|(
literal|"doesBucketExist"
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|doesBucketExist
argument_list|(
name|bucket
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
argument_list|new
name|FileNotFoundException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" does not exist"
argument_list|)
block|;     }
block|}
comment|/**    * Get S3A Instrumentation. For test purposes.    * @return this instance's instrumentation.    */
DECL|method|getInstrumentation ()
specifier|public
name|S3AInstrumentation
name|getInstrumentation
parameter_list|()
block|{
return|return
name|instrumentation
return|;
block|}
DECL|method|initTransferManager ()
specifier|private
name|void
name|initTransferManager
parameter_list|()
block|{
name|TransferManagerConfiguration
name|transferConfiguration
init|=
operator|new
name|TransferManagerConfiguration
argument_list|()
decl_stmt|;
name|transferConfiguration
operator|.
name|setMinimumUploadPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartUploadThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transfers
operator|=
operator|new
name|TransferManager
argument_list|(
name|s3
argument_list|,
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|transfers
operator|.
name|setConfiguration
argument_list|(
name|transferConfiguration
argument_list|)
expr_stmt|;
block|}
DECL|method|initCannedAcls (Configuration conf)
specifier|private
name|void
name|initCannedAcls
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|cannedACLName
init|=
name|conf
operator|.
name|get
argument_list|(
name|CANNED_ACL
argument_list|,
name|DEFAULT_CANNED_ACL
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|cannedACLName
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|cannedACL
operator|=
name|CannedAccessControlList
operator|.
name|valueOf
argument_list|(
name|cannedACLName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cannedACL
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|initMultipartUploads (Configuration conf)
specifier|private
name|void
name|initMultipartUploads
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|purgeExistingMultipart
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|PURGE_EXISTING_MULTIPART
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART
argument_list|)
decl_stmt|;
name|long
name|purgeExistingMultipartAge
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|PURGE_EXISTING_MULTIPART_AGE
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART_AGE
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|purgeExistingMultipart
condition|)
block|{
try|try
block|{
name|abortOutstandingMultipartUploads
argument_list|(
name|purgeExistingMultipartAge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AccessDeniedException
name|e
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to purge multipart uploads against {},"
operator|+
literal|" FS may be read only"
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Abort all outstanding MPUs older than a given age.    * @param seconds time in seconds    * @throws IOException on any failure, other than 403 "permission denied"    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|abortOutstandingMultipartUploads (long seconds)
specifier|public
name|void
name|abortOutstandingMultipartUploads
parameter_list|(
name|long
name|seconds
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|seconds
operator|>=
literal|0
argument_list|)
expr_stmt|;
name|Date
name|purgeBefore
init|=
operator|new
name|Date
argument_list|(
operator|new
name|Date
argument_list|()
operator|.
name|getTime
argument_list|()
operator|-
name|seconds
operator|*
literal|1000
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Purging outstanding multipart uploads older than {}"
argument_list|,
name|purgeBefore
argument_list|)
expr_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"Purging multipart uploads"
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|transfers
operator|.
name|abortMultipartUploads
argument_list|(
name|bucket
argument_list|,
name|purgeBefore
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Return the protocol scheme for the FileSystem.    *    * @return "s3a"    */
annotation|@
name|Override
DECL|method|getScheme ()
specifier|public
name|String
name|getScheme
parameter_list|()
block|{
return|return
literal|"s3a"
return|;
block|}
comment|/**    * Returns a URI whose scheme and authority identify this FileSystem.    */
annotation|@
name|Override
DECL|method|getUri ()
specifier|public
name|URI
name|getUri
parameter_list|()
block|{
return|return
name|uri
return|;
block|}
comment|/**    * Set the URI field through {@link S3xLoginHelper}.    * Exported for testing.    * @param uri filesystem URI.    */
annotation|@
name|VisibleForTesting
DECL|method|setUri (URI uri)
specifier|protected
name|void
name|setUri
parameter_list|(
name|URI
name|uri
parameter_list|)
block|{
name|this
operator|.
name|uri
operator|=
name|S3xLoginHelper
operator|.
name|buildFSURI
argument_list|(
name|uri
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|getDefaultPort ()
specifier|public
name|int
name|getDefaultPort
parameter_list|()
block|{
return|return
name|Constants
operator|.
name|S3A_DEFAULT_PORT
return|;
block|}
comment|/**    * Returns the S3 client used by this filesystem.    * This is for internal use within the S3A code itself.    * @return AmazonS3Client    */
DECL|method|getAmazonS3Client ()
name|AmazonS3
name|getAmazonS3Client
parameter_list|()
block|{
return|return
name|s3
return|;
block|}
comment|/**    * Returns the S3 client used by this filesystem.    *<i>Warning: this must only be used for testing, as it bypasses core    * S3A operations.</i>    * @param reason a justification for requesting access.    * @return AmazonS3Client    */
annotation|@
name|VisibleForTesting
DECL|method|getAmazonS3ClientForTesting (String reason)
specifier|public
name|AmazonS3
name|getAmazonS3ClientForTesting
parameter_list|(
name|String
name|reason
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Access to S3A client requested, reason {}"
argument_list|,
name|reason
argument_list|)
expr_stmt|;
return|return
name|s3
return|;
block|}
comment|/**    * Set the client -used in mocking tests to force in a different client.    * @param client client.    */
DECL|method|setAmazonS3Client (AmazonS3 client)
specifier|protected
name|void
name|setAmazonS3Client
parameter_list|(
name|AmazonS3
name|client
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|client
argument_list|,
literal|"client"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting S3 client to {}"
argument_list|,
name|client
argument_list|)
expr_stmt|;
name|s3
operator|=
name|client
expr_stmt|;
block|}
comment|/**    * Get the region of a bucket.    * @return the region in which a bucket is located    * @throws IOException on any failure.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getBucketLocation ()
specifier|public
name|String
name|getBucketLocation
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getBucketLocation
argument_list|(
name|bucket
argument_list|)
return|;
block|}
comment|/**    * Get the region of a bucket.    * Retry policy: retrying, translated.    * @param bucketName the name of the bucket    * @return the region in which a bucket is located    * @throws IOException on any failure.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getBucketLocation (String bucketName)
specifier|public
name|String
name|getBucketLocation
parameter_list|(
name|String
name|bucketName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|invoker
operator|.
name|retry
argument_list|(
literal|"getBucketLocation()"
argument_list|,
name|bucketName
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|getBucketLocation
argument_list|(
name|bucketName
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the read ahead range value used by this filesystem.    * @return the readahead range    */
annotation|@
name|VisibleForTesting
DECL|method|getReadAheadRange ()
name|long
name|getReadAheadRange
parameter_list|()
block|{
return|return
name|readAhead
return|;
block|}
comment|/**    * Get the input policy for this FS instance.    * @return the input policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|getInputPolicy ()
specifier|public
name|S3AInputPolicy
name|getInputPolicy
parameter_list|()
block|{
return|return
name|inputPolicy
return|;
block|}
comment|/**    * Demand create the directory allocator, then create a temporary file.    * {@link LocalDirAllocator#createTmpFileForWrite(String, long, Configuration)}.    *  @param pathStr prefix for the temporary file    *  @param size the size of the file that is going to be written    *  @param conf the Configuration object    *  @return a unique temporary file    *  @throws IOException IO problems    */
DECL|method|createTmpFileForWrite (String pathStr, long size, Configuration conf)
specifier|synchronized
name|File
name|createTmpFileForWrite
parameter_list|(
name|String
name|pathStr
parameter_list|,
name|long
name|size
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|directoryAllocator
operator|==
literal|null
condition|)
block|{
name|String
name|bufferDir
init|=
name|conf
operator|.
name|get
argument_list|(
name|BUFFER_DIR
argument_list|)
operator|!=
literal|null
condition|?
name|BUFFER_DIR
else|:
name|HADOOP_TMP_DIR
decl_stmt|;
name|directoryAllocator
operator|=
operator|new
name|LocalDirAllocator
argument_list|(
name|bufferDir
argument_list|)
expr_stmt|;
block|}
return|return
name|directoryAllocator
operator|.
name|createTmpFileForWrite
argument_list|(
name|pathStr
argument_list|,
name|size
argument_list|,
name|conf
argument_list|)
return|;
block|}
comment|/**    * Get the bucket of this filesystem.    * @return the bucket    */
DECL|method|getBucket ()
specifier|public
name|String
name|getBucket
parameter_list|()
block|{
return|return
name|bucket
return|;
block|}
comment|/**    * Set the bucket.    * @param bucket the bucket    */
annotation|@
name|VisibleForTesting
DECL|method|setBucket (String bucket)
specifier|protected
name|void
name|setBucket
parameter_list|(
name|String
name|bucket
parameter_list|)
block|{
name|this
operator|.
name|bucket
operator|=
name|bucket
expr_stmt|;
block|}
comment|/**    * Get the canned ACL of this FS.    * @return an ACL, if any    */
DECL|method|getCannedACL ()
name|CannedAccessControlList
name|getCannedACL
parameter_list|()
block|{
return|return
name|cannedACL
return|;
block|}
comment|/**    * Change the input policy for this FS.    * @param inputPolicy new policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|setInputPolicy (S3AInputPolicy inputPolicy)
specifier|public
name|void
name|setInputPolicy
parameter_list|(
name|S3AInputPolicy
name|inputPolicy
parameter_list|)
block|{
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|inputPolicy
argument_list|,
literal|"Null inputStrategy"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting input strategy: {}"
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputPolicy
operator|=
name|inputPolicy
expr_stmt|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key.    *    * @param path input path, may be relative to the working dir    * @return a key excluding the leading "/", or, if it is the root path, ""    */
annotation|@
name|VisibleForTesting
DECL|method|pathToKey (Path path)
specifier|public
name|String
name|pathToKey
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
if|if
condition|(
operator|!
name|path
operator|.
name|isAbsolute
argument_list|()
condition|)
block|{
name|path
operator|=
operator|new
name|Path
argument_list|(
name|workingDir
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
operator|!=
literal|null
operator|&&
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|""
return|;
block|}
return|return
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
return|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key, adding a trailing    * "/" if the path is not the root<i>and</i> does not already have a "/"    * at the end.    *    * @param key s3 key or ""    * @return the with a trailing "/", or, if it is the root key, "",    */
DECL|method|maybeAddTrailingSlash (String key)
specifier|private
name|String
name|maybeAddTrailingSlash
parameter_list|(
name|String
name|key
parameter_list|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
return|return
name|key
operator|+
literal|'/'
return|;
block|}
else|else
block|{
return|return
name|key
return|;
block|}
block|}
comment|/**    * Convert a path back to a key.    * @param key input key    * @return the path from this key    */
DECL|method|keyToPath (String key)
name|Path
name|keyToPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
literal|"/"
operator|+
name|key
argument_list|)
return|;
block|}
comment|/**    * Convert a key to a fully qualified path.    * @param key input key    * @return the fully qualified path including URI scheme and bucket name.    */
DECL|method|keyToQualifiedPath (String key)
specifier|public
name|Path
name|keyToQualifiedPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
name|qualify
argument_list|(
name|keyToPath
argument_list|(
name|key
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Qualify a path.    * @param path path to qualify    * @return a qualified path.    */
DECL|method|qualify (Path path)
specifier|public
name|Path
name|qualify
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|makeQualified
argument_list|(
name|uri
argument_list|,
name|workingDir
argument_list|)
return|;
block|}
comment|/**    * Check that a Path belongs to this FileSystem.    * Unlike the superclass, this version does not look at authority,    * only hostnames.    * @param path to check    * @throws IllegalArgumentException if there is an FS mismatch    */
annotation|@
name|Override
DECL|method|checkPath (Path path)
specifier|public
name|void
name|checkPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|S3xLoginHelper
operator|.
name|checkPath
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|getUri
argument_list|()
argument_list|,
name|path
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|canonicalizeUri (URI rawUri)
specifier|protected
name|URI
name|canonicalizeUri
parameter_list|(
name|URI
name|rawUri
parameter_list|)
block|{
return|return
name|S3xLoginHelper
operator|.
name|canonicalizeUri
argument_list|(
name|rawUri
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Opens an FSDataInputStream at the indicated Path.    * @param f the file name to open    * @param bufferSize the size of the buffer to be used.    */
DECL|method|open (Path f, int bufferSize)
specifier|public
name|FSDataInputStream
name|open
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening '{}' for reading; input policy = {}"
argument_list|,
name|f
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Can't open "
operator|+
name|f
operator|+
literal|" because it is a directory"
argument_list|)
throw|;
block|}
return|return
operator|new
name|FSDataInputStream
argument_list|(
operator|new
name|S3AInputStream
argument_list|(
operator|new
name|S3ObjectAttributes
argument_list|(
name|bucket
argument_list|,
name|pathToKey
argument_list|(
name|f
argument_list|)
argument_list|,
name|serverSideEncryptionAlgorithm
argument_list|,
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|fileStatus
operator|.
name|getLen
argument_list|()
argument_list|,
name|s3
argument_list|,
name|statistics
argument_list|,
name|instrumentation
argument_list|,
name|readAhead
argument_list|,
name|inputPolicy
argument_list|,
name|invoker
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Create an FSDataOutputStream at the indicated Path with write-progress    * reporting.    * Retry policy: retrying, translated on the getFileStatus() probe.    * No data is uploaded to S3 in this call, so retry issues related to that.    * @param f the file name to open    * @param permission the permission to set.    * @param overwrite if a file with this name already exists, then if true,    *   the file will be overwritten, and if false an error will be thrown.    * @param bufferSize the size of the buffer to be used.    * @param replication required block replication for the file.    * @param blockSize the requested block size.    * @param progress the progress reporter.    * @throws IOException in the event of IO related errors.    * @see #setPermission(Path, FsPermission)    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"IOResourceOpenedButNotSafelyClosed"
argument_list|)
DECL|method|create (Path f, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|create
parameter_list|(
name|Path
name|f
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// get the status or throw an FNFE
name|status
operator|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
expr_stmt|;
comment|// if the thread reaches here, there is something at the path
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|// path references a directory: automatic error
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|path
operator|+
literal|" is a directory"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|overwrite
condition|)
block|{
comment|// path references a file and overwrite is disabled
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|path
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overwriting file {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// this means the file is not found
block|}
name|instrumentation
operator|.
name|fileCreated
argument_list|()
expr_stmt|;
name|PutTracker
name|putTracker
init|=
name|committerIntegration
operator|.
name|createTracker
argument_list|(
name|path
argument_list|,
name|key
argument_list|)
decl_stmt|;
name|String
name|destKey
init|=
name|putTracker
operator|.
name|getDestKey
argument_list|()
decl_stmt|;
return|return
operator|new
name|FSDataOutputStream
argument_list|(
operator|new
name|S3ABlockOutputStream
argument_list|(
name|this
argument_list|,
name|destKey
argument_list|,
operator|new
name|SemaphoredDelegatingExecutor
argument_list|(
name|boundedThreadPool
argument_list|,
name|blockOutputActiveBlocks
argument_list|,
literal|true
argument_list|)
argument_list|,
name|progress
argument_list|,
name|partSize
argument_list|,
name|blockFactory
argument_list|,
name|instrumentation
operator|.
name|newOutputStreamStatistics
argument_list|(
name|statistics
argument_list|)
argument_list|,
name|getWriteOperationHelper
argument_list|()
argument_list|,
name|putTracker
argument_list|)
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Get a {@code WriteOperationHelper} instance.    *    * This class permits other low-level operations against the store.    * It is unstable and    * only intended for code with intimate knowledge of the object store.    * If using this, be prepared for changes even on minor point releases.    * @return a new helper.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|method|getWriteOperationHelper ()
specifier|public
name|WriteOperationHelper
name|getWriteOperationHelper
parameter_list|()
block|{
return|return
name|writeHelper
return|;
block|}
comment|/**    * {@inheritDoc}    * @throws FileNotFoundException if the parent directory is not present -or    * is not a directory.    */
annotation|@
name|Override
DECL|method|createNonRecursive (Path path, FsPermission permission, EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|createNonRecursive
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flags
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
comment|// expect this to raise an exception if there is no parent
if|if
condition|(
operator|!
name|getFileStatus
argument_list|(
name|parent
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Not a directory: "
operator|+
name|parent
argument_list|)
throw|;
block|}
block|}
return|return
name|create
argument_list|(
name|path
argument_list|,
name|permission
argument_list|,
name|flags
operator|.
name|contains
argument_list|(
name|CreateFlag
operator|.
name|OVERWRITE
argument_list|)
argument_list|,
name|bufferSize
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|,
name|progress
argument_list|)
return|;
block|}
comment|/**    * Append to an existing file (optional operation).    * @param f the existing file to be appended.    * @param bufferSize the size of the buffer to be used.    * @param progress for reporting progress if it is not null.    * @throws IOException indicating that append is not supported.    */
DECL|method|append (Path f, int bufferSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|append
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Append is not supported "
operator|+
literal|"by S3AFileSystem"
argument_list|)
throw|;
block|}
comment|/**    * Renames Path src to Path dst.  Can take place on local fs    * or remote DFS.    *    * Warning: S3 does not support renames. This method does a copy which can    * take S3 some time to execute with large files and directories. Since    * there is no Progressable passed in, this can time out jobs.    *    * Note: This implementation differs with other S3 drivers. Specifically:    *<pre>    *       Fails if src is a file and dst is a directory.    *       Fails if src is a directory and dst is a file.    *       Fails if the parent of dst does not exist or is a file.    *       Fails if dst is a directory that is not empty.    *</pre>    *    * @param src path to be renamed    * @param dst new path after rename    * @throws IOException on IO failure    * @return true if rename is successful    */
DECL|method|rename (Path src, Path dst)
specifier|public
name|boolean
name|rename
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|innerRename
argument_list|(
name|src
argument_list|,
name|dst
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"rename("
operator|+
name|src
operator|+
literal|", "
operator|+
name|dst
operator|+
literal|")"
argument_list|,
name|src
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|RenameFailedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|e
operator|.
name|getExitCode
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**    * The inner rename operation. See {@link #rename(Path, Path)} for    * the description of the operation.    * This operation throws an exception on any failure which needs to be    * reported and downgraded to a failure. That is: if a rename    * @param source path to be renamed    * @param dest new path after rename    * @throws RenameFailedException if some criteria for a state changing    * rename was not met. This means work didn't happen; it's not something    * which is reported upstream to the FileSystem APIs, for which the semantics    * of "false" are pretty vague.    * @throws FileNotFoundException there's no source file.    * @throws IOException on IO failure.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerRename (Path source, Path dest)
specifier|private
name|boolean
name|innerRename
parameter_list|(
name|Path
name|source
parameter_list|,
name|Path
name|dest
parameter_list|)
throws|throws
name|RenameFailedException
throws|,
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|src
init|=
name|qualify
argument_list|(
name|source
argument_list|)
decl_stmt|;
name|Path
name|dst
init|=
name|qualify
argument_list|(
name|dest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Rename path {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_RENAME
argument_list|)
expr_stmt|;
name|String
name|srcKey
init|=
name|pathToKey
argument_list|(
name|src
argument_list|)
decl_stmt|;
name|String
name|dstKey
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is root directory"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dstKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"dest is root directory"
argument_list|)
throw|;
block|}
comment|// get the source file status; this raises a FNFE if there is no source
comment|// file.
name|S3AFileStatus
name|srcStatus
init|=
name|innerGetFileStatus
argument_list|(
name|src
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|equals
argument_list|(
name|dstKey
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: src and dest refer to the same file or directory: {}"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source and dest refer to the same file or directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
name|S3AFileStatus
name|dstStatus
init|=
literal|null
decl_stmt|;
try|try
block|{
name|dstStatus
operator|=
name|innerGetFileStatus
argument_list|(
name|dst
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// if there is no destination entry, an exception is raised.
comment|// hence this code sequence can assume that there is something
comment|// at the end of the path; the only detail being what it is and
comment|// whether or not it can be the destination of the rename.
if|if
condition|(
name|srcStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is a directory and dest is a file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|dstStatus
operator|.
name|isEmptyDirectory
argument_list|()
operator|!=
name|Tristate
operator|.
name|TRUE
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Destination is a non-empty directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
comment|// at this point the destination is an empty directory
block|}
else|else
block|{
comment|// source is a file. The destination must be a directory,
comment|// empty or not
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Cannot rename onto an existing file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: destination path {} not found"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Parent must exist
name|Path
name|parent
init|=
name|dst
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|pathToKey
argument_list|(
name|parent
argument_list|)
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|S3AFileStatus
name|dstParentStatus
init|=
name|innerGetFileStatus
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|dstParentStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination parent is not a directory"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e2
parameter_list|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination has no parent "
argument_list|)
throw|;
block|}
block|}
block|}
comment|// If we have a MetadataStore, track deletions/creations.
name|Collection
argument_list|<
name|Path
argument_list|>
name|srcPaths
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|PathMetadata
argument_list|>
name|dstMetas
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|srcPaths
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
expr_stmt|;
comment|// srcPaths need fast look up before put
name|dstMetas
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
comment|// TODO S3Guard HADOOP-13761: retries when source paths are not visible yet
comment|// TODO S3Guard: performance: mark destination dirs as authoritative
comment|// Ok! Time to start
if|if
condition|(
name|srcStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: renaming file {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|long
name|length
init|=
name|srcStatus
operator|.
name|getLen
argument_list|()
decl_stmt|;
if|if
condition|(
name|dstStatus
operator|!=
literal|null
operator|&&
name|dstStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|String
name|newDstKey
init|=
name|dstKey
decl_stmt|;
if|if
condition|(
operator|!
name|newDstKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|newDstKey
operator|=
name|newDstKey
operator|+
literal|"/"
expr_stmt|;
block|}
name|String
name|filename
init|=
name|srcKey
operator|.
name|substring
argument_list|(
name|pathToKey
argument_list|(
name|src
operator|.
name|getParent
argument_list|()
argument_list|)
operator|.
name|length
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
name|newDstKey
operator|=
name|newDstKey
operator|+
name|filename
expr_stmt|;
name|copyFile
argument_list|(
name|srcKey
argument_list|,
name|newDstKey
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|S3Guard
operator|.
name|addMoveFile
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|src
argument_list|,
name|keyToQualifiedPath
argument_list|(
name|newDstKey
argument_list|)
argument_list|,
name|length
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|dst
argument_list|)
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|copyFile
argument_list|(
name|srcKey
argument_list|,
name|dstKey
argument_list|,
name|srcStatus
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
name|S3Guard
operator|.
name|addMoveFile
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|src
argument_list|,
name|dst
argument_list|,
name|length
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|dst
argument_list|)
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
name|innerDelete
argument_list|(
name|srcStatus
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: renaming directory {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// This is a directory to directory copy
if|if
condition|(
operator|!
name|dstKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|dstKey
operator|=
name|dstKey
operator|+
literal|"/"
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|srcKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|srcKey
operator|=
name|srcKey
operator|+
literal|"/"
expr_stmt|;
block|}
comment|//Verify dest is not a child of the source directory
if|if
condition|(
name|dstKey
operator|.
name|startsWith
argument_list|(
name|srcKey
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|srcKey
argument_list|,
name|dstKey
argument_list|,
literal|"cannot rename a directory to a subdirectory of itself "
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|dstStatus
operator|!=
literal|null
operator|&&
name|dstStatus
operator|.
name|isEmptyDirectory
argument_list|()
operator|==
name|Tristate
operator|.
name|TRUE
condition|)
block|{
comment|// delete unnecessary fake directory.
name|keysToDelete
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|dstKey
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|Path
name|parentPath
init|=
name|keyToQualifiedPath
argument_list|(
name|srcKey
argument_list|)
decl_stmt|;
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|iterator
init|=
name|listFilesAndEmptyDirectories
argument_list|(
name|parentPath
argument_list|,
literal|true
argument_list|)
decl_stmt|;
while|while
condition|(
name|iterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|LocatedFileStatus
name|status
init|=
name|iterator
operator|.
name|next
argument_list|()
decl_stmt|;
name|long
name|length
init|=
name|status
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
operator|&&
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|key
operator|+=
literal|"/"
expr_stmt|;
block|}
name|keysToDelete
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|newDstKey
init|=
name|dstKey
operator|+
name|key
operator|.
name|substring
argument_list|(
name|srcKey
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|copyFile
argument_list|(
name|key
argument_list|,
name|newDstKey
argument_list|,
name|length
argument_list|)
expr_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
comment|// with a metadata store, the object entries need to be updated,
comment|// including, potentially, the ancestors
name|Path
name|childSrc
init|=
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|Path
name|childDst
init|=
name|keyToQualifiedPath
argument_list|(
name|newDstKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|length
argument_list|)
condition|)
block|{
name|S3Guard
operator|.
name|addMoveDir
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|childSrc
argument_list|,
name|childDst
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|S3Guard
operator|.
name|addMoveFile
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|childSrc
argument_list|,
name|childDst
argument_list|,
name|length
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|childDst
argument_list|)
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
comment|// Ancestor directories may not be listed, so we explicitly add them
name|S3Guard
operator|.
name|addMoveAncestors
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|keyToQualifiedPath
argument_list|(
name|srcKey
argument_list|)
argument_list|,
name|childSrc
argument_list|,
name|childDst
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|keysToDelete
operator|.
name|size
argument_list|()
operator|==
name|MAX_ENTRIES_TO_DELETE
condition|)
block|{
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|keysToDelete
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// We moved all the children, now move the top-level dir
comment|// Empty directory should have been added as the object summary
if|if
condition|(
name|hasMetadataStore
argument_list|()
operator|&&
name|srcPaths
operator|!=
literal|null
operator|&&
operator|!
name|srcPaths
operator|.
name|contains
argument_list|(
name|src
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"To move the non-empty top-level dir src={} and dst={}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|S3Guard
operator|.
name|addMoveDir
argument_list|(
name|metadataStore
argument_list|,
name|srcPaths
argument_list|,
name|dstMetas
argument_list|,
name|src
argument_list|,
name|dst
argument_list|,
name|username
argument_list|)
expr_stmt|;
block|}
block|}
name|metadataStore
operator|.
name|move
argument_list|(
name|srcPaths
argument_list|,
name|dstMetas
argument_list|)
expr_stmt|;
if|if
condition|(
name|src
operator|.
name|getParent
argument_list|()
operator|!=
name|dst
operator|.
name|getParent
argument_list|()
condition|)
block|{
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
name|maybeCreateFakeParentDirectory
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Low-level call to get at the object metadata.    * @param path path to the object    * @return metadata    * @throws IOException IO and object access problems.    */
annotation|@
name|VisibleForTesting
DECL|method|getObjectMetadata (Path path)
specifier|public
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getObjectMetadata
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Does this Filesystem have a metadata store?    * @return true iff the FS has been instantiated with a metadata store    */
DECL|method|hasMetadataStore ()
specifier|public
name|boolean
name|hasMetadataStore
parameter_list|()
block|{
return|return
operator|!
name|S3Guard
operator|.
name|isNullMetadataStore
argument_list|(
name|metadataStore
argument_list|)
return|;
block|}
comment|/**    * Get the metadata store.    * This will always be non-null, but may be bound to the    * {@code NullMetadataStore}.    * @return the metadata store of this FS instance    */
annotation|@
name|VisibleForTesting
DECL|method|getMetadataStore ()
specifier|public
name|MetadataStore
name|getMetadataStore
parameter_list|()
block|{
return|return
name|metadataStore
return|;
block|}
comment|/** For testing only.  See ITestS3GuardEmptyDirs. */
annotation|@
name|VisibleForTesting
DECL|method|setMetadataStore (MetadataStore ms)
name|void
name|setMetadataStore
parameter_list|(
name|MetadataStore
name|ms
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|ms
argument_list|)
expr_stmt|;
name|metadataStore
operator|=
name|ms
expr_stmt|;
block|}
comment|/**    * Increment a statistic by 1.    * @param statistic The operation to increment    */
DECL|method|incrementStatistic (Statistic statistic)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|statistic
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a statistic by a specific value.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementStatistic (Statistic statistic, long count)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|storageStatistics
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Decrement a gauge by a specific value.    * @param statistic The operation to decrement    * @param count the count to decrement    */
DECL|method|decrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|decrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|decrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a gauge by a specific value.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|incrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback when an operation was retried.    * Increments the statistics of ignored errors or throttled requests,    * depending up on the exception class.    * @param ex exception.    */
DECL|method|operationRetried (Exception ex)
specifier|public
name|void
name|operationRetried
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|Statistic
name|stat
init|=
name|isThrottleException
argument_list|(
name|ex
argument_list|)
condition|?
name|STORE_IO_THROTTLED
else|:
name|IGNORED_ERRORS
decl_stmt|;
name|instrumentation
operator|.
name|incrementCounter
argument_list|(
name|stat
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|storageStatistics
operator|.
name|incrementCounter
argument_list|(
name|stat
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback from {@link Invoker} when an operation is retried.    * @param text text of the operation    * @param ex exception    * @param retries number of retries    * @param idempotent is the method idempotent    */
DECL|method|operationRetried ( String text, Exception ex, int retries, boolean idempotent)
specifier|public
name|void
name|operationRetried
parameter_list|(
name|String
name|text
parameter_list|,
name|Exception
name|ex
parameter_list|,
name|int
name|retries
parameter_list|,
name|boolean
name|idempotent
parameter_list|)
block|{
name|operationRetried
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback from {@link Invoker} when an operation against a metastore    * is retried.    * @param ex exception    * @param retries number of retries    * @param idempotent is the method idempotent    */
DECL|method|metastoreOperationRetried (Exception ex, int retries, boolean idempotent)
specifier|public
name|void
name|metastoreOperationRetried
parameter_list|(
name|Exception
name|ex
parameter_list|,
name|int
name|retries
parameter_list|,
name|boolean
name|idempotent
parameter_list|)
block|{
name|operationRetried
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the storage statistics of this filesystem.    * @return the storage statistics    */
annotation|@
name|Override
DECL|method|getStorageStatistics ()
specifier|public
name|S3AStorageStatistics
name|getStorageStatistics
parameter_list|()
block|{
return|return
name|storageStatistics
return|;
block|}
comment|/**    * Request object metadata; increments counters in the process.    * Retry policy: retry untranslated.    * @param key key    * @return the metadata    * @throws IOException if the retry invocation raises one (it shouldn't).    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|getObjectMetadata (String key)
specifier|protected
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|IOException
block|{
name|GetObjectMetadataRequest
name|request
init|=
operator|new
name|GetObjectMetadataRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
decl_stmt|;
comment|//SSE-C requires to be filled in if enabled for object metadata
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_C
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|&&
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|request
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ObjectMetadata
name|meta
init|=
name|invoker
operator|.
name|retryUntranslated
argument_list|(
literal|"GET "
operator|+
name|key
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_METADATA_REQUESTS
argument_list|)
expr_stmt|;
return|return
name|s3
operator|.
name|getObjectMetadata
argument_list|(
name|request
argument_list|)
return|;
block|}
argument_list|)
decl_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|meta
return|;
block|}
comment|/**    * Initiate a {@code listObjects} operation, incrementing metrics    * in the process.    *    * Retry policy: retry untranslated.    * @param request request to initiate    * @return the results    * @throws IOException if the retry invocation raises one (it shouldn't).    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|listObjects (S3ListRequest request)
specifier|protected
name|S3ListResult
name|listObjects
parameter_list|(
name|S3ListRequest
name|request
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementReadOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_LIST_REQUESTS
argument_list|)
expr_stmt|;
name|validateListArguments
argument_list|(
name|request
argument_list|)
expr_stmt|;
return|return
name|invoker
operator|.
name|retryUntranslated
argument_list|(
name|request
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
if|if
condition|(
name|useListV1
condition|)
block|{
return|return
name|S3ListResult
operator|.
name|v1
argument_list|(
name|s3
operator|.
name|listObjects
argument_list|(
name|request
operator|.
name|getV1
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|S3ListResult
operator|.
name|v2
argument_list|(
name|s3
operator|.
name|listObjectsV2
argument_list|(
name|request
operator|.
name|getV2
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/**    * Validate the list arguments with this bucket's settings.    * @param request the request to validate    */
DECL|method|validateListArguments (S3ListRequest request)
specifier|private
name|void
name|validateListArguments
parameter_list|(
name|S3ListRequest
name|request
parameter_list|)
block|{
if|if
condition|(
name|useListV1
condition|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|request
operator|.
name|isV1
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|request
operator|.
name|isV1
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * List the next set of objects.    * Retry policy: retry untranslated.    * @param request last list objects request to continue    * @param prevResult last paged result to continue from    * @return the next result object    * @throws IOException none, just there for retryUntranslated.    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|continueListObjects (S3ListRequest request, S3ListResult prevResult)
specifier|protected
name|S3ListResult
name|continueListObjects
parameter_list|(
name|S3ListRequest
name|request
parameter_list|,
name|S3ListResult
name|prevResult
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementReadOperations
argument_list|()
expr_stmt|;
name|validateListArguments
argument_list|(
name|request
argument_list|)
expr_stmt|;
return|return
name|invoker
operator|.
name|retryUntranslated
argument_list|(
name|request
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_CONTINUE_LIST_REQUESTS
argument_list|)
expr_stmt|;
if|if
condition|(
name|useListV1
condition|)
block|{
return|return
name|S3ListResult
operator|.
name|v1
argument_list|(
name|s3
operator|.
name|listNextBatchOfObjects
argument_list|(
name|prevResult
operator|.
name|getV1
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
name|request
operator|.
name|getV2
argument_list|()
operator|.
name|setContinuationToken
argument_list|(
name|prevResult
operator|.
name|getV2
argument_list|()
operator|.
name|getNextContinuationToken
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|S3ListResult
operator|.
name|v2
argument_list|(
name|s3
operator|.
name|listObjectsV2
argument_list|(
name|request
operator|.
name|getV2
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/**    * Increment read operations.    */
DECL|method|incrementReadOperations ()
specifier|public
name|void
name|incrementReadOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementReadOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment the write operation counter.    * This is somewhat inaccurate, as it appears to be invoked more    * often than needed in progress callbacks.    */
DECL|method|incrementWriteOperations ()
specifier|public
name|void
name|incrementWriteOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementWriteOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete an object. This is the low-level internal call which    *<i>does not</i> update the metastore.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    *    * Retry policy: retry untranslated; delete considered idempotent.    * @param key key to blob to delete.    * @throws AmazonClientException problems working with S3    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|deleteObject (String key)
specifier|protected
name|void
name|deleteObject
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|IOException
block|{
name|blockRootDelete
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|invoker
operator|.
name|retryUntranslated
argument_list|(
literal|"Delete "
operator|+
name|bucket
operator|+
literal|":/"
operator|+
name|key
argument_list|,
name|DELETE_CONSIDERED_IDEMPOTENT
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|)
expr_stmt|;
name|s3
operator|.
name|deleteObject
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete an object, also updating the metastore.    * This call does<i>not</i> create any mock parent entries.    * Retry policy: retry untranslated; delete considered idempotent.    * @param f path path to delete    * @param key key of entry    * @param isFile is the path a file (used for instrumentation only)    * @throws AmazonClientException problems working with S3    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|deleteObjectAtPath (Path f, String key, boolean isFile)
name|void
name|deleteObjectAtPath
parameter_list|(
name|Path
name|f
parameter_list|,
name|String
name|key
parameter_list|,
name|boolean
name|isFile
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|IOException
block|{
if|if
condition|(
name|isFile
condition|)
block|{
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|instrumentation
operator|.
name|directoryDeleted
argument_list|()
expr_stmt|;
block|}
name|deleteObject
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|metadataStore
operator|.
name|delete
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
comment|/**    * Reject any request to delete an object where the key is root.    * @param key key to validate    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
DECL|method|blockRootDelete (String key)
specifier|private
name|void
name|blockRootDelete
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|InvalidRequestException
block|{
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
operator|||
literal|"/"
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|InvalidRequestException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" cannot be deleted"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Perform a bulk object delete operation.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    * Retry policy: retry untranslated; delete considered idempotent.    * @param deleteRequest keys to delete on the s3-backend    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted.    * @throws AmazonClientException amazon-layer failure.    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|deleteObjects (DeleteObjectsRequest deleteRequest)
specifier|private
name|void
name|deleteObjects
parameter_list|(
name|DeleteObjectsRequest
name|deleteRequest
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
name|incrementWriteOperations
argument_list|()
expr_stmt|;
try|try
block|{
name|invoker
operator|.
name|retryUntranslated
argument_list|(
literal|"delete"
argument_list|,
name|DELETE_CONSIDERED_IDEMPOTENT
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
name|s3
operator|.
name|deleteObjects
argument_list|(
name|deleteRequest
argument_list|)
return|;
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|MultiObjectDeleteException
name|e
parameter_list|)
block|{
comment|// one or more of the operations failed.
name|List
argument_list|<
name|MultiObjectDeleteException
operator|.
name|DeleteError
argument_list|>
name|errors
init|=
name|e
operator|.
name|getErrors
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Partial failure of delete, {} errors"
argument_list|,
name|errors
operator|.
name|size
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
for|for
control|(
name|MultiObjectDeleteException
operator|.
name|DeleteError
name|error
range|:
name|errors
control|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"{}: \"{}\" - {}"
argument_list|,
name|error
operator|.
name|getKey
argument_list|()
argument_list|,
name|error
operator|.
name|getCode
argument_list|()
argument_list|,
name|error
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Create a putObject request.    * Adds the ACL and metadata    * @param key key of object    * @param metadata metadata header    * @param srcfile source file    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, File srcfile)
specifier|public
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|File
name|srcfile
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|srcfile
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a {@link PutObjectRequest} request.    * The metadata is assumed to have been configured with the size of the    * operation.    * @param key key of object    * @param metadata metadata header    * @param inputStream source data.    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, InputStream inputStream)
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|InputStream
name|inputStream
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|inputStream
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|key
argument_list|)
argument_list|,
literal|"Null/empty key"
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|inputStream
argument_list|,
name|metadata
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    * @return a new metadata instance    */
DECL|method|newObjectMetadata ()
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|()
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
operator|new
name|ObjectMetadata
argument_list|()
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|om
argument_list|)
expr_stmt|;
return|return
name|om
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    *    * @param length length of data to set in header.    * @return a new metadata instance    */
DECL|method|newObjectMetadata (long length)
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|(
name|long
name|length
parameter_list|)
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|length
operator|>=
literal|0
condition|)
block|{
name|om
operator|.
name|setContentLength
argument_list|(
name|length
argument_list|)
expr_stmt|;
block|}
return|return
name|om
return|;
block|}
comment|/**    * Start a transfer-manager managed async PUT of an object,    * incrementing the put requests and put bytes    * counters.    * It does not update the other counters,    * as existing code does that as progress callbacks come in.    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    * Because the operation is async, any stream supplied in the request    * must reference data (files, buffers) which stay valid until the upload    * completes.    * Retry policy: N/A: the transfer manager is performing the upload.    * @param putObjectRequest the request    * @return the upload initiated    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|putObject (PutObjectRequest putObjectRequest)
specifier|public
name|UploadInfo
name|putObject
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
block|{
name|long
name|len
init|=
name|getPutRequestLength
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT {} bytes to {} via transfer manager "
argument_list|,
name|len
argument_list|,
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
name|Upload
name|upload
init|=
name|transfers
operator|.
name|upload
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
return|return
operator|new
name|UploadInfo
argument_list|(
name|upload
argument_list|,
name|len
argument_list|)
return|;
block|}
comment|/**    * PUT an object directly (i.e. not via the transfer manager).    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    *    * Retry Policy: none.    *<i>Important: this call will close any input stream in the request.</i>    * @param putObjectRequest the request    * @return the upload initiated    * @throws AmazonClientException on problems    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|putObjectDirect (PutObjectRequest putObjectRequest)
name|PutObjectResult
name|putObjectDirect
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|long
name|len
init|=
name|getPutRequestLength
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT {} bytes to {}"
argument_list|,
name|len
argument_list|,
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|PutObjectResult
name|result
init|=
name|s3
operator|.
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
comment|// update metadata
name|finishedWrite
argument_list|(
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Get the length of the PUT, verifying that the length is known.    * @param putObjectRequest a request bound to a file or a stream.    * @return the request length    * @throws IllegalArgumentException if the length is negative    */
DECL|method|getPutRequestLength (PutObjectRequest putObjectRequest)
specifier|private
name|long
name|getPutRequestLength
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
block|{
name|long
name|len
decl_stmt|;
if|if
condition|(
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getMetadata
argument_list|()
operator|.
name|getContentLength
argument_list|()
expr_stmt|;
block|}
name|Preconditions
operator|.
name|checkState
argument_list|(
name|len
operator|>=
literal|0
argument_list|,
literal|"Cannot PUT object of unknown length"
argument_list|)
expr_stmt|;
return|return
name|len
return|;
block|}
comment|/**    * Upload part of a multi-partition file.    * Increments the write and put counters.    *<i>Important: this call does not close any input stream in the request.</i>    *    * Retry Policy: none.    * @param request request    * @return the result of the operation.    * @throws AmazonClientException on problems    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|uploadPart (UploadPartRequest request)
name|UploadPartResult
name|uploadPart
parameter_list|(
name|UploadPartRequest
name|request
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|long
name|len
init|=
name|request
operator|.
name|getPartSize
argument_list|()
decl_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|UploadPartResult
name|uploadPartResult
init|=
name|s3
operator|.
name|uploadPart
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|uploadPartResult
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * At the start of a put/multipart upload operation, update the    * relevant counters.    *    * @param bytes bytes in the request.    */
DECL|method|incrementPutStartStatistics (long bytes)
specifier|public
name|void
name|incrementPutStartStatistics
parameter_list|(
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT start {} bytes"
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS
argument_list|)
expr_stmt|;
name|incrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * At the end of a put/multipart upload operation, update the    * relevant counters and gauges.    *    * @param success did the operation succeed?    * @param bytes bytes in the request.    */
DECL|method|incrementPutCompletedStatistics (boolean success, long bytes)
specifier|public
name|void
name|incrementPutCompletedStatistics
parameter_list|(
name|boolean
name|success
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT completed success={}; {} bytes"
argument_list|,
name|success
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_BYTES
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS_COMPLETED
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback for use in progress callbacks from put/multipart upload events.    * Increments those statistics which are expected to be updated during    * the ongoing upload operation.    * @param key key to file that is being written (for logging)    * @param bytes bytes successfully uploaded.    */
DECL|method|incrementPutProgressStatistics (String key, long bytes)
specifier|public
name|void
name|incrementPutProgressStatistics
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|PROGRESS
operator|.
name|debug
argument_list|(
literal|"PUT {}: {} bytes"
argument_list|,
name|key
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|statistics
operator|.
name|incrementBytesWritten
argument_list|(
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * A helper method to delete a list of keys on a s3-backend.    * Retry policy: retry untranslated; delete considered idempotent.    * @param keysToDelete collection of keys to delete on the s3-backend.    *        if empty, no request is made of the object store.    * @param clearKeys clears the keysToDelete-list after processing the list    *            when set to true    * @param deleteFakeDir indicates whether this is for deleting fake dirs    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted in a multiple object delete operation.    * @throws AmazonClientException amazon-layer failure.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|removeKeys (List<DeleteObjectsRequest.KeyVersion> keysToDelete, boolean clearKeys, boolean deleteFakeDir)
name|void
name|removeKeys
parameter_list|(
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
name|boolean
name|clearKeys
parameter_list|,
name|boolean
name|deleteFakeDir
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
if|if
condition|(
name|keysToDelete
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// exit fast if there are no keys to delete
return|return;
block|}
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|blockRootDelete
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|enableMultiObjectsDelete
condition|)
block|{
name|deleteObjects
argument_list|(
operator|new
name|DeleteObjectsRequest
argument_list|(
name|bucket
argument_list|)
operator|.
name|withKeys
argument_list|(
name|keysToDelete
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|deleteObject
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|deleteFakeDir
condition|)
block|{
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|instrumentation
operator|.
name|fakeDirsDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|clearKeys
condition|)
block|{
name|keysToDelete
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Delete a Path. This operation is at least {@code O(files)}, with    * added overheads to enumerate the path. It is also not atomic.    *    * @param f the path to delete.    * @param recursive if path is a directory and set to    * true, the directory is deleted else throws an exception. In    * case of a file the recursive can be set to either true or false.    * @return true if the path existed and then was deleted; false if there    * was no path in the first place, or the corner cases of root path deletion    * have surfaced.    * @throws IOException due to inability to delete a directory or file.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|delete (Path f, boolean recursive)
specifier|public
name|boolean
name|delete
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|innerDelete
argument_list|(
name|innerGetFileStatus
argument_list|(
name|f
argument_list|,
literal|true
argument_list|)
argument_list|,
name|recursive
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Couldn't delete {} - does not exist"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"delete"
argument_list|,
name|f
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Delete an object. See {@link #delete(Path, boolean)}.    *    * @param status fileStatus object    * @param recursive if path is a directory and set to    * true, the directory is deleted else throws an exception. In    * case of a file the recursive can be set to either true or false.    * @return true, except in the corner cases of root directory deletion    * @throws IOException due to inability to delete a directory or file.    * @throws AmazonClientException on failures inside the AWS SDK    */
annotation|@
name|Retries
operator|.
name|RetryMixed
DECL|method|innerDelete (S3AFileStatus status, boolean recursive)
specifier|private
name|boolean
name|innerDelete
parameter_list|(
name|S3AFileStatus
name|status
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|f
init|=
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Delete path {} - recursive {}"
argument_list|,
name|f
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"delete: Path is a directory: {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|status
operator|.
name|isEmptyDirectory
argument_list|()
operator|!=
name|Tristate
operator|.
name|UNKNOWN
argument_list|,
literal|"File status must have directory emptiness computed"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|key
operator|=
name|key
operator|+
literal|"/"
expr_stmt|;
block|}
if|if
condition|(
name|key
operator|.
name|equals
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
return|return
name|rejectRootDirectoryDelete
argument_list|(
name|status
argument_list|,
name|recursive
argument_list|)
return|;
block|}
if|if
condition|(
operator|!
name|recursive
operator|&&
name|status
operator|.
name|isEmptyDirectory
argument_list|()
operator|==
name|Tristate
operator|.
name|FALSE
condition|)
block|{
throw|throw
operator|new
name|PathIsNotEmptyDirectoryException
argument_list|(
name|f
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|status
operator|.
name|isEmptyDirectory
argument_list|()
operator|==
name|Tristate
operator|.
name|TRUE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting fake empty directory {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
comment|// HADOOP-13761 s3guard: retries here
name|deleteObjectAtPath
argument_list|(
name|f
argument_list|,
name|key
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting objects for directory prefix {} to delete"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|S3ListRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|S3ListResult
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keys
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|objects
operator|.
name|getObjectSummaries
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|objects
operator|.
name|getObjectSummaries
argument_list|()
control|)
block|{
name|keys
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got object to delete {}"
argument_list|,
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|keys
operator|.
name|size
argument_list|()
operator|==
name|MAX_ENTRIES_TO_DELETE
condition|)
block|{
name|removeKeys
argument_list|(
name|keys
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|objects
operator|.
name|isTruncated
argument_list|()
condition|)
block|{
name|objects
operator|=
name|continueListObjects
argument_list|(
name|request
argument_list|,
name|objects
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|keys
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// TODO: HADOOP-13761 S3Guard: retries
name|removeKeys
argument_list|(
name|keys
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
block|}
name|metadataStore
operator|.
name|deleteSubtree
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"delete: Path is a file"
argument_list|)
expr_stmt|;
name|deleteObjectAtPath
argument_list|(
name|f
argument_list|,
name|key
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|maybeCreateFakeParentDirectory
argument_list|(
name|f
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Implements the specific logic to reject root directory deletion.    * The caller must return the result of this call, rather than    * attempt to continue with the delete operation: deleting root    * directories is never allowed. This method simply implements    * the policy of when to return an exit code versus raise an exception.    * @param status filesystem status    * @param recursive recursive flag from command    * @return a return code for the operation    * @throws PathIOException if the operation was explicitly rejected.    */
DECL|method|rejectRootDirectoryDelete (S3AFileStatus status, boolean recursive)
specifier|private
name|boolean
name|rejectRootDirectoryDelete
parameter_list|(
name|S3AFileStatus
name|status
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"s3a delete the {} root directory of {}"
argument_list|,
name|bucket
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
name|boolean
name|emptyRoot
init|=
name|status
operator|.
name|isEmptyDirectory
argument_list|()
operator|==
name|Tristate
operator|.
name|TRUE
decl_stmt|;
if|if
condition|(
name|emptyRoot
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|recursive
condition|)
block|{
return|return
literal|false
return|;
block|}
else|else
block|{
comment|// reject
throw|throw
operator|new
name|PathIOException
argument_list|(
name|bucket
argument_list|,
literal|"Cannot delete root path"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create a fake directory if required.    * That is: it is not the root path and the path does not exist.    * Retry policy: retrying; untranslated.    * @param f path to create    * @throws IOException IO problem    * @throws AmazonClientException untranslated AWS client problem    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createFakeDirectoryIfNecessary (Path f)
specifier|private
name|void
name|createFakeDirectoryIfNecessary
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|s3Exists
argument_list|(
name|f
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating new fake directory at {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a fake parent directory if required.    * That is: it parent is not the root path and does not yet exist.    * @param path whose parent is created if needed.    * @throws IOException IO problem    * @throws AmazonClientException untranslated AWS client problem    */
DECL|method|maybeCreateFakeParentDirectory (Path path)
name|void
name|maybeCreateFakeParentDirectory
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|createFakeDirectoryIfNecessary
argument_list|(
name|parent
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    *         IOException see specific implementation    */
DECL|method|listStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|listStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|once
argument_list|(
literal|"listStatus"
argument_list|,
name|f
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
name|innerListStatus
argument_list|(
name|f
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    * @throws IOException due to an IO problem.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerListStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|innerListStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"List status for path: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_STATUS
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|result
decl_stmt|;
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|key
operator|=
name|key
operator|+
literal|'/'
expr_stmt|;
block|}
name|DirListingMetadata
name|dirMeta
init|=
name|metadataStore
operator|.
name|listChildren
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|allowAuthoritative
operator|&&
name|dirMeta
operator|!=
literal|null
operator|&&
name|dirMeta
operator|.
name|isAuthoritative
argument_list|()
condition|)
block|{
return|return
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|dirMeta
argument_list|)
return|;
block|}
name|S3ListRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listStatus: doing listObjects for directory {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|Listing
operator|.
name|FileStatusListingIterator
name|files
init|=
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|request
argument_list|,
name|ACCEPT_ALL
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|getBatchSize
argument_list|()
argument_list|)
expr_stmt|;
while|while
condition|(
name|files
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|files
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|S3Guard
operator|.
name|dirListingUnion
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|result
argument_list|,
name|dirMeta
argument_list|,
name|allowAuthoritative
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding: rd (not a dir): {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|stats
init|=
operator|new
name|FileStatus
index|[
literal|1
index|]
decl_stmt|;
name|stats
index|[
literal|0
index|]
operator|=
name|fileStatus
expr_stmt|;
return|return
name|stats
return|;
block|}
block|}
comment|/**    * Create a {@code ListObjectsRequest} request against this bucket,    * with the maximum keys returned in a query set by {@link #maxKeys}.    * @param key key for request    * @param delimiter any delimiter    * @return the request    */
annotation|@
name|VisibleForTesting
DECL|method|createListObjectsRequest (String key, String delimiter)
name|S3ListRequest
name|createListObjectsRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|delimiter
parameter_list|)
block|{
return|return
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
name|delimiter
argument_list|,
literal|null
argument_list|)
return|;
block|}
DECL|method|createListObjectsRequest (String key, String delimiter, Integer overrideMaxKeys)
specifier|private
name|S3ListRequest
name|createListObjectsRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|delimiter
parameter_list|,
name|Integer
name|overrideMaxKeys
parameter_list|)
block|{
if|if
condition|(
operator|!
name|useListV1
condition|)
block|{
name|ListObjectsV2Request
name|request
init|=
operator|new
name|ListObjectsV2Request
argument_list|()
operator|.
name|withBucketName
argument_list|(
name|bucket
argument_list|)
operator|.
name|withMaxKeys
argument_list|(
name|maxKeys
argument_list|)
operator|.
name|withPrefix
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|delimiter
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setDelimiter
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|overrideMaxKeys
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setMaxKeys
argument_list|(
name|overrideMaxKeys
argument_list|)
expr_stmt|;
block|}
return|return
name|S3ListRequest
operator|.
name|v2
argument_list|(
name|request
argument_list|)
return|;
block|}
else|else
block|{
name|ListObjectsRequest
name|request
init|=
operator|new
name|ListObjectsRequest
argument_list|()
decl_stmt|;
name|request
operator|.
name|setBucketName
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
name|request
operator|.
name|setMaxKeys
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
name|request
operator|.
name|setPrefix
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|delimiter
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setDelimiter
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|overrideMaxKeys
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setMaxKeys
argument_list|(
name|overrideMaxKeys
argument_list|)
expr_stmt|;
block|}
return|return
name|S3ListRequest
operator|.
name|v1
argument_list|(
name|request
argument_list|)
return|;
block|}
block|}
comment|/**    * Set the current working directory for the given file system. All relative    * paths will be resolved relative to it.    *    * @param newDir the current working directory.    */
DECL|method|setWorkingDirectory (Path newDir)
specifier|public
name|void
name|setWorkingDirectory
parameter_list|(
name|Path
name|newDir
parameter_list|)
block|{
name|workingDir
operator|=
name|newDir
expr_stmt|;
block|}
comment|/**    * Get the current working directory for the given file system.    * @return the directory pathname    */
DECL|method|getWorkingDirectory ()
specifier|public
name|Path
name|getWorkingDirectory
parameter_list|()
block|{
return|return
name|workingDir
return|;
block|}
comment|/**    * Get the username of the FS.    * @return the short name of the user who instantiated the FS    */
DECL|method|getUsername ()
specifier|public
name|String
name|getUsername
parameter_list|()
block|{
return|return
name|username
return|;
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories. Has the semantics of Unix {@code 'mkdir -p'}.    * Existence of the directory hierarchy is not an error.    * @param path path to create    * @param permission to apply to f    * @return true if a directory was created or already existed    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    */
comment|// TODO: If we have created an empty file at /foo/bar and we then call
comment|// mkdirs for /foo/bar/baz/roo what happens to the empty file /foo/bar/?
DECL|method|mkdirs (Path path, FsPermission permission)
specifier|public
name|boolean
name|mkdirs
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
block|{
try|try
block|{
return|return
name|innerMkdirs
argument_list|(
name|path
argument_list|,
name|permission
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"innerMkdirs"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories.    * See {@link #mkdirs(Path, FsPermission)}    * @param p path to create    * @param permission to apply to f    * @return true if a directory was created or already existed    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerMkdirs (Path p, FsPermission permission)
specifier|private
name|boolean
name|innerMkdirs
parameter_list|(
name|Path
name|p
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|Path
name|f
init|=
name|qualify
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Making directory: {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_MKDIRS
argument_list|)
expr_stmt|;
name|FileStatus
name|fileStatus
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|metadataStoreDirs
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|metadataStoreDirs
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Path is a file: "
operator|+
name|f
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// Walk path to root, ensuring closest ancestor is a directory, not file
name|Path
name|fPart
init|=
name|f
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|metadataStoreDirs
operator|!=
literal|null
condition|)
block|{
name|metadataStoreDirs
operator|.
name|add
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
name|fPart
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|fPart
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Can't make directory for path '%s' since it is a file."
argument_list|,
name|fPart
argument_list|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
comment|// We create all missing directories in MetadataStore; it does not
comment|// infer directories exist by prefix like S3.
if|if
condition|(
name|metadataStoreDirs
operator|!=
literal|null
condition|)
block|{
name|metadataStoreDirs
operator|.
name|add
argument_list|(
name|fPart
argument_list|)
expr_stmt|;
block|}
block|}
name|fPart
operator|=
name|fPart
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|S3Guard
operator|.
name|makeDirsOrdered
argument_list|(
name|metadataStore
argument_list|,
name|metadataStoreDirs
argument_list|,
name|username
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// this is complicated because getParent(a/b/c/) returns a/b/c, but
comment|// we want a/b. See HADOOP-14428 for more details.
name|deleteUnnecessaryFakeDirectories
argument_list|(
operator|new
name|Path
argument_list|(
name|f
operator|.
name|toString
argument_list|()
argument_list|)
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
comment|/**    * Return a file status object that represents the path.    * @param f The path we want information from    * @return a FileStatus object    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getFileStatus (final Path f)
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|innerGetFileStatus
argument_list|(
name|f
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Internal version of {@link #getFileStatus(Path)}.    * @param f The path we want information from    * @param needEmptyDirectoryFlag if true, implementation will calculate    *        a TRUE or FALSE value for {@link S3AFileStatus#isEmptyDirectory()}    * @return a S3AFileStatus object    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerGetFileStatus (final Path f, boolean needEmptyDirectoryFlag)
name|S3AFileStatus
name|innerGetFileStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
name|boolean
name|needEmptyDirectoryFlag
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GET_FILE_STATUS
argument_list|)
expr_stmt|;
specifier|final
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting path status for {}  ({})"
argument_list|,
name|path
argument_list|,
name|key
argument_list|)
expr_stmt|;
comment|// Check MetadataStore, if any.
name|PathMetadata
name|pm
init|=
name|metadataStore
operator|.
name|get
argument_list|(
name|path
argument_list|,
name|needEmptyDirectoryFlag
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
init|=
name|Collections
operator|.
name|EMPTY_SET
decl_stmt|;
if|if
condition|(
name|pm
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|pm
operator|.
name|isDeleted
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Path "
operator|+
name|f
operator|+
literal|" is recorded as "
operator|+
literal|"deleted by S3Guard"
argument_list|)
throw|;
block|}
name|FileStatus
name|msStatus
init|=
name|pm
operator|.
name|getFileStatus
argument_list|()
decl_stmt|;
if|if
condition|(
name|needEmptyDirectoryFlag
operator|&&
name|msStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|pm
operator|.
name|isEmptyDirectory
argument_list|()
operator|!=
name|Tristate
operator|.
name|UNKNOWN
condition|)
block|{
comment|// We have a definitive true / false from MetadataStore, we are done.
return|return
name|S3AFileStatus
operator|.
name|fromFileStatus
argument_list|(
name|msStatus
argument_list|,
name|pm
operator|.
name|isEmptyDirectory
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
name|DirListingMetadata
name|children
init|=
name|metadataStore
operator|.
name|listChildren
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|tombstones
operator|=
name|children
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"MetadataStore doesn't know if dir is empty, using S3."
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Either this is not a directory, or we don't care if it is empty
return|return
name|S3AFileStatus
operator|.
name|fromFileStatus
argument_list|(
name|msStatus
argument_list|,
name|pm
operator|.
name|isEmptyDirectory
argument_list|()
argument_list|)
return|;
block|}
comment|// If the metadata store has no children for it and it's not listed in
comment|// S3 yet, we'll assume the empty directory is true;
name|S3AFileStatus
name|s3FileStatus
decl_stmt|;
try|try
block|{
name|s3FileStatus
operator|=
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|tombstones
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
return|return
name|S3AFileStatus
operator|.
name|fromFileStatus
argument_list|(
name|msStatus
argument_list|,
name|Tristate
operator|.
name|TRUE
argument_list|)
return|;
block|}
comment|// entry was found, save in S3Guard
return|return
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|s3FileStatus
argument_list|,
name|instrumentation
argument_list|)
return|;
block|}
else|else
block|{
comment|// there was no entry in S3Guard
comment|// retrieve the data and update the metadata store in the process.
return|return
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|tombstones
argument_list|)
argument_list|,
name|instrumentation
argument_list|)
return|;
block|}
block|}
comment|/**    * Raw {@code getFileStatus} that talks direct to S3.    * Used to implement {@link #innerGetFileStatus(Path, boolean)},    * and for direct management of empty directory blobs.    * Retry policy: retry translated.    * @param path Qualified path    * @param key  Key string for the path    * @return Status    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|s3GetFileStatus (final Path path, String key, Set<Path> tombstones)
specifier|private
name|S3AFileStatus
name|s3GetFileStatus
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
name|String
name|key
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: normal file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// Necessary?
if|if
condition|(
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|String
name|newKey
init|=
name|key
operator|+
literal|"/"
decl_stmt|;
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|newKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|newKey
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file (with /): fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file (with /): real file? should not happen: {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
try|try
block|{
name|key
operator|=
name|maybeAddTrailingSlash
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|S3ListRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|S3ListResult
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|prefixes
init|=
name|objects
operator|.
name|getCommonPrefixes
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|S3ObjectSummary
argument_list|>
name|summaries
init|=
name|objects
operator|.
name|getObjectSummaries
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|isEmptyOfKeys
argument_list|(
name|prefixes
argument_list|,
name|tombstones
argument_list|)
operator|||
operator|!
name|isEmptyOfObjects
argument_list|(
name|summaries
argument_list|,
name|tombstones
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found path as directory (with /): {}/{}"
argument_list|,
name|prefixes
operator|.
name|size
argument_list|()
argument_list|,
name|summaries
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|summaries
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Summary: {} {}"
argument_list|,
name|summary
operator|.
name|getKey
argument_list|()
argument_list|,
name|summary
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|prefix
range|:
name|prefixes
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Prefix: {}"
argument_list|,
name|prefix
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|FALSE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found root directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|key
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|key
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Not Found: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No such file or directory: "
operator|+
name|path
argument_list|)
throw|;
block|}
comment|/**    * Helper function to determine if a collection of paths is empty    * after accounting for tombstone markers (if provided).    * @param keys Collection of path (prefixes / directories or keys).    * @param tombstones Set of tombstone markers, or null if not applicable.    * @return false if summaries contains objects not accounted for by    * tombstones.    */
DECL|method|isEmptyOfKeys (Collection<String> keys, Set<Path> tombstones)
specifier|private
name|boolean
name|isEmptyOfKeys
parameter_list|(
name|Collection
argument_list|<
name|String
argument_list|>
name|keys
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
block|{
if|if
condition|(
name|tombstones
operator|==
literal|null
condition|)
block|{
return|return
name|keys
operator|.
name|isEmpty
argument_list|()
return|;
block|}
for|for
control|(
name|String
name|key
range|:
name|keys
control|)
block|{
name|Path
name|qualified
init|=
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|tombstones
operator|.
name|contains
argument_list|(
name|qualified
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Helper function to determine if a collection of object summaries is empty    * after accounting for tombstone markers (if provided).    * @param summaries Collection of objects as returned by listObjects.    * @param tombstones Set of tombstone markers, or null if not applicable.    * @return false if summaries contains objects not accounted for by    * tombstones.    */
DECL|method|isEmptyOfObjects (Collection<S3ObjectSummary> summaries, Set<Path> tombstones)
specifier|private
name|boolean
name|isEmptyOfObjects
parameter_list|(
name|Collection
argument_list|<
name|S3ObjectSummary
argument_list|>
name|summaries
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
block|{
if|if
condition|(
name|tombstones
operator|==
literal|null
condition|)
block|{
return|return
name|summaries
operator|.
name|isEmpty
argument_list|()
return|;
block|}
name|Collection
argument_list|<
name|String
argument_list|>
name|stringCollection
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|summaries
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|summaries
control|)
block|{
name|stringCollection
operator|.
name|add
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|isEmptyOfKeys
argument_list|(
name|stringCollection
argument_list|,
name|tombstones
argument_list|)
return|;
block|}
comment|/**    * Raw version of {@link FileSystem#exists(Path)} which uses S3 only:    * S3Guard MetadataStore, if any, will be skipped.    * Retry policy: retrying; translated.    * @return true if path exists in S3    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|s3Exists (final Path f)
specifier|private
name|boolean
name|s3Exists
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
try|try
block|{
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src path    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false    * @throws AmazonClientException failure in the AWS SDK    */
annotation|@
name|Override
DECL|method|copyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|public
name|void
name|copyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
name|innerCopyFromLocalFile
argument_list|(
name|delSrc
argument_list|,
name|overwrite
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src Source path: must be on local filesystem    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false, or if the destination is a directory.    * @throws FileNotFoundException if the source file does not exit    * @throws AmazonClientException failure in the AWS SDK    * @throws IllegalArgumentException if the source path is not on the local FS    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerCopyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|private
name|void
name|innerCopyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_COPY_FROM_LOCAL_FILE
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copying local file from {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Since we have a local file, we don't need to stream into a temporary file
name|LocalFileSystem
name|local
init|=
name|getLocal
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|File
name|srcfile
init|=
name|local
operator|.
name|pathToFile
argument_list|(
name|src
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|srcfile
operator|.
name|exists
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No file: "
operator|+
name|src
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|srcfile
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Not a file: "
operator|+
name|src
argument_list|)
throw|;
block|}
try|try
block|{
name|FileStatus
name|status
init|=
name|getFileStatus
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|status
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|dst
operator|+
literal|" exists and is not a file"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|overwrite
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|dst
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// no destination, all is well
block|}
specifier|final
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|(
name|srcfile
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|Progressable
name|progress
init|=
literal|null
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|key
argument_list|,
name|om
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"copyFromLocalFile("
operator|+
name|src
operator|+
literal|")"
argument_list|,
name|dst
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|executePut
argument_list|(
name|putObjectRequest
argument_list|,
name|progress
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|delSrc
condition|)
block|{
name|local
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Execute a PUT via the transfer manager, blocking for completion,    * updating the metastore afterwards.    * If the waiting for completion is interrupted, the upload will be    * aborted before an {@code InterruptedIOException} is thrown.    * @param putObjectRequest request    * @param progress optional progress callback    * @return the upload result    * @throws InterruptedIOException if the blocking was interrupted.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|executePut (PutObjectRequest putObjectRequest, Progressable progress)
name|UploadResult
name|executePut
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|InterruptedIOException
block|{
name|String
name|key
init|=
name|putObjectRequest
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|UploadInfo
name|info
init|=
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|Upload
name|upload
init|=
name|info
operator|.
name|getUpload
argument_list|()
decl_stmt|;
name|ProgressableProgressListener
name|listener
init|=
operator|new
name|ProgressableProgressListener
argument_list|(
name|this
argument_list|,
name|key
argument_list|,
name|upload
argument_list|,
name|progress
argument_list|)
decl_stmt|;
name|upload
operator|.
name|addProgressListener
argument_list|(
name|listener
argument_list|)
expr_stmt|;
name|UploadResult
name|result
init|=
name|waitForUploadCompletion
argument_list|(
name|key
argument_list|,
name|info
argument_list|)
decl_stmt|;
name|listener
operator|.
name|uploadCompleted
argument_list|()
expr_stmt|;
comment|// post-write actions
name|finishedWrite
argument_list|(
name|key
argument_list|,
name|info
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * Wait for an upload to complete.    * If the waiting for completion is interrupted, the upload will be    * aborted before an {@code InterruptedIOException} is thrown.    * @param upload upload to wait for    * @param key destination key    * @return the upload result    * @throws InterruptedIOException if the blocking was interrupted.    */
DECL|method|waitForUploadCompletion (String key, UploadInfo uploadInfo)
name|UploadResult
name|waitForUploadCompletion
parameter_list|(
name|String
name|key
parameter_list|,
name|UploadInfo
name|uploadInfo
parameter_list|)
throws|throws
name|InterruptedIOException
block|{
name|Upload
name|upload
init|=
name|uploadInfo
operator|.
name|getUpload
argument_list|()
decl_stmt|;
try|try
block|{
name|UploadResult
name|result
init|=
name|upload
operator|.
name|waitForUploadResult
argument_list|()
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|uploadInfo
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Interrupted: aborting upload"
argument_list|)
expr_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|uploadInfo
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|upload
operator|.
name|abort
argument_list|()
expr_stmt|;
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted in PUT to "
operator|+
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
argument_list|)
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Close the filesystem. This shuts down all transfers.    * @throws IOException IO problem    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
comment|// already closed
return|return;
block|}
try|try
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|transfers
operator|!=
literal|null
condition|)
block|{
name|transfers
operator|.
name|shutdownNow
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|transfers
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|metadataStore
operator|!=
literal|null
condition|)
block|{
name|metadataStore
operator|.
name|close
argument_list|()
expr_stmt|;
name|metadataStore
operator|=
literal|null
expr_stmt|;
block|}
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|instrumentation
argument_list|)
expr_stmt|;
name|instrumentation
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Override getCanonicalServiceName because we don't support token in S3A.    */
annotation|@
name|Override
DECL|method|getCanonicalServiceName ()
specifier|public
name|String
name|getCanonicalServiceName
parameter_list|()
block|{
comment|// Does not support Token
return|return
literal|null
return|;
block|}
comment|/**    * Copy a single object in the bucket via a COPY operation.    * @param srcKey source object path    * @param dstKey destination object path    * @param size object size    * @throws AmazonClientException on failures inside the AWS SDK    * @throws InterruptedIOException the operation was interrupted    * @throws IOException Other IO problems    */
DECL|method|copyFile (String srcKey, String dstKey, long size)
specifier|private
name|void
name|copyFile
parameter_list|(
name|String
name|srcKey
parameter_list|,
name|String
name|dstKey
parameter_list|,
name|long
name|size
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedIOException
throws|,
name|AmazonClientException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"copyFile {} -> {} "
argument_list|,
name|srcKey
argument_list|,
name|dstKey
argument_list|)
expr_stmt|;
try|try
block|{
name|ObjectMetadata
name|srcom
init|=
name|getObjectMetadata
argument_list|(
name|srcKey
argument_list|)
decl_stmt|;
name|ObjectMetadata
name|dstom
init|=
name|cloneObjectMetadata
argument_list|(
name|srcom
argument_list|)
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
name|CopyObjectRequest
name|copyObjectRequest
init|=
operator|new
name|CopyObjectRequest
argument_list|(
name|bucket
argument_list|,
name|srcKey
argument_list|,
name|bucket
argument_list|,
name|dstKey
argument_list|)
decl_stmt|;
name|setOptionalCopyObjectRequestParameters
argument_list|(
name|copyObjectRequest
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setCannedAccessControlList
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setNewObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
name|ProgressListener
name|progressListener
init|=
operator|new
name|ProgressListener
argument_list|()
block|{
specifier|public
name|void
name|progressChanged
parameter_list|(
name|ProgressEvent
name|progressEvent
parameter_list|)
block|{
switch|switch
condition|(
name|progressEvent
operator|.
name|getEventType
argument_list|()
condition|)
block|{
case|case
name|TRANSFER_PART_COMPLETED_EVENT
case|:
name|incrementWriteOperations
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
block|}
decl_stmt|;
name|Copy
name|copy
init|=
name|transfers
operator|.
name|copy
argument_list|(
name|copyObjectRequest
argument_list|)
decl_stmt|;
name|copy
operator|.
name|addProgressListener
argument_list|(
name|progressListener
argument_list|)
expr_stmt|;
try|try
block|{
name|copy
operator|.
name|waitForCopyResult
argument_list|()
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|instrumentation
operator|.
name|filesCopied
argument_list|(
literal|1
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted copying "
operator|+
name|srcKey
operator|+
literal|" to "
operator|+
name|dstKey
operator|+
literal|", cancelling"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"copyFile("
operator|+
name|srcKey
operator|+
literal|", "
operator|+
name|dstKey
operator|+
literal|")"
argument_list|,
name|srcKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
DECL|method|setOptionalMultipartUploadRequestParameters ( InitiateMultipartUploadRequest req)
specifier|protected
name|void
name|setOptionalMultipartUploadRequestParameters
parameter_list|(
name|InitiateMultipartUploadRequest
name|req
parameter_list|)
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|req
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
comment|//at the moment, only supports copy using the same key
name|req
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
comment|/**    * Initiate a multipart upload from the preconfigured request.    * Retry policy: none + untranslated.    * @param request request to initiate    * @return the result of the call    * @throws AmazonClientException on failures inside the AWS SDK    * @throws IOException Other IO problems    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|initiateMultipartUpload ( InitiateMultipartUploadRequest request)
name|InitiateMultipartUploadResult
name|initiateMultipartUpload
parameter_list|(
name|InitiateMultipartUploadRequest
name|request
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initiate multipart upload to {}"
argument_list|,
name|request
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_MULTIPART_UPLOAD_INITIATED
argument_list|)
expr_stmt|;
return|return
name|getAmazonS3Client
argument_list|()
operator|.
name|initiateMultipartUpload
argument_list|(
name|request
argument_list|)
return|;
block|}
DECL|method|setOptionalCopyObjectRequestParameters ( CopyObjectRequest copyObjectRequest)
specifier|protected
name|void
name|setOptionalCopyObjectRequestParameters
parameter_list|(
name|CopyObjectRequest
name|copyObjectRequest
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|copyObjectRequest
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
comment|//at the moment, only supports copy using the same key
name|SSECustomerKey
name|customerKey
init|=
name|generateSSECustomerKey
argument_list|()
decl_stmt|;
name|copyObjectRequest
operator|.
name|setSourceSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setDestinationSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalPutRequestParameters (PutObjectRequest request)
specifier|private
name|void
name|setOptionalPutRequestParameters
parameter_list|(
name|PutObjectRequest
name|request
parameter_list|)
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|request
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|request
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalObjectMetadata (ObjectMetadata metadata)
specifier|private
name|void
name|setOptionalObjectMetadata
parameter_list|(
name|ObjectMetadata
name|metadata
parameter_list|)
block|{
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_S3
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
condition|)
block|{
name|metadata
operator|.
name|setSSEAlgorithm
argument_list|(
name|serverSideEncryptionAlgorithm
operator|.
name|getMethod
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|generateSSEAwsKeyParams ()
specifier|private
name|SSEAwsKeyManagementParams
name|generateSSEAwsKeyParams
parameter_list|()
block|{
comment|//Use specified key, otherwise default to default master aws/s3 key by AWS
name|SSEAwsKeyManagementParams
name|sseAwsKeyManagementParams
init|=
operator|new
name|SSEAwsKeyManagementParams
argument_list|()
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|sseAwsKeyManagementParams
operator|=
operator|new
name|SSEAwsKeyManagementParams
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sseAwsKeyManagementParams
return|;
block|}
DECL|method|generateSSECustomerKey ()
specifier|private
name|SSECustomerKey
name|generateSSECustomerKey
parameter_list|()
block|{
name|SSECustomerKey
name|customerKey
init|=
operator|new
name|SSECustomerKey
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|customerKey
return|;
block|}
comment|/**    * Perform post-write actions.    * This operation MUST be called after any PUT/multipart PUT completes    * successfully.    * This includes    *<ol>    *<li>Calling {@link #deleteUnnecessaryFakeDirectories(Path)}</li>    *<li>Updating any metadata store with details on the newly created    *   object.</li>    *</ol>    * @param key key written to    * @param length  total length of file written    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|Retries
operator|.
name|RetryTranslated
argument_list|(
literal|"Exceptions are swallowed"
argument_list|)
DECL|method|finishedWrite (String key, long length)
name|void
name|finishedWrite
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|length
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished write to {}, len {}"
argument_list|,
name|key
argument_list|,
name|length
argument_list|)
expr_stmt|;
name|Path
name|p
init|=
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|p
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|length
operator|>=
literal|0
argument_list|,
literal|"content length is negative"
argument_list|)
expr_stmt|;
comment|// See note about failure semantics in S3Guard documentation
try|try
block|{
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|S3Guard
operator|.
name|addAncestors
argument_list|(
name|metadataStore
argument_list|,
name|p
argument_list|,
name|username
argument_list|)
expr_stmt|;
name|S3AFileStatus
name|status
init|=
name|createUploadFileStatus
argument_list|(
name|p
argument_list|,
name|S3AUtils
operator|.
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|length
argument_list|)
argument_list|,
name|length
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|p
argument_list|)
argument_list|,
name|username
argument_list|)
decl_stmt|;
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|status
argument_list|,
name|instrumentation
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"S3Guard: Error updating MetadataStore for write to {}:"
argument_list|,
name|key
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Delete mock parent directories which are no longer needed.    * Retry policy: retrying; exceptions swallowed.    * @param path path    */
annotation|@
name|Retries
operator|.
name|RetryRaw
argument_list|(
literal|"Exceptions are swallowed"
argument_list|)
DECL|method|deleteUnnecessaryFakeDirectories (Path path)
specifier|private
name|void
name|deleteUnnecessaryFakeDirectories
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|key
operator|=
operator|(
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
operator|)
condition|?
name|key
else|:
operator|(
name|key
operator|+
literal|"/"
operator|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"To delete unnecessary fake directory {} for {}"
argument_list|,
name|key
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|keysToRemove
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|path
operator|=
name|path
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|removeKeys
argument_list|(
name|keysToRemove
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
decl||
name|IOException
name|e
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|kv
range|:
name|keysToRemove
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|kv
operator|.
name|getKey
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"While deleting keys {} "
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Create a fake directory, always ending in "/".    * Retry policy: retrying; translated.    * @param objectName name of directory object.    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createFakeDirectory (final String objectName)
specifier|private
name|void
name|createFakeDirectory
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|objectName
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|createEmptyObject
argument_list|(
name|objectName
operator|+
literal|"/"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|createEmptyObject
argument_list|(
name|objectName
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Used to create an empty file that represents an empty directory.    * Retry policy: retrying; translated.    * @param objectName object to create    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createEmptyObject (final String objectName)
specifier|private
name|void
name|createEmptyObject
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|InputStream
name|im
init|=
operator|new
name|InputStream
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|objectName
argument_list|,
name|newObjectMetadata
argument_list|(
literal|0L
argument_list|)
argument_list|,
name|im
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"PUT 0-byte object "
argument_list|,
name|objectName
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|putObjectDirect
argument_list|(
name|putObjectRequest
argument_list|)
argument_list|)
expr_stmt|;
name|incrementPutProgressStatistics
argument_list|(
name|objectName
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|directoryCreated
argument_list|()
expr_stmt|;
block|}
comment|/**    * Creates a copy of the passed {@link ObjectMetadata}.    * Does so without using the {@link ObjectMetadata#clone()} method,    * to avoid copying unnecessary headers.    * @param source the {@link ObjectMetadata} to copy    * @return a copy of {@link ObjectMetadata} with only relevant attributes    */
DECL|method|cloneObjectMetadata (ObjectMetadata source)
specifier|private
name|ObjectMetadata
name|cloneObjectMetadata
parameter_list|(
name|ObjectMetadata
name|source
parameter_list|)
block|{
comment|// This approach may be too brittle, especially if
comment|// in future there are new attributes added to ObjectMetadata
comment|// that we do not explicitly call to set here
name|ObjectMetadata
name|ret
init|=
name|newObjectMetadata
argument_list|(
name|source
operator|.
name|getContentLength
argument_list|()
argument_list|)
decl_stmt|;
comment|// Possibly null attributes
comment|// Allowing nulls to pass breaks it during later use
if|if
condition|(
name|source
operator|.
name|getCacheControl
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setCacheControl
argument_list|(
name|source
operator|.
name|getCacheControl
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentDisposition
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentDisposition
argument_list|(
name|source
operator|.
name|getContentDisposition
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentEncoding
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentEncoding
argument_list|(
name|source
operator|.
name|getContentEncoding
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentMD5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentMD5
argument_list|(
name|source
operator|.
name|getContentMD5
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentType
argument_list|(
name|source
operator|.
name|getContentType
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTime
argument_list|(
name|source
operator|.
name|getExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTimeRuleId
argument_list|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setHttpExpiresDate
argument_list|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getLastModified
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setLastModified
argument_list|(
name|source
operator|.
name|getLastModified
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setOngoingRestore
argument_list|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setRestoreExpirationTime
argument_list|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSEAlgorithm
argument_list|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerAlgorithm
argument_list|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerKeyMd5
argument_list|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|source
operator|.
name|getUserMetadata
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|ret
operator|.
name|addUserMetadata
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * Return the number of bytes that large input files should be optimally    * be split into to minimize I/O time.    * @deprecated use {@link #getDefaultBlockSize(Path)} instead    */
annotation|@
name|Deprecated
DECL|method|getDefaultBlockSize ()
specifier|public
name|long
name|getDefaultBlockSize
parameter_list|()
block|{
return|return
name|getConf
argument_list|()
operator|.
name|getLongBytes
argument_list|(
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"S3AFileSystem{"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"uri="
argument_list|)
operator|.
name|append
argument_list|(
name|uri
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", workingDir="
argument_list|)
operator|.
name|append
argument_list|(
name|workingDir
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", inputPolicy="
argument_list|)
operator|.
name|append
argument_list|(
name|inputPolicy
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", partSize="
argument_list|)
operator|.
name|append
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", enableMultiObjectsDelete="
argument_list|)
operator|.
name|append
argument_list|(
name|enableMultiObjectsDelete
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", maxKeys="
argument_list|)
operator|.
name|append
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
if|if
condition|(
name|cannedACL
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", cannedACL="
argument_list|)
operator|.
name|append
argument_list|(
name|cannedACL
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", readAhead="
argument_list|)
operator|.
name|append
argument_list|(
name|readAhead
argument_list|)
expr_stmt|;
if|if
condition|(
name|getConf
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", blockSize="
argument_list|)
operator|.
name|append
argument_list|(
name|getDefaultBlockSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", multiPartThreshold="
argument_list|)
operator|.
name|append
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
if|if
condition|(
name|serverSideEncryptionAlgorithm
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", serverSideEncryptionAlgorithm='"
argument_list|)
operator|.
name|append
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|.
name|append
argument_list|(
literal|'\''
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|blockFactory
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", blockFactory="
argument_list|)
operator|.
name|append
argument_list|(
name|blockFactory
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", metastore="
argument_list|)
operator|.
name|append
argument_list|(
name|metadataStore
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", authoritative="
argument_list|)
operator|.
name|append
argument_list|(
name|allowAuthoritative
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", useListV1="
argument_list|)
operator|.
name|append
argument_list|(
name|useListV1
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", magicCommitter="
argument_list|)
operator|.
name|append
argument_list|(
name|isMagicCommitEnabled
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", boundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|boundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", unboundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", statistics {"
argument_list|)
operator|.
name|append
argument_list|(
name|statistics
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
if|if
condition|(
name|instrumentation
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", metrics {"
argument_list|)
operator|.
name|append
argument_list|(
name|instrumentation
operator|.
name|dump
argument_list|(
literal|"{"
argument_list|,
literal|"="
argument_list|,
literal|"} "
argument_list|,
literal|true
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Get the partition size for multipart operations.    * @return the value as set during initialization    */
DECL|method|getPartitionSize ()
specifier|public
name|long
name|getPartitionSize
parameter_list|()
block|{
return|return
name|partSize
return|;
block|}
comment|/**    * Get the threshold for multipart files.    * @return the value as set during initialization    */
DECL|method|getMultiPartThreshold ()
specifier|public
name|long
name|getMultiPartThreshold
parameter_list|()
block|{
return|return
name|multiPartThreshold
return|;
block|}
comment|/**    * Get the maximum key count.    * @return a value, valid after initialization    */
DECL|method|getMaxKeys ()
name|int
name|getMaxKeys
parameter_list|()
block|{
return|return
name|maxKeys
return|;
block|}
comment|/**    * Is magic commit enabled?    * @return true if magic commit support is turned on.    */
DECL|method|isMagicCommitEnabled ()
specifier|public
name|boolean
name|isMagicCommitEnabled
parameter_list|()
block|{
return|return
name|committerIntegration
operator|.
name|isMagicCommitEnabled
argument_list|()
return|;
block|}
comment|/**    * Predicate: is a path a magic commit path?    * True if magic commit is enabled and the path qualifies as special.    * @param path path to examine    * @return true if the path is or is under a magic directory    */
DECL|method|isMagicCommitPath (Path path)
specifier|public
name|boolean
name|isMagicCommitPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|committerIntegration
operator|.
name|isMagicCommitPath
argument_list|(
name|path
argument_list|)
return|;
block|}
comment|/**    * Increments the statistic {@link Statistic#INVOCATION_GLOB_STATUS}.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus (Path pathPattern)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
name|Path
name|pathPattern
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GLOB_STATUS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|globStatus
argument_list|(
name|pathPattern
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus (Path pathPattern, PathFilter filter)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
name|Path
name|pathPattern
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GLOB_STATUS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|globStatus
argument_list|(
name|pathPattern
argument_list|,
name|filter
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|exists (Path f)
specifier|public
name|boolean
name|exists
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_EXISTS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|exists
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isDirectory (Path f)
specifier|public
name|boolean
name|isDirectory
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_IS_DIRECTORY
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isDirectory
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isFile (Path f)
specifier|public
name|boolean
name|isFile
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_IS_FILE
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isFile
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    *    * This implementation is optimized for S3, which can do a bulk listing    * off all entries under a path in one single operation. Thus there is    * no need to recursively walk the directory tree.    *    * Instead a {@link ListObjectsRequest} is created requesting a (windowed)    * listing of all entries under the given path. This is used to construct    * an {@code ObjectListingIterator} instance, iteratively returning the    * sequence of lists of elements under the path. This is then iterated    * over in a {@code FileStatusListingIterator}, which generates    * {@link S3AFileStatus} instances, one per listing entry.    * These are then translated into {@link LocatedFileStatus} instances.    *    * This is essentially a nested and wrapped set of iterators, with some    * generator classes; an architecture which may become less convoluted    * using lambda-expressions.    * @param f a path    * @param recursive if the subdirectories need to be traversed recursively    *    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
DECL|method|listFiles (Path f, boolean recursive)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listFiles
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|innerListFiles
argument_list|(
name|f
argument_list|,
name|recursive
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptFilesOnly
argument_list|(
name|qualify
argument_list|(
name|f
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
DECL|method|listFilesAndEmptyDirectories (Path f, boolean recursive)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listFilesAndEmptyDirectories
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|innerListFiles
argument_list|(
name|f
argument_list|,
name|recursive
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptAllButS3nDirs
argument_list|()
argument_list|)
return|;
block|}
DECL|method|innerListFiles (Path f, boolean recursive, Listing.FileStatusAcceptor acceptor)
specifier|private
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|innerListFiles
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|,
name|Listing
operator|.
name|FileStatusAcceptor
name|acceptor
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_FILES
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listFiles({}, {})"
argument_list|,
name|path
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
try|try
block|{
comment|// lookup dir triggers existence check
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: do a bulk operation
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|delimiter
init|=
name|recursive
condition|?
literal|null
else|:
literal|"/"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Requesting all entries under {} with delimiter '{}'"
argument_list|,
name|key
argument_list|,
name|delimiter
argument_list|)
expr_stmt|;
specifier|final
name|RemoteIterator
argument_list|<
name|FileStatus
argument_list|>
name|cachedFilesIterator
decl_stmt|;
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
decl_stmt|;
if|if
condition|(
name|recursive
condition|)
block|{
specifier|final
name|PathMetadata
name|pm
init|=
name|metadataStore
operator|.
name|get
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// shouldn't need to check pm.isDeleted() because that will have
comment|// been caught by getFileStatus above.
name|MetadataStoreListFilesIterator
name|metadataStoreListFilesIterator
init|=
operator|new
name|MetadataStoreListFilesIterator
argument_list|(
name|metadataStore
argument_list|,
name|pm
argument_list|,
name|allowAuthoritative
argument_list|)
decl_stmt|;
name|tombstones
operator|=
name|metadataStoreListFilesIterator
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
name|cachedFilesIterator
operator|=
name|metadataStoreListFilesIterator
expr_stmt|;
block|}
else|else
block|{
name|DirListingMetadata
name|meta
init|=
name|metadataStore
operator|.
name|listChildren
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|meta
operator|!=
literal|null
condition|)
block|{
name|tombstones
operator|=
name|meta
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|tombstones
operator|=
literal|null
expr_stmt|;
block|}
name|cachedFilesIterator
operator|=
name|listing
operator|.
name|createProvidedFileStatusIterator
argument_list|(
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|meta
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
name|acceptor
argument_list|)
expr_stmt|;
if|if
condition|(
name|allowAuthoritative
operator|&&
name|meta
operator|!=
literal|null
operator|&&
name|meta
operator|.
name|isAuthoritative
argument_list|()
condition|)
block|{
comment|// metadata listing is authoritative, so return it directly
return|return
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|cachedFilesIterator
argument_list|)
return|;
block|}
block|}
return|return
name|listing
operator|.
name|createTombstoneReconcilingIterator
argument_list|(
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
name|delimiter
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
name|acceptor
argument_list|,
name|cachedFilesIterator
argument_list|)
argument_list|)
argument_list|,
name|tombstones
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
comment|// TODO S3Guard: retry on file not found exception
throw|throw
name|translateException
argument_list|(
literal|"listFiles"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|listLocatedStatus (Path f)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|listLocatedStatus
argument_list|(
name|f
argument_list|,
name|ACCEPT_ALL
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    *    * S3 Optimized directory listing. The initial operation performs the    * first bulk listing; extra listings will take place    * when all the current set of results are used up.    * @param f a path    * @param filter a path filter    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
DECL|method|listLocatedStatus (final Path f, final PathFilter filter)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_LOCATED_STATUS
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listLocatedStatus({}, {}"
argument_list|,
name|path
argument_list|,
name|filter
argument_list|)
expr_stmt|;
try|try
block|{
comment|// lookup dir triggers existence check
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|filter
operator|.
name|accept
argument_list|(
name|path
argument_list|)
condition|?
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: trigger a lookup
specifier|final
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|Listing
operator|.
name|FileStatusAcceptor
name|acceptor
init|=
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|DirListingMetadata
name|meta
init|=
name|metadataStore
operator|.
name|listChildren
argument_list|(
name|path
argument_list|)
decl_stmt|;
specifier|final
name|RemoteIterator
argument_list|<
name|FileStatus
argument_list|>
name|cachedFileStatusIterator
init|=
name|listing
operator|.
name|createProvidedFileStatusIterator
argument_list|(
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|meta
argument_list|)
argument_list|,
name|filter
argument_list|,
name|acceptor
argument_list|)
decl_stmt|;
return|return
operator|(
name|allowAuthoritative
operator|&&
name|meta
operator|!=
literal|null
operator|&&
name|meta
operator|.
name|isAuthoritative
argument_list|()
operator|)
condition|?
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|cachedFileStatusIterator
argument_list|)
else|:
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
argument_list|,
name|filter
argument_list|,
name|acceptor
argument_list|,
name|cachedFileStatusIterator
argument_list|)
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"listLocatedStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Build a {@link LocatedFileStatus} from a {@link FileStatus} instance.    * @param status file status    * @return a located status with block locations set up from this FS.    * @throws IOException IO Problems.    */
DECL|method|toLocatedFileStatus (FileStatus status)
name|LocatedFileStatus
name|toLocatedFileStatus
parameter_list|(
name|FileStatus
name|status
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|LocatedFileStatus
argument_list|(
name|status
argument_list|,
name|status
operator|.
name|isFile
argument_list|()
condition|?
name|getFileBlockLocations
argument_list|(
name|status
argument_list|,
literal|0
argument_list|,
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
comment|/**    * List any pending multipart uploads whose keys begin with prefix, using    * an iterator that can handle an unlimited number of entries.    * See {@link #listMultipartUploads(String)} for a non-iterator version of    * this.    *    * @param prefix optional key prefix to search    * @return Iterator over multipart uploads.    * @throws IOException on failure    */
DECL|method|listUploads (@ullable String prefix)
specifier|public
name|MultipartUtils
operator|.
name|UploadIterator
name|listUploads
parameter_list|(
annotation|@
name|Nullable
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|MultipartUtils
operator|.
name|listMultipartUploads
argument_list|(
name|s3
argument_list|,
name|invoker
argument_list|,
name|bucket
argument_list|,
name|maxKeys
argument_list|,
name|prefix
argument_list|)
return|;
block|}
comment|/**    * Listing all multipart uploads; limited to the first few hundred.    * See {@link #listUploads(String)} for an iterator-based version that does    * not limit the number of entries returned.    * Retry policy: retry, translated.    * @return a listing of multipart uploads.    * @param prefix prefix to scan for, "" for none    * @throws IOException IO failure, including any uprated AmazonClientException    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listMultipartUploads (String prefix)
specifier|public
name|List
argument_list|<
name|MultipartUpload
argument_list|>
name|listMultipartUploads
parameter_list|(
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|ListMultipartUploadsRequest
name|request
init|=
operator|new
name|ListMultipartUploadsRequest
argument_list|(
name|bucket
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|prefix
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|prefix
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|prefix
operator|=
name|prefix
operator|+
literal|"/"
expr_stmt|;
block|}
name|request
operator|.
name|setPrefix
argument_list|(
name|prefix
argument_list|)
expr_stmt|;
block|}
return|return
name|invoker
operator|.
name|retry
argument_list|(
literal|"listMultipartUploads"
argument_list|,
name|prefix
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|listMultipartUploads
argument_list|(
name|request
argument_list|)
operator|.
name|getMultipartUploads
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Abort a multipart upload.    * Retry policy: none.    * @param destKey destination key    * @param uploadId Upload ID    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|abortMultipartUpload (String destKey, String uploadId)
name|void
name|abortMultipartUpload
parameter_list|(
name|String
name|destKey
parameter_list|,
name|String
name|uploadId
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Aborting multipart upload {} to {}"
argument_list|,
name|uploadId
argument_list|,
name|destKey
argument_list|)
expr_stmt|;
name|getAmazonS3Client
argument_list|()
operator|.
name|abortMultipartUpload
argument_list|(
operator|new
name|AbortMultipartUploadRequest
argument_list|(
name|getBucket
argument_list|()
argument_list|,
name|destKey
argument_list|,
name|uploadId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Abort a multipart upload.    * Retry policy: none.    * @param upload the listed upload to abort.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|abortMultipartUpload (MultipartUpload upload)
name|void
name|abortMultipartUpload
parameter_list|(
name|MultipartUpload
name|upload
parameter_list|)
block|{
name|String
name|destKey
decl_stmt|;
name|String
name|uploadId
decl_stmt|;
name|destKey
operator|=
name|upload
operator|.
name|getKey
argument_list|()
expr_stmt|;
name|uploadId
operator|=
name|upload
operator|.
name|getUploadId
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|DateFormat
name|df
init|=
operator|new
name|SimpleDateFormat
argument_list|(
literal|"yyyy-MM-dd HH:mm:ss"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Aborting multipart upload {} to {} initiated by {} on {}"
argument_list|,
name|uploadId
argument_list|,
name|destKey
argument_list|,
name|upload
operator|.
name|getInitiator
argument_list|()
argument_list|,
name|df
operator|.
name|format
argument_list|(
name|upload
operator|.
name|getInitiated
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|getAmazonS3Client
argument_list|()
operator|.
name|abortMultipartUpload
argument_list|(
operator|new
name|AbortMultipartUploadRequest
argument_list|(
name|getBucket
argument_list|()
argument_list|,
name|destKey
argument_list|,
name|uploadId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a new instance of the committer statistics.    * @return a new committer statistics instance    */
DECL|method|newCommitterStatistics ()
specifier|public
name|S3AInstrumentation
operator|.
name|CommitterStatistics
name|newCommitterStatistics
parameter_list|()
block|{
return|return
name|instrumentation
operator|.
name|newCommitterStatistics
argument_list|()
return|;
block|}
comment|/**    * Return the capabilities of this filesystem instance.    * @param capability string to query the stream support for.    * @return whether the FS instance has the capability.    */
annotation|@
name|Override
DECL|method|hasCapability (String capability)
specifier|public
name|boolean
name|hasCapability
parameter_list|(
name|String
name|capability
parameter_list|)
block|{
switch|switch
condition|(
name|capability
operator|.
name|toLowerCase
argument_list|(
name|Locale
operator|.
name|ENGLISH
argument_list|)
condition|)
block|{
case|case
name|CommitConstants
operator|.
name|STORE_CAPABILITY_MAGIC_COMMITTER
case|:
comment|// capability depends on FS configuration
return|return
name|isMagicCommitEnabled
argument_list|()
return|;
default|default:
return|return
literal|false
return|;
block|}
block|}
block|}
end_class

end_unit

