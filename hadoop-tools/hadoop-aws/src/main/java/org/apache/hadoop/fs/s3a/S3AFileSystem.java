begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonClientException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonServiceException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|AmazonS3
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|AbortMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|AmazonS3Exception
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CannedAccessControlList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CompleteMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CompleteMultipartUploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CopyObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|DeleteObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|GetObjectMetadataRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|InitiateMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ObjectListing
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ObjectMetadata
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PartETag
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|S3ObjectSummary
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSEAwsKeyManagementParams
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSECustomerKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Copy
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManager
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManagerConfiguration
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Upload
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressEvent
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListeningExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|GlobalStorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|InvalidRequestException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalDirAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathIsNotEmptyDirectoryException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|RemoteIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3native
operator|.
name|S3xLoginHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Listing
operator|.
name|ACCEPT_ALL
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Statistic
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * The core S3A Filesystem implementation.  *  * This subclass is marked as private as code should not be creating it  * directly; use {@link FileSystem#get(Configuration)} and variants to  * create one.  *  * If cast to {@code S3AFileSystem}, extra methods and features may be accessed.  * Consider those private and unstable.  *  * Because it prints some of the state of the instrumentation,  * the output of {@link #toString()} must also be considered unstable.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|S3AFileSystem
specifier|public
class|class
name|S3AFileSystem
extends|extends
name|FileSystem
block|{
comment|/**    * Default blocksize as used in blocksize and FS status queries.    */
DECL|field|DEFAULT_BLOCKSIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKSIZE
init|=
literal|32
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
DECL|field|uri
specifier|private
name|URI
name|uri
decl_stmt|;
DECL|field|workingDir
specifier|private
name|Path
name|workingDir
decl_stmt|;
DECL|field|username
specifier|private
name|String
name|username
decl_stmt|;
DECL|field|s3
specifier|private
name|AmazonS3
name|s3
decl_stmt|;
DECL|field|bucket
specifier|private
name|String
name|bucket
decl_stmt|;
DECL|field|maxKeys
specifier|private
name|int
name|maxKeys
decl_stmt|;
DECL|field|listing
specifier|private
name|Listing
name|listing
decl_stmt|;
DECL|field|partSize
specifier|private
name|long
name|partSize
decl_stmt|;
DECL|field|enableMultiObjectsDelete
specifier|private
name|boolean
name|enableMultiObjectsDelete
decl_stmt|;
DECL|field|transfers
specifier|private
name|TransferManager
name|transfers
decl_stmt|;
DECL|field|boundedThreadPool
specifier|private
name|ListeningExecutorService
name|boundedThreadPool
decl_stmt|;
DECL|field|unboundedThreadPool
specifier|private
name|ExecutorService
name|unboundedThreadPool
decl_stmt|;
DECL|field|multiPartThreshold
specifier|private
name|long
name|multiPartThreshold
decl_stmt|;
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|S3AFileSystem
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|PROGRESS
specifier|private
specifier|static
specifier|final
name|Logger
name|PROGRESS
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"org.apache.hadoop.fs.s3a.S3AFileSystem.Progress"
argument_list|)
decl_stmt|;
DECL|field|directoryAllocator
specifier|private
name|LocalDirAllocator
name|directoryAllocator
decl_stmt|;
DECL|field|cannedACL
specifier|private
name|CannedAccessControlList
name|cannedACL
decl_stmt|;
DECL|field|serverSideEncryptionAlgorithm
specifier|private
name|S3AEncryptionMethods
name|serverSideEncryptionAlgorithm
decl_stmt|;
DECL|field|instrumentation
specifier|private
name|S3AInstrumentation
name|instrumentation
decl_stmt|;
DECL|field|storageStatistics
specifier|private
name|S3AStorageStatistics
name|storageStatistics
decl_stmt|;
DECL|field|readAhead
specifier|private
name|long
name|readAhead
decl_stmt|;
DECL|field|inputPolicy
specifier|private
name|S3AInputPolicy
name|inputPolicy
decl_stmt|;
DECL|field|closed
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// The maximum number of entries that can be deleted in any call to s3
DECL|field|MAX_ENTRIES_TO_DELETE
specifier|private
specifier|static
specifier|final
name|int
name|MAX_ENTRIES_TO_DELETE
init|=
literal|1000
decl_stmt|;
DECL|field|blockUploadEnabled
specifier|private
name|boolean
name|blockUploadEnabled
decl_stmt|;
DECL|field|blockOutputBuffer
specifier|private
name|String
name|blockOutputBuffer
decl_stmt|;
DECL|field|blockFactory
specifier|private
name|S3ADataBlocks
operator|.
name|BlockFactory
name|blockFactory
decl_stmt|;
DECL|field|blockOutputActiveBlocks
specifier|private
name|int
name|blockOutputActiveBlocks
decl_stmt|;
comment|/** Called after a new FileSystem instance is constructed.    * @param name a uri whose authority section names the host, port, etc.    *   for this FileSystem    * @param originalConf the configuration to use for the FS. The    * bucket-specific options are patched over the base ones before any use is    * made of the config.    */
DECL|method|initialize (URI name, Configuration originalConf)
specifier|public
name|void
name|initialize
parameter_list|(
name|URI
name|name
parameter_list|,
name|Configuration
name|originalConf
parameter_list|)
throws|throws
name|IOException
block|{
name|uri
operator|=
name|S3xLoginHelper
operator|.
name|buildFSURI
argument_list|(
name|name
argument_list|)
expr_stmt|;
comment|// get the host; this is guaranteed to be non-null, non-empty
name|bucket
operator|=
name|name
operator|.
name|getHost
argument_list|()
expr_stmt|;
comment|// clone the configuration into one with propagated bucket options
name|Configuration
name|conf
init|=
name|propagateBucketOptions
argument_list|(
name|originalConf
argument_list|,
name|bucket
argument_list|)
decl_stmt|;
name|patchSecurityCredentialProviders
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|super
operator|.
name|initialize
argument_list|(
name|name
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
try|try
block|{
name|instrumentation
operator|=
operator|new
name|S3AInstrumentation
argument_list|(
name|name
argument_list|)
expr_stmt|;
comment|// Username is the current user at the time the FS was instantiated.
name|username
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|workingDir
operator|=
operator|new
name|Path
argument_list|(
literal|"/user"
argument_list|,
name|username
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|this
operator|.
name|uri
argument_list|,
name|this
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
expr_stmt|;
name|Class
argument_list|<
name|?
extends|extends
name|S3ClientFactory
argument_list|>
name|s3ClientFactoryClass
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|S3_CLIENT_FACTORY_IMPL
argument_list|,
name|DEFAULT_S3_CLIENT_FACTORY_IMPL
argument_list|,
name|S3ClientFactory
operator|.
name|class
argument_list|)
decl_stmt|;
name|s3
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|s3ClientFactoryClass
argument_list|,
name|conf
argument_list|)
operator|.
name|createS3Client
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|maxKeys
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_PAGING_KEYS
argument_list|,
name|DEFAULT_MAX_PAGING_KEYS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|listing
operator|=
operator|new
name|Listing
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MULTIPART_SIZE
argument_list|,
name|DEFAULT_MULTIPART_SIZE
argument_list|)
expr_stmt|;
name|multiPartThreshold
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MIN_MULTIPART_THRESHOLD
argument_list|,
name|DEFAULT_MIN_MULTIPART_THRESHOLD
argument_list|)
expr_stmt|;
comment|//check but do not store the block size
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|enableMultiObjectsDelete
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|ENABLE_MULTI_DELETE
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|readAhead
operator|=
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|READAHEAD_RANGE
argument_list|,
name|DEFAULT_READAHEAD_RANGE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|storageStatistics
operator|=
operator|(
name|S3AStorageStatistics
operator|)
name|GlobalStorageStatistics
operator|.
name|INSTANCE
operator|.
name|put
argument_list|(
name|S3AStorageStatistics
operator|.
name|NAME
argument_list|,
operator|new
name|GlobalStorageStatistics
operator|.
name|StorageStatisticsProvider
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|StorageStatistics
name|provide
parameter_list|()
block|{
return|return
operator|new
name|S3AStorageStatistics
argument_list|()
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|int
name|maxThreads
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MAX_THREADS
argument_list|,
name|DEFAULT_MAX_THREADS
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxThreads
operator|<
literal|2
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|MAX_THREADS
operator|+
literal|" must be at least 2: forcing to 2."
argument_list|)
expr_stmt|;
name|maxThreads
operator|=
literal|2
expr_stmt|;
block|}
name|int
name|totalTasks
init|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_TOTAL_TASKS
argument_list|,
name|DEFAULT_MAX_TOTAL_TASKS
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|long
name|keepAliveTime
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|KEEPALIVE_TIME
argument_list|,
name|DEFAULT_KEEPALIVE_TIME
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|boundedThreadPool
operator|=
name|BlockingThreadPoolExecutorService
operator|.
name|newInstance
argument_list|(
name|maxThreads
argument_list|,
name|maxThreads
operator|+
name|totalTasks
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"s3a-transfer-shared"
argument_list|)
expr_stmt|;
name|unboundedThreadPool
operator|=
operator|new
name|ThreadPoolExecutor
argument_list|(
name|maxThreads
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|LinkedBlockingQueue
argument_list|<
name|Runnable
argument_list|>
argument_list|()
argument_list|,
name|BlockingThreadPoolExecutorService
operator|.
name|newDaemonThreadFactory
argument_list|(
literal|"s3a-transfer-unbounded"
argument_list|)
argument_list|)
expr_stmt|;
name|initTransferManager
argument_list|()
expr_stmt|;
name|initCannedAcls
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|verifyBucketExists
argument_list|()
expr_stmt|;
name|initMultipartUploads
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|serverSideEncryptionAlgorithm
operator|=
name|S3AEncryptionMethods
operator|.
name|getMethod
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|SERVER_SIDE_ENCRYPTION_ALGORITHM
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_C
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|&&
name|StringUtils
operator|.
name|isBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|Constants
operator|.
name|SSE_C_NO_KEY_ERROR
argument_list|)
throw|;
block|}
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_S3
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|&&
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|Constants
operator|.
name|SSE_S3_WITH_KEY_ERROR
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using encryption {}"
argument_list|,
name|serverSideEncryptionAlgorithm
argument_list|)
expr_stmt|;
name|inputPolicy
operator|=
name|S3AInputPolicy
operator|.
name|getPolicy
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|INPUT_FADVISE
argument_list|,
name|INPUT_FADV_NORMAL
argument_list|)
argument_list|)
expr_stmt|;
name|blockUploadEnabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|FAST_UPLOAD
argument_list|,
name|DEFAULT_FAST_UPLOAD
argument_list|)
expr_stmt|;
if|if
condition|(
name|blockUploadEnabled
condition|)
block|{
name|blockOutputBuffer
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|FAST_UPLOAD_BUFFER
argument_list|,
name|DEFAULT_FAST_UPLOAD_BUFFER
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|ensureOutputParameterInRange
argument_list|(
name|MULTIPART_SIZE
argument_list|,
name|partSize
argument_list|)
expr_stmt|;
name|blockFactory
operator|=
name|S3ADataBlocks
operator|.
name|createFactory
argument_list|(
name|this
argument_list|,
name|blockOutputBuffer
argument_list|)
expr_stmt|;
name|blockOutputActiveBlocks
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
name|DEFAULT_FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using S3ABlockOutputStream with buffer = {}; block={};"
operator|+
literal|" queue limit={}"
argument_list|,
name|blockOutputBuffer
argument_list|,
name|partSize
argument_list|,
name|blockOutputActiveBlocks
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using S3AOutputStream"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"initializing "
argument_list|,
operator|new
name|Path
argument_list|(
name|name
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Verify that the bucket exists. This does not check permissions,    * not even read access.    * @throws FileNotFoundException the bucket is absent    * @throws IOException any other problem talking to S3    */
DECL|method|verifyBucketExists ()
specifier|protected
name|void
name|verifyBucketExists
parameter_list|()
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
try|try
block|{
if|if
condition|(
operator|!
name|s3
operator|.
name|doesBucketExist
argument_list|(
name|bucket
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" does not exist"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonS3Exception
name|e
parameter_list|)
block|{
comment|// this is a sign of a serious startup problem so do dump everything
name|LOG
operator|.
name|warn
argument_list|(
name|stringify
argument_list|(
name|e
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|translateException
argument_list|(
literal|"doesBucketExist"
argument_list|,
name|bucket
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
comment|// this is a sign of a serious startup problem so do dump everything
name|LOG
operator|.
name|warn
argument_list|(
name|stringify
argument_list|(
name|e
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|translateException
argument_list|(
literal|"doesBucketExist"
argument_list|,
name|bucket
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"doesBucketExist"
argument_list|,
name|bucket
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get S3A Instrumentation. For test purposes.    * @return this instance's instrumentation.    */
DECL|method|getInstrumentation ()
specifier|public
name|S3AInstrumentation
name|getInstrumentation
parameter_list|()
block|{
return|return
name|instrumentation
return|;
block|}
DECL|method|initTransferManager ()
specifier|private
name|void
name|initTransferManager
parameter_list|()
block|{
name|TransferManagerConfiguration
name|transferConfiguration
init|=
operator|new
name|TransferManagerConfiguration
argument_list|()
decl_stmt|;
name|transferConfiguration
operator|.
name|setMinimumUploadPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartUploadThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transfers
operator|=
operator|new
name|TransferManager
argument_list|(
name|s3
argument_list|,
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|transfers
operator|.
name|setConfiguration
argument_list|(
name|transferConfiguration
argument_list|)
expr_stmt|;
block|}
DECL|method|initCannedAcls (Configuration conf)
specifier|private
name|void
name|initCannedAcls
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|cannedACLName
init|=
name|conf
operator|.
name|get
argument_list|(
name|CANNED_ACL
argument_list|,
name|DEFAULT_CANNED_ACL
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|cannedACLName
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|cannedACL
operator|=
name|CannedAccessControlList
operator|.
name|valueOf
argument_list|(
name|cannedACLName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cannedACL
operator|=
literal|null
expr_stmt|;
block|}
block|}
DECL|method|initMultipartUploads (Configuration conf)
specifier|private
name|void
name|initMultipartUploads
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|purgeExistingMultipart
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|PURGE_EXISTING_MULTIPART
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART
argument_list|)
decl_stmt|;
name|long
name|purgeExistingMultipartAge
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|PURGE_EXISTING_MULTIPART_AGE
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART_AGE
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|purgeExistingMultipart
condition|)
block|{
name|Date
name|purgeBefore
init|=
operator|new
name|Date
argument_list|(
operator|new
name|Date
argument_list|()
operator|.
name|getTime
argument_list|()
operator|-
name|purgeExistingMultipartAge
operator|*
literal|1000
argument_list|)
decl_stmt|;
try|try
block|{
name|transfers
operator|.
name|abortMultipartUploads
argument_list|(
name|bucket
argument_list|,
name|purgeBefore
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|==
literal|403
condition|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to purging multipart uploads against {},"
operator|+
literal|" FS may be read only"
argument_list|,
name|bucket
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|translateException
argument_list|(
literal|"purging multipart uploads"
argument_list|,
name|bucket
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Return the protocol scheme for the FileSystem.    *    * @return "s3a"    */
annotation|@
name|Override
DECL|method|getScheme ()
specifier|public
name|String
name|getScheme
parameter_list|()
block|{
return|return
literal|"s3a"
return|;
block|}
comment|/**    * Returns a URI whose scheme and authority identify this FileSystem.    */
annotation|@
name|Override
DECL|method|getUri ()
specifier|public
name|URI
name|getUri
parameter_list|()
block|{
return|return
name|uri
return|;
block|}
annotation|@
name|Override
DECL|method|getDefaultPort ()
specifier|public
name|int
name|getDefaultPort
parameter_list|()
block|{
return|return
name|Constants
operator|.
name|S3A_DEFAULT_PORT
return|;
block|}
comment|/**    * Returns the S3 client used by this filesystem.    * @return AmazonS3Client    */
annotation|@
name|VisibleForTesting
DECL|method|getAmazonS3Client ()
name|AmazonS3
name|getAmazonS3Client
parameter_list|()
block|{
return|return
name|s3
return|;
block|}
comment|/**    * Returns the read ahead range value used by this filesystem    * @return    */
annotation|@
name|VisibleForTesting
DECL|method|getReadAheadRange ()
name|long
name|getReadAheadRange
parameter_list|()
block|{
return|return
name|readAhead
return|;
block|}
comment|/**    * Get the input policy for this FS instance.    * @return the input policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|getInputPolicy ()
specifier|public
name|S3AInputPolicy
name|getInputPolicy
parameter_list|()
block|{
return|return
name|inputPolicy
return|;
block|}
comment|/**    * Demand create the directory allocator, then create a temporary file.    * {@link LocalDirAllocator#createTmpFileForWrite(String, long, Configuration)}.    *  @param pathStr prefix for the temporary file    *  @param size the size of the file that is going to be written    *  @param conf the Configuration object    *  @return a unique temporary file    *  @throws IOException IO problems    */
DECL|method|createTmpFileForWrite (String pathStr, long size, Configuration conf)
specifier|synchronized
name|File
name|createTmpFileForWrite
parameter_list|(
name|String
name|pathStr
parameter_list|,
name|long
name|size
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|directoryAllocator
operator|==
literal|null
condition|)
block|{
name|String
name|bufferDir
init|=
name|conf
operator|.
name|get
argument_list|(
name|BUFFER_DIR
argument_list|)
operator|!=
literal|null
condition|?
name|BUFFER_DIR
else|:
literal|"hadoop.tmp.dir"
decl_stmt|;
name|directoryAllocator
operator|=
operator|new
name|LocalDirAllocator
argument_list|(
name|bufferDir
argument_list|)
expr_stmt|;
block|}
return|return
name|directoryAllocator
operator|.
name|createTmpFileForWrite
argument_list|(
name|pathStr
argument_list|,
name|size
argument_list|,
name|conf
argument_list|)
return|;
block|}
comment|/**    * Get the bucket of this filesystem.    * @return the bucket    */
DECL|method|getBucket ()
specifier|public
name|String
name|getBucket
parameter_list|()
block|{
return|return
name|bucket
return|;
block|}
comment|/**    * Change the input policy for this FS.    * @param inputPolicy new policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|setInputPolicy (S3AInputPolicy inputPolicy)
specifier|public
name|void
name|setInputPolicy
parameter_list|(
name|S3AInputPolicy
name|inputPolicy
parameter_list|)
block|{
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|inputPolicy
argument_list|,
literal|"Null inputStrategy"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting input strategy: {}"
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputPolicy
operator|=
name|inputPolicy
expr_stmt|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key.    *    * @param path input path, may be relative to the working dir    * @return a key excluding the leading "/", or, if it is the root path, ""    */
DECL|method|pathToKey (Path path)
specifier|private
name|String
name|pathToKey
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
if|if
condition|(
operator|!
name|path
operator|.
name|isAbsolute
argument_list|()
condition|)
block|{
name|path
operator|=
operator|new
name|Path
argument_list|(
name|workingDir
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
operator|!=
literal|null
operator|&&
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|""
return|;
block|}
return|return
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
return|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key, adding a trailing    * "/" if the path is not the root<i>and</i> does not already have a "/"    * at the end.    *    * @param key s3 key or ""    * @return the with a trailing "/", or, if it is the root key, "",    */
DECL|method|maybeAddTrailingSlash (String key)
specifier|private
name|String
name|maybeAddTrailingSlash
parameter_list|(
name|String
name|key
parameter_list|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
return|return
name|key
operator|+
literal|'/'
return|;
block|}
else|else
block|{
return|return
name|key
return|;
block|}
block|}
comment|/**    * Convert a path back to a key.    * @param key input key    * @return the path from this key    */
DECL|method|keyToPath (String key)
specifier|private
name|Path
name|keyToPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
literal|"/"
operator|+
name|key
argument_list|)
return|;
block|}
comment|/**    * Convert a key to a fully qualified path.    * @param key input key    * @return the fully qualified path including URI scheme and bucket name.    */
DECL|method|keyToQualifiedPath (String key)
name|Path
name|keyToQualifiedPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
name|qualify
argument_list|(
name|keyToPath
argument_list|(
name|key
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Qualify a path.    * @param path path to qualify    * @return a qualified path.    */
DECL|method|qualify (Path path)
name|Path
name|qualify
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|makeQualified
argument_list|(
name|uri
argument_list|,
name|workingDir
argument_list|)
return|;
block|}
comment|/**    * Check that a Path belongs to this FileSystem.    * Unlike the superclass, this version does not look at authority,    * only hostnames.    * @param path to check    * @throws IllegalArgumentException if there is an FS mismatch    */
annotation|@
name|Override
DECL|method|checkPath (Path path)
specifier|public
name|void
name|checkPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|S3xLoginHelper
operator|.
name|checkPath
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|getUri
argument_list|()
argument_list|,
name|path
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|canonicalizeUri (URI rawUri)
specifier|protected
name|URI
name|canonicalizeUri
parameter_list|(
name|URI
name|rawUri
parameter_list|)
block|{
return|return
name|S3xLoginHelper
operator|.
name|canonicalizeUri
argument_list|(
name|rawUri
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Opens an FSDataInputStream at the indicated Path.    * @param f the file name to open    * @param bufferSize the size of the buffer to be used.    */
DECL|method|open (Path f, int bufferSize)
specifier|public
name|FSDataInputStream
name|open
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening '{}' for reading."
argument_list|,
name|f
argument_list|)
expr_stmt|;
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Can't open "
operator|+
name|f
operator|+
literal|" because it is a directory"
argument_list|)
throw|;
block|}
return|return
operator|new
name|FSDataInputStream
argument_list|(
operator|new
name|S3AInputStream
argument_list|(
operator|new
name|S3ObjectAttributes
argument_list|(
name|bucket
argument_list|,
name|pathToKey
argument_list|(
name|f
argument_list|)
argument_list|,
name|serverSideEncryptionAlgorithm
argument_list|,
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|fileStatus
operator|.
name|getLen
argument_list|()
argument_list|,
name|s3
argument_list|,
name|statistics
argument_list|,
name|instrumentation
argument_list|,
name|readAhead
argument_list|,
name|inputPolicy
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Create an FSDataOutputStream at the indicated Path with write-progress    * reporting.    * @param f the file name to open    * @param permission the permission to set.    * @param overwrite if a file with this name already exists, then if true,    *   the file will be overwritten, and if false an error will be thrown.    * @param bufferSize the size of the buffer to be used.    * @param replication required block replication for the file.    * @param blockSize the requested block size.    * @param progress the progress reporter.    * @throws IOException in the event of IO related errors.    * @see #setPermission(Path, FsPermission)    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"IOResourceOpenedButNotSafelyClosed"
argument_list|)
DECL|method|create (Path f, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|create
parameter_list|(
name|Path
name|f
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|S3AFileStatus
name|status
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// get the status or throw an FNFE
name|status
operator|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
expr_stmt|;
comment|// if the thread reaches here, there is something at the path
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|// path references a directory: automatic error
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|f
operator|+
literal|" is a directory"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|overwrite
condition|)
block|{
comment|// path references a file and overwrite is disabled
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|f
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overwriting file {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// this means the file is not found
block|}
name|instrumentation
operator|.
name|fileCreated
argument_list|()
expr_stmt|;
name|FSDataOutputStream
name|output
decl_stmt|;
if|if
condition|(
name|blockUploadEnabled
condition|)
block|{
name|output
operator|=
operator|new
name|FSDataOutputStream
argument_list|(
operator|new
name|S3ABlockOutputStream
argument_list|(
name|this
argument_list|,
name|key
argument_list|,
operator|new
name|SemaphoredDelegatingExecutor
argument_list|(
name|boundedThreadPool
argument_list|,
name|blockOutputActiveBlocks
argument_list|,
literal|true
argument_list|)
argument_list|,
name|progress
argument_list|,
name|partSize
argument_list|,
name|blockFactory
argument_list|,
name|instrumentation
operator|.
name|newOutputStreamStatistics
argument_list|(
name|statistics
argument_list|)
argument_list|,
operator|new
name|WriteOperationHelper
argument_list|(
name|key
argument_list|)
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// We pass null to FSDataOutputStream so it won't count writes that
comment|// are being buffered to a file
name|output
operator|=
operator|new
name|FSDataOutputStream
argument_list|(
operator|new
name|S3AOutputStream
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|this
argument_list|,
name|key
argument_list|,
name|progress
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
return|return
name|output
return|;
block|}
comment|/**    * {@inheritDoc}    * @throws FileNotFoundException if the parent directory is not present -or    * is not a directory.    */
annotation|@
name|Override
DECL|method|createNonRecursive (Path path, FsPermission permission, EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|createNonRecursive
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flags
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
comment|// expect this to raise an exception if there is no parent
if|if
condition|(
operator|!
name|getFileStatus
argument_list|(
name|parent
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Not a directory: "
operator|+
name|parent
argument_list|)
throw|;
block|}
block|}
return|return
name|create
argument_list|(
name|path
argument_list|,
name|permission
argument_list|,
name|flags
operator|.
name|contains
argument_list|(
name|CreateFlag
operator|.
name|OVERWRITE
argument_list|)
argument_list|,
name|bufferSize
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|,
name|progress
argument_list|)
return|;
block|}
comment|/**    * Append to an existing file (optional operation).    * @param f the existing file to be appended.    * @param bufferSize the size of the buffer to be used.    * @param progress for reporting progress if it is not null.    * @throws IOException indicating that append is not supported.    */
DECL|method|append (Path f, int bufferSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|append
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Append is not supported "
operator|+
literal|"by S3AFileSystem"
argument_list|)
throw|;
block|}
comment|/**    * Renames Path src to Path dst.  Can take place on local fs    * or remote DFS.    *    * Warning: S3 does not support renames. This method does a copy which can    * take S3 some time to execute with large files and directories. Since    * there is no Progressable passed in, this can time out jobs.    *    * Note: This implementation differs with other S3 drivers. Specifically:    *<pre>    *       Fails if src is a file and dst is a directory.    *       Fails if src is a directory and dst is a file.    *       Fails if the parent of dst does not exist or is a file.    *       Fails if dst is a directory that is not empty.    *</pre>    *    * @param src path to be renamed    * @param dst new path after rename    * @throws IOException on IO failure    * @return true if rename is successful    */
DECL|method|rename (Path src, Path dst)
specifier|public
name|boolean
name|rename
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|innerRename
argument_list|(
name|src
argument_list|,
name|dst
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"rename("
operator|+
name|src
operator|+
literal|", "
operator|+
name|dst
operator|+
literal|")"
argument_list|,
name|src
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|RenameFailedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|e
operator|.
name|getExitCode
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**    * The inner rename operation. See {@link #rename(Path, Path)} for    * the description of the operation.    * This operation throws an exception on any failure which needs to be    * reported and downgraded to a failure. That is: if a rename    * @param src path to be renamed    * @param dst new path after rename    * @throws RenameFailedException if some criteria for a state changing    * rename was not met. This means work didn't happen; it's not something    * which is reported upstream to the FileSystem APIs, for which the semantics    * of "false" are pretty vague.    * @throws FileNotFoundException there's no source file.    * @throws IOException on IO failure.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerRename (Path src, Path dst)
specifier|private
name|boolean
name|innerRename
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|RenameFailedException
throws|,
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Rename path {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_RENAME
argument_list|)
expr_stmt|;
name|String
name|srcKey
init|=
name|pathToKey
argument_list|(
name|src
argument_list|)
decl_stmt|;
name|String
name|dstKey
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is root directory"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dstKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"dest is root directory"
argument_list|)
throw|;
block|}
comment|// get the source file status; this raises a FNFE if there is no source
comment|// file.
name|S3AFileStatus
name|srcStatus
init|=
name|getFileStatus
argument_list|(
name|src
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|equals
argument_list|(
name|dstKey
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: src and dest refer to the same file or directory: {}"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source and dest refer to the same file or directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
name|S3AFileStatus
name|dstStatus
init|=
literal|null
decl_stmt|;
try|try
block|{
name|dstStatus
operator|=
name|getFileStatus
argument_list|(
name|dst
argument_list|)
expr_stmt|;
comment|// if there is no destination entry, an exception is raised.
comment|// hence this code sequence can assume that there is something
comment|// at the end of the path; the only detail being what it is and
comment|// whether or not it can be the destination of the rename.
if|if
condition|(
name|srcStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is a directory and dest is a file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|dstStatus
operator|.
name|isEmptyDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Destination is a non-empty directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
comment|// at this point the destination is an empty directory
block|}
else|else
block|{
comment|// source is a file. The destination must be a directory,
comment|// empty or not
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Cannot rename onto an existing file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: destination path {} not found"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Parent must exist
name|Path
name|parent
init|=
name|dst
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|pathToKey
argument_list|(
name|parent
argument_list|)
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|S3AFileStatus
name|dstParentStatus
init|=
name|getFileStatus
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|dstParentStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination parent is not a directory"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e2
parameter_list|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination has no parent "
argument_list|)
throw|;
block|}
block|}
block|}
comment|// Ok! Time to start
if|if
condition|(
name|srcStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: renaming file {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
if|if
condition|(
name|dstStatus
operator|!=
literal|null
operator|&&
name|dstStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|String
name|newDstKey
init|=
name|dstKey
decl_stmt|;
if|if
condition|(
operator|!
name|newDstKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|newDstKey
operator|=
name|newDstKey
operator|+
literal|"/"
expr_stmt|;
block|}
name|String
name|filename
init|=
name|srcKey
operator|.
name|substring
argument_list|(
name|pathToKey
argument_list|(
name|src
operator|.
name|getParent
argument_list|()
argument_list|)
operator|.
name|length
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
name|newDstKey
operator|=
name|newDstKey
operator|+
name|filename
expr_stmt|;
name|copyFile
argument_list|(
name|srcKey
argument_list|,
name|newDstKey
argument_list|,
name|srcStatus
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|copyFile
argument_list|(
name|srcKey
argument_list|,
name|dstKey
argument_list|,
name|srcStatus
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|innerDelete
argument_list|(
name|srcStatus
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: renaming directory {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// This is a directory to directory copy
if|if
condition|(
operator|!
name|dstKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|dstKey
operator|=
name|dstKey
operator|+
literal|"/"
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|srcKey
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|srcKey
operator|=
name|srcKey
operator|+
literal|"/"
expr_stmt|;
block|}
comment|//Verify dest is not a child of the source directory
if|if
condition|(
name|dstKey
operator|.
name|startsWith
argument_list|(
name|srcKey
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|srcKey
argument_list|,
name|dstKey
argument_list|,
literal|"cannot rename a directory to a subdirectory of itself "
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|dstStatus
operator|!=
literal|null
operator|&&
name|dstStatus
operator|.
name|isEmptyDirectory
argument_list|()
condition|)
block|{
comment|// delete unnecessary fake directory.
name|keysToDelete
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|dstKey
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|ListObjectsRequest
name|request
init|=
operator|new
name|ListObjectsRequest
argument_list|()
decl_stmt|;
name|request
operator|.
name|setBucketName
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
name|request
operator|.
name|setPrefix
argument_list|(
name|srcKey
argument_list|)
expr_stmt|;
name|request
operator|.
name|setMaxKeys
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
name|ObjectListing
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|objects
operator|.
name|getObjectSummaries
argument_list|()
control|)
block|{
name|keysToDelete
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|newDstKey
init|=
name|dstKey
operator|+
name|summary
operator|.
name|getKey
argument_list|()
operator|.
name|substring
argument_list|(
name|srcKey
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|copyFile
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|,
name|newDstKey
argument_list|,
name|summary
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|keysToDelete
operator|.
name|size
argument_list|()
operator|==
name|MAX_ENTRIES_TO_DELETE
condition|)
block|{
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|objects
operator|.
name|isTruncated
argument_list|()
condition|)
block|{
name|objects
operator|=
name|continueListObjects
argument_list|(
name|objects
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|keysToDelete
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
block|}
if|if
condition|(
name|src
operator|.
name|getParent
argument_list|()
operator|!=
name|dst
operator|.
name|getParent
argument_list|()
condition|)
block|{
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
name|createFakeDirectoryIfNecessary
argument_list|(
name|src
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Low-level call to get at the object metadata.    * @param path path to the object    * @return metadata    * @throws IOException IO and object access problems.    */
annotation|@
name|VisibleForTesting
DECL|method|getObjectMetadata (Path path)
specifier|public
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getObjectMetadata
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Increment a statistic by 1.    * @param statistic The operation to increment    */
DECL|method|incrementStatistic (Statistic statistic)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|statistic
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a statistic by a specific value.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementStatistic (Statistic statistic, long count)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|storageStatistics
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Decrement a gauge by a specific value.    * @param statistic The operation to decrement    * @param count the count to decrement    */
DECL|method|decrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|decrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|decrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a gauge by a specific value.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|incrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the storage statistics of this filesystem.    * @return the storage statistics    */
annotation|@
name|Override
DECL|method|getStorageStatistics ()
specifier|public
name|S3AStorageStatistics
name|getStorageStatistics
parameter_list|()
block|{
return|return
name|storageStatistics
return|;
block|}
comment|/**    * Request object metadata; increments counters in the process.    * @param key key    * @return the metadata    */
DECL|method|getObjectMetadata (String key)
specifier|protected
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|String
name|key
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_METADATA_REQUESTS
argument_list|)
expr_stmt|;
name|GetObjectMetadataRequest
name|request
init|=
operator|new
name|GetObjectMetadataRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
decl_stmt|;
comment|//SSE-C requires to be filled in if enabled for object metadata
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_C
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|&&
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|request
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ObjectMetadata
name|meta
init|=
name|s3
operator|.
name|getObjectMetadata
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|meta
return|;
block|}
comment|/**    * Initiate a {@code listObjects} operation, incrementing metrics    * in the process.    * @param request request to initiate    * @return the results    */
DECL|method|listObjects (ListObjectsRequest request)
specifier|protected
name|ObjectListing
name|listObjects
parameter_list|(
name|ListObjectsRequest
name|request
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_LIST_REQUESTS
argument_list|)
expr_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|s3
operator|.
name|listObjects
argument_list|(
name|request
argument_list|)
return|;
block|}
comment|/**    * List the next set of objects.    * @param objects paged result    * @return the next result object    */
DECL|method|continueListObjects (ObjectListing objects)
specifier|protected
name|ObjectListing
name|continueListObjects
parameter_list|(
name|ObjectListing
name|objects
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_CONTINUE_LIST_REQUESTS
argument_list|)
expr_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|s3
operator|.
name|listNextBatchOfObjects
argument_list|(
name|objects
argument_list|)
return|;
block|}
comment|/**    * Increment read operations.    */
DECL|method|incrementReadOperations ()
specifier|public
name|void
name|incrementReadOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementReadOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment the write operation counter.    * This is somewhat inaccurate, as it appears to be invoked more    * often than needed in progress callbacks.    */
DECL|method|incrementWriteOperations ()
specifier|public
name|void
name|incrementWriteOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementWriteOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete an object.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    * @param key key to blob to delete.    */
DECL|method|deleteObject (String key)
specifier|private
name|void
name|deleteObject
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|InvalidRequestException
block|{
name|blockRootDelete
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|)
expr_stmt|;
name|s3
operator|.
name|deleteObject
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
expr_stmt|;
block|}
comment|/**    * Reject any request to delete an object where the key is root.    * @param key key to validate    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
DECL|method|blockRootDelete (String key)
specifier|private
name|void
name|blockRootDelete
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|InvalidRequestException
block|{
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
operator|||
literal|"/"
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|InvalidRequestException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" cannot be deleted"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Perform a bulk object delete operation.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    * @param deleteRequest keys to delete on the s3-backend    */
DECL|method|deleteObjects (DeleteObjectsRequest deleteRequest)
specifier|private
name|void
name|deleteObjects
parameter_list|(
name|DeleteObjectsRequest
name|deleteRequest
parameter_list|)
block|{
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|s3
operator|.
name|deleteObjects
argument_list|(
name|deleteRequest
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a putObject request.    * Adds the ACL and metadata    * @param key key of object    * @param metadata metadata header    * @param srcfile source file    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, File srcfile)
specifier|public
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|File
name|srcfile
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|srcfile
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a {@link PutObjectRequest} request.    * The metadata is assumed to have been configured with the size of the    * operation.    * @param key key of object    * @param metadata metadata header    * @param inputStream source data.    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, InputStream inputStream)
specifier|private
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|InputStream
name|inputStream
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|inputStream
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|inputStream
argument_list|,
name|metadata
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    * @return a new metadata instance    */
DECL|method|newObjectMetadata ()
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|()
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
operator|new
name|ObjectMetadata
argument_list|()
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|om
argument_list|)
expr_stmt|;
return|return
name|om
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    *    * @param length length of data to set in header.    * @return a new metadata instance    */
DECL|method|newObjectMetadata (long length)
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|(
name|long
name|length
parameter_list|)
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|length
operator|>=
literal|0
condition|)
block|{
name|om
operator|.
name|setContentLength
argument_list|(
name|length
argument_list|)
expr_stmt|;
block|}
return|return
name|om
return|;
block|}
comment|/**    * Start a transfer-manager managed async PUT of an object,    * incrementing the put requests and put bytes    * counters.    * It does not update the other counters,    * as existing code does that as progress callbacks come in.    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    * Because the operation is async, any stream supplied in the request    * must reference data (files, buffers) which stay valid until the upload    * completes.    * @param putObjectRequest the request    * @return the upload initiated    */
DECL|method|putObject (PutObjectRequest putObjectRequest)
specifier|public
name|Upload
name|putObject
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
block|{
name|long
name|len
decl_stmt|;
if|if
condition|(
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getMetadata
argument_list|()
operator|.
name|getContentLength
argument_list|()
expr_stmt|;
block|}
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|Upload
name|upload
init|=
name|transfers
operator|.
name|upload
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|upload
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * PUT an object directly (i.e. not via the transfer manager).    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    *<i>Important: this call will close any input stream in the request.</i>    * @param putObjectRequest the request    * @return the upload initiated    * @throws AmazonClientException on problems    */
DECL|method|putObjectDirect (PutObjectRequest putObjectRequest)
specifier|public
name|PutObjectResult
name|putObjectDirect
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|long
name|len
decl_stmt|;
if|if
condition|(
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getMetadata
argument_list|()
operator|.
name|getContentLength
argument_list|()
expr_stmt|;
block|}
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|PutObjectResult
name|result
init|=
name|s3
operator|.
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Upload part of a multi-partition file.    * Increments the write and put counters.    *<i>Important: this call does not close any input stream in the request.</i>    * @param request request    * @return the result of the operation.    * @throws AmazonClientException on problems    */
DECL|method|uploadPart (UploadPartRequest request)
specifier|public
name|UploadPartResult
name|uploadPart
parameter_list|(
name|UploadPartRequest
name|request
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|long
name|len
init|=
name|request
operator|.
name|getPartSize
argument_list|()
decl_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|UploadPartResult
name|uploadPartResult
init|=
name|s3
operator|.
name|uploadPart
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|uploadPartResult
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * At the start of a put/multipart upload operation, update the    * relevant counters.    *    * @param bytes bytes in the request.    */
DECL|method|incrementPutStartStatistics (long bytes)
specifier|public
name|void
name|incrementPutStartStatistics
parameter_list|(
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT start {} bytes"
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS
argument_list|)
expr_stmt|;
name|incrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * At the end of a put/multipart upload operation, update the    * relevant counters and gauges.    *    * @param success did the operation succeed?    * @param bytes bytes in the request.    */
DECL|method|incrementPutCompletedStatistics (boolean success, long bytes)
specifier|public
name|void
name|incrementPutCompletedStatistics
parameter_list|(
name|boolean
name|success
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT completed success={}; {} bytes"
argument_list|,
name|success
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_BYTES
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS_COMPLETED
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback for use in progress callbacks from put/multipart upload events.    * Increments those statistics which are expected to be updated during    * the ongoing upload operation.    * @param key key to file that is being written (for logging)    * @param bytes bytes successfully uploaded.    */
DECL|method|incrementPutProgressStatistics (String key, long bytes)
specifier|public
name|void
name|incrementPutProgressStatistics
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|PROGRESS
operator|.
name|debug
argument_list|(
literal|"PUT {}: {} bytes"
argument_list|,
name|key
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|statistics
operator|.
name|incrementBytesWritten
argument_list|(
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * A helper method to delete a list of keys on a s3-backend.    *    * @param keysToDelete collection of keys to delete on the s3-backend.    *        if empty, no request is made of the object store.    * @param clearKeys clears the keysToDelete-list after processing the list    *            when set to true    * @param deleteFakeDir indicates whether this is for deleting fake dirs    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
DECL|method|removeKeys (List<DeleteObjectsRequest.KeyVersion> keysToDelete, boolean clearKeys, boolean deleteFakeDir)
specifier|private
name|void
name|removeKeys
parameter_list|(
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
name|boolean
name|clearKeys
parameter_list|,
name|boolean
name|deleteFakeDir
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|InvalidRequestException
block|{
if|if
condition|(
name|keysToDelete
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// exit fast if there are no keys to delete
return|return;
block|}
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|blockRootDelete
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|enableMultiObjectsDelete
condition|)
block|{
name|deleteObjects
argument_list|(
operator|new
name|DeleteObjectsRequest
argument_list|(
name|bucket
argument_list|)
operator|.
name|withKeys
argument_list|(
name|keysToDelete
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|deleteObject
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|deleteFakeDir
condition|)
block|{
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|instrumentation
operator|.
name|fakeDirsDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|clearKeys
condition|)
block|{
name|keysToDelete
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Delete a Path. This operation is at least {@code O(files)}, with    * added overheads to enumerate the path. It is also not atomic.    *    * @param f the path to delete.    * @param recursive if path is a directory and set to    * true, the directory is deleted else throws an exception. In    * case of a file the recursive can be set to either true or false.    * @return  true if delete is successful else false.    * @throws IOException due to inability to delete a directory or file.    */
DECL|method|delete (Path f, boolean recursive)
specifier|public
name|boolean
name|delete
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|innerDelete
argument_list|(
name|getFileStatus
argument_list|(
name|f
argument_list|)
argument_list|,
name|recursive
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Couldn't delete {} - does not exist"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"delete"
argument_list|,
name|f
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Delete an object. See {@link #delete(Path, boolean)}.    *    * @param status fileStatus object    * @param recursive if path is a directory and set to    * true, the directory is deleted else throws an exception. In    * case of a file the recursive can be set to either true or false.    * @return  true if delete is successful else false.    * @throws IOException due to inability to delete a directory or file.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerDelete (S3AFileStatus status, boolean recursive)
specifier|private
name|boolean
name|innerDelete
parameter_list|(
name|S3AFileStatus
name|status
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|f
init|=
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Delete path {} - recursive {}"
argument_list|,
name|f
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"delete: Path is a directory: {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|key
operator|=
name|key
operator|+
literal|"/"
expr_stmt|;
block|}
if|if
condition|(
name|key
operator|.
name|equals
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
return|return
name|rejectRootDirectoryDelete
argument_list|(
name|status
argument_list|,
name|recursive
argument_list|)
return|;
block|}
if|if
condition|(
operator|!
name|recursive
operator|&&
operator|!
name|status
operator|.
name|isEmptyDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|PathIsNotEmptyDirectoryException
argument_list|(
name|f
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|status
operator|.
name|isEmptyDirectory
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting fake empty directory {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|deleteObject
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|directoryDeleted
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting objects for directory prefix {} to delete"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|ListObjectsRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|ObjectListing
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keys
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|objects
operator|.
name|getObjectSummaries
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|objects
operator|.
name|getObjectSummaries
argument_list|()
control|)
block|{
name|keys
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got object to delete {}"
argument_list|,
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|keys
operator|.
name|size
argument_list|()
operator|==
name|MAX_ENTRIES_TO_DELETE
condition|)
block|{
name|removeKeys
argument_list|(
name|keys
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|objects
operator|.
name|isTruncated
argument_list|()
condition|)
block|{
name|objects
operator|=
name|continueListObjects
argument_list|(
name|objects
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|keys
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|removeKeys
argument_list|(
name|keys
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"delete: Path is a file"
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|deleteObject
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
name|Path
name|parent
init|=
name|f
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|createFakeDirectoryIfNecessary
argument_list|(
name|parent
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Implements the specific logic to reject root directory deletion.    * The caller must return the result of this call, rather than    * attempt to continue with the delete operation: deleting root    * directories is never allowed. This method simply implements    * the policy of when to return an exit code versus raise an exception.    * @param status filesystem status    * @param recursive recursive flag from command    * @return a return code for the operation    * @throws PathIOException if the operation was explicitly rejected.    */
DECL|method|rejectRootDirectoryDelete (S3AFileStatus status, boolean recursive)
specifier|private
name|boolean
name|rejectRootDirectoryDelete
parameter_list|(
name|S3AFileStatus
name|status
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"s3a delete the {} root directory of {}"
argument_list|,
name|bucket
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
name|boolean
name|emptyRoot
init|=
name|status
operator|.
name|isEmptyDirectory
argument_list|()
decl_stmt|;
if|if
condition|(
name|emptyRoot
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|recursive
condition|)
block|{
return|return
literal|false
return|;
block|}
else|else
block|{
comment|// reject
throw|throw
operator|new
name|PathIOException
argument_list|(
name|bucket
argument_list|,
literal|"Cannot delete root path"
argument_list|)
throw|;
block|}
block|}
DECL|method|createFakeDirectoryIfNecessary (Path f)
specifier|private
name|void
name|createFakeDirectoryIfNecessary
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|exists
argument_list|(
name|f
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating new fake directory at {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    *         IOException see specific implementation    */
DECL|method|listStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|listStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
try|try
block|{
return|return
name|innerListStatus
argument_list|(
name|f
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"listStatus"
argument_list|,
name|f
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    * @throws IOException due to an IO problem.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerListStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|innerListStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"List status for path: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_STATUS
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|result
decl_stmt|;
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|key
operator|=
name|key
operator|+
literal|'/'
expr_stmt|;
block|}
name|ListObjectsRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listStatus: doing listObjects for directory {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|Listing
operator|.
name|FileStatusListingIterator
name|files
init|=
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|request
argument_list|,
name|ACCEPT_ALL
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|getBatchSize
argument_list|()
argument_list|)
expr_stmt|;
while|while
condition|(
name|files
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|files
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|result
operator|.
name|toArray
argument_list|(
operator|new
name|FileStatus
index|[
name|result
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding: rd (not a dir): {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|stats
init|=
operator|new
name|FileStatus
index|[
literal|1
index|]
decl_stmt|;
name|stats
index|[
literal|0
index|]
operator|=
name|fileStatus
expr_stmt|;
return|return
name|stats
return|;
block|}
block|}
comment|/**    * Create a {@code ListObjectsRequest} request against this bucket,    * with the maximum keys returned in a query set by {@link #maxKeys}.    * @param key key for request    * @param delimiter any delimiter    * @return the request    */
DECL|method|createListObjectsRequest (String key, String delimiter)
specifier|private
name|ListObjectsRequest
name|createListObjectsRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|delimiter
parameter_list|)
block|{
name|ListObjectsRequest
name|request
init|=
operator|new
name|ListObjectsRequest
argument_list|()
decl_stmt|;
name|request
operator|.
name|setBucketName
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
name|request
operator|.
name|setMaxKeys
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
name|request
operator|.
name|setPrefix
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|delimiter
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setDelimiter
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
return|return
name|request
return|;
block|}
comment|/**    * Set the current working directory for the given file system. All relative    * paths will be resolved relative to it.    *    * @param newDir the current working directory.    */
DECL|method|setWorkingDirectory (Path newDir)
specifier|public
name|void
name|setWorkingDirectory
parameter_list|(
name|Path
name|newDir
parameter_list|)
block|{
name|workingDir
operator|=
name|newDir
expr_stmt|;
block|}
comment|/**    * Get the current working directory for the given file system.    * @return the directory pathname    */
DECL|method|getWorkingDirectory ()
specifier|public
name|Path
name|getWorkingDirectory
parameter_list|()
block|{
return|return
name|workingDir
return|;
block|}
comment|/**    * Get the username of the FS.    * @return the short name of the user who instantiated the FS    */
DECL|method|getUsername ()
specifier|public
name|String
name|getUsername
parameter_list|()
block|{
return|return
name|username
return|;
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories. Has the semantics of Unix {@code 'mkdir -p'}.    * Existence of the directory hierarchy is not an error.    * @param path path to create    * @param permission to apply to f    * @return true if a directory was created    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    */
comment|// TODO: If we have created an empty file at /foo/bar and we then call
comment|// mkdirs for /foo/bar/baz/roo what happens to the empty file /foo/bar/?
DECL|method|mkdirs (Path path, FsPermission permission)
specifier|public
name|boolean
name|mkdirs
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
block|{
try|try
block|{
return|return
name|innerMkdirs
argument_list|(
name|path
argument_list|,
name|permission
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"innerMkdirs"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories.    * See {@link #mkdirs(Path, FsPermission)}    * @param f path to create    * @param permission to apply to f    * @return true if a directory was created    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerMkdirs (Path f, FsPermission permission)
specifier|private
name|boolean
name|innerMkdirs
parameter_list|(
name|Path
name|f
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Making directory: {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|INVOCATION_MKDIRS
argument_list|)
expr_stmt|;
name|FileStatus
name|fileStatus
decl_stmt|;
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Path is a file: "
operator|+
name|f
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|Path
name|fPart
init|=
name|f
operator|.
name|getParent
argument_list|()
decl_stmt|;
do|do
block|{
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|fPart
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Can't make directory for path '%s' since it is a file."
argument_list|,
name|fPart
argument_list|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
block|}
name|fPart
operator|=
name|fPart
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
do|while
condition|(
name|fPart
operator|!=
literal|null
condition|)
do|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|f
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
comment|/**    * Return a file status object that represents the path.    * @param f The path we want information from    * @return a FileStatus object    * @throws java.io.FileNotFoundException when the path does not exist;    * @throws IOException on other problems.    */
DECL|method|getFileStatus (final Path f)
specifier|public
name|S3AFileStatus
name|getFileStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GET_FILE_STATUS
argument_list|)
expr_stmt|;
specifier|final
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting path status for {}  ({})"
argument_list|,
name|path
argument_list|,
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: normal file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// Necessary?
if|if
condition|(
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|String
name|newKey
init|=
name|key
operator|+
literal|"/"
decl_stmt|;
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|newKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|newKey
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file (with /): fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file (with /): real file? should not happen: {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
try|try
block|{
name|key
operator|=
name|maybeAddTrailingSlash
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|ListObjectsRequest
name|request
init|=
operator|new
name|ListObjectsRequest
argument_list|()
decl_stmt|;
name|request
operator|.
name|setBucketName
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
name|request
operator|.
name|setPrefix
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|request
operator|.
name|setDelimiter
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
name|request
operator|.
name|setMaxKeys
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|ObjectListing
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|objects
operator|.
name|getCommonPrefixes
argument_list|()
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|objects
operator|.
name|getObjectSummaries
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found path as directory (with /): {}/{}"
argument_list|,
name|objects
operator|.
name|getCommonPrefixes
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|objects
operator|.
name|getObjectSummaries
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|objects
operator|.
name|getObjectSummaries
argument_list|()
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Summary: {} {}"
argument_list|,
name|summary
operator|.
name|getKey
argument_list|()
argument_list|,
name|summary
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|prefix
range|:
name|objects
operator|.
name|getCommonPrefixes
argument_list|()
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Prefix: {}"
argument_list|,
name|prefix
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|S3AFileStatus
argument_list|(
literal|false
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found root directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
literal|true
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
literal|404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|key
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|key
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Not Found: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No such file or directory: "
operator|+
name|path
argument_list|)
throw|;
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src path    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false    * @throws AmazonClientException failure in the AWS SDK    */
annotation|@
name|Override
DECL|method|copyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|public
name|void
name|copyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|innerCopyFromLocalFile
argument_list|(
name|delSrc
argument_list|,
name|overwrite
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"copyFromLocalFile("
operator|+
name|src
operator|+
literal|", "
operator|+
name|dst
operator|+
literal|")"
argument_list|,
name|src
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src path    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false    * @throws AmazonClientException failure in the AWS SDK    */
DECL|method|innerCopyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|private
name|void
name|innerCopyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_COPY_FROM_LOCAL_FILE
argument_list|)
expr_stmt|;
specifier|final
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|overwrite
operator|&&
name|exists
argument_list|(
name|dst
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|dst
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copying local file from {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Since we have a local file, we don't need to stream into a temporary file
name|LocalFileSystem
name|local
init|=
name|getLocal
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|File
name|srcfile
init|=
name|local
operator|.
name|pathToFile
argument_list|(
name|src
argument_list|)
decl_stmt|;
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|(
name|srcfile
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|key
argument_list|,
name|om
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|Upload
name|up
init|=
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|ProgressableProgressListener
name|listener
init|=
operator|new
name|ProgressableProgressListener
argument_list|(
name|this
argument_list|,
name|key
argument_list|,
name|up
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|up
operator|.
name|addProgressListener
argument_list|(
name|listener
argument_list|)
expr_stmt|;
try|try
block|{
name|up
operator|.
name|waitForUploadResult
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted copying "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|dst
operator|+
literal|", cancelling"
argument_list|)
throw|;
block|}
name|listener
operator|.
name|uploadCompleted
argument_list|()
expr_stmt|;
comment|// This will delete unnecessary fake parent directories
name|finishedWrite
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|delSrc
condition|)
block|{
name|local
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Close the filesystem. This shuts down all transfers.    * @throws IOException IO problem    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
comment|// already closed
return|return;
block|}
try|try
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|transfers
operator|!=
literal|null
condition|)
block|{
name|transfers
operator|.
name|shutdownNow
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|transfers
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Override getCanonicalServiceName because we don't support token in S3A.    */
annotation|@
name|Override
DECL|method|getCanonicalServiceName ()
specifier|public
name|String
name|getCanonicalServiceName
parameter_list|()
block|{
comment|// Does not support Token
return|return
literal|null
return|;
block|}
comment|/**    * Copy a single object in the bucket via a COPY operation.    * @param srcKey source object path    * @param dstKey destination object path    * @param size object size    * @throws AmazonClientException on failures inside the AWS SDK    * @throws InterruptedIOException the operation was interrupted    * @throws IOException Other IO problems    */
DECL|method|copyFile (String srcKey, String dstKey, long size)
specifier|private
name|void
name|copyFile
parameter_list|(
name|String
name|srcKey
parameter_list|,
name|String
name|dstKey
parameter_list|,
name|long
name|size
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedIOException
throws|,
name|AmazonClientException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"copyFile {} -> {} "
argument_list|,
name|srcKey
argument_list|,
name|dstKey
argument_list|)
expr_stmt|;
try|try
block|{
name|ObjectMetadata
name|srcom
init|=
name|getObjectMetadata
argument_list|(
name|srcKey
argument_list|)
decl_stmt|;
name|ObjectMetadata
name|dstom
init|=
name|cloneObjectMetadata
argument_list|(
name|srcom
argument_list|)
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
name|CopyObjectRequest
name|copyObjectRequest
init|=
operator|new
name|CopyObjectRequest
argument_list|(
name|bucket
argument_list|,
name|srcKey
argument_list|,
name|bucket
argument_list|,
name|dstKey
argument_list|)
decl_stmt|;
name|setOptionalCopyObjectRequestParameters
argument_list|(
name|copyObjectRequest
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setCannedAccessControlList
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setNewObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
name|ProgressListener
name|progressListener
init|=
operator|new
name|ProgressListener
argument_list|()
block|{
specifier|public
name|void
name|progressChanged
parameter_list|(
name|ProgressEvent
name|progressEvent
parameter_list|)
block|{
switch|switch
condition|(
name|progressEvent
operator|.
name|getEventType
argument_list|()
condition|)
block|{
case|case
name|TRANSFER_PART_COMPLETED_EVENT
case|:
name|incrementWriteOperations
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
block|}
decl_stmt|;
name|Copy
name|copy
init|=
name|transfers
operator|.
name|copy
argument_list|(
name|copyObjectRequest
argument_list|)
decl_stmt|;
name|copy
operator|.
name|addProgressListener
argument_list|(
name|progressListener
argument_list|)
expr_stmt|;
try|try
block|{
name|copy
operator|.
name|waitForCopyResult
argument_list|()
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|instrumentation
operator|.
name|filesCopied
argument_list|(
literal|1
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted copying "
operator|+
name|srcKey
operator|+
literal|" to "
operator|+
name|dstKey
operator|+
literal|", cancelling"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"copyFile("
operator|+
name|srcKey
operator|+
literal|", "
operator|+
name|dstKey
operator|+
literal|")"
argument_list|,
name|srcKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
DECL|method|setOptionalMultipartUploadRequestParameters ( InitiateMultipartUploadRequest req)
specifier|protected
name|void
name|setOptionalMultipartUploadRequestParameters
parameter_list|(
name|InitiateMultipartUploadRequest
name|req
parameter_list|)
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|req
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
comment|//at the moment, only supports copy using the same key
name|req
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalCopyObjectRequestParameters ( CopyObjectRequest copyObjectRequest)
specifier|protected
name|void
name|setOptionalCopyObjectRequestParameters
parameter_list|(
name|CopyObjectRequest
name|copyObjectRequest
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|copyObjectRequest
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
comment|//at the moment, only supports copy using the same key
name|SSECustomerKey
name|customerKey
init|=
name|generateSSECustomerKey
argument_list|()
decl_stmt|;
name|copyObjectRequest
operator|.
name|setSourceSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setDestinationSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalPutRequestParameters (PutObjectRequest request)
specifier|private
name|void
name|setOptionalPutRequestParameters
parameter_list|(
name|PutObjectRequest
name|request
parameter_list|)
block|{
switch|switch
condition|(
name|serverSideEncryptionAlgorithm
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|request
operator|.
name|setSSEAwsKeyManagementParams
argument_list|(
name|generateSSEAwsKeyParams
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|request
operator|.
name|setSSECustomerKey
argument_list|(
name|generateSSECustomerKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalObjectMetadata (ObjectMetadata metadata)
specifier|private
name|void
name|setOptionalObjectMetadata
parameter_list|(
name|ObjectMetadata
name|metadata
parameter_list|)
block|{
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_S3
operator|.
name|equals
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
condition|)
block|{
name|metadata
operator|.
name|setSSEAlgorithm
argument_list|(
name|serverSideEncryptionAlgorithm
operator|.
name|getMethod
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
DECL|method|generateSSEAwsKeyParams ()
specifier|private
name|SSEAwsKeyManagementParams
name|generateSSEAwsKeyParams
parameter_list|()
block|{
comment|//Use specified key, otherwise default to default master aws/s3 key by AWS
name|SSEAwsKeyManagementParams
name|sseAwsKeyManagementParams
init|=
operator|new
name|SSEAwsKeyManagementParams
argument_list|()
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotBlank
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|sseAwsKeyManagementParams
operator|=
operator|new
name|SSEAwsKeyManagementParams
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sseAwsKeyManagementParams
return|;
block|}
DECL|method|generateSSECustomerKey ()
specifier|private
name|SSECustomerKey
name|generateSSECustomerKey
parameter_list|()
block|{
name|SSECustomerKey
name|customerKey
init|=
operator|new
name|SSECustomerKey
argument_list|(
name|getServerSideEncryptionKey
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|customerKey
return|;
block|}
comment|/**    * Perform post-write actions.    * @param key key written to    */
DECL|method|finishedWrite (String key)
specifier|public
name|void
name|finishedWrite
parameter_list|(
name|String
name|key
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished write to {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|keyToPath
argument_list|(
name|key
argument_list|)
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete mock parent directories which are no longer needed.    * This code swallows IO exceptions encountered    * @param path path    */
DECL|method|deleteUnnecessaryFakeDirectories (Path path)
specifier|private
name|void
name|deleteUnnecessaryFakeDirectories
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|key
operator|=
operator|(
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
operator|)
condition|?
name|key
else|:
operator|(
name|key
operator|+
literal|"/"
operator|)
expr_stmt|;
name|keysToRemove
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|path
operator|=
name|path
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|removeKeys
argument_list|(
name|keysToRemove
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
decl||
name|InvalidRequestException
name|e
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|kv
range|:
name|keysToRemove
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|kv
operator|.
name|getKey
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"While deleting keys {} "
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
DECL|method|createFakeDirectory (final String objectName)
specifier|private
name|void
name|createFakeDirectory
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|AmazonServiceException
throws|,
name|InterruptedIOException
block|{
if|if
condition|(
operator|!
name|objectName
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|createEmptyObject
argument_list|(
name|objectName
operator|+
literal|"/"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|createEmptyObject
argument_list|(
name|objectName
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Used to create an empty file that represents an empty directory
DECL|method|createEmptyObject (final String objectName)
specifier|private
name|void
name|createEmptyObject
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|AmazonServiceException
throws|,
name|InterruptedIOException
block|{
specifier|final
name|InputStream
name|im
init|=
operator|new
name|InputStream
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|objectName
argument_list|,
name|newObjectMetadata
argument_list|(
literal|0L
argument_list|)
argument_list|,
name|im
argument_list|)
decl_stmt|;
name|Upload
name|upload
init|=
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
try|try
block|{
name|upload
operator|.
name|waitForUploadResult
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted creating "
operator|+
name|objectName
argument_list|)
throw|;
block|}
name|incrementPutProgressStatistics
argument_list|(
name|objectName
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|directoryCreated
argument_list|()
expr_stmt|;
block|}
comment|/**    * Creates a copy of the passed {@link ObjectMetadata}.    * Does so without using the {@link ObjectMetadata#clone()} method,    * to avoid copying unnecessary headers.    * @param source the {@link ObjectMetadata} to copy    * @return a copy of {@link ObjectMetadata} with only relevant attributes    */
DECL|method|cloneObjectMetadata (ObjectMetadata source)
specifier|private
name|ObjectMetadata
name|cloneObjectMetadata
parameter_list|(
name|ObjectMetadata
name|source
parameter_list|)
block|{
comment|// This approach may be too brittle, especially if
comment|// in future there are new attributes added to ObjectMetadata
comment|// that we do not explicitly call to set here
name|ObjectMetadata
name|ret
init|=
name|newObjectMetadata
argument_list|(
name|source
operator|.
name|getContentLength
argument_list|()
argument_list|)
decl_stmt|;
comment|// Possibly null attributes
comment|// Allowing nulls to pass breaks it during later use
if|if
condition|(
name|source
operator|.
name|getCacheControl
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setCacheControl
argument_list|(
name|source
operator|.
name|getCacheControl
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentDisposition
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentDisposition
argument_list|(
name|source
operator|.
name|getContentDisposition
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentEncoding
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentEncoding
argument_list|(
name|source
operator|.
name|getContentEncoding
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentMD5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentMD5
argument_list|(
name|source
operator|.
name|getContentMD5
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentType
argument_list|(
name|source
operator|.
name|getContentType
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTime
argument_list|(
name|source
operator|.
name|getExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTimeRuleId
argument_list|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setHttpExpiresDate
argument_list|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getLastModified
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setLastModified
argument_list|(
name|source
operator|.
name|getLastModified
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setOngoingRestore
argument_list|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setRestoreExpirationTime
argument_list|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSEAlgorithm
argument_list|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerAlgorithm
argument_list|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerKeyMd5
argument_list|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|source
operator|.
name|getUserMetadata
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|ret
operator|.
name|addUserMetadata
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * Return the number of bytes that large input files should be optimally    * be split into to minimize I/O time.    * @deprecated use {@link #getDefaultBlockSize(Path)} instead    */
annotation|@
name|Deprecated
DECL|method|getDefaultBlockSize ()
specifier|public
name|long
name|getDefaultBlockSize
parameter_list|()
block|{
return|return
name|getConf
argument_list|()
operator|.
name|getLongBytes
argument_list|(
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"S3AFileSystem{"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"uri="
argument_list|)
operator|.
name|append
argument_list|(
name|uri
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", workingDir="
argument_list|)
operator|.
name|append
argument_list|(
name|workingDir
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", inputPolicy="
argument_list|)
operator|.
name|append
argument_list|(
name|inputPolicy
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", partSize="
argument_list|)
operator|.
name|append
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", enableMultiObjectsDelete="
argument_list|)
operator|.
name|append
argument_list|(
name|enableMultiObjectsDelete
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", maxKeys="
argument_list|)
operator|.
name|append
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
if|if
condition|(
name|cannedACL
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", cannedACL="
argument_list|)
operator|.
name|append
argument_list|(
name|cannedACL
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", readAhead="
argument_list|)
operator|.
name|append
argument_list|(
name|readAhead
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", blockSize="
argument_list|)
operator|.
name|append
argument_list|(
name|getDefaultBlockSize
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", multiPartThreshold="
argument_list|)
operator|.
name|append
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
if|if
condition|(
name|serverSideEncryptionAlgorithm
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", serverSideEncryptionAlgorithm='"
argument_list|)
operator|.
name|append
argument_list|(
name|serverSideEncryptionAlgorithm
argument_list|)
operator|.
name|append
argument_list|(
literal|'\''
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|blockFactory
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", blockFactory="
argument_list|)
operator|.
name|append
argument_list|(
name|blockFactory
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", boundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|boundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", unboundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", statistics {"
argument_list|)
operator|.
name|append
argument_list|(
name|statistics
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", metrics {"
argument_list|)
operator|.
name|append
argument_list|(
name|instrumentation
operator|.
name|dump
argument_list|(
literal|"{"
argument_list|,
literal|"="
argument_list|,
literal|"} "
argument_list|,
literal|true
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Get the partition size for multipart operations.    * @return the value as set during initialization    */
DECL|method|getPartitionSize ()
specifier|public
name|long
name|getPartitionSize
parameter_list|()
block|{
return|return
name|partSize
return|;
block|}
comment|/**    * Get the threshold for multipart files.    * @return the value as set during initialization    */
DECL|method|getMultiPartThreshold ()
specifier|public
name|long
name|getMultiPartThreshold
parameter_list|()
block|{
return|return
name|multiPartThreshold
return|;
block|}
comment|/**    * Get the maximum key count.    * @return a value, valid after initialization    */
DECL|method|getMaxKeys ()
name|int
name|getMaxKeys
parameter_list|()
block|{
return|return
name|maxKeys
return|;
block|}
comment|/**    * Increments the statistic {@link Statistic#INVOCATION_GLOB_STATUS}.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus (Path pathPattern)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
name|Path
name|pathPattern
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GLOB_STATUS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|globStatus
argument_list|(
name|pathPattern
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus (Path pathPattern, PathFilter filter)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
name|Path
name|pathPattern
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_GLOB_STATUS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|globStatus
argument_list|(
name|pathPattern
argument_list|,
name|filter
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|exists (Path f)
specifier|public
name|boolean
name|exists
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_EXISTS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|exists
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isDirectory (Path f)
specifier|public
name|boolean
name|isDirectory
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_IS_DIRECTORY
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isDirectory
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isFile (Path f)
specifier|public
name|boolean
name|isFile
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_IS_FILE
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isFile
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    *    * This implementation is optimized for S3, which can do a bulk listing    * off all entries under a path in one single operation. Thus there is    * no need to recursively walk the directory tree.    *    * Instead a {@link ListObjectsRequest} is created requesting a (windowed)    * listing of all entries under the given path. This is used to construct    * an {@code ObjectListingIterator} instance, iteratively returning the    * sequence of lists of elements under the path. This is then iterated    * over in a {@code FileStatusListingIterator}, which generates    * {@link S3AFileStatus} instances, one per listing entry.    * These are then translated into {@link LocatedFileStatus} instances.    *    * This is essentially a nested and wrapped set of iterators, with some    * generator classes; an architecture which may become less convoluted    * using lambda-expressions.    * @param f a path    * @param recursive if the subdirectories need to be traversed recursively    *    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
DECL|method|listFiles (Path f, boolean recursive)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listFiles
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_FILES
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listFiles({}, {})"
argument_list|,
name|path
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
try|try
block|{
comment|// lookup dir triggers existence check
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: do a bulk operation
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|delimiter
init|=
name|recursive
condition|?
literal|null
else|:
literal|"/"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Requesting all entries under {} with delimiter '{}'"
argument_list|,
name|key
argument_list|,
name|delimiter
argument_list|)
expr_stmt|;
return|return
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
name|delimiter
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptFilesOnly
argument_list|(
name|path
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"listFiles"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|listLocatedStatus (Path f)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|listLocatedStatus
argument_list|(
name|f
argument_list|,
name|ACCEPT_ALL
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    *    * S3 Optimized directory listing. The initial operation performs the    * first bulk listing; extra listings will take place    * when all the current set of results are used up.    * @param f a path    * @param filter a path filter    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
DECL|method|listLocatedStatus (final Path f, final PathFilter filter)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
name|incrementStatistic
argument_list|(
name|INVOCATION_LIST_LOCATED_STATUS
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listLocatedStatus({}, {}"
argument_list|,
name|path
argument_list|,
name|filter
argument_list|)
expr_stmt|;
try|try
block|{
comment|// lookup dir triggers existence check
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|filter
operator|.
name|accept
argument_list|(
name|path
argument_list|)
condition|?
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: trigger a lookup
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
argument_list|,
name|filter
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"listLocatedStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Build a {@link LocatedFileStatus} from a {@link FileStatus} instance.    * @param status file status    * @return a located status with block locations set up from this FS.    * @throws IOException IO Problems.    */
DECL|method|toLocatedFileStatus (FileStatus status)
name|LocatedFileStatus
name|toLocatedFileStatus
parameter_list|(
name|FileStatus
name|status
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|LocatedFileStatus
argument_list|(
name|status
argument_list|,
name|status
operator|.
name|isFile
argument_list|()
condition|?
name|getFileBlockLocations
argument_list|(
name|status
argument_list|,
literal|0
argument_list|,
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
comment|/**    * Helper for an ongoing write operation.    *<p>    * It hides direct access to the S3 API from the output stream,    * and is a location where the object upload process can be evolved/enhanced.    *<p>    * Features    *<ul>    *<li>Methods to create and submit requests to S3, so avoiding    *   all direct interaction with the AWS APIs.</li>    *<li>Some extra preflight checks of arguments, so failing fast on    *   errors.</li>    *<li>Callbacks to let the FS know of events in the output stream    *   upload process.</li>    *</ul>    *    * Each instance of this state is unique to a single output stream.    */
DECL|class|WriteOperationHelper
specifier|final
class|class
name|WriteOperationHelper
block|{
DECL|field|key
specifier|private
specifier|final
name|String
name|key
decl_stmt|;
DECL|method|WriteOperationHelper (String key)
specifier|private
name|WriteOperationHelper
parameter_list|(
name|String
name|key
parameter_list|)
block|{
name|this
operator|.
name|key
operator|=
name|key
expr_stmt|;
block|}
comment|/**      * Create a {@link PutObjectRequest} request.      * If {@code length} is set, the metadata is configured with the size of      * the upload.      * @param inputStream source data.      * @param length size, if known. Use -1 for not known      * @return the request      */
DECL|method|newPutRequest (InputStream inputStream, long length)
name|PutObjectRequest
name|newPutRequest
parameter_list|(
name|InputStream
name|inputStream
parameter_list|,
name|long
name|length
parameter_list|)
block|{
name|PutObjectRequest
name|request
init|=
name|newPutObjectRequest
argument_list|(
name|key
argument_list|,
name|newObjectMetadata
argument_list|(
name|length
argument_list|)
argument_list|,
name|inputStream
argument_list|)
decl_stmt|;
return|return
name|request
return|;
block|}
comment|/**      * Create a {@link PutObjectRequest} request to upload a file.      * @param sourceFile source file      * @return the request      */
DECL|method|newPutRequest (File sourceFile)
name|PutObjectRequest
name|newPutRequest
parameter_list|(
name|File
name|sourceFile
parameter_list|)
block|{
name|int
name|length
init|=
operator|(
name|int
operator|)
name|sourceFile
operator|.
name|length
argument_list|()
decl_stmt|;
name|PutObjectRequest
name|request
init|=
name|newPutObjectRequest
argument_list|(
name|key
argument_list|,
name|newObjectMetadata
argument_list|(
name|length
argument_list|)
argument_list|,
name|sourceFile
argument_list|)
decl_stmt|;
return|return
name|request
return|;
block|}
comment|/**      * Callback on a successful write.      */
DECL|method|writeSuccessful ()
name|void
name|writeSuccessful
parameter_list|()
block|{
name|finishedWrite
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
comment|/**      * Callback on a write failure.      * @param e Any exception raised which triggered the failure.      */
DECL|method|writeFailed (Exception e)
name|void
name|writeFailed
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Write to {} failed"
argument_list|,
name|this
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|/**      * Create a new object metadata instance.      * Any standard metadata headers are added here, for example:      * encryption.      * @param length size, if known. Use -1 for not known      * @return a new metadata instance      */
DECL|method|newObjectMetadata (long length)
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|(
name|long
name|length
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|newObjectMetadata
argument_list|(
name|length
argument_list|)
return|;
block|}
comment|/**      * Start the multipart upload process.      * @return the upload result containing the ID      * @throws IOException IO problem      */
DECL|method|initiateMultiPartUpload ()
name|String
name|initiateMultiPartUpload
parameter_list|()
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initiating Multipart upload"
argument_list|)
expr_stmt|;
specifier|final
name|InitiateMultipartUploadRequest
name|initiateMPURequest
init|=
operator|new
name|InitiateMultipartUploadRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|newObjectMetadata
argument_list|(
operator|-
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|initiateMPURequest
operator|.
name|setCannedACL
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|setOptionalMultipartUploadRequestParameters
argument_list|(
name|initiateMPURequest
argument_list|)
expr_stmt|;
try|try
block|{
return|return
name|s3
operator|.
name|initiateMultipartUpload
argument_list|(
name|initiateMPURequest
argument_list|)
operator|.
name|getUploadId
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|ace
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"initiate MultiPartUpload"
argument_list|,
name|key
argument_list|,
name|ace
argument_list|)
throw|;
block|}
block|}
comment|/**      * Complete a multipart upload operation.      * @param uploadId multipart operation Id      * @param partETags list of partial uploads      * @return the result      * @throws AmazonClientException on problems.      */
DECL|method|completeMultipartUpload (String uploadId, List<PartETag> partETags)
name|CompleteMultipartUploadResult
name|completeMultipartUpload
parameter_list|(
name|String
name|uploadId
parameter_list|,
name|List
argument_list|<
name|PartETag
argument_list|>
name|partETags
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|uploadId
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|partETags
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|partETags
operator|.
name|isEmpty
argument_list|()
argument_list|,
literal|"No partitions have been uploaded"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Completing multipart upload {} with {} parts"
argument_list|,
name|uploadId
argument_list|,
name|partETags
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// a copy of the list is required, so that the AWS SDK doesn't
comment|// attempt to sort an unmodifiable list.
return|return
name|s3
operator|.
name|completeMultipartUpload
argument_list|(
operator|new
name|CompleteMultipartUploadRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|uploadId
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|partETags
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Abort a multipart upload operation.      * @param uploadId multipart operation Id      * @throws AmazonClientException on problems.      */
DECL|method|abortMultipartUpload (String uploadId)
name|void
name|abortMultipartUpload
parameter_list|(
name|String
name|uploadId
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Aborting multipart upload {}"
argument_list|,
name|uploadId
argument_list|)
expr_stmt|;
name|s3
operator|.
name|abortMultipartUpload
argument_list|(
operator|new
name|AbortMultipartUploadRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|uploadId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**      * Create and initialize a part request of a multipart upload.      * Exactly one of: {@code uploadStream} or {@code sourceFile}      * must be specified.      * @param uploadId ID of ongoing upload      * @param partNumber current part number of the upload      * @param size amount of data      * @param uploadStream source of data to upload      * @param sourceFile optional source file.      * @return the request.      */
DECL|method|newUploadPartRequest (String uploadId, int partNumber, int size, InputStream uploadStream, File sourceFile)
name|UploadPartRequest
name|newUploadPartRequest
parameter_list|(
name|String
name|uploadId
parameter_list|,
name|int
name|partNumber
parameter_list|,
name|int
name|size
parameter_list|,
name|InputStream
name|uploadStream
parameter_list|,
name|File
name|sourceFile
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|uploadId
argument_list|)
expr_stmt|;
comment|// exactly one source must be set; xor verifies this
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|(
name|uploadStream
operator|!=
literal|null
operator|)
operator|^
operator|(
name|sourceFile
operator|!=
literal|null
operator|)
argument_list|,
literal|"Data source"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|size
operator|>
literal|0
argument_list|,
literal|"Invalid partition size %s"
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|partNumber
operator|>
literal|0
operator|&&
name|partNumber
operator|<=
literal|10000
argument_list|,
literal|"partNumber must be between 1 and 10000 inclusive, but is %s"
argument_list|,
name|partNumber
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating part upload request for {} #{} size {}"
argument_list|,
name|uploadId
argument_list|,
name|partNumber
argument_list|,
name|size
argument_list|)
expr_stmt|;
name|UploadPartRequest
name|request
init|=
operator|new
name|UploadPartRequest
argument_list|()
operator|.
name|withBucketName
argument_list|(
name|bucket
argument_list|)
operator|.
name|withKey
argument_list|(
name|key
argument_list|)
operator|.
name|withUploadId
argument_list|(
name|uploadId
argument_list|)
operator|.
name|withPartNumber
argument_list|(
name|partNumber
argument_list|)
operator|.
name|withPartSize
argument_list|(
name|size
argument_list|)
decl_stmt|;
if|if
condition|(
name|uploadStream
operator|!=
literal|null
condition|)
block|{
comment|// there's an upload stream. Bind to it.
name|request
operator|.
name|setInputStream
argument_list|(
name|uploadStream
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|request
operator|.
name|setFile
argument_list|(
name|sourceFile
argument_list|)
expr_stmt|;
block|}
return|return
name|request
return|;
block|}
comment|/**      * The toString method is intended to be used in logging/toString calls.      * @return a string description.      */
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"{bucket="
argument_list|)
operator|.
name|append
argument_list|(
name|bucket
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", key='"
argument_list|)
operator|.
name|append
argument_list|(
name|key
argument_list|)
operator|.
name|append
argument_list|(
literal|'\''
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**      * PUT an object directly (i.e. not via the transfer manager).      * @param putObjectRequest the request      * @return the upload initiated      * @throws IOException on problems      */
DECL|method|putObject (PutObjectRequest putObjectRequest)
name|PutObjectResult
name|putObject
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
return|return
name|putObjectDirect
argument_list|(
name|putObjectRequest
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"put"
argument_list|,
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
end_class

end_unit

