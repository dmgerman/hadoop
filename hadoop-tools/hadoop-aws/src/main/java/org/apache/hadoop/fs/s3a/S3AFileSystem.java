begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.fs.s3a
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|AccessDeniedException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|DateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|SimpleDateFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|Instant
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|OffsetDateTime
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|ZoneOffset
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Date
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletableFuture
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonClientException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|AmazonServiceException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|SdkBaseException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|AmazonS3
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|AbortMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CannedAccessControlList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|CopyObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|DeleteObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|DeleteObjectsResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|GetObjectMetadataRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|InitiateMultipartUploadRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|InitiateMultipartUploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListMultipartUploadsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListObjectsRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ListObjectsV2Request
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|MultiObjectDeleteException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|MultipartUpload
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|ObjectMetadata
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|PutObjectResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|S3ObjectSummary
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSEAwsKeyManagementParams
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|SSECustomerKey
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartRequest
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|model
operator|.
name|UploadPartResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Copy
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManager
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|TransferManagerConfiguration
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|Upload
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|model
operator|.
name|CopyResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|services
operator|.
name|s3
operator|.
name|transfer
operator|.
name|model
operator|.
name|UploadResult
import|;
end_import

begin_import
import|import
name|com
operator|.
name|amazonaws
operator|.
name|event
operator|.
name|ProgressListener
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListeningExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|tuple
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|tuple
operator|.
name|Triple
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CommonPathCapabilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|CreateFlag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Globber
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|ChangeDetectionPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|ContextAccessors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|CopyOutcome
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|DeleteOperation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|InternalConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|MultiObjectDeleteSupport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|OperationCallbacks
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|RenameOperation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|StatusProbeEnum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|StoreContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|BulkOperationState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|select
operator|.
name|InternalSelectConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DurationInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|LambdaUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileAlreadyExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|GlobalStorageStatistics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|InvalidRequestException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalDirAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocalFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|RemoteIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|StreamCapabilities
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|RoleModel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|AWSPolicyProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|EncryptionSecretOperations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|EncryptionSecrets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|S3ADelegationTokens
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|AbstractS3ATokenIdentifier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|CommitConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|PutTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|commit
operator|.
name|MagicCommitIntegration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|ChangeTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|select
operator|.
name|SelectBinding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|select
operator|.
name|SelectConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|DirListingMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|MetadataStoreListFilesIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|MetadataStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|PathMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|S3Guard
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|s3guard
operator|.
name|ITtlTimeProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3native
operator|.
name|S3xLoginHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|retry
operator|.
name|RetryPolicies
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|store
operator|.
name|EtagChecksum
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|BlockingThreadPoolExecutorService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|token
operator|.
name|Token
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|SemaphoredDelegatingExecutor
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|impl
operator|.
name|AbstractFSBuilderImpl
operator|.
name|rejectUnknownMandatoryKeys
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|impl
operator|.
name|PathCapabilitiesSupport
operator|.
name|validatePathCapabilityArgs
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Constants
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Invoker
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|S3AUtils
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|Statistic
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
operator|.
name|isNotEmpty
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|RolePolicies
operator|.
name|STATEMENT_ALLOW_SSE_KMS_RW
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|RolePolicies
operator|.
name|allowS3Operations
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|S3ADelegationTokens
operator|.
name|TokenIssuingPolicy
operator|.
name|NoTokensAvailable
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|auth
operator|.
name|delegation
operator|.
name|S3ADelegationTokens
operator|.
name|hasDelegationTokenBinding
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|s3a
operator|.
name|impl
operator|.
name|InternalConstants
operator|.
name|SC_404
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
operator|.
name|cleanupWithLogger
import|;
end_import

begin_comment
comment|/**  * The core S3A Filesystem implementation.  *  * This subclass is marked as private as code should not be creating it  * directly; use {@link FileSystem#get(Configuration)} and variants to  * create one.  *  * If cast to {@code S3AFileSystem}, extra methods and features may be accessed.  * Consider those private and unstable.  *  * Because it prints some of the state of the instrumentation,  * the output of {@link #toString()} must also be considered unstable.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|S3AFileSystem
specifier|public
class|class
name|S3AFileSystem
extends|extends
name|FileSystem
implements|implements
name|StreamCapabilities
implements|,
name|AWSPolicyProvider
block|{
comment|/**    * Default blocksize as used in blocksize and FS status queries.    */
DECL|field|DEFAULT_BLOCKSIZE
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKSIZE
init|=
literal|32
operator|*
literal|1024
operator|*
literal|1024
decl_stmt|;
comment|/**    * This declared delete as idempotent.    * This is an "interesting" topic in past Hadoop FS work.    * Essentially: with a single caller, DELETE is idempotent    * but in a shared filesystem, it is is very much not so.    * Here, on the basis that isn't a filesystem with consistency guarantees,    * retryable results in files being deleted.   */
DECL|field|DELETE_CONSIDERED_IDEMPOTENT
specifier|public
specifier|static
specifier|final
name|boolean
name|DELETE_CONSIDERED_IDEMPOTENT
init|=
literal|true
decl_stmt|;
DECL|field|uri
specifier|private
name|URI
name|uri
decl_stmt|;
DECL|field|workingDir
specifier|private
name|Path
name|workingDir
decl_stmt|;
DECL|field|username
specifier|private
name|String
name|username
decl_stmt|;
DECL|field|s3
specifier|private
name|AmazonS3
name|s3
decl_stmt|;
comment|// initial callback policy is fail-once; it's there just to assist
comment|// some mock tests and other codepaths trying to call the low level
comment|// APIs on an uninitialized filesystem.
DECL|field|invoker
specifier|private
name|Invoker
name|invoker
init|=
operator|new
name|Invoker
argument_list|(
name|RetryPolicies
operator|.
name|TRY_ONCE_THEN_FAIL
argument_list|,
name|Invoker
operator|.
name|LOG_EVENT
argument_list|)
decl_stmt|;
comment|// Only used for very specific code paths which behave differently for
comment|// S3Guard. Retries FileNotFound, so be careful if you use this.
DECL|field|s3guardInvoker
specifier|private
name|Invoker
name|s3guardInvoker
init|=
operator|new
name|Invoker
argument_list|(
name|RetryPolicies
operator|.
name|TRY_ONCE_THEN_FAIL
argument_list|,
name|Invoker
operator|.
name|LOG_EVENT
argument_list|)
decl_stmt|;
DECL|field|onRetry
specifier|private
specifier|final
name|Retried
name|onRetry
init|=
name|this
operator|::
name|operationRetried
decl_stmt|;
DECL|field|bucket
specifier|private
name|String
name|bucket
decl_stmt|;
DECL|field|maxKeys
specifier|private
name|int
name|maxKeys
decl_stmt|;
DECL|field|listing
specifier|private
name|Listing
name|listing
decl_stmt|;
DECL|field|partSize
specifier|private
name|long
name|partSize
decl_stmt|;
DECL|field|enableMultiObjectsDelete
specifier|private
name|boolean
name|enableMultiObjectsDelete
decl_stmt|;
DECL|field|transfers
specifier|private
name|TransferManager
name|transfers
decl_stmt|;
DECL|field|boundedThreadPool
specifier|private
name|ListeningExecutorService
name|boundedThreadPool
decl_stmt|;
DECL|field|unboundedThreadPool
specifier|private
name|ThreadPoolExecutor
name|unboundedThreadPool
decl_stmt|;
DECL|field|executorCapacity
specifier|private
name|int
name|executorCapacity
decl_stmt|;
DECL|field|multiPartThreshold
specifier|private
name|long
name|multiPartThreshold
decl_stmt|;
DECL|field|LOG
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|S3AFileSystem
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|PROGRESS
specifier|private
specifier|static
specifier|final
name|Logger
name|PROGRESS
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
literal|"org.apache.hadoop.fs.s3a.S3AFileSystem.Progress"
argument_list|)
decl_stmt|;
DECL|field|directoryAllocator
specifier|private
name|LocalDirAllocator
name|directoryAllocator
decl_stmt|;
DECL|field|cannedACL
specifier|private
name|CannedAccessControlList
name|cannedACL
decl_stmt|;
DECL|field|failOnMetadataWriteError
specifier|private
name|boolean
name|failOnMetadataWriteError
decl_stmt|;
comment|/**    * This must never be null; until initialized it just declares that there    * is no encryption.    */
DECL|field|encryptionSecrets
specifier|private
name|EncryptionSecrets
name|encryptionSecrets
init|=
operator|new
name|EncryptionSecrets
argument_list|()
decl_stmt|;
DECL|field|instrumentation
specifier|private
name|S3AInstrumentation
name|instrumentation
decl_stmt|;
DECL|field|storageStatistics
specifier|private
specifier|final
name|S3AStorageStatistics
name|storageStatistics
init|=
name|createStorageStatistics
argument_list|()
decl_stmt|;
DECL|field|readAhead
specifier|private
name|long
name|readAhead
decl_stmt|;
DECL|field|inputPolicy
specifier|private
name|S3AInputPolicy
name|inputPolicy
decl_stmt|;
DECL|field|changeDetectionPolicy
specifier|private
name|ChangeDetectionPolicy
name|changeDetectionPolicy
decl_stmt|;
DECL|field|closed
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
DECL|field|isClosed
specifier|private
specifier|volatile
name|boolean
name|isClosed
init|=
literal|false
decl_stmt|;
DECL|field|metadataStore
specifier|private
name|MetadataStore
name|metadataStore
decl_stmt|;
DECL|field|allowAuthoritativeMetadataStore
specifier|private
name|boolean
name|allowAuthoritativeMetadataStore
decl_stmt|;
DECL|field|allowAuthoritativePaths
specifier|private
name|Collection
argument_list|<
name|String
argument_list|>
name|allowAuthoritativePaths
decl_stmt|;
comment|/** Delegation token integration; non-empty when DT support is enabled. */
DECL|field|delegationTokens
specifier|private
name|Optional
argument_list|<
name|S3ADelegationTokens
argument_list|>
name|delegationTokens
init|=
name|Optional
operator|.
name|empty
argument_list|()
decl_stmt|;
comment|/** Principal who created the FS; recorded during initialization. */
DECL|field|owner
specifier|private
name|UserGroupInformation
name|owner
decl_stmt|;
DECL|field|blockOutputBuffer
specifier|private
name|String
name|blockOutputBuffer
decl_stmt|;
DECL|field|blockFactory
specifier|private
name|S3ADataBlocks
operator|.
name|BlockFactory
name|blockFactory
decl_stmt|;
DECL|field|blockOutputActiveBlocks
specifier|private
name|int
name|blockOutputActiveBlocks
decl_stmt|;
DECL|field|writeHelper
specifier|private
name|WriteOperationHelper
name|writeHelper
decl_stmt|;
DECL|field|selectBinding
specifier|private
name|SelectBinding
name|selectBinding
decl_stmt|;
DECL|field|useListV1
specifier|private
name|boolean
name|useListV1
decl_stmt|;
DECL|field|committerIntegration
specifier|private
name|MagicCommitIntegration
name|committerIntegration
decl_stmt|;
DECL|field|credentials
specifier|private
name|AWSCredentialProviderList
name|credentials
decl_stmt|;
DECL|field|signerManager
specifier|private
name|SignerManager
name|signerManager
decl_stmt|;
DECL|field|ttlTimeProvider
specifier|private
name|ITtlTimeProvider
name|ttlTimeProvider
decl_stmt|;
comment|/**    * Specific operations used by rename and delete operations.    */
specifier|private
specifier|final
name|S3AFileSystem
operator|.
name|OperationCallbacksImpl
DECL|field|operationCallbacks
name|operationCallbacks
init|=
operator|new
name|OperationCallbacksImpl
argument_list|()
decl_stmt|;
comment|/** Add any deprecated keys. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|addDeprecatedKeys ()
specifier|private
specifier|static
name|void
name|addDeprecatedKeys
parameter_list|()
block|{
comment|// this is retained as a placeholder for when new deprecated keys
comment|// need to be added.
name|Configuration
operator|.
name|DeprecationDelta
index|[]
name|deltas
init|=
block|{     }
decl_stmt|;
if|if
condition|(
name|deltas
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|Configuration
operator|.
name|addDeprecations
argument_list|(
name|deltas
argument_list|)
expr_stmt|;
name|Configuration
operator|.
name|reloadExistingConfigurations
argument_list|()
expr_stmt|;
block|}
block|}
static|static
block|{
name|addDeprecatedKeys
argument_list|()
expr_stmt|;
block|}
comment|/** Called after a new FileSystem instance is constructed.    * @param name a uri whose authority section names the host, port, etc.    *   for this FileSystem    * @param originalConf the configuration to use for the FS. The    * bucket-specific options are patched over the base ones before any use is    * made of the config.    */
DECL|method|initialize (URI name, Configuration originalConf)
specifier|public
name|void
name|initialize
parameter_list|(
name|URI
name|name
parameter_list|,
name|Configuration
name|originalConf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// get the host; this is guaranteed to be non-null, non-empty
name|bucket
operator|=
name|name
operator|.
name|getHost
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initializing S3AFileSystem for {}"
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
comment|// clone the configuration into one with propagated bucket options
name|Configuration
name|conf
init|=
name|propagateBucketOptions
argument_list|(
name|originalConf
argument_list|,
name|bucket
argument_list|)
decl_stmt|;
comment|// patch the Hadoop security providers
name|patchSecurityCredentialProviders
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// look for delegation token support early.
name|boolean
name|delegationTokensEnabled
init|=
name|hasDelegationTokenBinding
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|delegationTokensEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using delegation tokens"
argument_list|)
expr_stmt|;
block|}
comment|// set the URI, this will do any fixup of the URI to remove secrets,
comment|// canonicalize.
name|setUri
argument_list|(
name|name
argument_list|,
name|delegationTokensEnabled
argument_list|)
expr_stmt|;
name|super
operator|.
name|initialize
argument_list|(
name|uri
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
try|try
block|{
comment|// look for encryption data
comment|// DT Bindings may override this
name|setEncryptionSecrets
argument_list|(
operator|new
name|EncryptionSecrets
argument_list|(
name|getEncryptionAlgorithm
argument_list|(
name|bucket
argument_list|,
name|conf
argument_list|)
argument_list|,
name|getServerSideEncryptionKey
argument_list|(
name|bucket
argument_list|,
name|getConf
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|invoker
operator|=
operator|new
name|Invoker
argument_list|(
operator|new
name|S3ARetryPolicy
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|onRetry
argument_list|)
expr_stmt|;
name|instrumentation
operator|=
operator|new
name|S3AInstrumentation
argument_list|(
name|uri
argument_list|)
expr_stmt|;
comment|// Username is the current user at the time the FS was instantiated.
name|owner
operator|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
expr_stmt|;
name|username
operator|=
name|owner
operator|.
name|getShortUserName
argument_list|()
expr_stmt|;
name|workingDir
operator|=
operator|new
name|Path
argument_list|(
literal|"/user"
argument_list|,
name|username
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|this
operator|.
name|uri
argument_list|,
name|this
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
expr_stmt|;
name|s3guardInvoker
operator|=
operator|new
name|Invoker
argument_list|(
operator|new
name|S3GuardExistsRetryPolicy
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|onRetry
argument_list|)
expr_stmt|;
name|writeHelper
operator|=
operator|new
name|WriteOperationHelper
argument_list|(
name|this
argument_list|,
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|failOnMetadataWriteError
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|FAIL_ON_METADATA_WRITE_ERROR
argument_list|,
name|FAIL_ON_METADATA_WRITE_ERROR_DEFAULT
argument_list|)
expr_stmt|;
name|maxKeys
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_PAGING_KEYS
argument_list|,
name|DEFAULT_MAX_PAGING_KEYS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|listing
operator|=
operator|new
name|Listing
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MULTIPART_SIZE
argument_list|,
name|DEFAULT_MULTIPART_SIZE
argument_list|)
expr_stmt|;
name|multiPartThreshold
operator|=
name|getMultipartSizeProperty
argument_list|(
name|conf
argument_list|,
name|MIN_MULTIPART_THRESHOLD
argument_list|,
name|DEFAULT_MIN_MULTIPART_THRESHOLD
argument_list|)
expr_stmt|;
comment|//check but do not store the block size
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|enableMultiObjectsDelete
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|ENABLE_MULTI_DELETE
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|readAhead
operator|=
name|longBytesOption
argument_list|(
name|conf
argument_list|,
name|READAHEAD_RANGE
argument_list|,
name|DEFAULT_READAHEAD_RANGE
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|initThreadPools
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|int
name|listVersion
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|LIST_VERSION
argument_list|,
name|DEFAULT_LIST_VERSION
argument_list|)
decl_stmt|;
if|if
condition|(
name|listVersion
argument_list|<
literal|1
operator|||
name|listVersion
argument_list|>
literal|2
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Configured fs.s3a.list.version {} is invalid, forcing "
operator|+
literal|"version 2"
argument_list|,
name|listVersion
argument_list|)
expr_stmt|;
block|}
name|useListV1
operator|=
operator|(
name|listVersion
operator|==
literal|1
operator|)
expr_stmt|;
name|signerManager
operator|=
operator|new
name|SignerManager
argument_list|()
expr_stmt|;
name|signerManager
operator|.
name|initCustomSigners
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// creates the AWS client, including overriding auth chain if
comment|// the FS came with a DT
comment|// this may do some patching of the configuration (e.g. setting
comment|// the encryption algorithms)
name|bindAWSClient
argument_list|(
name|name
argument_list|,
name|delegationTokensEnabled
argument_list|)
expr_stmt|;
name|initTransferManager
argument_list|()
expr_stmt|;
name|initCannedAcls
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|verifyBucketExists
argument_list|()
expr_stmt|;
name|inputPolicy
operator|=
name|S3AInputPolicy
operator|.
name|getPolicy
argument_list|(
name|conf
operator|.
name|getTrimmed
argument_list|(
name|INPUT_FADVISE
argument_list|,
name|INPUT_FADV_NORMAL
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Input fadvise policy = {}"
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
name|changeDetectionPolicy
operator|=
name|ChangeDetectionPolicy
operator|.
name|getPolicy
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Change detection policy = {}"
argument_list|,
name|changeDetectionPolicy
argument_list|)
expr_stmt|;
name|boolean
name|magicCommitterEnabled
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|CommitConstants
operator|.
name|MAGIC_COMMITTER_ENABLED
argument_list|,
name|CommitConstants
operator|.
name|DEFAULT_MAGIC_COMMITTER_ENABLED
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Filesystem support for magic committers {} enabled"
argument_list|,
name|magicCommitterEnabled
condition|?
literal|"is"
else|:
literal|"is not"
argument_list|)
expr_stmt|;
name|committerIntegration
operator|=
operator|new
name|MagicCommitIntegration
argument_list|(
name|this
argument_list|,
name|magicCommitterEnabled
argument_list|)
expr_stmt|;
comment|// instantiate S3 Select support
name|selectBinding
operator|=
operator|new
name|SelectBinding
argument_list|(
name|writeHelper
argument_list|)
expr_stmt|;
name|boolean
name|blockUploadEnabled
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|FAST_UPLOAD
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|blockUploadEnabled
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The \"slow\" output stream is no longer supported"
argument_list|)
expr_stmt|;
block|}
name|blockOutputBuffer
operator|=
name|conf
operator|.
name|getTrimmed
argument_list|(
name|FAST_UPLOAD_BUFFER
argument_list|,
name|DEFAULT_FAST_UPLOAD_BUFFER
argument_list|)
expr_stmt|;
name|partSize
operator|=
name|ensureOutputParameterInRange
argument_list|(
name|MULTIPART_SIZE
argument_list|,
name|partSize
argument_list|)
expr_stmt|;
name|blockFactory
operator|=
name|S3ADataBlocks
operator|.
name|createFactory
argument_list|(
name|this
argument_list|,
name|blockOutputBuffer
argument_list|)
expr_stmt|;
name|blockOutputActiveBlocks
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
name|DEFAULT_FAST_UPLOAD_ACTIVE_BLOCKS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using S3ABlockOutputStream with buffer = {}; block={};"
operator|+
literal|" queue limit={}"
argument_list|,
name|blockOutputBuffer
argument_list|,
name|partSize
argument_list|,
name|blockOutputActiveBlocks
argument_list|)
expr_stmt|;
name|long
name|authDirTtl
init|=
name|conf
operator|.
name|getTimeDuration
argument_list|(
name|METADATASTORE_METADATA_TTL
argument_list|,
name|DEFAULT_METADATASTORE_METADATA_TTL
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|ttlTimeProvider
operator|=
operator|new
name|S3Guard
operator|.
name|TtlTimeProvider
argument_list|(
name|authDirTtl
argument_list|)
expr_stmt|;
name|setMetadataStore
argument_list|(
name|S3Guard
operator|.
name|getMetadataStore
argument_list|(
name|this
argument_list|,
name|ttlTimeProvider
argument_list|)
argument_list|)
expr_stmt|;
name|allowAuthoritativeMetadataStore
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|METADATASTORE_AUTHORITATIVE
argument_list|,
name|DEFAULT_METADATASTORE_AUTHORITATIVE
argument_list|)
expr_stmt|;
name|allowAuthoritativePaths
operator|=
name|S3Guard
operator|.
name|getAuthoritativePaths
argument_list|(
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using metadata store {}, authoritative store={}, authoritative path={}"
argument_list|,
name|getMetadataStore
argument_list|()
argument_list|,
name|allowAuthoritativeMetadataStore
argument_list|,
name|allowAuthoritativePaths
argument_list|)
expr_stmt|;
block|}
name|initMultipartUploads
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"initializing "
argument_list|,
operator|new
name|Path
argument_list|(
name|name
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Initialize the thread pool.    * This must be re-invoked after replacing the S3Client during test    * runs.    * @param conf configuration.    */
DECL|method|initThreadPools (Configuration conf)
specifier|private
name|void
name|initThreadPools
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|int
name|maxThreads
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|MAX_THREADS
argument_list|,
name|DEFAULT_MAX_THREADS
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxThreads
operator|<
literal|2
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|MAX_THREADS
operator|+
literal|" must be at least 2: forcing to 2."
argument_list|)
expr_stmt|;
name|maxThreads
operator|=
literal|2
expr_stmt|;
block|}
name|int
name|totalTasks
init|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|MAX_TOTAL_TASKS
argument_list|,
name|DEFAULT_MAX_TOTAL_TASKS
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|long
name|keepAliveTime
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|KEEPALIVE_TIME
argument_list|,
name|DEFAULT_KEEPALIVE_TIME
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|boundedThreadPool
operator|=
name|BlockingThreadPoolExecutorService
operator|.
name|newInstance
argument_list|(
name|maxThreads
argument_list|,
name|maxThreads
operator|+
name|totalTasks
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
literal|"s3a-transfer-shared"
argument_list|)
expr_stmt|;
name|unboundedThreadPool
operator|=
operator|new
name|ThreadPoolExecutor
argument_list|(
name|maxThreads
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|,
name|keepAliveTime
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
argument_list|,
name|BlockingThreadPoolExecutorService
operator|.
name|newDaemonThreadFactory
argument_list|(
literal|"s3a-transfer-unbounded"
argument_list|)
argument_list|)
expr_stmt|;
name|unboundedThreadPool
operator|.
name|allowCoreThreadTimeOut
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|executorCapacity
operator|=
name|intOption
argument_list|(
name|conf
argument_list|,
name|EXECUTOR_CAPACITY
argument_list|,
name|DEFAULT_EXECUTOR_CAPACITY
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create the storage statistics or bind to an existing one.    * @return a storage statistics instance.    */
DECL|method|createStorageStatistics ()
specifier|protected
specifier|static
name|S3AStorageStatistics
name|createStorageStatistics
parameter_list|()
block|{
return|return
operator|(
name|S3AStorageStatistics
operator|)
name|GlobalStorageStatistics
operator|.
name|INSTANCE
operator|.
name|put
argument_list|(
name|S3AStorageStatistics
operator|.
name|NAME
argument_list|,
parameter_list|()
lambda|->
operator|new
name|S3AStorageStatistics
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Verify that the bucket exists. This does not check permissions,    * not even read access.    * Retry policy: retrying, translated.    * @throws FileNotFoundException the bucket is absent    * @throws IOException any other problem talking to S3    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|verifyBucketExists ()
specifier|protected
name|void
name|verifyBucketExists
parameter_list|()
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
if|if
condition|(
operator|!
name|invoker
operator|.
name|retry
argument_list|(
literal|"doesBucketExist"
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|doesBucketExist
argument_list|(
name|bucket
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
argument_list|new
name|FileNotFoundException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" does not exist"
argument_list|)
block|;     }
block|}
comment|/**    * Get S3A Instrumentation. For test purposes.    * @return this instance's instrumentation.    */
DECL|method|getInstrumentation ()
specifier|public
name|S3AInstrumentation
name|getInstrumentation
parameter_list|()
block|{
return|return
name|instrumentation
return|;
block|}
comment|/**    * Set up the client bindings.    * If delegation tokens are enabled, the FS first looks for a DT    * ahead of any other bindings;.    * If there is a DT it uses that to do the auth    * and switches to the DT authenticator automatically (and exclusively)    * @param name URI of the FS    * @param dtEnabled are delegation tokens enabled?    * @throws IOException failure.    */
DECL|method|bindAWSClient (URI name, boolean dtEnabled)
specifier|private
name|void
name|bindAWSClient
parameter_list|(
name|URI
name|name
parameter_list|,
name|boolean
name|dtEnabled
parameter_list|)
throws|throws
name|IOException
block|{
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|credentials
operator|=
literal|null
expr_stmt|;
name|String
name|uaSuffix
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|dtEnabled
condition|)
block|{
comment|// Delegation support.
comment|// Create and start the DT integration.
comment|// Then look for an existing DT for this bucket, switch to authenticating
comment|// with it if so.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using delegation tokens"
argument_list|)
expr_stmt|;
name|S3ADelegationTokens
name|tokens
init|=
operator|new
name|S3ADelegationTokens
argument_list|()
decl_stmt|;
name|this
operator|.
name|delegationTokens
operator|=
name|Optional
operator|.
name|of
argument_list|(
name|tokens
argument_list|)
expr_stmt|;
name|tokens
operator|.
name|bindToFileSystem
argument_list|(
name|getCanonicalUri
argument_list|()
argument_list|,
name|this
argument_list|)
expr_stmt|;
name|tokens
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|tokens
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// switch to the DT provider and bypass all other configured
comment|// providers.
if|if
condition|(
name|tokens
operator|.
name|isBoundToDT
argument_list|()
condition|)
block|{
comment|// A DT was retrieved.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using existing delegation token"
argument_list|)
expr_stmt|;
comment|// and use the encryption settings from that client, whatever they were
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No delegation token for this instance"
argument_list|)
expr_stmt|;
block|}
comment|// Get new credential chain
name|credentials
operator|=
name|tokens
operator|.
name|getCredentialProviders
argument_list|()
expr_stmt|;
comment|// and any encryption secrets which came from a DT
name|tokens
operator|.
name|getEncryptionSecrets
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|this
operator|::
name|setEncryptionSecrets
argument_list|)
expr_stmt|;
comment|// and update the UA field with any diagnostics provided by
comment|// the DT binding.
name|uaSuffix
operator|=
name|tokens
operator|.
name|getUserAgentField
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// DT support is disabled, so create the normal credential chain
name|credentials
operator|=
name|createAWSCredentialProviderSet
argument_list|(
name|name
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Using credential provider {}"
argument_list|,
name|credentials
argument_list|)
expr_stmt|;
name|Class
argument_list|<
name|?
extends|extends
name|S3ClientFactory
argument_list|>
name|s3ClientFactoryClass
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|S3_CLIENT_FACTORY_IMPL
argument_list|,
name|DEFAULT_S3_CLIENT_FACTORY_IMPL
argument_list|,
name|S3ClientFactory
operator|.
name|class
argument_list|)
decl_stmt|;
name|s3
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|s3ClientFactoryClass
argument_list|,
name|conf
argument_list|)
operator|.
name|createS3Client
argument_list|(
name|getUri
argument_list|()
argument_list|,
name|bucket
argument_list|,
name|credentials
argument_list|,
name|uaSuffix
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set the encryption secrets for requests.    * @param secrets secrets    */
DECL|method|setEncryptionSecrets (final EncryptionSecrets secrets)
specifier|protected
name|void
name|setEncryptionSecrets
parameter_list|(
specifier|final
name|EncryptionSecrets
name|secrets
parameter_list|)
block|{
name|this
operator|.
name|encryptionSecrets
operator|=
name|secrets
expr_stmt|;
block|}
comment|/**    * Get the encryption secrets.    * This potentially sensitive information and must be treated with care.    * @return the current encryption secrets.    */
DECL|method|getEncryptionSecrets ()
specifier|public
name|EncryptionSecrets
name|getEncryptionSecrets
parameter_list|()
block|{
return|return
name|encryptionSecrets
return|;
block|}
DECL|method|initTransferManager ()
specifier|private
name|void
name|initTransferManager
parameter_list|()
block|{
name|TransferManagerConfiguration
name|transferConfiguration
init|=
operator|new
name|TransferManagerConfiguration
argument_list|()
decl_stmt|;
name|transferConfiguration
operator|.
name|setMinimumUploadPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartUploadThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyPartSize
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|transferConfiguration
operator|.
name|setMultipartCopyThreshold
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
name|transfers
operator|=
operator|new
name|TransferManager
argument_list|(
name|s3
argument_list|,
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|transfers
operator|.
name|setConfiguration
argument_list|(
name|transferConfiguration
argument_list|)
expr_stmt|;
block|}
DECL|method|initCannedAcls (Configuration conf)
specifier|private
name|void
name|initCannedAcls
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|cannedACLName
init|=
name|conf
operator|.
name|get
argument_list|(
name|CANNED_ACL
argument_list|,
name|DEFAULT_CANNED_ACL
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|cannedACLName
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|cannedACL
operator|=
name|CannedAccessControlList
operator|.
name|valueOf
argument_list|(
name|cannedACLName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cannedACL
operator|=
literal|null
expr_stmt|;
block|}
block|}
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|initMultipartUploads (Configuration conf)
specifier|private
name|void
name|initMultipartUploads
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|purgeExistingMultipart
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|PURGE_EXISTING_MULTIPART
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART
argument_list|)
decl_stmt|;
name|long
name|purgeExistingMultipartAge
init|=
name|longOption
argument_list|(
name|conf
argument_list|,
name|PURGE_EXISTING_MULTIPART_AGE
argument_list|,
name|DEFAULT_PURGE_EXISTING_MULTIPART_AGE
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|purgeExistingMultipart
condition|)
block|{
try|try
block|{
name|abortOutstandingMultipartUploads
argument_list|(
name|purgeExistingMultipartAge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AccessDeniedException
name|e
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to purge multipart uploads against {},"
operator|+
literal|" FS may be read only"
argument_list|,
name|bucket
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Abort all outstanding MPUs older than a given age.    * @param seconds time in seconds    * @throws IOException on any failure, other than 403 "permission denied"    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|abortOutstandingMultipartUploads (long seconds)
specifier|public
name|void
name|abortOutstandingMultipartUploads
parameter_list|(
name|long
name|seconds
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|seconds
operator|>=
literal|0
argument_list|)
expr_stmt|;
name|Date
name|purgeBefore
init|=
operator|new
name|Date
argument_list|(
operator|new
name|Date
argument_list|()
operator|.
name|getTime
argument_list|()
operator|-
name|seconds
operator|*
literal|1000
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Purging outstanding multipart uploads older than {}"
argument_list|,
name|purgeBefore
argument_list|)
expr_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"Purging multipart uploads"
argument_list|,
name|bucket
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|transfers
operator|.
name|abortMultipartUploads
argument_list|(
name|bucket
argument_list|,
name|purgeBefore
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Return the protocol scheme for the FileSystem.    *    * @return "s3a"    */
annotation|@
name|Override
DECL|method|getScheme ()
specifier|public
name|String
name|getScheme
parameter_list|()
block|{
return|return
literal|"s3a"
return|;
block|}
comment|/**    * Returns a URI whose scheme and authority identify this FileSystem.    */
annotation|@
name|Override
DECL|method|getUri ()
specifier|public
name|URI
name|getUri
parameter_list|()
block|{
return|return
name|uri
return|;
block|}
comment|/**    * Set the URI field through {@link S3xLoginHelper} and    * optionally {@link #canonicalizeUri(URI)}    * Exported for testing.    * @param fsUri filesystem URI.    * @param canonicalize true if the URI should be canonicalized.    */
annotation|@
name|VisibleForTesting
DECL|method|setUri (URI fsUri, boolean canonicalize)
specifier|protected
name|void
name|setUri
parameter_list|(
name|URI
name|fsUri
parameter_list|,
name|boolean
name|canonicalize
parameter_list|)
block|{
name|URI
name|u
init|=
name|S3xLoginHelper
operator|.
name|buildFSURI
argument_list|(
name|fsUri
argument_list|)
decl_stmt|;
name|this
operator|.
name|uri
operator|=
name|canonicalize
condition|?
name|u
else|:
name|canonicalizeUri
argument_list|(
name|u
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the canonical URI.    * @return the canonical URI of this FS.    */
DECL|method|getCanonicalUri ()
specifier|public
name|URI
name|getCanonicalUri
parameter_list|()
block|{
return|return
name|uri
return|;
block|}
annotation|@
name|VisibleForTesting
annotation|@
name|Override
DECL|method|getDefaultPort ()
specifier|public
name|int
name|getDefaultPort
parameter_list|()
block|{
return|return
literal|0
return|;
block|}
comment|/**    * Returns the S3 client used by this filesystem.    * This is for internal use within the S3A code itself.    * @return AmazonS3Client    */
DECL|method|getAmazonS3Client ()
name|AmazonS3
name|getAmazonS3Client
parameter_list|()
block|{
return|return
name|s3
return|;
block|}
comment|/**    * Returns the S3 client used by this filesystem.    *<i>Warning: this must only be used for testing, as it bypasses core    * S3A operations.</i>    * @param reason a justification for requesting access.    * @return AmazonS3Client    */
annotation|@
name|VisibleForTesting
DECL|method|getAmazonS3ClientForTesting (String reason)
specifier|public
name|AmazonS3
name|getAmazonS3ClientForTesting
parameter_list|(
name|String
name|reason
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Access to S3A client requested, reason {}"
argument_list|,
name|reason
argument_list|)
expr_stmt|;
return|return
name|s3
return|;
block|}
comment|/**    * Set the client -used in mocking tests to force in a different client.    * @param client client.    */
DECL|method|setAmazonS3Client (AmazonS3 client)
specifier|protected
name|void
name|setAmazonS3Client
parameter_list|(
name|AmazonS3
name|client
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|client
argument_list|,
literal|"client"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting S3 client to {}"
argument_list|,
name|client
argument_list|)
expr_stmt|;
name|s3
operator|=
name|client
expr_stmt|;
comment|// Need to use a new TransferManager that uses the new client.
comment|// Also, using a new TransferManager requires a new threadpool as the old
comment|// TransferManager will shut the thread pool down when it is garbage
comment|// collected.
name|initThreadPools
argument_list|(
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|initTransferManager
argument_list|()
expr_stmt|;
block|}
comment|/**    * Get the region of a bucket.    * @return the region in which a bucket is located    * @throws IOException on any failure.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getBucketLocation ()
specifier|public
name|String
name|getBucketLocation
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|getBucketLocation
argument_list|(
name|bucket
argument_list|)
return|;
block|}
comment|/**    * Get the region of a bucket.    * Retry policy: retrying, translated.    * @param bucketName the name of the bucket    * @return the region in which a bucket is located    * @throws IOException on any failure.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getBucketLocation (String bucketName)
specifier|public
name|String
name|getBucketLocation
parameter_list|(
name|String
name|bucketName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|invoker
operator|.
name|retry
argument_list|(
literal|"getBucketLocation()"
argument_list|,
name|bucketName
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|getBucketLocation
argument_list|(
name|bucketName
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the read ahead range value used by this filesystem.    * @return the readahead range    */
annotation|@
name|VisibleForTesting
DECL|method|getReadAheadRange ()
name|long
name|getReadAheadRange
parameter_list|()
block|{
return|return
name|readAhead
return|;
block|}
comment|/**    * Get the input policy for this FS instance.    * @return the input policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|getInputPolicy ()
specifier|public
name|S3AInputPolicy
name|getInputPolicy
parameter_list|()
block|{
return|return
name|inputPolicy
return|;
block|}
comment|/**    * Get the change detection policy for this FS instance.    * Only public to allow access in tests in other packages.    * @return the change detection policy    */
annotation|@
name|VisibleForTesting
DECL|method|getChangeDetectionPolicy ()
specifier|public
name|ChangeDetectionPolicy
name|getChangeDetectionPolicy
parameter_list|()
block|{
return|return
name|changeDetectionPolicy
return|;
block|}
comment|/**    * Get the encryption algorithm of this endpoint.    * @return the encryption algorithm.    */
DECL|method|getServerSideEncryptionAlgorithm ()
specifier|public
name|S3AEncryptionMethods
name|getServerSideEncryptionAlgorithm
parameter_list|()
block|{
return|return
name|encryptionSecrets
operator|.
name|getEncryptionMethod
argument_list|()
return|;
block|}
comment|/**    * Demand create the directory allocator, then create a temporary file.    * This does not mark the file for deletion when a process exits.    * {@link LocalDirAllocator#createTmpFileForWrite(String, long, Configuration)}.    * @param pathStr prefix for the temporary file    * @param size the size of the file that is going to be written    * @param conf the Configuration object    * @return a unique temporary file    * @throws IOException IO problems    */
DECL|method|createTmpFileForWrite (String pathStr, long size, Configuration conf)
name|File
name|createTmpFileForWrite
parameter_list|(
name|String
name|pathStr
parameter_list|,
name|long
name|size
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|directoryAllocator
operator|==
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|this
init|)
block|{
name|String
name|bufferDir
init|=
name|conf
operator|.
name|get
argument_list|(
name|BUFFER_DIR
argument_list|)
operator|!=
literal|null
condition|?
name|BUFFER_DIR
else|:
name|HADOOP_TMP_DIR
decl_stmt|;
name|directoryAllocator
operator|=
operator|new
name|LocalDirAllocator
argument_list|(
name|bufferDir
argument_list|)
expr_stmt|;
block|}
block|}
name|Path
name|path
init|=
name|directoryAllocator
operator|.
name|getLocalPathForWrite
argument_list|(
name|pathStr
argument_list|,
name|size
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|File
name|dir
init|=
operator|new
name|File
argument_list|(
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|prefix
init|=
name|path
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// create a temp file on this directory
return|return
name|File
operator|.
name|createTempFile
argument_list|(
name|prefix
argument_list|,
literal|null
argument_list|,
name|dir
argument_list|)
return|;
block|}
comment|/**    * Get the bucket of this filesystem.    * @return the bucket    */
DECL|method|getBucket ()
specifier|public
name|String
name|getBucket
parameter_list|()
block|{
return|return
name|bucket
return|;
block|}
comment|/**    * Set the bucket.    * @param bucket the bucket    */
annotation|@
name|VisibleForTesting
DECL|method|setBucket (String bucket)
specifier|protected
name|void
name|setBucket
parameter_list|(
name|String
name|bucket
parameter_list|)
block|{
name|this
operator|.
name|bucket
operator|=
name|bucket
expr_stmt|;
block|}
comment|/**    * Get the canned ACL of this FS.    * @return an ACL, if any    */
DECL|method|getCannedACL ()
name|CannedAccessControlList
name|getCannedACL
parameter_list|()
block|{
return|return
name|cannedACL
return|;
block|}
comment|/**    * Change the input policy for this FS.    * @param inputPolicy new policy    */
annotation|@
name|InterfaceStability
operator|.
name|Unstable
DECL|method|setInputPolicy (S3AInputPolicy inputPolicy)
specifier|public
name|void
name|setInputPolicy
parameter_list|(
name|S3AInputPolicy
name|inputPolicy
parameter_list|)
block|{
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|inputPolicy
argument_list|,
literal|"Null inputStrategy"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Setting input strategy: {}"
argument_list|,
name|inputPolicy
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputPolicy
operator|=
name|inputPolicy
expr_stmt|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key.    *    * @param path input path, may be relative to the working dir    * @return a key excluding the leading "/", or, if it is the root path, ""    */
annotation|@
name|VisibleForTesting
DECL|method|pathToKey (Path path)
specifier|public
name|String
name|pathToKey
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
if|if
condition|(
operator|!
name|path
operator|.
name|isAbsolute
argument_list|()
condition|)
block|{
name|path
operator|=
operator|new
name|Path
argument_list|(
name|workingDir
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getScheme
argument_list|()
operator|!=
literal|null
operator|&&
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|""
return|;
block|}
return|return
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|.
name|substring
argument_list|(
literal|1
argument_list|)
return|;
block|}
comment|/**    * Turns a path (relative or otherwise) into an S3 key, adding a trailing    * "/" if the path is not the root<i>and</i> does not already have a "/"    * at the end.    *    * @param key s3 key or ""    * @return the with a trailing "/", or, if it is the root key, "",    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|method|maybeAddTrailingSlash (String key)
specifier|public
name|String
name|maybeAddTrailingSlash
parameter_list|(
name|String
name|key
parameter_list|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
return|return
name|key
operator|+
literal|'/'
return|;
block|}
else|else
block|{
return|return
name|key
return|;
block|}
block|}
comment|/**    * Convert a path back to a key.    * @param key input key    * @return the path from this key    */
DECL|method|keyToPath (String key)
name|Path
name|keyToPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
literal|"/"
operator|+
name|key
argument_list|)
return|;
block|}
comment|/**    * Convert a key to a fully qualified path.    * @param key input key    * @return the fully qualified path including URI scheme and bucket name.    */
DECL|method|keyToQualifiedPath (String key)
specifier|public
name|Path
name|keyToQualifiedPath
parameter_list|(
name|String
name|key
parameter_list|)
block|{
return|return
name|qualify
argument_list|(
name|keyToPath
argument_list|(
name|key
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Qualify a path.    * @param path path to qualify    * @return a qualified path.    */
DECL|method|qualify (Path path)
specifier|public
name|Path
name|qualify
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|path
operator|.
name|makeQualified
argument_list|(
name|uri
argument_list|,
name|workingDir
argument_list|)
return|;
block|}
comment|/**    * Check that a Path belongs to this FileSystem.    * Unlike the superclass, this version does not look at authority,    * only hostnames.    * @param path to check    * @throws IllegalArgumentException if there is an FS mismatch    */
annotation|@
name|Override
DECL|method|checkPath (Path path)
specifier|public
name|void
name|checkPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|S3xLoginHelper
operator|.
name|checkPath
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|getUri
argument_list|()
argument_list|,
name|path
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Override the base canonicalization logic and relay to    * {@link S3xLoginHelper#canonicalizeUri(URI, int)}.    * This allows for the option of changing this logic for better DT handling.    * @param rawUri raw URI.    * @return the canonical URI to use in delegation tokens and file context.    */
annotation|@
name|Override
DECL|method|canonicalizeUri (URI rawUri)
specifier|protected
name|URI
name|canonicalizeUri
parameter_list|(
name|URI
name|rawUri
parameter_list|)
block|{
return|return
name|S3xLoginHelper
operator|.
name|canonicalizeUri
argument_list|(
name|rawUri
argument_list|,
name|getDefaultPort
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Opens an FSDataInputStream at the indicated Path.    * @param f the file name to open    * @param bufferSize the size of the buffer to be used.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|open (Path f, int bufferSize)
specifier|public
name|FSDataInputStream
name|open
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|open
argument_list|(
name|f
argument_list|,
name|Optional
operator|.
name|empty
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Opens an FSDataInputStream at the indicated Path.    * @param path the file to open    * @param options configuration options if opened with the builder API.    * @throws IOException IO failure.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|open ( final Path path, final Optional<Configuration> options)
specifier|private
name|FSDataInputStream
name|open
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Optional
argument_list|<
name|Configuration
argument_list|>
name|options
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_OPEN
argument_list|)
expr_stmt|;
specifier|final
name|S3AFileStatus
name|fileStatus
init|=
operator|(
name|S3AFileStatus
operator|)
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Can't open "
operator|+
name|path
operator|+
literal|" because it is a directory"
argument_list|)
throw|;
block|}
name|S3AReadOpContext
name|readContext
decl_stmt|;
if|if
condition|(
name|options
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|Configuration
name|o
init|=
name|options
operator|.
name|get
argument_list|()
decl_stmt|;
comment|// normal path. Open the file with the chosen seek policy, if different
comment|// from the normal one.
comment|// and readahead.
name|S3AInputPolicy
name|policy
init|=
name|S3AInputPolicy
operator|.
name|getPolicy
argument_list|(
name|o
operator|.
name|get
argument_list|(
name|INPUT_FADVISE
argument_list|,
name|inputPolicy
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|readAheadRange2
init|=
name|o
operator|.
name|getLong
argument_list|(
name|READAHEAD_RANGE
argument_list|,
name|readAhead
argument_list|)
decl_stmt|;
comment|// TODO support change detection policy from options?
name|readContext
operator|=
name|createReadContext
argument_list|(
name|fileStatus
argument_list|,
name|policy
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|readAheadRange2
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|readContext
operator|=
name|createReadContext
argument_list|(
name|fileStatus
argument_list|,
name|inputPolicy
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|readAhead
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening '{}'"
argument_list|,
name|readContext
argument_list|)
expr_stmt|;
return|return
operator|new
name|FSDataInputStream
argument_list|(
operator|new
name|S3AInputStream
argument_list|(
name|readContext
argument_list|,
name|createObjectAttributes
argument_list|(
name|fileStatus
argument_list|)
argument_list|,
name|s3
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Create the read context for reading from the referenced file,    * using FS state as well as the status.    * @param fileStatus file status.    * @param seekPolicy input policy for this operation    * @param readAheadRange readahead value.    * @return a context for read and select operations.    */
DECL|method|createReadContext ( final FileStatus fileStatus, final S3AInputPolicy seekPolicy, final ChangeDetectionPolicy changePolicy, final long readAheadRange)
specifier|private
name|S3AReadOpContext
name|createReadContext
parameter_list|(
specifier|final
name|FileStatus
name|fileStatus
parameter_list|,
specifier|final
name|S3AInputPolicy
name|seekPolicy
parameter_list|,
specifier|final
name|ChangeDetectionPolicy
name|changePolicy
parameter_list|,
specifier|final
name|long
name|readAheadRange
parameter_list|)
block|{
return|return
operator|new
name|S3AReadOpContext
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|hasMetadataStore
argument_list|()
argument_list|,
name|invoker
argument_list|,
name|s3guardInvoker
argument_list|,
name|statistics
argument_list|,
name|instrumentation
argument_list|,
name|fileStatus
argument_list|,
name|seekPolicy
argument_list|,
name|changePolicy
argument_list|,
name|readAheadRange
argument_list|)
return|;
block|}
comment|/**    * Create the attributes of an object for subsequent use.    * @param f path path of the request.    * @param eTag the eTag of the S3 object    * @param versionId S3 object version ID    * @param len length of the file    * @return attributes to use when building the query.    */
DECL|method|createObjectAttributes ( final Path f, final String eTag, final String versionId, final long len)
specifier|private
name|S3ObjectAttributes
name|createObjectAttributes
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|String
name|eTag
parameter_list|,
specifier|final
name|String
name|versionId
parameter_list|,
specifier|final
name|long
name|len
parameter_list|)
block|{
return|return
operator|new
name|S3ObjectAttributes
argument_list|(
name|bucket
argument_list|,
name|f
argument_list|,
name|pathToKey
argument_list|(
name|f
argument_list|)
argument_list|,
name|getServerSideEncryptionAlgorithm
argument_list|()
argument_list|,
name|encryptionSecrets
operator|.
name|getEncryptionKey
argument_list|()
argument_list|,
name|eTag
argument_list|,
name|versionId
argument_list|,
name|len
argument_list|)
return|;
block|}
comment|/**    * Create the attributes of an object for subsequent use.    * @param fileStatus file status to build from.    * @return attributes to use when building the query.    */
DECL|method|createObjectAttributes ( final S3AFileStatus fileStatus)
specifier|private
name|S3ObjectAttributes
name|createObjectAttributes
parameter_list|(
specifier|final
name|S3AFileStatus
name|fileStatus
parameter_list|)
block|{
return|return
name|createObjectAttributes
argument_list|(
name|fileStatus
operator|.
name|getPath
argument_list|()
argument_list|,
name|fileStatus
operator|.
name|getETag
argument_list|()
argument_list|,
name|fileStatus
operator|.
name|getVersionId
argument_list|()
argument_list|,
name|fileStatus
operator|.
name|getLen
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Create an FSDataOutputStream at the indicated Path with write-progress    * reporting.    * Retry policy: retrying, translated on the getFileStatus() probe.    * No data is uploaded to S3 in this call, so retry issues related to that.    * @param f the file name to open    * @param permission the permission to set.    * @param overwrite if a file with this name already exists, then if true,    *   the file will be overwritten, and if false an error will be thrown.    * @param bufferSize the size of the buffer to be used.    * @param replication required block replication for the file.    * @param blockSize the requested block size.    * @param progress the progress reporter.    * @throws IOException in the event of IO related errors.    * @see #setPermission(Path, FsPermission)    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"IOResourceOpenedButNotSafelyClosed"
argument_list|)
DECL|method|create (Path f, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|create
parameter_list|(
name|Path
name|f
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_CREATE
argument_list|)
expr_stmt|;
specifier|final
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// get the status or throw an FNFE.
comment|// when overwriting, there is no need to look for any existing file,
comment|// and attempting to do so can poison the load balancers with 404
comment|// entries.
name|status
operator|=
name|innerGetFileStatus
argument_list|(
name|path
argument_list|,
literal|false
argument_list|,
name|overwrite
condition|?
name|StatusProbeEnum
operator|.
name|DIRECTORIES
else|:
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
expr_stmt|;
comment|// if the thread reaches here, there is something at the path
if|if
condition|(
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|// path references a directory: automatic error
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|path
operator|+
literal|" is a directory"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|overwrite
condition|)
block|{
comment|// path references a file and overwrite is disabled
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|path
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Overwriting file {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// this means the file is not found
block|}
name|instrumentation
operator|.
name|fileCreated
argument_list|()
expr_stmt|;
name|PutTracker
name|putTracker
init|=
name|committerIntegration
operator|.
name|createTracker
argument_list|(
name|path
argument_list|,
name|key
argument_list|)
decl_stmt|;
name|String
name|destKey
init|=
name|putTracker
operator|.
name|getDestKey
argument_list|()
decl_stmt|;
return|return
operator|new
name|FSDataOutputStream
argument_list|(
operator|new
name|S3ABlockOutputStream
argument_list|(
name|this
argument_list|,
name|destKey
argument_list|,
operator|new
name|SemaphoredDelegatingExecutor
argument_list|(
name|boundedThreadPool
argument_list|,
name|blockOutputActiveBlocks
argument_list|,
literal|true
argument_list|)
argument_list|,
name|progress
argument_list|,
name|partSize
argument_list|,
name|blockFactory
argument_list|,
name|instrumentation
operator|.
name|newOutputStreamStatistics
argument_list|(
name|statistics
argument_list|)
argument_list|,
name|getWriteOperationHelper
argument_list|()
argument_list|,
name|putTracker
argument_list|)
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Get a {@code WriteOperationHelper} instance.    *    * This class permits other low-level operations against the store.    * It is unstable and    * only intended for code with intimate knowledge of the object store.    * If using this, be prepared for changes even on minor point releases.    * @return a new helper.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|method|getWriteOperationHelper ()
specifier|public
name|WriteOperationHelper
name|getWriteOperationHelper
parameter_list|()
block|{
return|return
name|writeHelper
return|;
block|}
comment|/**    * {@inheritDoc}    * @throws FileNotFoundException if the parent directory is not present -or    * is not a directory.    */
annotation|@
name|Override
DECL|method|createNonRecursive (Path path, FsPermission permission, EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|createNonRecursive
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|,
name|EnumSet
argument_list|<
name|CreateFlag
argument_list|>
name|flags
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|short
name|replication
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_CREATE_NON_RECURSIVE
argument_list|)
expr_stmt|;
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
comment|// expect this to raise an exception if there is no parent
if|if
condition|(
operator|!
name|getFileStatus
argument_list|(
name|parent
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Not a directory: "
operator|+
name|parent
argument_list|)
throw|;
block|}
block|}
return|return
name|create
argument_list|(
name|path
argument_list|,
name|permission
argument_list|,
name|flags
operator|.
name|contains
argument_list|(
name|CreateFlag
operator|.
name|OVERWRITE
argument_list|)
argument_list|,
name|bufferSize
argument_list|,
name|replication
argument_list|,
name|blockSize
argument_list|,
name|progress
argument_list|)
return|;
block|}
comment|/**    * Append to an existing file (optional operation).    * @param f the existing file to be appended.    * @param bufferSize the size of the buffer to be used.    * @param progress for reporting progress if it is not null.    * @throws IOException indicating that append is not supported.    */
DECL|method|append (Path f, int bufferSize, Progressable progress)
specifier|public
name|FSDataOutputStream
name|append
parameter_list|(
name|Path
name|f
parameter_list|,
name|int
name|bufferSize
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Append is not supported "
operator|+
literal|"by S3AFileSystem"
argument_list|)
throw|;
block|}
comment|/**    * Renames Path src to Path dst.  Can take place on local fs    * or remote DFS.    *    * Warning: S3 does not support renames. This method does a copy which can    * take S3 some time to execute with large files and directories. Since    * there is no Progressable passed in, this can time out jobs.    *    * Note: This implementation differs with other S3 drivers. Specifically:    *<pre>    *       Fails if src is a file and dst is a directory.    *       Fails if src is a directory and dst is a file.    *       Fails if the parent of dst does not exist or is a file.    *       Fails if dst is a directory that is not empty.    *</pre>    *    * @param src path to be renamed    * @param dst new path after rename    * @throws IOException on IO failure    * @return true if rename is successful    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|rename (Path src, Path dst)
specifier|public
name|boolean
name|rename
parameter_list|(
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"rename(%s, %s"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
init|)
block|{
name|long
name|bytesCopied
init|=
name|innerRename
argument_list|(
name|src
argument_list|,
name|dst
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copied {} bytes"
argument_list|,
name|bytesCopied
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"rename("
operator|+
name|src
operator|+
literal|", "
operator|+
name|dst
operator|+
literal|")"
argument_list|,
name|src
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|RenameFailedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|e
operator|.
name|getExitCode
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Validate the rename parameters and status of the filesystem;    * returns the source and any destination File Status.    * @param src qualified path to be renamed    * @param dst qualified path after rename    * @return the source and (possibly null) destination status entries.    * @throws RenameFailedException if some criteria for a state changing    * rename was not met. This means work didn't happen; it's not something    * which is reported upstream to the FileSystem APIs, for which the semantics    * of "false" are pretty vague.    * @throws FileNotFoundException there's no source file.    * @throws IOException on IO failure.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|initiateRename ( final Path src, final Path dst)
specifier|private
name|Pair
argument_list|<
name|S3AFileStatus
argument_list|,
name|S3AFileStatus
argument_list|>
name|initiateRename
parameter_list|(
specifier|final
name|Path
name|src
parameter_list|,
specifier|final
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|srcKey
init|=
name|pathToKey
argument_list|(
name|src
argument_list|)
decl_stmt|;
name|String
name|dstKey
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is root directory"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dstKey
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"dest is root directory"
argument_list|)
throw|;
block|}
comment|// get the source file status; this raises a FNFE if there is no source
comment|// file.
name|S3AFileStatus
name|srcStatus
init|=
name|innerGetFileStatus
argument_list|(
name|src
argument_list|,
literal|true
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcKey
operator|.
name|equals
argument_list|(
name|dstKey
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: src and dest refer to the same file or directory: {}"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source and dest refer to the same file or directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
name|S3AFileStatus
name|dstStatus
init|=
literal|null
decl_stmt|;
try|try
block|{
name|dstStatus
operator|=
name|innerGetFileStatus
argument_list|(
name|dst
argument_list|,
literal|true
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
expr_stmt|;
comment|// if there is no destination entry, an exception is raised.
comment|// hence this code sequence can assume that there is something
comment|// at the end of the path; the only detail being what it is and
comment|// whether or not it can be the destination of the rename.
if|if
condition|(
name|srcStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"source is a directory and dest is a file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
name|srcStatus
operator|.
name|isFile
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|dstStatus
operator|.
name|isEmptyDirectory
argument_list|()
operator|!=
name|Tristate
operator|.
name|TRUE
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Destination is a non-empty directory"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
comment|// at this point the destination is an empty directory
block|}
else|else
block|{
comment|// source is a file. The destination must be a directory,
comment|// empty or not
if|if
condition|(
name|dstStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"Cannot rename onto an existing file"
argument_list|)
operator|.
name|withExitCode
argument_list|(
literal|false
argument_list|)
throw|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"rename: destination path {} not found"
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Parent must exist
name|Path
name|parent
init|=
name|dst
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|pathToKey
argument_list|(
name|parent
argument_list|)
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
try|try
block|{
name|S3AFileStatus
name|dstParentStatus
init|=
name|innerGetFileStatus
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|,
literal|false
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|dstParentStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination parent is not a directory"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e2
parameter_list|)
block|{
throw|throw
operator|new
name|RenameFailedException
argument_list|(
name|src
argument_list|,
name|dst
argument_list|,
literal|"destination has no parent "
argument_list|)
throw|;
block|}
block|}
block|}
return|return
name|Pair
operator|.
name|of
argument_list|(
name|srcStatus
argument_list|,
name|dstStatus
argument_list|)
return|;
block|}
comment|/**    * The inner rename operation. See {@link #rename(Path, Path)} for    * the description of the operation.    * This operation throws an exception on any failure which needs to be    * reported and downgraded to a failure.    * Retries: retry translated, assuming all operations it is called do    * so. For safely, consider catch and handle AmazonClientException    * because this is such a complex method there's a risk it could surface.    * @param source path to be renamed    * @param dest new path after rename    * @throws RenameFailedException if some criteria for a state changing    * rename was not met. This means work didn't happen; it's not something    * which is reported upstream to the FileSystem APIs, for which the semantics    * of "false" are pretty vague.    * @return the number of bytes copied.    * @throws FileNotFoundException there's no source file.    * @throws IOException on IO failure.    * @throws AmazonClientException on failures inside the AWS SDK    */
annotation|@
name|Retries
operator|.
name|RetryMixed
DECL|method|innerRename (Path source, Path dest)
specifier|private
name|long
name|innerRename
parameter_list|(
name|Path
name|source
parameter_list|,
name|Path
name|dest
parameter_list|)
throws|throws
name|RenameFailedException
throws|,
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|src
init|=
name|qualify
argument_list|(
name|source
argument_list|)
decl_stmt|;
name|Path
name|dst
init|=
name|qualify
argument_list|(
name|dest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Rename path {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|entryPoint
argument_list|(
name|INVOCATION_RENAME
argument_list|)
expr_stmt|;
name|String
name|srcKey
init|=
name|pathToKey
argument_list|(
name|src
argument_list|)
decl_stmt|;
name|String
name|dstKey
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
name|Pair
argument_list|<
name|S3AFileStatus
argument_list|,
name|S3AFileStatus
argument_list|>
name|p
init|=
name|initiateRename
argument_list|(
name|src
argument_list|,
name|dst
argument_list|)
decl_stmt|;
comment|// Initiate the rename.
comment|// this will call back into this class via the rename callbacks
comment|// and interact directly with any metastore.
name|RenameOperation
name|renameOperation
init|=
operator|new
name|RenameOperation
argument_list|(
name|createStoreContext
argument_list|()
argument_list|,
name|src
argument_list|,
name|srcKey
argument_list|,
name|p
operator|.
name|getLeft
argument_list|()
argument_list|,
name|dst
argument_list|,
name|dstKey
argument_list|,
name|p
operator|.
name|getRight
argument_list|()
argument_list|,
name|operationCallbacks
argument_list|)
decl_stmt|;
return|return
name|renameOperation
operator|.
name|execute
argument_list|()
return|;
block|}
comment|/**    * The callbacks made by the rename and delete operations.    * This separation allows the operation to be factored out and    * still avoid knowledge of the S3AFilesystem implementation.    */
DECL|class|OperationCallbacksImpl
specifier|private
class|class
name|OperationCallbacksImpl
implements|implements
name|OperationCallbacks
block|{
annotation|@
name|Override
DECL|method|createObjectAttributes (final Path path, final String eTag, final String versionId, final long len)
specifier|public
name|S3ObjectAttributes
name|createObjectAttributes
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|String
name|eTag
parameter_list|,
specifier|final
name|String
name|versionId
parameter_list|,
specifier|final
name|long
name|len
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|createObjectAttributes
argument_list|(
name|path
argument_list|,
name|eTag
argument_list|,
name|versionId
argument_list|,
name|len
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|createObjectAttributes ( final S3AFileStatus fileStatus)
specifier|public
name|S3ObjectAttributes
name|createObjectAttributes
parameter_list|(
specifier|final
name|S3AFileStatus
name|fileStatus
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|createObjectAttributes
argument_list|(
name|fileStatus
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|createReadContext (final FileStatus fileStatus)
specifier|public
name|S3AReadOpContext
name|createReadContext
parameter_list|(
specifier|final
name|FileStatus
name|fileStatus
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|createReadContext
argument_list|(
name|fileStatus
argument_list|,
name|inputPolicy
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|readAhead
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|deleteObjectAtPath (final Path path, final String key, final boolean isFile, final BulkOperationState operationState)
specifier|public
name|void
name|deleteObjectAtPath
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|String
name|key
parameter_list|,
specifier|final
name|boolean
name|isFile
parameter_list|,
specifier|final
name|BulkOperationState
name|operationState
parameter_list|)
throws|throws
name|IOException
block|{
name|once
argument_list|(
literal|"delete"
argument_list|,
name|key
argument_list|,
parameter_list|()
lambda|->
name|S3AFileSystem
operator|.
name|this
operator|.
name|deleteObjectAtPath
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|isFile
argument_list|,
name|operationState
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listFilesAndEmptyDirectories ( final Path path, final S3AFileStatus status, final boolean collectTombstones, final boolean includeSelf)
specifier|public
name|RemoteIterator
argument_list|<
name|S3ALocatedFileStatus
argument_list|>
name|listFilesAndEmptyDirectories
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|S3AFileStatus
name|status
parameter_list|,
specifier|final
name|boolean
name|collectTombstones
parameter_list|,
specifier|final
name|boolean
name|includeSelf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|innerListFiles
argument_list|(
name|path
argument_list|,
literal|true
argument_list|,
name|includeSelf
condition|?
name|Listing
operator|.
name|ACCEPT_ALL_BUT_S3N
else|:
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
argument_list|,
name|status
argument_list|,
name|collectTombstones
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|copyFile (final String srcKey, final String destKey, final S3ObjectAttributes srcAttributes, final S3AReadOpContext readContext)
specifier|public
name|CopyResult
name|copyFile
parameter_list|(
specifier|final
name|String
name|srcKey
parameter_list|,
specifier|final
name|String
name|destKey
parameter_list|,
specifier|final
name|S3ObjectAttributes
name|srcAttributes
parameter_list|,
specifier|final
name|S3AReadOpContext
name|readContext
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|copyFile
argument_list|(
name|srcKey
argument_list|,
name|destKey
argument_list|,
name|srcAttributes
operator|.
name|getLen
argument_list|()
argument_list|,
name|srcAttributes
argument_list|,
name|readContext
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|removeKeys ( final List<DeleteObjectsRequest.KeyVersion> keysToDelete, final boolean deleteFakeDir, final List<Path> undeletedObjectsOnFailure, final BulkOperationState operationState, final boolean quiet)
specifier|public
name|DeleteObjectsResult
name|removeKeys
parameter_list|(
specifier|final
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
specifier|final
name|boolean
name|deleteFakeDir
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|undeletedObjectsOnFailure
parameter_list|,
specifier|final
name|BulkOperationState
name|operationState
parameter_list|,
specifier|final
name|boolean
name|quiet
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
name|deleteFakeDir
argument_list|,
name|undeletedObjectsOnFailure
argument_list|,
name|operationState
argument_list|,
name|quiet
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|finishRename (final Path sourceRenamed, final Path destCreated)
specifier|public
name|void
name|finishRename
parameter_list|(
specifier|final
name|Path
name|sourceRenamed
parameter_list|,
specifier|final
name|Path
name|destCreated
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|destParent
init|=
name|destCreated
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|sourceRenamed
operator|.
name|getParent
argument_list|()
operator|.
name|equals
argument_list|(
name|destParent
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"source& dest parents are different; fix up dir markers"
argument_list|)
expr_stmt|;
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|destParent
argument_list|)
expr_stmt|;
name|maybeCreateFakeParentDirectory
argument_list|(
name|sourceRenamed
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
DECL|method|allowAuthoritative (final Path p)
specifier|public
name|boolean
name|allowAuthoritative
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|allowAuthoritative
argument_list|(
name|p
argument_list|)
return|;
block|}
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listObjects ( final Path path, final String key)
specifier|public
name|RemoteIterator
argument_list|<
name|S3AFileStatus
argument_list|>
name|listObjects
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|String
name|key
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|once
argument_list|(
literal|"listObjects"
argument_list|,
name|key
argument_list|,
parameter_list|()
lambda|->
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|null
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
name|Listing
operator|.
name|ACCEPT_ALL_BUT_S3N
argument_list|,
literal|null
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * Low-level call to get at the object metadata.    * @param path path to the object    * @return metadata    * @throws IOException IO and object access problems.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getObjectMetadata (Path path)
specifier|public
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getObjectMetadata
argument_list|(
name|path
argument_list|,
literal|null
argument_list|,
name|invoker
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Low-level call to get at the object metadata.    * @param path path to the object    * @param changeTracker the change tracker to detect version inconsistencies    * @param changeInvoker the invoker providing the retry policy    * @param operation the operation being performed (e.g. "read" or "copy")    * @return metadata    * @throws IOException IO and object access problems.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getObjectMetadata (Path path, ChangeTracker changeTracker, Invoker changeInvoker, String operation)
specifier|public
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|Path
name|path
parameter_list|,
name|ChangeTracker
name|changeTracker
parameter_list|,
name|Invoker
name|changeInvoker
parameter_list|,
name|String
name|operation
parameter_list|)
throws|throws
name|IOException
block|{
name|checkNotClosed
argument_list|()
expr_stmt|;
return|return
name|once
argument_list|(
literal|"getObjectMetadata"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
comment|// this always does a full HEAD to the object
name|getObjectMetadata
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|,
name|changeTracker
argument_list|,
name|changeInvoker
argument_list|,
name|operation
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Get all the headers of the object of a path, if the object exists.    * @param path path to probe    * @return an immutable map of object headers.    * @throws IOException failure of the query    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getObjectHeaders (Path path)
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|getObjectHeaders
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"getObjectHeaders({})"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|checkNotClosed
argument_list|()
expr_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|getObjectMetadata
argument_list|(
name|path
argument_list|)
operator|.
name|getRawMetadata
argument_list|()
return|;
block|}
comment|/**    * Does this Filesystem have a metadata store?    * @return true iff the FS has been instantiated with a metadata store    */
DECL|method|hasMetadataStore ()
specifier|public
name|boolean
name|hasMetadataStore
parameter_list|()
block|{
return|return
operator|!
name|S3Guard
operator|.
name|isNullMetadataStore
argument_list|(
name|metadataStore
argument_list|)
return|;
block|}
comment|/**    * Does the filesystem have an authoritative metadata store?    * @return true if there is a metadata store and the authoritative flag    * is set for this filesystem.    */
annotation|@
name|VisibleForTesting
DECL|method|hasAuthoritativeMetadataStore ()
specifier|public
name|boolean
name|hasAuthoritativeMetadataStore
parameter_list|()
block|{
return|return
name|hasMetadataStore
argument_list|()
operator|&&
name|allowAuthoritativeMetadataStore
return|;
block|}
comment|/**    * Get the metadata store.    * This will always be non-null, but may be bound to the    * {@code NullMetadataStore}.    * @return the metadata store of this FS instance    */
annotation|@
name|VisibleForTesting
DECL|method|getMetadataStore ()
specifier|public
name|MetadataStore
name|getMetadataStore
parameter_list|()
block|{
return|return
name|metadataStore
return|;
block|}
comment|/** For testing only.  See ITestS3GuardEmptyDirs. */
annotation|@
name|VisibleForTesting
DECL|method|setMetadataStore (MetadataStore ms)
name|void
name|setMetadataStore
parameter_list|(
name|MetadataStore
name|ms
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|ms
argument_list|)
expr_stmt|;
name|metadataStore
operator|=
name|ms
expr_stmt|;
block|}
comment|/**    * Entry point to an operation.    * Increments the statistic; verifies the FS is active.    * @param operation The operation to increment    * @throws IOException if the    */
DECL|method|entryPoint (Statistic operation)
specifier|protected
name|void
name|entryPoint
parameter_list|(
name|Statistic
name|operation
parameter_list|)
throws|throws
name|IOException
block|{
name|checkNotClosed
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|operation
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a statistic by 1.    * This increments both the instrumentation and storage statistics.    * @param statistic The operation to increment    */
DECL|method|incrementStatistic (Statistic statistic)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|)
block|{
name|incrementStatistic
argument_list|(
name|statistic
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a statistic by a specific value.    * This increments both the instrumentation and storage statistics.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementStatistic (Statistic statistic, long count)
specifier|protected
name|void
name|incrementStatistic
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|storageStatistics
operator|.
name|incrementCounter
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Decrement a gauge by a specific value.    * @param statistic The operation to decrement    * @param count the count to decrement    */
DECL|method|decrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|decrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|decrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment a gauge by a specific value.    * @param statistic The operation to increment    * @param count the count to increment    */
DECL|method|incrementGauge (Statistic statistic, long count)
specifier|protected
name|void
name|incrementGauge
parameter_list|(
name|Statistic
name|statistic
parameter_list|,
name|long
name|count
parameter_list|)
block|{
name|instrumentation
operator|.
name|incrementGauge
argument_list|(
name|statistic
argument_list|,
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback when an operation was retried.    * Increments the statistics of ignored errors or throttled requests,    * depending up on the exception class.    * @param ex exception.    */
DECL|method|operationRetried (Exception ex)
specifier|public
name|void
name|operationRetried
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|Statistic
name|stat
init|=
name|isThrottleException
argument_list|(
name|ex
argument_list|)
condition|?
name|STORE_IO_THROTTLED
else|:
name|IGNORED_ERRORS
decl_stmt|;
name|incrementStatistic
argument_list|(
name|stat
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback from {@link Invoker} when an operation is retried.    * @param text text of the operation    * @param ex exception    * @param retries number of retries    * @param idempotent is the method idempotent    */
DECL|method|operationRetried ( String text, Exception ex, int retries, boolean idempotent)
specifier|public
name|void
name|operationRetried
parameter_list|(
name|String
name|text
parameter_list|,
name|Exception
name|ex
parameter_list|,
name|int
name|retries
parameter_list|,
name|boolean
name|idempotent
parameter_list|)
block|{
name|operationRetried
argument_list|(
name|ex
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback from {@link Invoker} when an operation against a metastore    * is retried.    * Always increments the {@link Statistic#S3GUARD_METADATASTORE_RETRY}    * statistic/counter;    * if it is a throttling exception will update the associated    * throttled metrics/statistics.    *    * @param ex exception    * @param retries number of retries    * @param idempotent is the method idempotent    */
DECL|method|metastoreOperationRetried (Exception ex, int retries, boolean idempotent)
specifier|public
name|void
name|metastoreOperationRetried
parameter_list|(
name|Exception
name|ex
parameter_list|,
name|int
name|retries
parameter_list|,
name|boolean
name|idempotent
parameter_list|)
block|{
name|operationRetried
argument_list|(
name|ex
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|S3GUARD_METADATASTORE_RETRY
argument_list|)
expr_stmt|;
if|if
condition|(
name|isThrottleException
argument_list|(
name|ex
argument_list|)
condition|)
block|{
name|incrementStatistic
argument_list|(
name|S3GUARD_METADATASTORE_THROTTLED
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|addValueToQuantiles
argument_list|(
name|S3GUARD_METADATASTORE_THROTTLE_RATE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Get the storage statistics of this filesystem.    * @return the storage statistics    */
annotation|@
name|Override
DECL|method|getStorageStatistics ()
specifier|public
name|S3AStorageStatistics
name|getStorageStatistics
parameter_list|()
block|{
return|return
name|storageStatistics
return|;
block|}
comment|/**    * Request object metadata; increments counters in the process.    * Retry policy: retry untranslated.    * @param key key    * @return the metadata    * @throws IOException if the retry invocation raises one (it shouldn't).    */
annotation|@
name|Retries
operator|.
name|RetryRaw
annotation|@
name|VisibleForTesting
DECL|method|getObjectMetadata (String key)
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getObjectMetadata
argument_list|(
name|key
argument_list|,
literal|null
argument_list|,
name|invoker
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Request object metadata; increments counters in the process.    * Retry policy: retry untranslated.    * Uses changeTracker to detect an unexpected file version (eTag or versionId)    * @param key key    * @param changeTracker the change tracker to detect unexpected object version    * @param changeInvoker the invoker providing the retry policy    * @param operation the operation (e.g. "read" or "copy") triggering this call    * @return the metadata    * @throws IOException if the retry invocation raises one (it shouldn't).    * @throws RemoteFileChangedException if an unexpected version is detected    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|getObjectMetadata (String key, ChangeTracker changeTracker, Invoker changeInvoker, String operation)
specifier|protected
name|ObjectMetadata
name|getObjectMetadata
parameter_list|(
name|String
name|key
parameter_list|,
name|ChangeTracker
name|changeTracker
parameter_list|,
name|Invoker
name|changeInvoker
parameter_list|,
name|String
name|operation
parameter_list|)
throws|throws
name|IOException
block|{
name|GetObjectMetadataRequest
name|request
init|=
operator|new
name|GetObjectMetadataRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
decl_stmt|;
comment|//SSE-C requires to be filled in if enabled for object metadata
name|generateSSECustomerKey
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSECustomerKey
argument_list|)
expr_stmt|;
name|ObjectMetadata
name|meta
init|=
name|changeInvoker
operator|.
name|retryUntranslated
argument_list|(
literal|"GET "
operator|+
name|key
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_METADATA_REQUESTS
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"HEAD {} with change tracker {}"
argument_list|,
name|key
argument_list|,
name|changeTracker
argument_list|)
expr_stmt|;
if|if
condition|(
name|changeTracker
operator|!=
literal|null
condition|)
block|{
name|changeTracker
operator|.
name|maybeApplyConstraint
argument_list|(
name|request
argument_list|)
expr_stmt|;
block|}
name|ObjectMetadata
name|objectMetadata
init|=
name|s3
operator|.
name|getObjectMetadata
argument_list|(
name|request
argument_list|)
decl_stmt|;
if|if
condition|(
name|changeTracker
operator|!=
literal|null
condition|)
block|{
name|changeTracker
operator|.
name|processMetadata
argument_list|(
name|objectMetadata
argument_list|,
name|operation
argument_list|)
expr_stmt|;
block|}
return|return
name|objectMetadata
return|;
block|}
argument_list|)
decl_stmt|;
name|incrementReadOperations
argument_list|()
expr_stmt|;
return|return
name|meta
return|;
block|}
comment|/**    * Initiate a {@code listObjects} operation, incrementing metrics    * in the process.    *    * Retry policy: retry untranslated.    * @param request request to initiate    * @return the results    * @throws IOException if the retry invocation raises one (it shouldn't).    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|listObjects (S3ListRequest request)
specifier|protected
name|S3ListResult
name|listObjects
parameter_list|(
name|S3ListRequest
name|request
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementReadOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_LIST_REQUESTS
argument_list|)
expr_stmt|;
name|validateListArguments
argument_list|(
name|request
argument_list|)
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"LIST"
argument_list|)
init|)
block|{
return|return
name|invoker
operator|.
name|retryUntranslated
argument_list|(
name|request
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
if|if
condition|(
name|useListV1
condition|)
block|{
return|return
name|S3ListResult
operator|.
name|v1
argument_list|(
name|s3
operator|.
name|listObjects
argument_list|(
name|request
operator|.
name|getV1
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|S3ListResult
operator|.
name|v2
argument_list|(
name|s3
operator|.
name|listObjectsV2
argument_list|(
name|request
operator|.
name|getV2
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
block|}
comment|/**    * Validate the list arguments with this bucket's settings.    * @param request the request to validate    */
DECL|method|validateListArguments (S3ListRequest request)
specifier|private
name|void
name|validateListArguments
parameter_list|(
name|S3ListRequest
name|request
parameter_list|)
block|{
if|if
condition|(
name|useListV1
condition|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|request
operator|.
name|isV1
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|request
operator|.
name|isV1
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * List the next set of objects.    * Retry policy: retry untranslated.    * @param request last list objects request to continue    * @param prevResult last paged result to continue from    * @return the next result object    * @throws IOException none, just there for retryUntranslated.    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|continueListObjects (S3ListRequest request, S3ListResult prevResult)
specifier|protected
name|S3ListResult
name|continueListObjects
parameter_list|(
name|S3ListRequest
name|request
parameter_list|,
name|S3ListResult
name|prevResult
parameter_list|)
throws|throws
name|IOException
block|{
name|incrementReadOperations
argument_list|()
expr_stmt|;
name|validateListArguments
argument_list|(
name|request
argument_list|)
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"LIST (continued)"
argument_list|)
init|)
block|{
return|return
name|invoker
operator|.
name|retryUntranslated
argument_list|(
name|request
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_CONTINUE_LIST_REQUESTS
argument_list|)
expr_stmt|;
if|if
condition|(
name|useListV1
condition|)
block|{
return|return
name|S3ListResult
operator|.
name|v1
argument_list|(
name|s3
operator|.
name|listNextBatchOfObjects
argument_list|(
name|prevResult
operator|.
name|getV1
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
name|request
operator|.
name|getV2
argument_list|()
operator|.
name|setContinuationToken
argument_list|(
name|prevResult
operator|.
name|getV2
argument_list|()
operator|.
name|getNextContinuationToken
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|S3ListResult
operator|.
name|v2
argument_list|(
name|s3
operator|.
name|listObjectsV2
argument_list|(
name|request
operator|.
name|getV2
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
block|}
comment|/**    * Increment read operations.    */
DECL|method|incrementReadOperations ()
specifier|public
name|void
name|incrementReadOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementReadOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Increment the write operation counter.    * This is somewhat inaccurate, as it appears to be invoked more    * often than needed in progress callbacks.    */
DECL|method|incrementWriteOperations ()
specifier|public
name|void
name|incrementWriteOperations
parameter_list|()
block|{
name|statistics
operator|.
name|incrementWriteOps
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete an object. This is the low-level internal call which    *<i>does not</i> update the metastore.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    * This call does<i>not</i> create any mock parent entries.    *    * Retry policy: retry untranslated; delete considered idempotent.    * @param key key to blob to delete.    * @throws AmazonClientException problems working with S3    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|deleteObject (String key)
specifier|protected
name|void
name|deleteObject
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|IOException
block|{
name|blockRootDelete
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"deleting %s"
argument_list|,
name|key
argument_list|)
init|)
block|{
name|invoker
operator|.
name|retryUntranslated
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Delete %s:/%s"
argument_list|,
name|bucket
argument_list|,
name|key
argument_list|)
argument_list|,
name|DELETE_CONSIDERED_IDEMPOTENT
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|)
expr_stmt|;
name|s3
operator|.
name|deleteObject
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete an object, also updating the metastore.    * This call does<i>not</i> create any mock parent entries.    * Retry policy: retry untranslated; delete considered idempotent.    * @param f path path to delete    * @param key key of entry    * @param isFile is the path a file (used for instrumentation only)    * @param operationState (nullable) operational state for a bulk update    * @throws AmazonClientException problems working with S3    * @throws IOException IO failure in the metastore    */
annotation|@
name|Retries
operator|.
name|RetryMixed
DECL|method|deleteObjectAtPath (Path f, String key, boolean isFile, @Nullable final BulkOperationState operationState)
name|void
name|deleteObjectAtPath
parameter_list|(
name|Path
name|f
parameter_list|,
name|String
name|key
parameter_list|,
name|boolean
name|isFile
parameter_list|,
annotation|@
name|Nullable
specifier|final
name|BulkOperationState
name|operationState
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|IOException
block|{
if|if
condition|(
name|isFile
condition|)
block|{
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|instrumentation
operator|.
name|directoryDeleted
argument_list|()
expr_stmt|;
block|}
name|deleteObject
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|metadataStore
operator|.
name|delete
argument_list|(
name|f
argument_list|,
name|operationState
argument_list|)
expr_stmt|;
block|}
comment|/**    * Reject any request to delete an object where the key is root.    * @param key key to validate    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    */
DECL|method|blockRootDelete (String key)
specifier|private
name|void
name|blockRootDelete
parameter_list|(
name|String
name|key
parameter_list|)
throws|throws
name|InvalidRequestException
block|{
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
operator|||
literal|"/"
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|InvalidRequestException
argument_list|(
literal|"Bucket "
operator|+
name|bucket
operator|+
literal|" cannot be deleted"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Perform a bulk object delete operation.    * Increments the {@code OBJECT_DELETE_REQUESTS} and write    * operation statistics.    * Retry policy: retry untranslated; delete considered idempotent.    * @param deleteRequest keys to delete on the s3-backend    * @return the AWS response    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted.    * @throws AmazonClientException amazon-layer failure.    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|deleteObjects (DeleteObjectsRequest deleteRequest)
specifier|private
name|DeleteObjectsResult
name|deleteObjects
parameter_list|(
name|DeleteObjectsRequest
name|deleteRequest
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
name|incrementWriteOperations
argument_list|()
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"DELETE %d keys"
argument_list|,
name|deleteRequest
operator|.
name|getKeys
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
init|)
block|{
return|return
name|invoker
operator|.
name|retryUntranslated
argument_list|(
literal|"delete"
argument_list|,
name|DELETE_CONSIDERED_IDEMPOTENT
argument_list|,
parameter_list|()
lambda|->
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_DELETE_REQUESTS
argument_list|,
literal|1
argument_list|)
expr_stmt|;
return|return
name|s3
operator|.
name|deleteObjects
argument_list|(
name|deleteRequest
argument_list|)
return|;
block|}
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MultiObjectDeleteException
name|e
parameter_list|)
block|{
comment|// one or more of the operations failed.
name|List
argument_list|<
name|MultiObjectDeleteException
operator|.
name|DeleteError
argument_list|>
name|errors
init|=
name|e
operator|.
name|getErrors
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Partial failure of delete, {} errors"
argument_list|,
name|errors
operator|.
name|size
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
for|for
control|(
name|MultiObjectDeleteException
operator|.
name|DeleteError
name|error
range|:
name|errors
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{}: \"{}\" - {}"
argument_list|,
name|error
operator|.
name|getKey
argument_list|()
argument_list|,
name|error
operator|.
name|getCode
argument_list|()
argument_list|,
name|error
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Create a putObject request.    * Adds the ACL and metadata    * @param key key of object    * @param metadata metadata header    * @param srcfile source file    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, File srcfile)
specifier|public
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|File
name|srcfile
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|srcfile
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setMetadata
argument_list|(
name|metadata
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a {@link PutObjectRequest} request.    * The metadata is assumed to have been configured with the size of the    * operation.    * @param key key of object    * @param metadata metadata header    * @param inputStream source data.    * @return the request    */
DECL|method|newPutObjectRequest (String key, ObjectMetadata metadata, InputStream inputStream)
name|PutObjectRequest
name|newPutObjectRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|ObjectMetadata
name|metadata
parameter_list|,
name|InputStream
name|inputStream
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|inputStream
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|isNotEmpty
argument_list|(
name|key
argument_list|)
argument_list|,
literal|"Null/empty key"
argument_list|)
expr_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
operator|new
name|PutObjectRequest
argument_list|(
name|bucket
argument_list|,
name|key
argument_list|,
name|inputStream
argument_list|,
name|metadata
argument_list|)
decl_stmt|;
name|setOptionalPutRequestParameters
argument_list|(
name|putObjectRequest
argument_list|)
expr_stmt|;
name|putObjectRequest
operator|.
name|setCannedAcl
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
return|return
name|putObjectRequest
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    * @return a new metadata instance    */
DECL|method|newObjectMetadata ()
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|()
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
operator|new
name|ObjectMetadata
argument_list|()
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|om
argument_list|)
expr_stmt|;
return|return
name|om
return|;
block|}
comment|/**    * Create a new object metadata instance.    * Any standard metadata headers are added here, for example:    * encryption.    *    * @param length length of data to set in header.    * @return a new metadata instance    */
DECL|method|newObjectMetadata (long length)
specifier|public
name|ObjectMetadata
name|newObjectMetadata
parameter_list|(
name|long
name|length
parameter_list|)
block|{
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|length
operator|>=
literal|0
condition|)
block|{
name|om
operator|.
name|setContentLength
argument_list|(
name|length
argument_list|)
expr_stmt|;
block|}
return|return
name|om
return|;
block|}
comment|/**    * Start a transfer-manager managed async PUT of an object,    * incrementing the put requests and put bytes    * counters.    * It does not update the other counters,    * as existing code does that as progress callbacks come in.    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    * Because the operation is async, any stream supplied in the request    * must reference data (files, buffers) which stay valid until the upload    * completes.    * Retry policy: N/A: the transfer manager is performing the upload.    * @param putObjectRequest the request    * @return the upload initiated    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|putObject (PutObjectRequest putObjectRequest)
specifier|public
name|UploadInfo
name|putObject
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
block|{
name|long
name|len
init|=
name|getPutRequestLength
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT {} bytes to {} via transfer manager "
argument_list|,
name|len
argument_list|,
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
name|Upload
name|upload
init|=
name|transfers
operator|.
name|upload
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
return|return
operator|new
name|UploadInfo
argument_list|(
name|upload
argument_list|,
name|len
argument_list|)
return|;
block|}
comment|/**    * PUT an object directly (i.e. not via the transfer manager).    * Byte length is calculated from the file length, or, if there is no    * file, from the content length of the header.    *    * Retry Policy: none.    *<i>Important: this call will close any input stream in the request.</i>    * @param putObjectRequest the request    * @return the upload initiated    * @throws AmazonClientException on problems    * @throws MetadataPersistenceException if metadata about the write could    * not be saved to the metadata store and    * fs.s3a.metadatastore.fail.on.write.error=true    */
annotation|@
name|Retries
operator|.
name|OnceRaw
argument_list|(
literal|"For PUT; post-PUT actions are RetryTranslated"
argument_list|)
DECL|method|putObjectDirect (PutObjectRequest putObjectRequest)
name|PutObjectResult
name|putObjectDirect
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
throws|throws
name|AmazonClientException
throws|,
name|MetadataPersistenceException
block|{
name|long
name|len
init|=
name|getPutRequestLength
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT {} bytes to {}"
argument_list|,
name|len
argument_list|,
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|PutObjectResult
name|result
init|=
name|s3
operator|.
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
comment|// update metadata
name|finishedWrite
argument_list|(
name|putObjectRequest
operator|.
name|getKey
argument_list|()
argument_list|,
name|len
argument_list|,
name|result
operator|.
name|getETag
argument_list|()
argument_list|,
name|result
operator|.
name|getVersionId
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Get the length of the PUT, verifying that the length is known.    * @param putObjectRequest a request bound to a file or a stream.    * @return the request length    * @throws IllegalArgumentException if the length is negative    */
DECL|method|getPutRequestLength (PutObjectRequest putObjectRequest)
specifier|private
name|long
name|getPutRequestLength
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|)
block|{
name|long
name|len
decl_stmt|;
if|if
condition|(
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getFile
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|len
operator|=
name|putObjectRequest
operator|.
name|getMetadata
argument_list|()
operator|.
name|getContentLength
argument_list|()
expr_stmt|;
block|}
name|Preconditions
operator|.
name|checkState
argument_list|(
name|len
operator|>=
literal|0
argument_list|,
literal|"Cannot PUT object of unknown length"
argument_list|)
expr_stmt|;
return|return
name|len
return|;
block|}
comment|/**    * Upload part of a multi-partition file.    * Increments the write and put counters.    *<i>Important: this call does not close any input stream in the request.</i>    *    * Retry Policy: none.    * @param request request    * @return the result of the operation.    * @throws AmazonClientException on problems    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|uploadPart (UploadPartRequest request)
name|UploadPartResult
name|uploadPart
parameter_list|(
name|UploadPartRequest
name|request
parameter_list|)
throws|throws
name|AmazonClientException
block|{
name|long
name|len
init|=
name|request
operator|.
name|getPartSize
argument_list|()
decl_stmt|;
name|incrementPutStartStatistics
argument_list|(
name|len
argument_list|)
expr_stmt|;
try|try
block|{
name|setOptionalUploadPartRequestParameters
argument_list|(
name|request
argument_list|)
expr_stmt|;
name|UploadPartResult
name|uploadPartResult
init|=
name|s3
operator|.
name|uploadPart
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|len
argument_list|)
expr_stmt|;
return|return
name|uploadPartResult
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|len
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * At the start of a put/multipart upload operation, update the    * relevant counters.    *    * @param bytes bytes in the request.    */
DECL|method|incrementPutStartStatistics (long bytes)
specifier|public
name|void
name|incrementPutStartStatistics
parameter_list|(
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT start {} bytes"
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS
argument_list|)
expr_stmt|;
name|incrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * At the end of a put/multipart upload operation, update the    * relevant counters and gauges.    *    * @param success did the operation succeed?    * @param bytes bytes in the request.    */
DECL|method|incrementPutCompletedStatistics (boolean success, long bytes)
specifier|public
name|void
name|incrementPutCompletedStatistics
parameter_list|(
name|boolean
name|success
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"PUT completed success={}; {} bytes"
argument_list|,
name|success
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_BYTES
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_BYTES_PENDING
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
block|}
name|incrementStatistic
argument_list|(
name|OBJECT_PUT_REQUESTS_COMPLETED
argument_list|)
expr_stmt|;
name|decrementGauge
argument_list|(
name|OBJECT_PUT_REQUESTS_ACTIVE
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Callback for use in progress callbacks from put/multipart upload events.    * Increments those statistics which are expected to be updated during    * the ongoing upload operation.    * @param key key to file that is being written (for logging)    * @param bytes bytes successfully uploaded.    */
DECL|method|incrementPutProgressStatistics (String key, long bytes)
specifier|public
name|void
name|incrementPutProgressStatistics
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|bytes
parameter_list|)
block|{
name|PROGRESS
operator|.
name|debug
argument_list|(
literal|"PUT {}: {} bytes"
argument_list|,
name|key
argument_list|,
name|bytes
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
if|if
condition|(
name|bytes
operator|>
literal|0
condition|)
block|{
name|statistics
operator|.
name|incrementBytesWritten
argument_list|(
name|bytes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete a list of keys on a s3-backend.    * This does<i>not</i> update the metastore.    * Retry policy: retry untranslated; delete considered idempotent.    * @param keysToDelete collection of keys to delete on the s3-backend.    *        if empty, no request is made of the object store.    * @param deleteFakeDir indicates whether this is for deleting fake dirs    * @param quiet should a bulk query be quiet, or should its result list    * all deleted keys?    * @return the deletion result if a multi object delete was invoked    * and it returned without a failure.    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted in a multiple object delete operation.    * The number of rejected objects will be added to the metric    * {@link Statistic#FILES_DELETE_REJECTED}.    * @throws AmazonClientException other amazon-layer failure.    */
annotation|@
name|Retries
operator|.
name|RetryRaw
DECL|method|removeKeysS3 ( List<DeleteObjectsRequest.KeyVersion> keysToDelete, boolean deleteFakeDir, boolean quiet)
specifier|private
name|DeleteObjectsResult
name|removeKeysS3
parameter_list|(
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
name|boolean
name|deleteFakeDir
parameter_list|,
name|boolean
name|quiet
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
name|DeleteObjectsResult
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|keysToDelete
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// exit fast if there are no keys to delete
return|return
name|result
return|;
block|}
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|blockRootDelete
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|enableMultiObjectsDelete
condition|)
block|{
name|result
operator|=
name|deleteObjects
argument_list|(
operator|new
name|DeleteObjectsRequest
argument_list|(
name|bucket
argument_list|)
operator|.
name|withKeys
argument_list|(
name|keysToDelete
argument_list|)
operator|.
name|withQuiet
argument_list|(
name|quiet
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|keyVersion
range|:
name|keysToDelete
control|)
block|{
name|deleteObject
argument_list|(
name|keyVersion
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|MultiObjectDeleteException
name|ex
parameter_list|)
block|{
comment|// partial delete.
comment|// Update the stats with the count of the actual number of successful
comment|// deletions.
name|int
name|rejected
init|=
name|ex
operator|.
name|getErrors
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|noteDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
operator|-
name|rejected
argument_list|,
name|deleteFakeDir
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|FILES_DELETE_REJECTED
argument_list|,
name|rejected
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
name|noteDeleted
argument_list|(
name|keysToDelete
operator|.
name|size
argument_list|()
argument_list|,
name|deleteFakeDir
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * Note the deletion of files or fake directories deleted.    * @param count count of keys deleted.    * @param deleteFakeDir are the deletions fake directories?    */
DECL|method|noteDeleted (final int count, final boolean deleteFakeDir)
specifier|private
name|void
name|noteDeleted
parameter_list|(
specifier|final
name|int
name|count
parameter_list|,
specifier|final
name|boolean
name|deleteFakeDir
parameter_list|)
block|{
if|if
condition|(
operator|!
name|deleteFakeDir
condition|)
block|{
name|instrumentation
operator|.
name|fileDeleted
argument_list|(
name|count
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|instrumentation
operator|.
name|fakeDirsDeleted
argument_list|(
name|count
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Invoke {@link #removeKeysS3(List, boolean)} with handling of    * {@code MultiObjectDeleteException}.    *    * @param keysToDelete collection of keys to delete on the s3-backend.    *        if empty, no request is made of the object store.    * @param deleteFakeDir indicates whether this is for deleting fake dirs    * @param operationState (nullable) operational state for a bulk update    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted in a multiple object delete operation.    * @throws AmazonClientException amazon-layer failure.    * @throws IOException other IO Exception.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryMixed
DECL|method|removeKeys ( final List<DeleteObjectsRequest.KeyVersion> keysToDelete, final boolean deleteFakeDir, final BulkOperationState operationState)
name|void
name|removeKeys
parameter_list|(
specifier|final
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
specifier|final
name|boolean
name|deleteFakeDir
parameter_list|,
specifier|final
name|BulkOperationState
name|operationState
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
name|removeKeys
argument_list|(
name|keysToDelete
argument_list|,
name|deleteFakeDir
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|,
name|operationState
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Invoke {@link #removeKeysS3(List, boolean, boolean)} with handling of    * {@code MultiObjectDeleteException} before the exception is rethrown.    * Specifically:    *<ol>    *<li>Failure and !deleteFakeDir: S3Guard is updated with all    *    deleted entries</li>    *<li>Failure where deleteFakeDir == true: do nothing with S3Guard</li>    *<li>Success: do nothing with S3Guard</li>    *</ol>    * @param keysToDelete collection of keys to delete on the s3-backend.    *        if empty, no request is made of the object store.    * @param deleteFakeDir indicates whether this is for deleting fake dirs.    * @param undeletedObjectsOnFailure List which will be built up of all    * files that were not deleted. This happens even as an exception    * is raised.    * @param operationState (nullable) operational state for a bulk update    * @param quiet should a bulk query be quiet, or should its result list    * all deleted keys    * @return the deletion result if a multi object delete was invoked    * and it returned without a failure, else null.    * @throws InvalidRequestException if the request was rejected due to    * a mistaken attempt to delete the root directory.    * @throws MultiObjectDeleteException one or more of the keys could not    * be deleted in a multiple object delete operation.    * @throws AmazonClientException amazon-layer failure.    * @throws IOException other IO Exception.    */
annotation|@
name|Retries
operator|.
name|RetryMixed
DECL|method|removeKeys ( final List<DeleteObjectsRequest.KeyVersion> keysToDelete, final boolean deleteFakeDir, final List<Path> undeletedObjectsOnFailure, final BulkOperationState operationState, final boolean quiet)
name|DeleteObjectsResult
name|removeKeys
parameter_list|(
specifier|final
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToDelete
parameter_list|,
specifier|final
name|boolean
name|deleteFakeDir
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|undeletedObjectsOnFailure
parameter_list|,
specifier|final
name|BulkOperationState
name|operationState
parameter_list|,
specifier|final
name|boolean
name|quiet
parameter_list|)
throws|throws
name|MultiObjectDeleteException
throws|,
name|AmazonClientException
throws|,
name|IOException
block|{
name|undeletedObjectsOnFailure
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
init|(
name|DurationInfo
name|ignored
init|=
operator|new
name|DurationInfo
argument_list|(
name|LOG
argument_list|,
literal|false
argument_list|,
literal|"Deleting"
argument_list|)
init|)
block|{
return|return
name|removeKeysS3
argument_list|(
name|keysToDelete
argument_list|,
name|deleteFakeDir
argument_list|,
name|quiet
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|MultiObjectDeleteException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Partial delete failure"
argument_list|)
expr_stmt|;
comment|// what to do if an IOE was raised? Given an exception was being
comment|// raised anyway, and the failures are logged, do nothing.
if|if
condition|(
operator|!
name|deleteFakeDir
condition|)
block|{
comment|// when deleting fake directories we don't want to delete metastore
comment|// entries so we only process these failures on "real" deletes.
name|Triple
argument_list|<
name|List
argument_list|<
name|Path
argument_list|>
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|IOException
argument_list|>
argument_list|>
argument_list|>
name|results
init|=
operator|new
name|MultiObjectDeleteSupport
argument_list|(
name|createStoreContext
argument_list|()
argument_list|,
name|operationState
argument_list|)
operator|.
name|processDeleteFailure
argument_list|(
name|ex
argument_list|,
name|keysToDelete
argument_list|)
decl_stmt|;
name|undeletedObjectsOnFailure
operator|.
name|addAll
argument_list|(
name|results
operator|.
name|getMiddle
argument_list|()
argument_list|)
expr_stmt|;
block|}
throw|throw
name|ex
throw|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
decl||
name|IOException
name|ex
parameter_list|)
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|paths
init|=
operator|new
name|MultiObjectDeleteSupport
argument_list|(
name|createStoreContext
argument_list|()
argument_list|,
name|operationState
argument_list|)
operator|.
name|processDeleteFailureGenericException
argument_list|(
name|ex
argument_list|,
name|keysToDelete
argument_list|)
decl_stmt|;
comment|// other failures. Assume nothing was deleted
name|undeletedObjectsOnFailure
operator|.
name|addAll
argument_list|(
name|paths
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
comment|/**    * Delete a Path. This operation is at least {@code O(files)}, with    * added overheads to enumerate the path. It is also not atomic.    *    * @param f the path to delete.    * @param recursive if path is a directory and set to    * true, the directory is deleted else throws an exception. In    * case of a file the recursive can be set to either true or false.    * @return true if the path existed and then was deleted; false if there    * was no path in the first place, or the corner cases of root path deletion    * have surfaced.    * @throws IOException due to inability to delete a directory or file.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|delete (Path f, boolean recursive)
specifier|public
name|boolean
name|delete
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|entryPoint
argument_list|(
name|INVOCATION_DELETE
argument_list|)
expr_stmt|;
name|DeleteOperation
name|deleteOperation
init|=
operator|new
name|DeleteOperation
argument_list|(
name|createStoreContext
argument_list|()
argument_list|,
name|innerGetFileStatus
argument_list|(
name|f
argument_list|,
literal|true
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
argument_list|,
name|recursive
argument_list|,
name|operationCallbacks
argument_list|,
name|InternalConstants
operator|.
name|MAX_ENTRIES_TO_DELETE
argument_list|)
decl_stmt|;
name|boolean
name|outcome
init|=
name|deleteOperation
operator|.
name|execute
argument_list|()
decl_stmt|;
if|if
condition|(
name|outcome
condition|)
block|{
try|try
block|{
name|maybeCreateFakeParentDirectory
argument_list|(
name|f
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AccessDeniedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot create directory marker at {}: {}"
argument_list|,
name|f
operator|.
name|getParent
argument_list|()
argument_list|,
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to create fake dir above {}"
argument_list|,
name|f
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|outcome
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Couldn't delete {} - does not exist: {}"
argument_list|,
name|f
argument_list|,
name|e
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"delete"
argument_list|,
name|f
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Create a fake directory if required.    * That is: it is not the root path and the path does not exist.    * Retry policy: retrying; untranslated.    * @param f path to create    * @throws IOException IO problem    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createFakeDirectoryIfNecessary (Path f)
specifier|private
name|void
name|createFakeDirectoryIfNecessary
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
comment|// we only make the LIST call; the codepaths to get here should not
comment|// be reached if there is an empty dir marker -and if they do, it
comment|// is mostly harmless to create a new one.
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|s3Exists
argument_list|(
name|f
argument_list|,
name|EnumSet
operator|.
name|of
argument_list|(
name|StatusProbeEnum
operator|.
name|List
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating new fake directory at {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a fake parent directory if required.    * That is: it parent is not the root path and does not yet exist.    * @param path whose parent is created if needed.    * @throws IOException IO problem    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|maybeCreateFakeParentDirectory (Path path)
name|void
name|maybeCreateFakeParentDirectory
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|parent
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|createFakeDirectoryIfNecessary
argument_list|(
name|parent
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    *         IOException see specific implementation    */
DECL|method|listStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|listStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|once
argument_list|(
literal|"listStatus"
argument_list|,
name|f
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
name|innerListStatus
argument_list|(
name|f
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * List the statuses of the files/directories in the given path if the path is    * a directory.    *    * @param f given path    * @return the statuses of the files/directories in the given patch    * @throws FileNotFoundException when the path does not exist;    * @throws IOException due to an IO problem.    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerListStatus (Path f)
specifier|public
name|FileStatus
index|[]
name|innerListStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
throws|,
name|AmazonClientException
block|{
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"List status for path: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|entryPoint
argument_list|(
name|INVOCATION_LIST_STATUS
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|S3AFileStatus
argument_list|>
name|result
decl_stmt|;
specifier|final
name|FileStatus
name|fileStatus
init|=
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|key
operator|=
name|key
operator|+
literal|'/'
expr_stmt|;
block|}
name|DirListingMetadata
name|dirMeta
init|=
name|S3Guard
operator|.
name|listChildrenWithTtl
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|ttlTimeProvider
argument_list|)
decl_stmt|;
name|boolean
name|allowAuthoritative
init|=
name|allowAuthoritative
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|allowAuthoritative
operator|&&
name|dirMeta
operator|!=
literal|null
operator|&&
name|dirMeta
operator|.
name|isAuthoritative
argument_list|()
condition|)
block|{
return|return
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|dirMeta
argument_list|)
return|;
block|}
name|S3ListRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listStatus: doing listObjects for directory {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
name|Listing
operator|.
name|FileStatusListingIterator
name|files
init|=
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|request
argument_list|,
name|ACCEPT_ALL
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|result
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|getBatchSize
argument_list|()
argument_list|)
expr_stmt|;
while|while
condition|(
name|files
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|files
operator|.
name|next
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// merge the results. This will update the store as needed
return|return
name|S3Guard
operator|.
name|dirListingUnion
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|result
argument_list|,
name|dirMeta
argument_list|,
name|allowAuthoritative
argument_list|,
name|ttlTimeProvider
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding: rd (not a dir): {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|FileStatus
index|[]
name|stats
init|=
operator|new
name|FileStatus
index|[
literal|1
index|]
decl_stmt|;
name|stats
index|[
literal|0
index|]
operator|=
name|fileStatus
expr_stmt|;
return|return
name|stats
return|;
block|}
block|}
comment|/**    * Is a path to be considered as authoritative?    * True iff there is an authoritative metastore or if there    * is a non-auth store with the supplied path under    * one of the paths declared as authoritative.    * @param path path    * @return true if the path is auth    */
DECL|method|allowAuthoritative (final Path path)
specifier|protected
name|boolean
name|allowAuthoritative
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|)
block|{
return|return
name|S3Guard
operator|.
name|allowAuthoritative
argument_list|(
name|path
argument_list|,
name|this
argument_list|,
name|allowAuthoritativeMetadataStore
argument_list|,
name|allowAuthoritativePaths
argument_list|)
return|;
block|}
comment|/**    * Create a {@code ListObjectsRequest} request against this bucket,    * with the maximum keys returned in a query set by {@link #maxKeys}.    * @param key key for request    * @param delimiter any delimiter    * @return the request    */
annotation|@
name|VisibleForTesting
DECL|method|createListObjectsRequest (String key, String delimiter)
specifier|public
name|S3ListRequest
name|createListObjectsRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|delimiter
parameter_list|)
block|{
return|return
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
name|delimiter
argument_list|,
literal|null
argument_list|)
return|;
block|}
DECL|method|createListObjectsRequest (String key, String delimiter, Integer overrideMaxKeys)
specifier|private
name|S3ListRequest
name|createListObjectsRequest
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|delimiter
parameter_list|,
name|Integer
name|overrideMaxKeys
parameter_list|)
block|{
if|if
condition|(
operator|!
name|useListV1
condition|)
block|{
name|ListObjectsV2Request
name|request
init|=
operator|new
name|ListObjectsV2Request
argument_list|()
operator|.
name|withBucketName
argument_list|(
name|bucket
argument_list|)
operator|.
name|withMaxKeys
argument_list|(
name|maxKeys
argument_list|)
operator|.
name|withPrefix
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|delimiter
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setDelimiter
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|overrideMaxKeys
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setMaxKeys
argument_list|(
name|overrideMaxKeys
argument_list|)
expr_stmt|;
block|}
return|return
name|S3ListRequest
operator|.
name|v2
argument_list|(
name|request
argument_list|)
return|;
block|}
else|else
block|{
name|ListObjectsRequest
name|request
init|=
operator|new
name|ListObjectsRequest
argument_list|()
decl_stmt|;
name|request
operator|.
name|setBucketName
argument_list|(
name|bucket
argument_list|)
expr_stmt|;
name|request
operator|.
name|setMaxKeys
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
name|request
operator|.
name|setPrefix
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|delimiter
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setDelimiter
argument_list|(
name|delimiter
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|overrideMaxKeys
operator|!=
literal|null
condition|)
block|{
name|request
operator|.
name|setMaxKeys
argument_list|(
name|overrideMaxKeys
argument_list|)
expr_stmt|;
block|}
return|return
name|S3ListRequest
operator|.
name|v1
argument_list|(
name|request
argument_list|)
return|;
block|}
block|}
comment|/**    * Set the current working directory for the given file system. All relative    * paths will be resolved relative to it.    *    * @param newDir the current working directory.    */
DECL|method|setWorkingDirectory (Path newDir)
specifier|public
name|void
name|setWorkingDirectory
parameter_list|(
name|Path
name|newDir
parameter_list|)
block|{
name|workingDir
operator|=
name|makeQualified
argument_list|(
name|newDir
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the current working directory for the given file system.    * @return the directory pathname    */
DECL|method|getWorkingDirectory ()
specifier|public
name|Path
name|getWorkingDirectory
parameter_list|()
block|{
return|return
name|workingDir
return|;
block|}
comment|/**    * Get the username of the FS.    * @return the short name of the user who instantiated the FS    */
DECL|method|getUsername ()
specifier|public
name|String
name|getUsername
parameter_list|()
block|{
return|return
name|username
return|;
block|}
comment|/**    * Get the owner of this FS: who created it?    * @return the owner of the FS.    */
DECL|method|getOwner ()
specifier|public
name|UserGroupInformation
name|getOwner
parameter_list|()
block|{
return|return
name|owner
return|;
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories. Has the semantics of Unix {@code 'mkdir -p'}.    * Existence of the directory hierarchy is not an error.    * @param path path to create    * @param permission to apply to f    * @return true if a directory was created or already existed    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    */
comment|// TODO: If we have created an empty file at /foo/bar and we then call
comment|// mkdirs for /foo/bar/baz/roo what happens to the empty file /foo/bar/?
DECL|method|mkdirs (Path path, FsPermission permission)
specifier|public
name|boolean
name|mkdirs
parameter_list|(
name|Path
name|path
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
block|{
try|try
block|{
return|return
name|innerMkdirs
argument_list|(
name|path
argument_list|,
name|permission
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"innerMkdirs"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    *    * Make the given path and all non-existent parents into    * directories.    * See {@link #mkdirs(Path, FsPermission)}    * @param p path to create    * @param permission to apply to f    * @return true if a directory was created or already existed    * @throws FileAlreadyExistsException there is a file at the path specified    * @throws IOException other IO problems    * @throws AmazonClientException on failures inside the AWS SDK    */
DECL|method|innerMkdirs (Path p, FsPermission permission)
specifier|private
name|boolean
name|innerMkdirs
parameter_list|(
name|Path
name|p
parameter_list|,
name|FsPermission
name|permission
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|Path
name|f
init|=
name|qualify
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Making directory: {}"
argument_list|,
name|f
argument_list|)
expr_stmt|;
name|entryPoint
argument_list|(
name|INVOCATION_MKDIRS
argument_list|)
expr_stmt|;
name|FileStatus
name|fileStatus
decl_stmt|;
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|f
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
literal|"Path is a file: "
operator|+
name|f
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// Walk path to root, ensuring closest ancestor is a directory, not file
name|Path
name|fPart
init|=
name|f
operator|.
name|getParent
argument_list|()
decl_stmt|;
while|while
condition|(
name|fPart
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|fileStatus
operator|=
name|getFileStatus
argument_list|(
name|fPart
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
break|break;
block|}
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|String
operator|.
name|format
argument_list|(
literal|"Can't make directory for path '%s' since it is a file."
argument_list|,
name|fPart
argument_list|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
block|}
name|fPart
operator|=
name|fPart
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|f
argument_list|)
decl_stmt|;
comment|// this will create the marker file, delete the parent entries
comment|// and update S3Guard
name|createFakeDirectory
argument_list|(
name|key
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
comment|/**    * Return a file status object that represents the path.    * @param f The path we want information from    * @return a FileStatus object    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getFileStatus (final Path f)
specifier|public
name|FileStatus
name|getFileStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_GET_FILE_STATUS
argument_list|)
expr_stmt|;
return|return
name|innerGetFileStatus
argument_list|(
name|f
argument_list|,
literal|false
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|)
return|;
block|}
comment|/**    * Get the status of a file or directory, first through S3Guard and then    * through S3.    * The S3 probes can leave 404 responses in the S3 load balancers; if    * a check is only needed for a directory, declaring this saves time and    * avoids creating one for the object.    * When only probing for directories, if an entry for a file is found in    * S3Guard it is returned, but checks for updated values are skipped.    * Internal version of {@link #getFileStatus(Path)}.    * @param f The path we want information from    * @param needEmptyDirectoryFlag if true, implementation will calculate    *        a TRUE or FALSE value for {@link S3AFileStatus#isEmptyDirectory()}    * @param probes probes to make    * @return a S3AFileStatus object    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|VisibleForTesting
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerGetFileStatus (final Path f, final boolean needEmptyDirectoryFlag, final Set<StatusProbeEnum> probes)
name|S3AFileStatus
name|innerGetFileStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|boolean
name|needEmptyDirectoryFlag
parameter_list|,
specifier|final
name|Set
argument_list|<
name|StatusProbeEnum
argument_list|>
name|probes
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting path status for {}  ({})"
argument_list|,
name|path
argument_list|,
name|key
argument_list|)
expr_stmt|;
comment|// Check MetadataStore, if any.
name|PathMetadata
name|pm
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|pm
operator|=
name|S3Guard
operator|.
name|getWithTtl
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|ttlTimeProvider
argument_list|,
name|needEmptyDirectoryFlag
argument_list|)
expr_stmt|;
block|}
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
init|=
name|Collections
operator|.
name|emptySet
argument_list|()
decl_stmt|;
if|if
condition|(
name|pm
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|pm
operator|.
name|isDeleted
argument_list|()
condition|)
block|{
name|OffsetDateTime
name|deletedAt
init|=
name|OffsetDateTime
operator|.
name|ofInstant
argument_list|(
name|Instant
operator|.
name|ofEpochMilli
argument_list|(
name|pm
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getModificationTime
argument_list|()
argument_list|)
argument_list|,
name|ZoneOffset
operator|.
name|UTC
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Path "
operator|+
name|path
operator|+
literal|" is recorded as "
operator|+
literal|"deleted by S3Guard at "
operator|+
name|deletedAt
argument_list|)
throw|;
block|}
comment|// if ms is not authoritative, check S3 if there's any recent
comment|// modification - compare the modTime to check if metadata is up to date
comment|// Skip going to s3 if the file checked is a directory. Because if the
comment|// dest is also a directory, there's no difference.
comment|// TODO After HADOOP-16085 the modification detection can be done with
comment|//  etags or object version instead of modTime
name|boolean
name|allowAuthoritative
init|=
name|allowAuthoritative
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|pm
operator|.
name|getFileStatus
argument_list|()
operator|.
name|isDirectory
argument_list|()
operator|&&
operator|!
name|allowAuthoritative
operator|&&
name|probes
operator|.
name|contains
argument_list|(
name|StatusProbeEnum
operator|.
name|Head
argument_list|)
condition|)
block|{
comment|// a file has been found in a non-auth path and the caller has not said
comment|// they only care about directories
name|LOG
operator|.
name|debug
argument_list|(
literal|"Metadata for {} found in the non-auth metastore."
argument_list|,
name|path
argument_list|)
expr_stmt|;
specifier|final
name|long
name|msModTime
init|=
name|pm
operator|.
name|getFileStatus
argument_list|()
operator|.
name|getModificationTime
argument_list|()
decl_stmt|;
name|S3AFileStatus
name|s3AFileStatus
decl_stmt|;
try|try
block|{
name|s3AFileStatus
operator|=
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|probes
argument_list|,
name|tombstones
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fne
parameter_list|)
block|{
name|s3AFileStatus
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|s3AFileStatus
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to find file {}. Either it is not yet visible, or "
operator|+
literal|"it has been deleted."
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
specifier|final
name|long
name|s3ModTime
init|=
name|s3AFileStatus
operator|.
name|getModificationTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|s3ModTime
operator|>
name|msModTime
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"S3Guard metadata for {} is outdated;"
operator|+
literal|" s3modtime={}; msModTime={} updating metastore"
argument_list|,
name|path
argument_list|,
name|s3ModTime
argument_list|,
name|msModTime
argument_list|)
expr_stmt|;
return|return
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|s3AFileStatus
argument_list|,
name|instrumentation
argument_list|,
name|ttlTimeProvider
argument_list|)
return|;
block|}
block|}
block|}
name|S3AFileStatus
name|msStatus
init|=
name|pm
operator|.
name|getFileStatus
argument_list|()
decl_stmt|;
if|if
condition|(
name|needEmptyDirectoryFlag
operator|&&
name|msStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
if|if
condition|(
name|pm
operator|.
name|isEmptyDirectory
argument_list|()
operator|!=
name|Tristate
operator|.
name|UNKNOWN
condition|)
block|{
comment|// We have a definitive true / false from MetadataStore, we are done.
return|return
name|msStatus
return|;
block|}
else|else
block|{
name|DirListingMetadata
name|children
init|=
name|S3Guard
operator|.
name|listChildrenWithTtl
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|ttlTimeProvider
argument_list|)
decl_stmt|;
if|if
condition|(
name|children
operator|!=
literal|null
condition|)
block|{
name|tombstones
operator|=
name|children
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"MetadataStore doesn't know if dir is empty, using S3."
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Either this is not a directory, or we don't care if it is empty
return|return
name|msStatus
return|;
block|}
comment|// If the metadata store has no children for it and it's not listed in
comment|// S3 yet, we'll assume the empty directory is true;
name|S3AFileStatus
name|s3FileStatus
decl_stmt|;
try|try
block|{
name|s3FileStatus
operator|=
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|probes
argument_list|,
name|tombstones
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
return|return
name|S3AFileStatus
operator|.
name|fromFileStatus
argument_list|(
name|msStatus
argument_list|,
name|Tristate
operator|.
name|TRUE
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|// entry was found, save in S3Guard
return|return
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|s3FileStatus
argument_list|,
name|instrumentation
argument_list|,
name|ttlTimeProvider
argument_list|)
return|;
block|}
else|else
block|{
comment|// there was no entry in S3Guard
comment|// retrieve the data and update the metadata store in the process.
return|return
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|StatusProbeEnum
operator|.
name|ALL
argument_list|,
name|tombstones
argument_list|)
argument_list|,
name|instrumentation
argument_list|,
name|ttlTimeProvider
argument_list|)
return|;
block|}
block|}
comment|/**    * Raw {@code getFileStatus} that talks direct to S3.    * Used to implement {@link #innerGetFileStatus(Path, boolean)},    * and for direct management of empty directory blobs.    * Retry policy: retry translated.    * @param path Qualified path    * @param key  Key string for the path    * @param probes probes to make    * @param tombstones tombstones to filter    * @return Status    * @throws FileNotFoundException when the path does not exist    * @throws IOException on other problems.    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|s3GetFileStatus (final Path path, String key, final Set<StatusProbeEnum> probes, final Set<Path> tombstones)
specifier|private
name|S3AFileStatus
name|s3GetFileStatus
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
name|String
name|key
parameter_list|,
specifier|final
name|Set
argument_list|<
name|StatusProbeEnum
argument_list|>
name|probes
parameter_list|,
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|key
operator|.
name|isEmpty
argument_list|()
operator|&&
name|probes
operator|.
name|contains
argument_list|(
name|StatusProbeEnum
operator|.
name|Head
argument_list|)
condition|)
block|{
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found exact file: normal file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|,
name|meta
operator|.
name|getETag
argument_list|()
argument_list|,
name|meta
operator|.
name|getVersionId
argument_list|()
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
name|SC_404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// Look for the dir marker
if|if
condition|(
operator|!
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
operator|&&
name|probes
operator|.
name|contains
argument_list|(
name|StatusProbeEnum
operator|.
name|DirMarker
argument_list|)
condition|)
block|{
name|String
name|newKey
init|=
name|key
operator|+
literal|"/"
decl_stmt|;
try|try
block|{
name|ObjectMetadata
name|meta
init|=
name|getObjectMetadata
argument_list|(
name|newKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|objectRepresentsDirectory
argument_list|(
name|newKey
argument_list|,
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file (with /): fake directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file (with /): real file? should not happen: {}"
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|meta
operator|.
name|getContentLength
argument_list|()
argument_list|,
name|dateToLong
argument_list|(
name|meta
operator|.
name|getLastModified
argument_list|()
argument_list|)
argument_list|,
name|path
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|path
argument_list|)
argument_list|,
name|username
argument_list|,
name|meta
operator|.
name|getETag
argument_list|()
argument_list|,
name|meta
operator|.
name|getVersionId
argument_list|()
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
name|SC_404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|newKey
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|// execute the list
if|if
condition|(
name|probes
operator|.
name|contains
argument_list|(
name|StatusProbeEnum
operator|.
name|List
argument_list|)
condition|)
block|{
try|try
block|{
name|key
operator|=
name|maybeAddTrailingSlash
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|S3ListRequest
name|request
init|=
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|S3ListResult
name|objects
init|=
name|listObjects
argument_list|(
name|request
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|String
argument_list|>
name|prefixes
init|=
name|objects
operator|.
name|getCommonPrefixes
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|S3ObjectSummary
argument_list|>
name|summaries
init|=
name|objects
operator|.
name|getObjectSummaries
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|isEmptyOfKeys
argument_list|(
name|prefixes
argument_list|,
name|tombstones
argument_list|)
operator|||
operator|!
name|isEmptyOfObjects
argument_list|(
name|summaries
argument_list|,
name|tombstones
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found path as directory (with /): {}/{}"
argument_list|,
name|prefixes
operator|.
name|size
argument_list|()
argument_list|,
name|summaries
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|summaries
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Summary: {} {}"
argument_list|,
name|summary
operator|.
name|getKey
argument_list|()
argument_list|,
name|summary
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|prefix
range|:
name|prefixes
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Prefix: {}"
argument_list|,
name|prefix
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|FALSE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found root directory"
argument_list|)
expr_stmt|;
return|return
operator|new
name|S3AFileStatus
argument_list|(
name|Tristate
operator|.
name|TRUE
argument_list|,
name|path
argument_list|,
name|username
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonServiceException
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|.
name|getStatusCode
argument_list|()
operator|!=
name|SC_404
condition|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
throw|throw
name|translateException
argument_list|(
literal|"getFileStatus"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Not Found: {}"
argument_list|,
name|path
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No such file or directory: "
operator|+
name|path
argument_list|)
throw|;
block|}
comment|/**    * Helper function to determine if a collection of paths is empty    * after accounting for tombstone markers (if provided).    * @param keys Collection of path (prefixes / directories or keys).    * @param tombstones Set of tombstone markers, or null if not applicable.    * @return false if summaries contains objects not accounted for by    * tombstones.    */
DECL|method|isEmptyOfKeys (Collection<String> keys, Set<Path> tombstones)
specifier|private
name|boolean
name|isEmptyOfKeys
parameter_list|(
name|Collection
argument_list|<
name|String
argument_list|>
name|keys
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
block|{
if|if
condition|(
name|tombstones
operator|==
literal|null
condition|)
block|{
return|return
name|keys
operator|.
name|isEmpty
argument_list|()
return|;
block|}
for|for
control|(
name|String
name|key
range|:
name|keys
control|)
block|{
name|Path
name|qualified
init|=
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|tombstones
operator|.
name|contains
argument_list|(
name|qualified
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Helper function to determine if a collection of object summaries is empty    * after accounting for tombstone markers (if provided).    * @param summaries Collection of objects as returned by listObjects.    * @param tombstones Set of tombstone markers, or null if not applicable.    * @return false if summaries contains objects not accounted for by    * tombstones.    */
DECL|method|isEmptyOfObjects (Collection<S3ObjectSummary> summaries, Set<Path> tombstones)
specifier|private
name|boolean
name|isEmptyOfObjects
parameter_list|(
name|Collection
argument_list|<
name|S3ObjectSummary
argument_list|>
name|summaries
parameter_list|,
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
parameter_list|)
block|{
if|if
condition|(
name|tombstones
operator|==
literal|null
condition|)
block|{
return|return
name|summaries
operator|.
name|isEmpty
argument_list|()
return|;
block|}
name|Collection
argument_list|<
name|String
argument_list|>
name|stringCollection
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|summaries
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|S3ObjectSummary
name|summary
range|:
name|summaries
control|)
block|{
name|stringCollection
operator|.
name|add
argument_list|(
name|summary
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|isEmptyOfKeys
argument_list|(
name|stringCollection
argument_list|,
name|tombstones
argument_list|)
return|;
block|}
comment|/**    * Raw version of {@link FileSystem#exists(Path)} which uses S3 only:    * S3Guard MetadataStore, if any, will be skipped.    * Retry policy: retrying; translated.    * @param path qualified path to look for    * @param probes probes to make    * @return true if path exists in S3    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|s3Exists (final Path path, final Set<StatusProbeEnum> probes)
specifier|private
name|boolean
name|s3Exists
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Set
argument_list|<
name|StatusProbeEnum
argument_list|>
name|probes
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
try|try
block|{
name|s3GetFileStatus
argument_list|(
name|path
argument_list|,
name|key
argument_list|,
name|probes
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src path    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false    * @throws AmazonClientException failure in the AWS SDK    */
annotation|@
name|Override
DECL|method|copyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|public
name|void
name|copyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_COPY_FROM_LOCAL_FILE
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copying local file from {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|//    innerCopyFromLocalFile(delSrc, overwrite, src, dst);
name|super
operator|.
name|copyFromLocalFile
argument_list|(
name|delSrc
argument_list|,
name|overwrite
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
block|}
comment|/**    * The src file is on the local disk.  Add it to FS at    * the given dst name.    *    * This version doesn't need to create a temporary file to calculate the md5.    * Sadly this doesn't seem to be used by the shell cp :(    *    *<i>HADOOP-15932:</i> this method has been unwired from    * {@link #copyFromLocalFile(boolean, boolean, Path, Path)} until    * it is extended to list and copy whole directories.    * delSrc indicates if the source should be removed    * @param delSrc whether to delete the src    * @param overwrite whether to overwrite an existing file    * @param src Source path: must be on local filesystem    * @param dst path    * @throws IOException IO problem    * @throws FileAlreadyExistsException the destination file exists and    * overwrite==false, or if the destination is a directory.    * @throws FileNotFoundException if the source file does not exit    * @throws AmazonClientException failure in the AWS SDK    * @throws IllegalArgumentException if the source path is not on the local FS    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerCopyFromLocalFile (boolean delSrc, boolean overwrite, Path src, Path dst)
specifier|private
name|void
name|innerCopyFromLocalFile
parameter_list|(
name|boolean
name|delSrc
parameter_list|,
name|boolean
name|overwrite
parameter_list|,
name|Path
name|src
parameter_list|,
name|Path
name|dst
parameter_list|)
throws|throws
name|IOException
throws|,
name|FileAlreadyExistsException
throws|,
name|AmazonClientException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_COPY_FROM_LOCAL_FILE
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copying local file from {} to {}"
argument_list|,
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
comment|// Since we have a local file, we don't need to stream into a temporary file
name|LocalFileSystem
name|local
init|=
name|getLocal
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|File
name|srcfile
init|=
name|local
operator|.
name|pathToFile
argument_list|(
name|src
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|srcfile
operator|.
name|exists
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No file: "
operator|+
name|src
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|srcfile
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"Not a file: "
operator|+
name|src
argument_list|)
throw|;
block|}
try|try
block|{
name|FileStatus
name|status
init|=
name|getFileStatus
argument_list|(
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|status
operator|.
name|isFile
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|dst
operator|+
literal|" exists and is not a file"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|overwrite
condition|)
block|{
throw|throw
operator|new
name|FileAlreadyExistsException
argument_list|(
name|dst
operator|+
literal|" already exists"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// no destination, all is well
block|}
specifier|final
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|dst
argument_list|)
decl_stmt|;
specifier|final
name|ObjectMetadata
name|om
init|=
name|newObjectMetadata
argument_list|(
name|srcfile
operator|.
name|length
argument_list|()
argument_list|)
decl_stmt|;
name|Progressable
name|progress
init|=
literal|null
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|key
argument_list|,
name|om
argument_list|,
name|srcfile
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"copyFromLocalFile("
operator|+
name|src
operator|+
literal|")"
argument_list|,
name|dst
operator|.
name|toString
argument_list|()
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|executePut
argument_list|(
name|putObjectRequest
argument_list|,
name|progress
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|delSrc
condition|)
block|{
name|local
operator|.
name|delete
argument_list|(
name|src
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Execute a PUT via the transfer manager, blocking for completion,    * updating the metastore afterwards.    * If the waiting for completion is interrupted, the upload will be    * aborted before an {@code InterruptedIOException} is thrown.    * @param putObjectRequest request    * @param progress optional progress callback    * @return the upload result    * @throws InterruptedIOException if the blocking was interrupted.    * @throws MetadataPersistenceException if metadata about the write could    * not be saved to the metadata store and    * fs.s3a.metadatastore.fail.on.write.error=true    */
annotation|@
name|Retries
operator|.
name|OnceRaw
argument_list|(
literal|"For PUT; post-PUT actions are RetryTranslated"
argument_list|)
DECL|method|executePut (PutObjectRequest putObjectRequest, Progressable progress)
name|UploadResult
name|executePut
parameter_list|(
name|PutObjectRequest
name|putObjectRequest
parameter_list|,
name|Progressable
name|progress
parameter_list|)
throws|throws
name|InterruptedIOException
throws|,
name|MetadataPersistenceException
block|{
name|String
name|key
init|=
name|putObjectRequest
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|UploadInfo
name|info
init|=
name|putObject
argument_list|(
name|putObjectRequest
argument_list|)
decl_stmt|;
name|Upload
name|upload
init|=
name|info
operator|.
name|getUpload
argument_list|()
decl_stmt|;
name|ProgressableProgressListener
name|listener
init|=
operator|new
name|ProgressableProgressListener
argument_list|(
name|this
argument_list|,
name|key
argument_list|,
name|upload
argument_list|,
name|progress
argument_list|)
decl_stmt|;
name|upload
operator|.
name|addProgressListener
argument_list|(
name|listener
argument_list|)
expr_stmt|;
name|UploadResult
name|result
init|=
name|waitForUploadCompletion
argument_list|(
name|key
argument_list|,
name|info
argument_list|)
decl_stmt|;
name|listener
operator|.
name|uploadCompleted
argument_list|()
expr_stmt|;
comment|// post-write actions
name|finishedWrite
argument_list|(
name|key
argument_list|,
name|info
operator|.
name|getLength
argument_list|()
argument_list|,
name|result
operator|.
name|getETag
argument_list|()
argument_list|,
name|result
operator|.
name|getVersionId
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
comment|/**    * Wait for an upload to complete.    * If the waiting for completion is interrupted, the upload will be    * aborted before an {@code InterruptedIOException} is thrown.    * If the upload (or its result collection) failed, this is where    * the failure is raised as an AWS exception    * @param key destination key    * @param uploadInfo upload to wait for    * @return the upload result    * @throws InterruptedIOException if the blocking was interrupted.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|waitForUploadCompletion (String key, UploadInfo uploadInfo)
name|UploadResult
name|waitForUploadCompletion
parameter_list|(
name|String
name|key
parameter_list|,
name|UploadInfo
name|uploadInfo
parameter_list|)
throws|throws
name|InterruptedIOException
block|{
name|Upload
name|upload
init|=
name|uploadInfo
operator|.
name|getUpload
argument_list|()
decl_stmt|;
try|try
block|{
name|UploadResult
name|result
init|=
name|upload
operator|.
name|waitForUploadResult
argument_list|()
decl_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|true
argument_list|,
name|uploadInfo
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Interrupted: aborting upload"
argument_list|)
expr_stmt|;
name|incrementPutCompletedStatistics
argument_list|(
literal|false
argument_list|,
name|uploadInfo
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|upload
operator|.
name|abort
argument_list|()
expr_stmt|;
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted in PUT to "
operator|+
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
argument_list|)
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Close the filesystem. This shuts down all transfers.    * @throws IOException IO problem    */
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|getAndSet
argument_list|(
literal|true
argument_list|)
condition|)
block|{
comment|// already closed
return|return;
block|}
name|isClosed
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Filesystem {} is closed"
argument_list|,
name|uri
argument_list|)
expr_stmt|;
try|try
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|transfers
operator|!=
literal|null
condition|)
block|{
name|transfers
operator|.
name|shutdownNow
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|transfers
operator|=
literal|null
expr_stmt|;
block|}
name|S3AUtils
operator|.
name|closeAll
argument_list|(
name|LOG
argument_list|,
name|metadataStore
argument_list|,
name|instrumentation
argument_list|)
expr_stmt|;
name|metadataStore
operator|=
literal|null
expr_stmt|;
name|instrumentation
operator|=
literal|null
expr_stmt|;
name|closeAutocloseables
argument_list|(
name|LOG
argument_list|,
name|credentials
argument_list|)
expr_stmt|;
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|delegationTokens
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|signerManager
argument_list|)
expr_stmt|;
name|signerManager
operator|=
literal|null
expr_stmt|;
name|credentials
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Verify that the input stream is open. Non blocking; this gives    * the last state of the volatile {@link #closed} field.    * @throws IOException if the connection is closed.    */
DECL|method|checkNotClosed ()
specifier|private
name|void
name|checkNotClosed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|uri
operator|+
literal|": "
operator|+
name|E_FS_CLOSED
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get the delegation token support for this filesystem;    * not null iff delegation support is enabled.    * @return the token support, or an empty option.    */
annotation|@
name|VisibleForTesting
DECL|method|getDelegationTokens ()
specifier|public
name|Optional
argument_list|<
name|S3ADelegationTokens
argument_list|>
name|getDelegationTokens
parameter_list|()
block|{
return|return
name|delegationTokens
return|;
block|}
comment|/**    * Return a service name iff delegation tokens are enabled and the    * token binding is issuing delegation tokens.    * @return the canonical service name or null    */
annotation|@
name|Override
DECL|method|getCanonicalServiceName ()
specifier|public
name|String
name|getCanonicalServiceName
parameter_list|()
block|{
comment|// this could all be done in map statements, but it'd be harder to
comment|// understand and maintain.
comment|// Essentially: no DTs, no canonical service name.
if|if
condition|(
operator|!
name|delegationTokens
operator|.
name|isPresent
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// DTs present: ask the binding if it is willing to
comment|// serve tokens (or fail noisily).
name|S3ADelegationTokens
name|dt
init|=
name|delegationTokens
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
name|dt
operator|.
name|getTokenIssuingPolicy
argument_list|()
operator|!=
name|NoTokensAvailable
condition|?
name|dt
operator|.
name|getCanonicalServiceName
argument_list|()
else|:
literal|null
return|;
block|}
comment|/**    * Get a delegation token if the FS is set up for them.    * If the user already has a token, it is returned,    *<i>even if it has expired</i>.    * @param renewer the account name that is allowed to renew the token.    * @return the delegation token or null    * @throws IOException IO failure    */
annotation|@
name|Override
DECL|method|getDelegationToken (String renewer)
specifier|public
name|Token
argument_list|<
name|AbstractS3ATokenIdentifier
argument_list|>
name|getDelegationToken
parameter_list|(
name|String
name|renewer
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|Statistic
operator|.
name|INVOCATION_GET_DELEGATION_TOKEN
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Delegation token requested"
argument_list|)
expr_stmt|;
if|if
condition|(
name|delegationTokens
operator|.
name|isPresent
argument_list|()
condition|)
block|{
return|return
name|delegationTokens
operator|.
name|get
argument_list|()
operator|.
name|getBoundOrNewDT
argument_list|(
name|encryptionSecrets
argument_list|)
return|;
block|}
else|else
block|{
comment|// Delegation token support is not set up
name|LOG
operator|.
name|debug
argument_list|(
literal|"Token support is not enabled"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Build the AWS policy for restricted access to the resources needed    * by this bucket.    * The policy generated includes S3 access, S3Guard access    * if needed, and KMS operations.    * @param access access level desired.    * @return a policy for use in roles    */
annotation|@
name|Override
DECL|method|listAWSPolicyRules ( final Set<AccessLevel> access)
specifier|public
name|List
argument_list|<
name|RoleModel
operator|.
name|Statement
argument_list|>
name|listAWSPolicyRules
parameter_list|(
specifier|final
name|Set
argument_list|<
name|AccessLevel
argument_list|>
name|access
parameter_list|)
block|{
if|if
condition|(
name|access
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
name|List
argument_list|<
name|RoleModel
operator|.
name|Statement
argument_list|>
name|statements
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|allowS3Operations
argument_list|(
name|bucket
argument_list|,
name|access
operator|.
name|contains
argument_list|(
name|AccessLevel
operator|.
name|WRITE
argument_list|)
operator|||
name|access
operator|.
name|contains
argument_list|(
name|AccessLevel
operator|.
name|ADMIN
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|// no attempt is made to qualify KMS access; there's no
comment|// way to predict read keys, and not worried about granting
comment|// too much encryption access.
name|statements
operator|.
name|add
argument_list|(
name|STATEMENT_ALLOW_SSE_KMS_RW
argument_list|)
expr_stmt|;
comment|// add any metastore policies
if|if
condition|(
name|metadataStore
operator|instanceof
name|AWSPolicyProvider
condition|)
block|{
name|statements
operator|.
name|addAll
argument_list|(
operator|(
operator|(
name|AWSPolicyProvider
operator|)
name|metadataStore
operator|)
operator|.
name|listAWSPolicyRules
argument_list|(
name|access
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|statements
return|;
block|}
comment|/**    * Copy a single object in the bucket via a COPY operation.    * There's no update of metadata, directory markers, etc.    * Callers must implement.    * @param srcKey source object path    * @param dstKey destination object path    * @param size object size    * @param srcAttributes S3 attributes of the source object    * @param readContext the read context    * @return the result of the copy    * @throws InterruptedIOException the operation was interrupted    * @throws IOException Other IO problems    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|copyFile (String srcKey, String dstKey, long size, S3ObjectAttributes srcAttributes, S3AReadOpContext readContext)
specifier|private
name|CopyResult
name|copyFile
parameter_list|(
name|String
name|srcKey
parameter_list|,
name|String
name|dstKey
parameter_list|,
name|long
name|size
parameter_list|,
name|S3ObjectAttributes
name|srcAttributes
parameter_list|,
name|S3AReadOpContext
name|readContext
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedIOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"copyFile {} -> {} "
argument_list|,
name|srcKey
argument_list|,
name|dstKey
argument_list|)
expr_stmt|;
name|ProgressListener
name|progressListener
init|=
name|progressEvent
lambda|->
block|{
switch|switch
condition|(
name|progressEvent
operator|.
name|getEventType
argument_list|()
condition|)
block|{
case|case
name|TRANSFER_PART_COMPLETED_EVENT
case|:
name|incrementWriteOperations
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
decl_stmt|;
name|ChangeTracker
name|changeTracker
init|=
operator|new
name|ChangeTracker
argument_list|(
name|keyToQualifiedPath
argument_list|(
name|srcKey
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|readContext
operator|.
name|instrumentation
operator|.
name|newInputStreamStatistics
argument_list|()
operator|.
name|getVersionMismatchCounter
argument_list|()
argument_list|,
name|srcAttributes
argument_list|)
decl_stmt|;
name|String
name|action
init|=
literal|"copyFile("
operator|+
name|srcKey
operator|+
literal|", "
operator|+
name|dstKey
operator|+
literal|")"
decl_stmt|;
name|Invoker
name|readInvoker
init|=
name|readContext
operator|.
name|getReadInvoker
argument_list|()
decl_stmt|;
name|ObjectMetadata
name|srcom
decl_stmt|;
try|try
block|{
name|srcom
operator|=
name|once
argument_list|(
name|action
argument_list|,
name|srcKey
argument_list|,
parameter_list|()
lambda|->
name|getObjectMetadata
argument_list|(
name|srcKey
argument_list|,
name|changeTracker
argument_list|,
name|readInvoker
argument_list|,
literal|"copy"
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
comment|// if rename fails at this point it means that the expected file was not
comment|// found.
comment|// The cause is believed to always be one of
comment|//  - File was deleted since LIST/S3Guard metastore.list.() knew of it.
comment|//  - S3Guard is asking for a specific version and it's been removed by
comment|//    lifecycle rules.
comment|//  - there's a 404 cached in the S3 load balancers.
name|LOG
operator|.
name|debug
argument_list|(
literal|"getObjectMetadata({}) failed to find an expected file"
argument_list|,
name|srcKey
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|// We create an exception, but the text depends on the S3Guard state
name|String
name|message
init|=
name|hasMetadataStore
argument_list|()
condition|?
name|RemoteFileChangedException
operator|.
name|FILE_NEVER_FOUND
else|:
name|RemoteFileChangedException
operator|.
name|FILE_NOT_FOUND_SINGLE_ATTEMPT
decl_stmt|;
throw|throw
operator|new
name|RemoteFileChangedException
argument_list|(
name|keyToQualifiedPath
argument_list|(
name|srcKey
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|,
name|action
argument_list|,
name|message
argument_list|,
name|e
argument_list|)
throw|;
block|}
name|ObjectMetadata
name|dstom
init|=
name|cloneObjectMetadata
argument_list|(
name|srcom
argument_list|)
decl_stmt|;
name|setOptionalObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
return|return
name|readInvoker
operator|.
name|retry
argument_list|(
name|action
argument_list|,
name|srcKey
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
block|{
name|CopyObjectRequest
name|copyObjectRequest
init|=
operator|new
name|CopyObjectRequest
argument_list|(
name|bucket
argument_list|,
name|srcKey
argument_list|,
name|bucket
argument_list|,
name|dstKey
argument_list|)
decl_stmt|;
name|changeTracker
operator|.
name|maybeApplyConstraint
argument_list|(
name|copyObjectRequest
argument_list|)
expr_stmt|;
name|setOptionalCopyObjectRequestParameters
argument_list|(
name|copyObjectRequest
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setCannedAccessControlList
argument_list|(
name|cannedACL
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setNewObjectMetadata
argument_list|(
name|dstom
argument_list|)
expr_stmt|;
name|Optional
operator|.
name|ofNullable
argument_list|(
name|srcom
operator|.
name|getStorageClass
argument_list|()
argument_list|)
operator|.
name|ifPresent
argument_list|(
name|copyObjectRequest
operator|::
name|setStorageClass
argument_list|)
expr_stmt|;
name|Copy
name|copy
init|=
name|transfers
operator|.
name|copy
argument_list|(
name|copyObjectRequest
argument_list|)
decl_stmt|;
name|copy
operator|.
name|addProgressListener
argument_list|(
name|progressListener
argument_list|)
expr_stmt|;
name|CopyOutcome
name|copyOutcome
init|=
name|CopyOutcome
operator|.
name|waitForCopy
argument_list|(
name|copy
argument_list|)
decl_stmt|;
name|InterruptedException
name|interruptedException
init|=
name|copyOutcome
operator|.
name|getInterruptedException
argument_list|()
decl_stmt|;
if|if
condition|(
name|interruptedException
operator|!=
literal|null
condition|)
block|{
comment|// copy interrupted: convert to an IOException.
throw|throw
operator|(
name|IOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"Interrupted copying "
operator|+
name|srcKey
operator|+
literal|" to "
operator|+
name|dstKey
operator|+
literal|", cancelling"
argument_list|)
operator|.
name|initCause
argument_list|(
name|interruptedException
argument_list|)
throw|;
block|}
name|SdkBaseException
name|awsException
init|=
name|copyOutcome
operator|.
name|getAwsException
argument_list|()
decl_stmt|;
if|if
condition|(
name|awsException
operator|!=
literal|null
condition|)
block|{
name|changeTracker
operator|.
name|processException
argument_list|(
name|awsException
argument_list|,
literal|"copy"
argument_list|)
expr_stmt|;
throw|throw
name|awsException
throw|;
block|}
name|CopyResult
name|result
init|=
name|copyOutcome
operator|.
name|getCopyResult
argument_list|()
decl_stmt|;
name|changeTracker
operator|.
name|processResponse
argument_list|(
name|result
argument_list|)
expr_stmt|;
name|incrementWriteOperations
argument_list|()
expr_stmt|;
name|instrumentation
operator|.
name|filesCopied
argument_list|(
literal|1
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
argument_list|)
return|;
block|}
comment|/**    * Set the optional parameters when initiating the request (encryption,    * headers, storage, etc).    * @param request request to patch.    */
DECL|method|setOptionalMultipartUploadRequestParameters ( InitiateMultipartUploadRequest request)
specifier|protected
name|void
name|setOptionalMultipartUploadRequestParameters
parameter_list|(
name|InitiateMultipartUploadRequest
name|request
parameter_list|)
block|{
name|generateSSEAwsKeyParams
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSEAwsKeyManagementParams
argument_list|)
expr_stmt|;
name|generateSSECustomerKey
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSECustomerKey
argument_list|)
expr_stmt|;
block|}
comment|/**    * Sets server side encryption parameters to the part upload    * request when encryption is enabled.    * @param request upload part request    */
DECL|method|setOptionalUploadPartRequestParameters ( UploadPartRequest request)
specifier|protected
name|void
name|setOptionalUploadPartRequestParameters
parameter_list|(
name|UploadPartRequest
name|request
parameter_list|)
block|{
name|generateSSECustomerKey
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSECustomerKey
argument_list|)
expr_stmt|;
block|}
comment|/**    * Initiate a multipart upload from the preconfigured request.    * Retry policy: none + untranslated.    * @param request request to initiate    * @return the result of the call    * @throws AmazonClientException on failures inside the AWS SDK    * @throws IOException Other IO problems    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|initiateMultipartUpload ( InitiateMultipartUploadRequest request)
name|InitiateMultipartUploadResult
name|initiateMultipartUpload
parameter_list|(
name|InitiateMultipartUploadRequest
name|request
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Initiate multipart upload to {}"
argument_list|,
name|request
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
name|incrementStatistic
argument_list|(
name|OBJECT_MULTIPART_UPLOAD_INITIATED
argument_list|)
expr_stmt|;
return|return
name|getAmazonS3Client
argument_list|()
operator|.
name|initiateMultipartUpload
argument_list|(
name|request
argument_list|)
return|;
block|}
DECL|method|setOptionalCopyObjectRequestParameters ( CopyObjectRequest copyObjectRequest)
specifier|protected
name|void
name|setOptionalCopyObjectRequestParameters
parameter_list|(
name|CopyObjectRequest
name|copyObjectRequest
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|getServerSideEncryptionAlgorithm
argument_list|()
condition|)
block|{
case|case
name|SSE_KMS
case|:
name|generateSSEAwsKeyParams
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|copyObjectRequest
operator|::
name|setSSEAwsKeyManagementParams
argument_list|)
expr_stmt|;
break|break;
case|case
name|SSE_C
case|:
name|generateSSECustomerKey
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|customerKey
lambda|->
block|{
name|copyObjectRequest
operator|.
name|setSourceSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
name|copyObjectRequest
operator|.
name|setDestinationSSECustomerKey
argument_list|(
name|customerKey
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
break|break;
default|default:
block|}
block|}
DECL|method|setOptionalPutRequestParameters (PutObjectRequest request)
specifier|private
name|void
name|setOptionalPutRequestParameters
parameter_list|(
name|PutObjectRequest
name|request
parameter_list|)
block|{
name|generateSSEAwsKeyParams
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSEAwsKeyManagementParams
argument_list|)
expr_stmt|;
name|generateSSECustomerKey
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|request
operator|::
name|setSSECustomerKey
argument_list|)
expr_stmt|;
block|}
DECL|method|setOptionalObjectMetadata (ObjectMetadata metadata)
specifier|private
name|void
name|setOptionalObjectMetadata
parameter_list|(
name|ObjectMetadata
name|metadata
parameter_list|)
block|{
specifier|final
name|S3AEncryptionMethods
name|algorithm
init|=
name|getServerSideEncryptionAlgorithm
argument_list|()
decl_stmt|;
if|if
condition|(
name|S3AEncryptionMethods
operator|.
name|SSE_S3
operator|.
name|equals
argument_list|(
name|algorithm
argument_list|)
condition|)
block|{
name|metadata
operator|.
name|setSSEAlgorithm
argument_list|(
name|algorithm
operator|.
name|getMethod
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create the AWS SDK structure used to configure SSE,    * if the encryption secrets contain the information/settings for this.    * @return an optional set of KMS Key settings    */
DECL|method|generateSSEAwsKeyParams ()
specifier|private
name|Optional
argument_list|<
name|SSEAwsKeyManagementParams
argument_list|>
name|generateSSEAwsKeyParams
parameter_list|()
block|{
return|return
name|EncryptionSecretOperations
operator|.
name|createSSEAwsKeyManagementParams
argument_list|(
name|encryptionSecrets
argument_list|)
return|;
block|}
comment|/**    * Create the SSE-C structure for the AWS SDK, if the encryption secrets    * contain the information/settings for this.    * This will contain a secret extracted from the bucket/configuration.    * @return an optional customer key.    */
DECL|method|generateSSECustomerKey ()
specifier|private
name|Optional
argument_list|<
name|SSECustomerKey
argument_list|>
name|generateSSECustomerKey
parameter_list|()
block|{
return|return
name|EncryptionSecretOperations
operator|.
name|createSSECustomerKey
argument_list|(
name|encryptionSecrets
argument_list|)
return|;
block|}
comment|/**    * Perform post-write actions.    * Calls {@link #deleteUnnecessaryFakeDirectories(Path)} and then    * updates any metastore.    * This operation MUST be called after any PUT/multipart PUT completes    * successfully.    *    * The operations actions include    *<ol>    *<li>Calling {@link #deleteUnnecessaryFakeDirectories(Path)}</li>    *<li>Updating any metadata store with details on the newly created    *   object.</li>    *</ol>    * @param key key written to    * @param length  total length of file written    * @param eTag eTag of the written object    * @param versionId S3 object versionId of the written object    * @param operationState state of any ongoing bulk operation.    * @throws MetadataPersistenceException if metadata about the write could    * not be saved to the metadata store and    * fs.s3a.metadatastore.fail.on.write.error=true    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|Retries
operator|.
name|RetryTranslated
argument_list|(
literal|"Except if failOnMetadataWriteError=false, in which"
operator|+
literal|" case RetryExceptionsSwallowed"
argument_list|)
DECL|method|finishedWrite (String key, long length, String eTag, String versionId, @Nullable final BulkOperationState operationState)
name|void
name|finishedWrite
parameter_list|(
name|String
name|key
parameter_list|,
name|long
name|length
parameter_list|,
name|String
name|eTag
parameter_list|,
name|String
name|versionId
parameter_list|,
annotation|@
name|Nullable
specifier|final
name|BulkOperationState
name|operationState
parameter_list|)
throws|throws
name|MetadataPersistenceException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished write to {}, len {}. etag {}, version {}"
argument_list|,
name|key
argument_list|,
name|length
argument_list|,
name|eTag
argument_list|,
name|versionId
argument_list|)
expr_stmt|;
name|Path
name|p
init|=
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|length
operator|>=
literal|0
argument_list|,
literal|"content length is negative"
argument_list|)
expr_stmt|;
name|deleteUnnecessaryFakeDirectories
argument_list|(
name|p
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
comment|// this is only set if there is a metastore to update and the
comment|// operationState parameter passed in was null.
name|BulkOperationState
name|stateToClose
init|=
literal|null
decl_stmt|;
comment|// See note about failure semantics in S3Guard documentation
try|try
block|{
if|if
condition|(
name|hasMetadataStore
argument_list|()
condition|)
block|{
name|BulkOperationState
name|activeState
init|=
name|operationState
decl_stmt|;
if|if
condition|(
name|activeState
operator|==
literal|null
condition|)
block|{
comment|// create an operation state if there was none, so that the
comment|// information gleaned from addAncestors is preserved into the
comment|// subsequent put.
name|stateToClose
operator|=
name|S3Guard
operator|.
name|initiateBulkWrite
argument_list|(
name|metadataStore
argument_list|,
name|BulkOperationState
operator|.
name|OperationType
operator|.
name|Put
argument_list|,
name|keyToPath
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|activeState
operator|=
name|stateToClose
expr_stmt|;
block|}
name|S3Guard
operator|.
name|addAncestors
argument_list|(
name|metadataStore
argument_list|,
name|p
argument_list|,
name|ttlTimeProvider
argument_list|,
name|activeState
argument_list|)
expr_stmt|;
name|S3AFileStatus
name|status
init|=
name|createUploadFileStatus
argument_list|(
name|p
argument_list|,
name|S3AUtils
operator|.
name|objectRepresentsDirectory
argument_list|(
name|key
argument_list|,
name|length
argument_list|)
argument_list|,
name|length
argument_list|,
name|getDefaultBlockSize
argument_list|(
name|p
argument_list|)
argument_list|,
name|username
argument_list|,
name|eTag
argument_list|,
name|versionId
argument_list|)
decl_stmt|;
name|S3Guard
operator|.
name|putAndReturn
argument_list|(
name|metadataStore
argument_list|,
name|status
argument_list|,
name|instrumentation
argument_list|,
name|ttlTimeProvider
argument_list|,
name|activeState
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|failOnMetadataWriteError
condition|)
block|{
throw|throw
operator|new
name|MetadataPersistenceException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"S3Guard: Error updating MetadataStore for write to {}"
argument_list|,
name|p
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
comment|// if a new operation state was created, close it.
name|IOUtils
operator|.
name|cleanupWithLogger
argument_list|(
name|LOG
argument_list|,
name|stateToClose
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete mock parent directories which are no longer needed.    * Retry policy: retrying; exceptions swallowed.    * @param path path    */
annotation|@
name|Retries
operator|.
name|RetryExceptionsSwallowed
DECL|method|deleteUnnecessaryFakeDirectories (Path path)
specifier|private
name|void
name|deleteUnnecessaryFakeDirectories
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
name|List
argument_list|<
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|>
name|keysToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
while|while
condition|(
operator|!
name|path
operator|.
name|isRoot
argument_list|()
condition|)
block|{
name|String
name|key
init|=
name|pathToKey
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|key
operator|=
operator|(
name|key
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
operator|)
condition|?
name|key
else|:
operator|(
name|key
operator|+
literal|"/"
operator|)
expr_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"To delete unnecessary fake directory {} for {}"
argument_list|,
name|key
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|keysToRemove
operator|.
name|add
argument_list|(
operator|new
name|DeleteObjectsRequest
operator|.
name|KeyVersion
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|path
operator|=
name|path
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
try|try
block|{
name|removeKeys
argument_list|(
name|keysToRemove
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AmazonClientException
decl||
name|IOException
name|e
parameter_list|)
block|{
name|instrumentation
operator|.
name|errorIgnored
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|DeleteObjectsRequest
operator|.
name|KeyVersion
name|kv
range|:
name|keysToRemove
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|kv
operator|.
name|getKey
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"While deleting keys {} "
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Create a fake directory, always ending in "/".    * Retry policy: retrying; translated.    * @param objectName name of directory object.    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createFakeDirectory (final String objectName)
specifier|private
name|void
name|createFakeDirectory
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|objectName
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|createEmptyObject
argument_list|(
name|objectName
operator|+
literal|"/"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|createEmptyObject
argument_list|(
name|objectName
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Used to create an empty file that represents an empty directory.    * Retry policy: retrying; translated.    * @param objectName object to create    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|createEmptyObject (final String objectName)
specifier|private
name|void
name|createEmptyObject
parameter_list|(
specifier|final
name|String
name|objectName
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|InputStream
name|im
init|=
operator|new
name|InputStream
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|-
literal|1
return|;
block|}
block|}
decl_stmt|;
name|PutObjectRequest
name|putObjectRequest
init|=
name|newPutObjectRequest
argument_list|(
name|objectName
argument_list|,
name|newObjectMetadata
argument_list|(
literal|0L
argument_list|)
argument_list|,
name|im
argument_list|)
decl_stmt|;
name|invoker
operator|.
name|retry
argument_list|(
literal|"PUT 0-byte object "
argument_list|,
name|objectName
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|putObjectDirect
argument_list|(
name|putObjectRequest
argument_list|)
argument_list|)
expr_stmt|;
name|incrementPutProgressStatistics
argument_list|(
name|objectName
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|instrumentation
operator|.
name|directoryCreated
argument_list|()
expr_stmt|;
block|}
comment|/**    * Creates a copy of the passed {@link ObjectMetadata}.    * Does so without using the {@link ObjectMetadata#clone()} method,    * to avoid copying unnecessary headers.    * @param source the {@link ObjectMetadata} to copy    * @return a copy of {@link ObjectMetadata} with only relevant attributes    */
DECL|method|cloneObjectMetadata (ObjectMetadata source)
specifier|private
name|ObjectMetadata
name|cloneObjectMetadata
parameter_list|(
name|ObjectMetadata
name|source
parameter_list|)
block|{
comment|// This approach may be too brittle, especially if
comment|// in future there are new attributes added to ObjectMetadata
comment|// that we do not explicitly call to set here
name|ObjectMetadata
name|ret
init|=
name|newObjectMetadata
argument_list|(
name|source
operator|.
name|getContentLength
argument_list|()
argument_list|)
decl_stmt|;
comment|// Possibly null attributes
comment|// Allowing nulls to pass breaks it during later use
if|if
condition|(
name|source
operator|.
name|getCacheControl
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setCacheControl
argument_list|(
name|source
operator|.
name|getCacheControl
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentDisposition
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentDisposition
argument_list|(
name|source
operator|.
name|getContentDisposition
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentEncoding
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentEncoding
argument_list|(
name|source
operator|.
name|getContentEncoding
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentMD5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentMD5
argument_list|(
name|source
operator|.
name|getContentMD5
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getContentType
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setContentType
argument_list|(
name|source
operator|.
name|getContentType
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTime
argument_list|(
name|source
operator|.
name|getExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setExpirationTimeRuleId
argument_list|(
name|source
operator|.
name|getExpirationTimeRuleId
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setHttpExpiresDate
argument_list|(
name|source
operator|.
name|getHttpExpiresDate
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getLastModified
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setLastModified
argument_list|(
name|source
operator|.
name|getLastModified
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setOngoingRestore
argument_list|(
name|source
operator|.
name|getOngoingRestore
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setRestoreExpirationTime
argument_list|(
name|source
operator|.
name|getRestoreExpirationTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSEAlgorithm
argument_list|(
name|source
operator|.
name|getSSEAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerAlgorithm
argument_list|(
name|source
operator|.
name|getSSECustomerAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|ret
operator|.
name|setSSECustomerKeyMd5
argument_list|(
name|source
operator|.
name|getSSECustomerKeyMd5
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|e
range|:
name|source
operator|.
name|getUserMetadata
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|ret
operator|.
name|addUserMetadata
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * Return the number of bytes that large input files should be optimally    * be split into to minimize I/O time.    * @deprecated use {@link #getDefaultBlockSize(Path)} instead    */
annotation|@
name|Deprecated
DECL|method|getDefaultBlockSize ()
specifier|public
name|long
name|getDefaultBlockSize
parameter_list|()
block|{
return|return
name|getConf
argument_list|()
operator|.
name|getLongBytes
argument_list|(
name|FS_S3A_BLOCK_SIZE
argument_list|,
name|DEFAULT_BLOCKSIZE
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|toString ()
specifier|public
name|String
name|toString
parameter_list|()
block|{
specifier|final
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"S3AFileSystem{"
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"uri="
argument_list|)
operator|.
name|append
argument_list|(
name|uri
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", workingDir="
argument_list|)
operator|.
name|append
argument_list|(
name|workingDir
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", inputPolicy="
argument_list|)
operator|.
name|append
argument_list|(
name|inputPolicy
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", partSize="
argument_list|)
operator|.
name|append
argument_list|(
name|partSize
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", enableMultiObjectsDelete="
argument_list|)
operator|.
name|append
argument_list|(
name|enableMultiObjectsDelete
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", maxKeys="
argument_list|)
operator|.
name|append
argument_list|(
name|maxKeys
argument_list|)
expr_stmt|;
if|if
condition|(
name|cannedACL
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", cannedACL="
argument_list|)
operator|.
name|append
argument_list|(
name|cannedACL
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", readAhead="
argument_list|)
operator|.
name|append
argument_list|(
name|readAhead
argument_list|)
expr_stmt|;
if|if
condition|(
name|getConf
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", blockSize="
argument_list|)
operator|.
name|append
argument_list|(
name|getDefaultBlockSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", multiPartThreshold="
argument_list|)
operator|.
name|append
argument_list|(
name|multiPartThreshold
argument_list|)
expr_stmt|;
if|if
condition|(
name|getServerSideEncryptionAlgorithm
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", serverSideEncryptionAlgorithm='"
argument_list|)
operator|.
name|append
argument_list|(
name|getServerSideEncryptionAlgorithm
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|'\''
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|blockFactory
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", blockFactory="
argument_list|)
operator|.
name|append
argument_list|(
name|blockFactory
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", metastore="
argument_list|)
operator|.
name|append
argument_list|(
name|metadataStore
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", authoritativeStore="
argument_list|)
operator|.
name|append
argument_list|(
name|allowAuthoritativeMetadataStore
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", authoritativePath="
argument_list|)
operator|.
name|append
argument_list|(
name|allowAuthoritativePaths
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", useListV1="
argument_list|)
operator|.
name|append
argument_list|(
name|useListV1
argument_list|)
expr_stmt|;
if|if
condition|(
name|committerIntegration
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", magicCommitter="
argument_list|)
operator|.
name|append
argument_list|(
name|isMagicCommitEnabled
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", boundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|boundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", unboundedExecutor="
argument_list|)
operator|.
name|append
argument_list|(
name|unboundedThreadPool
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", credentials="
argument_list|)
operator|.
name|append
argument_list|(
name|credentials
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", delegation tokens="
argument_list|)
operator|.
name|append
argument_list|(
name|delegationTokens
operator|.
name|map
argument_list|(
name|Objects
operator|::
name|toString
argument_list|)
operator|.
name|orElse
argument_list|(
literal|"disabled"
argument_list|)
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", statistics {"
argument_list|)
operator|.
name|append
argument_list|(
name|statistics
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
if|if
condition|(
name|instrumentation
operator|!=
literal|null
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", metrics {"
argument_list|)
operator|.
name|append
argument_list|(
name|instrumentation
operator|.
name|dump
argument_list|(
literal|"{"
argument_list|,
literal|"="
argument_list|,
literal|"} "
argument_list|,
literal|true
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|'}'
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Get the partition size for multipart operations.    * @return the value as set during initialization    */
DECL|method|getPartitionSize ()
specifier|public
name|long
name|getPartitionSize
parameter_list|()
block|{
return|return
name|partSize
return|;
block|}
comment|/**    * Get the threshold for multipart files.    * @return the value as set during initialization    */
DECL|method|getMultiPartThreshold ()
specifier|public
name|long
name|getMultiPartThreshold
parameter_list|()
block|{
return|return
name|multiPartThreshold
return|;
block|}
comment|/**    * Get the maximum key count.    * @return a value, valid after initialization    */
DECL|method|getMaxKeys ()
name|int
name|getMaxKeys
parameter_list|()
block|{
return|return
name|maxKeys
return|;
block|}
comment|/**    * Is magic commit enabled?    * @return true if magic commit support is turned on.    */
DECL|method|isMagicCommitEnabled ()
specifier|public
name|boolean
name|isMagicCommitEnabled
parameter_list|()
block|{
return|return
name|committerIntegration
operator|.
name|isMagicCommitEnabled
argument_list|()
return|;
block|}
comment|/**    * Predicate: is a path a magic commit path?    * True if magic commit is enabled and the path qualifies as special.    * @param path path to examine    * @return true if the path is or is under a magic directory    */
DECL|method|isMagicCommitPath (Path path)
specifier|public
name|boolean
name|isMagicCommitPath
parameter_list|(
name|Path
name|path
parameter_list|)
block|{
return|return
name|committerIntegration
operator|.
name|isMagicCommitPath
argument_list|(
name|path
argument_list|)
return|;
block|}
comment|/**    * Increments the statistic {@link Statistic#INVOCATION_GLOB_STATUS}.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus (Path pathPattern)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
name|Path
name|pathPattern
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|globStatus
argument_list|(
name|pathPattern
argument_list|,
name|ACCEPT_ALL
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to disable symlink resolution and so avoid    * some calls to the FS which may have problems when the store is being    * inconsistent.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|globStatus ( final Path pathPattern, final PathFilter filter)
specifier|public
name|FileStatus
index|[]
name|globStatus
parameter_list|(
specifier|final
name|Path
name|pathPattern
parameter_list|,
specifier|final
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_GLOB_STATUS
argument_list|)
expr_stmt|;
return|return
name|Globber
operator|.
name|createGlobber
argument_list|(
name|this
argument_list|)
operator|.
name|withPathPattern
argument_list|(
name|pathPattern
argument_list|)
operator|.
name|withPathFiltern
argument_list|(
name|filter
argument_list|)
operator|.
name|withResolveSymlinks
argument_list|(
literal|true
argument_list|)
operator|.
name|build
argument_list|()
operator|.
name|glob
argument_list|()
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|exists (Path f)
specifier|public
name|boolean
name|exists
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_EXISTS
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|exists
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isDirectory (Path f)
specifier|public
name|boolean
name|isDirectory
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_IS_DIRECTORY
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isDirectory
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
DECL|method|isFile (Path f)
specifier|public
name|boolean
name|isFile
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_IS_FILE
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|isFile
argument_list|(
name|f
argument_list|)
return|;
block|}
comment|/**    * When enabled, get the etag of a object at the path via HEAD request and    * return it as a checksum object.    *<ol>    *<li>If a tag has not changed, consider the object unchanged.</li>    *<li>Two tags being different does not imply the data is different.</li>    *</ol>    * Different S3 implementations may offer different guarantees.    *    * This check is (currently) only made if    * {@link Constants#ETAG_CHECKSUM_ENABLED} is set; turning it on    * has caused problems with Distcp (HADOOP-15273).    *    * @param f The file path    * @param length The length of the file range for checksum calculation    * @return The EtagChecksum or null if checksums are not enabled or supported.    * @throws IOException IO failure    * @see<a href="http://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonResponseHeaders.html">Common Response Headers</a>    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|getFileChecksum (Path f, final long length)
specifier|public
name|EtagChecksum
name|getFileChecksum
parameter_list|(
name|Path
name|f
parameter_list|,
specifier|final
name|long
name|length
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|length
operator|>=
literal|0
argument_list|)
expr_stmt|;
name|entryPoint
argument_list|(
name|INVOCATION_GET_FILE_CHECKSUM
argument_list|)
expr_stmt|;
if|if
condition|(
name|getConf
argument_list|()
operator|.
name|getBoolean
argument_list|(
name|ETAG_CHECKSUM_ENABLED
argument_list|,
name|ETAG_CHECKSUM_ENABLED_DEFAULT
argument_list|)
condition|)
block|{
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"getFileChecksum({})"
argument_list|,
name|path
argument_list|)
expr_stmt|;
name|ObjectMetadata
name|headers
init|=
name|getObjectMetadata
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|String
name|eTag
init|=
name|headers
operator|.
name|getETag
argument_list|()
decl_stmt|;
return|return
name|eTag
operator|!=
literal|null
condition|?
operator|new
name|EtagChecksum
argument_list|(
name|eTag
argument_list|)
else|:
literal|null
return|;
block|}
else|else
block|{
comment|// disabled
return|return
literal|null
return|;
block|}
block|}
comment|/**    * {@inheritDoc}.    *    * This implementation is optimized for S3, which can do a bulk listing    * off all entries under a path in one single operation. Thus there is    * no need to recursively walk the directory tree.    *    * Instead a {@link ListObjectsRequest} is created requesting a (windowed)    * listing of all entries under the given path. This is used to construct    * an {@code ObjectListingIterator} instance, iteratively returning the    * sequence of lists of elements under the path. This is then iterated    * over in a {@code FileStatusListingIterator}, which generates    * {@link S3AFileStatus} instances, one per listing entry.    * These are then translated into {@link LocatedFileStatus} instances.    *    * This is essentially a nested and wrapped set of iterators, with some    * generator classes.    * @param f a path    * @param recursive if the subdirectories need to be traversed recursively    *    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listFiles (Path f, boolean recursive)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listFiles
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|toLocatedFileStatusIterator
argument_list|(
name|innerListFiles
argument_list|(
name|f
argument_list|,
name|recursive
argument_list|,
operator|new
name|Listing
operator|.
name|AcceptFilesOnly
argument_list|(
name|qualify
argument_list|(
name|f
argument_list|)
argument_list|)
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
argument_list|)
return|;
block|}
DECL|method|toLocatedFileStatusIterator ( RemoteIterator<? extends LocatedFileStatus> iterator)
specifier|private
specifier|static
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|toLocatedFileStatusIterator
parameter_list|(
name|RemoteIterator
argument_list|<
name|?
extends|extends
name|LocatedFileStatus
argument_list|>
name|iterator
parameter_list|)
block|{
return|return
operator|new
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|hasNext
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|iterator
operator|.
name|hasNext
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|LocatedFileStatus
name|next
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|iterator
operator|.
name|next
argument_list|()
return|;
block|}
block|}
return|;
block|}
comment|/**    * Recursive List of files and empty directories.    * @param f path to list from    * @return an iterator.    * @throws IOException failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listFilesAndEmptyDirectories ( Path f, boolean recursive)
specifier|public
name|RemoteIterator
argument_list|<
name|S3ALocatedFileStatus
argument_list|>
name|listFilesAndEmptyDirectories
parameter_list|(
name|Path
name|f
parameter_list|,
name|boolean
name|recursive
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|innerListFiles
argument_list|(
name|f
argument_list|,
name|recursive
argument_list|,
name|Listing
operator|.
name|ACCEPT_ALL_BUT_S3N
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * List files under the path.    *<ol>    *<li>    *     If the path is authoritative on the client,    *     only S3Guard will be queried.    *</li>    *<li>    *     Otherwise, the S3Guard values are returned first, then the S3    *     entries will be retrieved and returned if not already listed.</li>    *<li>    *     when collectTombstones} is true, S3Guard tombstones will    *     be used to filter out deleted files.    *     They MUST be used for normal listings; it is only for    *     deletion and low-level operations that they MAY be bypassed.    *</li>    *<li>    *     The optional {@code status} parameter will be used to skip the    *     initial getFileStatus call.    *</li>    *</ol>    *    * @param f path    * @param recursive recursive listing?    * @param acceptor file status filter    * @param status optional status of path to list.    * @param collectTombstones should tombstones be collected from S3Guard?    * @return an iterator over the listing.    * @throws IOException failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|innerListFiles ( final Path f, final boolean recursive, final Listing.FileStatusAcceptor acceptor, final S3AFileStatus status, final boolean collectTombstones)
specifier|private
name|RemoteIterator
argument_list|<
name|S3ALocatedFileStatus
argument_list|>
name|innerListFiles
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|boolean
name|recursive
parameter_list|,
specifier|final
name|Listing
operator|.
name|FileStatusAcceptor
name|acceptor
parameter_list|,
specifier|final
name|S3AFileStatus
name|status
parameter_list|,
specifier|final
name|boolean
name|collectTombstones
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_LIST_FILES
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listFiles({}, {})"
argument_list|,
name|path
argument_list|,
name|recursive
argument_list|)
expr_stmt|;
try|try
block|{
comment|// if a status was given, that is used, otherwise
comment|// call getFileStatus, which triggers an existence check
specifier|final
name|S3AFileStatus
name|fileStatus
init|=
name|status
operator|!=
literal|null
condition|?
name|status
else|:
operator|(
name|S3AFileStatus
operator|)
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: do a bulk operation
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|delimiter
init|=
name|recursive
condition|?
literal|null
else|:
literal|"/"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Requesting all entries under {} with delimiter '{}'"
argument_list|,
name|key
argument_list|,
name|delimiter
argument_list|)
expr_stmt|;
specifier|final
name|RemoteIterator
argument_list|<
name|S3AFileStatus
argument_list|>
name|cachedFilesIterator
decl_stmt|;
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|tombstones
decl_stmt|;
name|boolean
name|allowAuthoritative
init|=
name|allowAuthoritative
argument_list|(
name|f
argument_list|)
decl_stmt|;
if|if
condition|(
name|recursive
condition|)
block|{
specifier|final
name|PathMetadata
name|pm
init|=
name|metadataStore
operator|.
name|get
argument_list|(
name|path
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// shouldn't need to check pm.isDeleted() because that will have
comment|// been caught by getFileStatus above.
name|MetadataStoreListFilesIterator
name|metadataStoreListFilesIterator
init|=
operator|new
name|MetadataStoreListFilesIterator
argument_list|(
name|metadataStore
argument_list|,
name|pm
argument_list|,
name|allowAuthoritative
argument_list|)
decl_stmt|;
name|tombstones
operator|=
name|metadataStoreListFilesIterator
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
name|cachedFilesIterator
operator|=
name|metadataStoreListFilesIterator
expr_stmt|;
block|}
else|else
block|{
name|DirListingMetadata
name|meta
init|=
name|S3Guard
operator|.
name|listChildrenWithTtl
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|ttlTimeProvider
argument_list|)
decl_stmt|;
if|if
condition|(
name|meta
operator|!=
literal|null
condition|)
block|{
name|tombstones
operator|=
name|meta
operator|.
name|listTombstones
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|tombstones
operator|=
literal|null
expr_stmt|;
block|}
name|cachedFilesIterator
operator|=
name|listing
operator|.
name|createProvidedFileStatusIterator
argument_list|(
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|meta
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
name|acceptor
argument_list|)
expr_stmt|;
if|if
condition|(
name|allowAuthoritative
operator|&&
name|meta
operator|!=
literal|null
operator|&&
name|meta
operator|.
name|isAuthoritative
argument_list|()
condition|)
block|{
comment|// metadata listing is authoritative, so return it directly
return|return
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|cachedFilesIterator
argument_list|)
return|;
block|}
block|}
return|return
name|listing
operator|.
name|createTombstoneReconcilingIterator
argument_list|(
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
name|delimiter
argument_list|)
argument_list|,
name|ACCEPT_ALL
argument_list|,
name|acceptor
argument_list|,
name|cachedFilesIterator
argument_list|)
argument_list|)
argument_list|,
name|collectTombstones
condition|?
name|tombstones
else|:
literal|null
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|AmazonClientException
name|e
parameter_list|)
block|{
comment|// TODO S3Guard: retry on file not found exception
throw|throw
name|translateException
argument_list|(
literal|"listFiles"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Override superclass so as to add statistic collection.    * {@inheritDoc}    */
annotation|@
name|Override
DECL|method|listLocatedStatus (Path f)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
name|Path
name|f
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
return|return
name|listLocatedStatus
argument_list|(
name|f
argument_list|,
name|ACCEPT_ALL
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}.    *    * S3 Optimized directory listing. The initial operation performs the    * first bulk listing; extra listings will take place    * when all the current set of results are used up.    * @param f a path    * @param filter a path filter    * @return an iterator that traverses statuses of the files/directories    *         in the given path    * @throws FileNotFoundException if {@code path} does not exist    * @throws IOException if any I/O error occurred    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|OnceTranslated
argument_list|(
literal|"s3guard not retrying"
argument_list|)
DECL|method|listLocatedStatus (final Path f, final PathFilter filter)
specifier|public
name|RemoteIterator
argument_list|<
name|LocatedFileStatus
argument_list|>
name|listLocatedStatus
parameter_list|(
specifier|final
name|Path
name|f
parameter_list|,
specifier|final
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
name|entryPoint
argument_list|(
name|INVOCATION_LIST_LOCATED_STATUS
argument_list|)
expr_stmt|;
name|Path
name|path
init|=
name|qualify
argument_list|(
name|f
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"listLocatedStatus({}, {}"
argument_list|,
name|path
argument_list|,
name|filter
argument_list|)
expr_stmt|;
name|RemoteIterator
argument_list|<
name|?
extends|extends
name|LocatedFileStatus
argument_list|>
name|iterator
init|=
name|once
argument_list|(
literal|"listLocatedStatus"
argument_list|,
name|path
operator|.
name|toString
argument_list|()
argument_list|,
parameter_list|()
lambda|->
block|{
comment|// lookup dir triggers existence check
specifier|final
name|S3AFileStatus
name|fileStatus
init|=
operator|(
name|S3AFileStatus
operator|)
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileStatus
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// simple case: File
name|LOG
operator|.
name|debug
argument_list|(
literal|"Path is a file"
argument_list|)
expr_stmt|;
return|return
operator|new
name|Listing
operator|.
name|SingleStatusRemoteIterator
argument_list|(
name|filter
operator|.
name|accept
argument_list|(
name|path
argument_list|)
condition|?
name|toLocatedFileStatus
argument_list|(
name|fileStatus
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
else|else
block|{
comment|// directory: trigger a lookup
specifier|final
name|String
name|key
init|=
name|maybeAddTrailingSlash
argument_list|(
name|pathToKey
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|Listing
operator|.
name|FileStatusAcceptor
name|acceptor
init|=
operator|new
name|Listing
operator|.
name|AcceptAllButSelfAndS3nDirs
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|DirListingMetadata
name|meta
init|=
name|S3Guard
operator|.
name|listChildrenWithTtl
argument_list|(
name|metadataStore
argument_list|,
name|path
argument_list|,
name|ttlTimeProvider
argument_list|)
decl_stmt|;
specifier|final
name|RemoteIterator
argument_list|<
name|S3AFileStatus
argument_list|>
name|cachedFileStatusIterator
init|=
name|listing
operator|.
name|createProvidedFileStatusIterator
argument_list|(
name|S3Guard
operator|.
name|dirMetaToStatuses
argument_list|(
name|meta
argument_list|)
argument_list|,
name|filter
argument_list|,
name|acceptor
argument_list|)
decl_stmt|;
name|boolean
name|allowAuthoritative
init|=
name|allowAuthoritative
argument_list|(
name|f
argument_list|)
decl_stmt|;
return|return
operator|(
name|allowAuthoritative
operator|&&
name|meta
operator|!=
literal|null
operator|&&
name|meta
operator|.
name|isAuthoritative
argument_list|()
operator|)
condition|?
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|cachedFileStatusIterator
argument_list|)
else|:
name|listing
operator|.
name|createLocatedFileStatusIterator
argument_list|(
name|listing
operator|.
name|createFileStatusListingIterator
argument_list|(
name|path
argument_list|,
name|createListObjectsRequest
argument_list|(
name|key
argument_list|,
literal|"/"
argument_list|)
argument_list|,
name|filter
argument_list|,
name|acceptor
argument_list|,
name|cachedFileStatusIterator
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
return|return
name|toLocatedFileStatusIterator
argument_list|(
name|iterator
argument_list|)
return|;
block|}
comment|/**    * Build a {@link S3ALocatedFileStatus} from a {@link FileStatus} instance.    * @param status file status    * @return a located status with block locations set up from this FS.    * @throws IOException IO Problems.    */
DECL|method|toLocatedFileStatus (S3AFileStatus status)
name|S3ALocatedFileStatus
name|toLocatedFileStatus
parameter_list|(
name|S3AFileStatus
name|status
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|S3ALocatedFileStatus
argument_list|(
name|status
argument_list|,
name|status
operator|.
name|isFile
argument_list|()
condition|?
name|getFileBlockLocations
argument_list|(
name|status
argument_list|,
literal|0
argument_list|,
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
else|:
literal|null
argument_list|)
return|;
block|}
comment|/**    * List any pending multipart uploads whose keys begin with prefix, using    * an iterator that can handle an unlimited number of entries.    * See {@link #listMultipartUploads(String)} for a non-iterator version of    * this.    *    * @param prefix optional key prefix to search    * @return Iterator over multipart uploads.    * @throws IOException on failure    */
DECL|method|listUploads (@ullable String prefix)
specifier|public
name|MultipartUtils
operator|.
name|UploadIterator
name|listUploads
parameter_list|(
annotation|@
name|Nullable
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|MultipartUtils
operator|.
name|listMultipartUploads
argument_list|(
name|s3
argument_list|,
name|invoker
argument_list|,
name|bucket
argument_list|,
name|maxKeys
argument_list|,
name|prefix
argument_list|)
return|;
block|}
comment|/**    * Listing all multipart uploads; limited to the first few hundred.    * See {@link #listUploads(String)} for an iterator-based version that does    * not limit the number of entries returned.    * Retry policy: retry, translated.    * @return a listing of multipart uploads.    * @param prefix prefix to scan for, "" for none    * @throws IOException IO failure, including any uprated AmazonClientException    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|listMultipartUploads (String prefix)
specifier|public
name|List
argument_list|<
name|MultipartUpload
argument_list|>
name|listMultipartUploads
parameter_list|(
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|ListMultipartUploadsRequest
name|request
init|=
operator|new
name|ListMultipartUploadsRequest
argument_list|(
name|bucket
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|prefix
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|prefix
operator|.
name|endsWith
argument_list|(
literal|"/"
argument_list|)
condition|)
block|{
name|prefix
operator|=
name|prefix
operator|+
literal|"/"
expr_stmt|;
block|}
name|request
operator|.
name|setPrefix
argument_list|(
name|prefix
argument_list|)
expr_stmt|;
block|}
return|return
name|invoker
operator|.
name|retry
argument_list|(
literal|"listMultipartUploads"
argument_list|,
name|prefix
argument_list|,
literal|true
argument_list|,
parameter_list|()
lambda|->
name|s3
operator|.
name|listMultipartUploads
argument_list|(
name|request
argument_list|)
operator|.
name|getMultipartUploads
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Abort a multipart upload.    * Retry policy: none.    * @param destKey destination key    * @param uploadId Upload ID    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|abortMultipartUpload (String destKey, String uploadId)
name|void
name|abortMultipartUpload
parameter_list|(
name|String
name|destKey
parameter_list|,
name|String
name|uploadId
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Aborting multipart upload {} to {}"
argument_list|,
name|uploadId
argument_list|,
name|destKey
argument_list|)
expr_stmt|;
name|getAmazonS3Client
argument_list|()
operator|.
name|abortMultipartUpload
argument_list|(
operator|new
name|AbortMultipartUploadRequest
argument_list|(
name|getBucket
argument_list|()
argument_list|,
name|destKey
argument_list|,
name|uploadId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Abort a multipart upload.    * Retry policy: none.    * @param upload the listed upload to abort.    */
annotation|@
name|Retries
operator|.
name|OnceRaw
DECL|method|abortMultipartUpload (MultipartUpload upload)
name|void
name|abortMultipartUpload
parameter_list|(
name|MultipartUpload
name|upload
parameter_list|)
block|{
name|String
name|destKey
decl_stmt|;
name|String
name|uploadId
decl_stmt|;
name|destKey
operator|=
name|upload
operator|.
name|getKey
argument_list|()
expr_stmt|;
name|uploadId
operator|=
name|upload
operator|.
name|getUploadId
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|DateFormat
name|df
init|=
operator|new
name|SimpleDateFormat
argument_list|(
literal|"yyyy-MM-dd HH:mm:ss"
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Aborting multipart upload {} to {} initiated by {} on {}"
argument_list|,
name|uploadId
argument_list|,
name|destKey
argument_list|,
name|upload
operator|.
name|getInitiator
argument_list|()
argument_list|,
name|df
operator|.
name|format
argument_list|(
name|upload
operator|.
name|getInitiated
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|getAmazonS3Client
argument_list|()
operator|.
name|abortMultipartUpload
argument_list|(
operator|new
name|AbortMultipartUploadRequest
argument_list|(
name|getBucket
argument_list|()
argument_list|,
name|destKey
argument_list|,
name|uploadId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a new instance of the committer statistics.    * @return a new committer statistics instance    */
DECL|method|newCommitterStatistics ()
specifier|public
name|S3AInstrumentation
operator|.
name|CommitterStatistics
name|newCommitterStatistics
parameter_list|()
block|{
return|return
name|instrumentation
operator|.
name|newCommitterStatistics
argument_list|()
return|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
annotation|@
name|Override
DECL|method|hasPathCapability (final Path path, final String capability)
specifier|public
name|boolean
name|hasPathCapability
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|String
name|capability
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|p
init|=
name|makeQualified
argument_list|(
name|path
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|validatePathCapabilityArgs
argument_list|(
name|p
argument_list|,
name|capability
argument_list|)
condition|)
block|{
case|case
name|CommitConstants
operator|.
name|STORE_CAPABILITY_MAGIC_COMMITTER
case|:
case|case
name|CommitConstants
operator|.
name|STORE_CAPABILITY_MAGIC_COMMITTER_OLD
case|:
comment|// capability depends on FS configuration
return|return
name|isMagicCommitEnabled
argument_list|()
return|;
case|case
name|SelectConstants
operator|.
name|S3_SELECT_CAPABILITY
case|:
comment|// select is only supported if enabled
return|return
name|selectBinding
operator|.
name|isEnabled
argument_list|()
return|;
case|case
name|CommonPathCapabilities
operator|.
name|FS_CHECKSUMS
case|:
comment|// capability depends on FS configuration
return|return
name|getConf
argument_list|()
operator|.
name|getBoolean
argument_list|(
name|ETAG_CHECKSUM_ENABLED
argument_list|,
name|ETAG_CHECKSUM_ENABLED_DEFAULT
argument_list|)
return|;
default|default:
return|return
name|super
operator|.
name|hasPathCapability
argument_list|(
name|p
argument_list|,
name|capability
argument_list|)
return|;
block|}
block|}
comment|/**    * Return the capabilities of this filesystem instance.    *    * This has been supplanted by {@link #hasPathCapability(Path, String)}.    * @param capability string to query the stream support for.    * @return whether the FS instance has the capability.    */
annotation|@
name|Deprecated
annotation|@
name|Override
DECL|method|hasCapability (String capability)
specifier|public
name|boolean
name|hasCapability
parameter_list|(
name|String
name|capability
parameter_list|)
block|{
try|try
block|{
return|return
name|hasPathCapability
argument_list|(
name|workingDir
argument_list|,
name|capability
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// should never happen, so log and downgrade.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Ignoring exception on hasCapability({}})"
argument_list|,
name|capability
argument_list|,
name|ex
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Get a shared copy of the AWS credentials, with its reference    * counter updated.    * Caller is required to call {@code close()} on this after    * they have finished using it.    * @param purpose what is this for? This is initially for logging    * @return a reference to shared credentials.    */
DECL|method|shareCredentials (final String purpose)
specifier|public
name|AWSCredentialProviderList
name|shareCredentials
parameter_list|(
specifier|final
name|String
name|purpose
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Sharing credentials for: {}"
argument_list|,
name|purpose
argument_list|)
expr_stmt|;
return|return
name|credentials
operator|.
name|share
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|getTtlTimeProvider ()
specifier|public
name|ITtlTimeProvider
name|getTtlTimeProvider
parameter_list|()
block|{
return|return
name|ttlTimeProvider
return|;
block|}
annotation|@
name|VisibleForTesting
DECL|method|setTtlTimeProvider (ITtlTimeProvider ttlTimeProvider)
specifier|protected
name|void
name|setTtlTimeProvider
parameter_list|(
name|ITtlTimeProvider
name|ttlTimeProvider
parameter_list|)
block|{
name|this
operator|.
name|ttlTimeProvider
operator|=
name|ttlTimeProvider
expr_stmt|;
name|metadataStore
operator|.
name|setTtlTimeProvider
argument_list|(
name|ttlTimeProvider
argument_list|)
expr_stmt|;
block|}
comment|/**    * This is a proof of concept of a select API.    * Once a proper factory mechanism for opening files is added to the    * FileSystem APIs, this will be deleted<i>without any warning</i>.    * @param source path to source data    * @param expression select expression    * @param options request configuration from the builder.    * @return the stream of the results    * @throws IOException IO failure    */
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|select (final Path source, final String expression, final Configuration options)
specifier|private
name|FSDataInputStream
name|select
parameter_list|(
specifier|final
name|Path
name|source
parameter_list|,
specifier|final
name|String
name|expression
parameter_list|,
specifier|final
name|Configuration
name|options
parameter_list|)
throws|throws
name|IOException
block|{
name|entryPoint
argument_list|(
name|OBJECT_SELECT_REQUESTS
argument_list|)
expr_stmt|;
name|requireSelectSupport
argument_list|(
name|source
argument_list|)
expr_stmt|;
specifier|final
name|Path
name|path
init|=
name|makeQualified
argument_list|(
name|source
argument_list|)
decl_stmt|;
comment|// call getFileStatus(), which will look at S3Guard first,
comment|// so the operation will fail if it is not there or S3Guard believes it has
comment|// been deleted.
comment|// validation of the file status are delegated to the binding.
specifier|final
name|S3AFileStatus
name|fileStatus
init|=
operator|(
name|S3AFileStatus
operator|)
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
comment|// readahead range can be dynamically set
name|long
name|ra
init|=
name|options
operator|.
name|getLong
argument_list|(
name|READAHEAD_RANGE
argument_list|,
name|readAhead
argument_list|)
decl_stmt|;
name|S3ObjectAttributes
name|objectAttributes
init|=
name|createObjectAttributes
argument_list|(
name|fileStatus
argument_list|)
decl_stmt|;
name|S3AReadOpContext
name|readContext
init|=
name|createReadContext
argument_list|(
name|fileStatus
argument_list|,
name|inputPolicy
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|ra
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fileStatus
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
comment|// check that the object metadata lines up with what is expected
comment|// based on the object attributes (which may contain an eTag or
comment|// versionId) from S3Guard
name|ChangeTracker
name|changeTracker
init|=
operator|new
name|ChangeTracker
argument_list|(
name|uri
operator|.
name|toString
argument_list|()
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|readContext
operator|.
name|instrumentation
operator|.
name|newInputStreamStatistics
argument_list|()
operator|.
name|getVersionMismatchCounter
argument_list|()
argument_list|,
name|objectAttributes
argument_list|)
decl_stmt|;
comment|// will retry internally if wrong version detected
name|Invoker
name|readInvoker
init|=
name|readContext
operator|.
name|getReadInvoker
argument_list|()
decl_stmt|;
name|getObjectMetadata
argument_list|(
name|path
argument_list|,
name|changeTracker
argument_list|,
name|readInvoker
argument_list|,
literal|"select"
argument_list|)
expr_stmt|;
block|}
comment|// build and execute the request
return|return
name|selectBinding
operator|.
name|select
argument_list|(
name|readContext
argument_list|,
name|expression
argument_list|,
name|options
argument_list|,
name|generateSSECustomerKey
argument_list|()
argument_list|,
name|objectAttributes
argument_list|)
return|;
block|}
comment|/**    * Verify the FS supports S3 Select.    * @param source source file.    * @throws UnsupportedOperationException if not.    */
DECL|method|requireSelectSupport (final Path source)
specifier|private
name|void
name|requireSelectSupport
parameter_list|(
specifier|final
name|Path
name|source
parameter_list|)
throws|throws
name|UnsupportedOperationException
block|{
if|if
condition|(
operator|!
name|selectBinding
operator|.
name|isEnabled
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|SelectConstants
operator|.
name|SELECT_UNSUPPORTED
argument_list|)
throw|;
block|}
block|}
comment|/**    * Initiate the open or select operation.    * This is invoked from both the FileSystem and FileContext APIs    * @param path path to the file    * @param mandatoryKeys set of options declared as mandatory.    * @param options options set during the build sequence.    * @return a future which will evaluate to the opened/selected file.    * @throws IOException failure to resolve the link.    * @throws PathIOException operation is a select request but S3 select is    * disabled    * @throws IllegalArgumentException unknown mandatory key    */
annotation|@
name|Override
annotation|@
name|Retries
operator|.
name|RetryTranslated
DECL|method|openFileWithOptions ( final Path path, final Set<String> mandatoryKeys, final Configuration options, final int bufferSize)
specifier|public
name|CompletableFuture
argument_list|<
name|FSDataInputStream
argument_list|>
name|openFileWithOptions
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|mandatoryKeys
parameter_list|,
specifier|final
name|Configuration
name|options
parameter_list|,
specifier|final
name|int
name|bufferSize
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|sql
init|=
name|options
operator|.
name|get
argument_list|(
name|SelectConstants
operator|.
name|SELECT_SQL
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|boolean
name|isSelect
init|=
name|sql
operator|!=
literal|null
decl_stmt|;
comment|// choice of keys depends on open type
if|if
condition|(
name|isSelect
condition|)
block|{
name|rejectUnknownMandatoryKeys
argument_list|(
name|mandatoryKeys
argument_list|,
name|InternalSelectConstants
operator|.
name|SELECT_OPTIONS
argument_list|,
literal|"for "
operator|+
name|path
operator|+
literal|" in S3 Select operation"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|rejectUnknownMandatoryKeys
argument_list|(
name|mandatoryKeys
argument_list|,
name|InternalConstants
operator|.
name|STANDARD_OPENFILE_KEYS
argument_list|,
literal|"for "
operator|+
name|path
operator|+
literal|" in non-select file I/O"
argument_list|)
expr_stmt|;
block|}
name|CompletableFuture
argument_list|<
name|FSDataInputStream
argument_list|>
name|result
init|=
operator|new
name|CompletableFuture
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|isSelect
condition|)
block|{
comment|// normal path.
name|unboundedThreadPool
operator|.
name|submit
argument_list|(
parameter_list|()
lambda|->
name|LambdaUtils
operator|.
name|eval
argument_list|(
name|result
argument_list|,
parameter_list|()
lambda|->
name|open
argument_list|(
name|path
argument_list|,
name|Optional
operator|.
name|of
argument_list|(
name|options
argument_list|)
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// it is a select statement.
comment|// fail fast if the method is not present
name|requireSelectSupport
argument_list|(
name|path
argument_list|)
expr_stmt|;
comment|// submit the query
name|unboundedThreadPool
operator|.
name|submit
argument_list|(
parameter_list|()
lambda|->
name|LambdaUtils
operator|.
name|eval
argument_list|(
name|result
argument_list|,
parameter_list|()
lambda|->
name|select
argument_list|(
name|path
argument_list|,
name|sql
argument_list|,
name|options
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * Build an immutable store context.    * If called while the FS is being initialized,    * some of the context will be incomplete.    * new store context instances should be created as appropriate.    * @return the store context of this FS.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
DECL|method|createStoreContext ()
specifier|public
name|StoreContext
name|createStoreContext
parameter_list|()
block|{
return|return
operator|new
name|StoreContext
argument_list|(
name|getUri
argument_list|()
argument_list|,
name|getBucket
argument_list|()
argument_list|,
name|getConf
argument_list|()
argument_list|,
name|getUsername
argument_list|()
argument_list|,
name|owner
argument_list|,
name|boundedThreadPool
argument_list|,
name|executorCapacity
argument_list|,
name|invoker
argument_list|,
name|getInstrumentation
argument_list|()
argument_list|,
name|getStorageStatistics
argument_list|()
argument_list|,
name|getInputPolicy
argument_list|()
argument_list|,
name|changeDetectionPolicy
argument_list|,
name|enableMultiObjectsDelete
argument_list|,
name|metadataStore
argument_list|,
name|useListV1
argument_list|,
operator|new
name|ContextAccessorsImpl
argument_list|()
argument_list|,
name|getTtlTimeProvider
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * The implementation of context accessors.    */
DECL|class|ContextAccessorsImpl
specifier|private
class|class
name|ContextAccessorsImpl
implements|implements
name|ContextAccessors
block|{
annotation|@
name|Override
DECL|method|keyToPath (final String key)
specifier|public
name|Path
name|keyToPath
parameter_list|(
specifier|final
name|String
name|key
parameter_list|)
block|{
return|return
name|keyToQualifiedPath
argument_list|(
name|key
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|pathToKey (final Path path)
specifier|public
name|String
name|pathToKey
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|)
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|pathToKey
argument_list|(
name|path
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|createTempFile (final String prefix, final long size)
specifier|public
name|File
name|createTempFile
parameter_list|(
specifier|final
name|String
name|prefix
parameter_list|,
specifier|final
name|long
name|size
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createTmpFileForWrite
argument_list|(
name|prefix
argument_list|,
name|size
argument_list|,
name|getConf
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
DECL|method|getBucketLocation ()
specifier|public
name|String
name|getBucketLocation
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|S3AFileSystem
operator|.
name|this
operator|.
name|getBucketLocation
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

