begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *<p/>  * http://www.apache.org/licenses/LICENSE-2.0  *<p/>  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.metrics2.sink
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|sink
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Strings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|Producer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|KafkaProducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|configuration
operator|.
name|SubsetConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|AbstractMetric
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsSink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|metrics2
operator|.
name|MetricsTag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|ProducerRecord
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|kafka
operator|.
name|clients
operator|.
name|producer
operator|.
name|RecordMetadata
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|Charset
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|Instant
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|LocalDateTime
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|ZoneId
import|;
end_import

begin_import
import|import
name|java
operator|.
name|time
operator|.
name|format
operator|.
name|DateTimeFormatter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_comment
comment|/**  * A metrics sink that writes to a Kafka broker. This requires you to configure  * a broker_list and a topic in the metrics2 configuration file. The broker_list  * must contain a comma-separated list of kafka broker host and ports. The topic  * will contain only one topic.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Evolving
DECL|class|KafkaSink
specifier|public
class|class
name|KafkaSink
implements|implements
name|MetricsSink
implements|,
name|Closeable
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|KafkaSink
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|BROKER_LIST
specifier|public
specifier|static
specifier|final
name|String
name|BROKER_LIST
init|=
literal|"broker_list"
decl_stmt|;
DECL|field|TOPIC
specifier|public
specifier|static
specifier|final
name|String
name|TOPIC
init|=
literal|"topic"
decl_stmt|;
DECL|field|hostname
specifier|private
name|String
name|hostname
init|=
literal|null
decl_stmt|;
DECL|field|brokerList
specifier|private
name|String
name|brokerList
init|=
literal|null
decl_stmt|;
DECL|field|topic
specifier|private
name|String
name|topic
init|=
literal|null
decl_stmt|;
DECL|field|producer
specifier|private
name|Producer
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
name|producer
init|=
literal|null
decl_stmt|;
DECL|field|dateFormat
specifier|private
specifier|final
name|DateTimeFormatter
name|dateFormat
init|=
name|DateTimeFormatter
operator|.
name|ofPattern
argument_list|(
literal|"yyyy-MM-dd"
argument_list|)
decl_stmt|;
DECL|field|timeFormat
specifier|private
specifier|final
name|DateTimeFormatter
name|timeFormat
init|=
name|DateTimeFormatter
operator|.
name|ofPattern
argument_list|(
literal|"HH:mm:ss"
argument_list|)
decl_stmt|;
DECL|field|zoneId
specifier|private
specifier|final
name|ZoneId
name|zoneId
init|=
name|ZoneId
operator|.
name|systemDefault
argument_list|()
decl_stmt|;
DECL|method|setProducer (Producer<Integer, byte[]> p)
specifier|public
name|void
name|setProducer
parameter_list|(
name|Producer
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
name|p
parameter_list|)
block|{
name|this
operator|.
name|producer
operator|=
name|p
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|init (SubsetConfiguration conf)
specifier|public
name|void
name|init
parameter_list|(
name|SubsetConfiguration
name|conf
parameter_list|)
block|{
comment|// Get Kafka broker configuration.
name|Properties
name|props
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|brokerList
operator|=
name|conf
operator|.
name|getString
argument_list|(
name|BROKER_LIST
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Broker list "
operator|+
name|brokerList
argument_list|)
expr_stmt|;
block|}
name|props
operator|.
name|put
argument_list|(
literal|"bootstrap.servers"
argument_list|,
name|brokerList
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Kafka brokers: "
operator|+
name|brokerList
argument_list|)
expr_stmt|;
block|}
comment|// Get Kafka topic configuration.
name|topic
operator|=
name|conf
operator|.
name|getString
argument_list|(
name|TOPIC
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Kafka topic "
operator|+
name|topic
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Strings
operator|.
name|isNullOrEmpty
argument_list|(
name|topic
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Kafka topic can not be null"
argument_list|)
throw|;
block|}
comment|// Set the rest of Kafka configuration.
name|props
operator|.
name|put
argument_list|(
literal|"key.serializer"
argument_list|,
literal|"org.apache.kafka.common.serialization.ByteArraySerializer"
argument_list|)
expr_stmt|;
name|props
operator|.
name|put
argument_list|(
literal|"value.serializer"
argument_list|,
literal|"org.apache.kafka.common.serialization.ByteArraySerializer"
argument_list|)
expr_stmt|;
name|props
operator|.
name|put
argument_list|(
literal|"request.required.acks"
argument_list|,
literal|"0"
argument_list|)
expr_stmt|;
comment|// Set the hostname once and use it in every message.
name|hostname
operator|=
literal|"null"
expr_stmt|;
try|try
block|{
name|hostname
operator|=
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
operator|.
name|getHostName
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error getting Hostname, going to continue"
argument_list|)
expr_stmt|;
block|}
try|try
block|{
comment|// Create the producer object.
name|producer
operator|=
operator|new
name|KafkaProducer
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|(
name|props
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error creating Producer, "
operator|+
name|brokerList
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|putMetrics (MetricsRecord record)
specifier|public
name|void
name|putMetrics
parameter_list|(
name|MetricsRecord
name|record
parameter_list|)
block|{
if|if
condition|(
name|producer
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Producer in KafkaSink is null!"
argument_list|)
throw|;
block|}
comment|// Create the json object.
name|StringBuilder
name|jsonLines
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|long
name|timestamp
init|=
name|record
operator|.
name|timestamp
argument_list|()
decl_stmt|;
name|Instant
name|instant
init|=
name|Instant
operator|.
name|ofEpochMilli
argument_list|(
name|timestamp
argument_list|)
decl_stmt|;
name|LocalDateTime
name|ldt
init|=
name|LocalDateTime
operator|.
name|ofInstant
argument_list|(
name|instant
argument_list|,
name|zoneId
argument_list|)
decl_stmt|;
name|String
name|date
init|=
name|ldt
operator|.
name|format
argument_list|(
name|dateFormat
argument_list|)
decl_stmt|;
name|String
name|time
init|=
name|ldt
operator|.
name|format
argument_list|(
name|timeFormat
argument_list|)
decl_stmt|;
comment|// Collect datapoints and populate the json object.
name|jsonLines
operator|.
name|append
argument_list|(
literal|"{\"hostname\": \""
operator|+
name|hostname
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|"\", \"timestamp\": "
operator|+
name|timestamp
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|", \"date\": \""
operator|+
name|date
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|"\",\"time\": \""
operator|+
name|time
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|"\",\"name\": \""
operator|+
name|record
operator|.
name|name
argument_list|()
operator|+
literal|"\" "
argument_list|)
expr_stmt|;
for|for
control|(
name|MetricsTag
name|tag
range|:
name|record
operator|.
name|tags
argument_list|()
control|)
block|{
name|jsonLines
operator|.
name|append
argument_list|(
literal|", \""
operator|+
name|tag
operator|.
name|name
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"[\\p{Cc}]"
argument_list|,
literal|""
argument_list|)
operator|+
literal|"\": "
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|" \""
operator|+
name|tag
operator|.
name|value
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|AbstractMetric
name|metric
range|:
name|record
operator|.
name|metrics
argument_list|()
control|)
block|{
name|jsonLines
operator|.
name|append
argument_list|(
literal|", \""
operator|+
name|metric
operator|.
name|name
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"[\\p{Cc}]"
argument_list|,
literal|""
argument_list|)
operator|+
literal|"\": "
argument_list|)
expr_stmt|;
name|jsonLines
operator|.
name|append
argument_list|(
literal|" \""
operator|+
name|metric
operator|.
name|value
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|"\""
argument_list|)
expr_stmt|;
block|}
name|jsonLines
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"kafka message: "
operator|+
name|jsonLines
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
comment|// Create the record to be sent from the json.
name|ProducerRecord
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
name|data
init|=
operator|new
name|ProducerRecord
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|(
name|topic
argument_list|,
name|jsonLines
operator|.
name|toString
argument_list|()
operator|.
name|getBytes
argument_list|(
name|Charset
operator|.
name|forName
argument_list|(
literal|"UTF-8"
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|// Send the data to the Kafka broker. Here is an example of this data:
comment|// {"hostname": "...", "timestamp": 1436913651516,
comment|// "date": "2015-6-14","time": "22:40:51","context": "yarn","name":
comment|// "QueueMetrics, "running_0": "1", "running_60": "0", "running_300": "0",
comment|// "running_1440": "0", "AppsSubmitted": "1", "AppsRunning": "1",
comment|// "AppsPending": "0", "AppsCompleted": "0", "AppsKilled": "0",
comment|// "AppsFailed": "0", "AllocatedMB": "134656", "AllocatedVCores": "132",
comment|// "AllocatedContainers": "132", "AggregateContainersAllocated": "132",
comment|// "AggregateContainersReleased": "0", "AvailableMB": "0",
comment|// "AvailableVCores": "0", "PendingMB": "275456", "PendingVCores": "269",
comment|// "PendingContainers": "269", "ReservedMB": "0", "ReservedVCores": "0",
comment|// "ReservedContainers": "0", "ActiveUsers": "1", "ActiveApplications": "1"}
name|Future
argument_list|<
name|RecordMetadata
argument_list|>
name|future
init|=
name|producer
operator|.
name|send
argument_list|(
name|data
argument_list|)
decl_stmt|;
name|jsonLines
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error sending data"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error sending data"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
DECL|method|flush ()
specifier|public
name|void
name|flush
parameter_list|()
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Kafka seems not to have any flush() mechanism!"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
DECL|method|close ()
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Close the producer and set it to null.
try|try
block|{
name|producer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|MetricsException
argument_list|(
literal|"Error closing producer"
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|producer
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

