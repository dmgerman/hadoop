begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.streaming
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|streaming
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStreamReader
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStreamWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|StringTokenizer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|ClusterMapReduceTestCase
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Counters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|JobConf
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|RunningJob
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|SkipBadRecords
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|Utils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|server
operator|.
name|jobtracker
operator|.
name|JTConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_class
DECL|class|TestStreamingBadRecords
specifier|public
class|class
name|TestStreamingBadRecords
extends|extends
name|ClusterMapReduceTestCase
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TestStreamingBadRecords
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|MAPPER_BAD_RECORDS
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|MAPPER_BAD_RECORDS
init|=
name|Arrays
operator|.
name|asList
argument_list|(
literal|"hey022"
argument_list|,
literal|"hey023"
argument_list|,
literal|"hey099"
argument_list|)
decl_stmt|;
DECL|field|REDUCER_BAD_RECORDS
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|String
argument_list|>
name|REDUCER_BAD_RECORDS
init|=
name|Arrays
operator|.
name|asList
argument_list|(
literal|"hey001"
argument_list|,
literal|"hey018"
argument_list|)
decl_stmt|;
DECL|field|badMapper
specifier|private
specifier|static
specifier|final
name|String
name|badMapper
init|=
name|UtilTest
operator|.
name|makeJavaCommand
argument_list|(
name|BadApp
operator|.
name|class
argument_list|,
operator|new
name|String
index|[]
block|{}
argument_list|)
decl_stmt|;
DECL|field|badReducer
specifier|private
specifier|static
specifier|final
name|String
name|badReducer
init|=
name|UtilTest
operator|.
name|makeJavaCommand
argument_list|(
name|BadApp
operator|.
name|class
argument_list|,
operator|new
name|String
index|[]
block|{
literal|"true"
block|}
argument_list|)
decl_stmt|;
DECL|field|INPUTSIZE
specifier|private
specifier|static
specifier|final
name|int
name|INPUTSIZE
init|=
literal|100
decl_stmt|;
DECL|method|TestStreamingBadRecords ()
specifier|public
name|TestStreamingBadRecords
parameter_list|()
throws|throws
name|IOException
block|{
name|UtilTest
name|utilTest
init|=
operator|new
name|UtilTest
argument_list|(
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|utilTest
operator|.
name|checkUserDir
argument_list|()
expr_stmt|;
name|utilTest
operator|.
name|redirectIfAntJunit
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Before
DECL|method|setUp ()
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|Properties
name|props
init|=
operator|new
name|Properties
argument_list|()
decl_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
name|JTConfig
operator|.
name|JT_RETIREJOBS
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|props
operator|.
name|setProperty
argument_list|(
name|JTConfig
operator|.
name|JT_PERSIST_JOBSTATUS
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
name|startCluster
argument_list|(
literal|true
argument_list|,
name|props
argument_list|)
expr_stmt|;
block|}
DECL|method|createInput ()
specifier|private
name|void
name|createInput
parameter_list|()
throws|throws
name|Exception
block|{
name|OutputStream
name|os
init|=
name|getFileSystem
argument_list|()
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
name|getInputDir
argument_list|()
argument_list|,
literal|"text.txt"
argument_list|)
argument_list|)
decl_stmt|;
name|Writer
name|wr
init|=
operator|new
name|OutputStreamWriter
argument_list|(
name|os
argument_list|)
decl_stmt|;
comment|//increasing the record size so that we have stream flushing
name|String
name|prefix
init|=
operator|new
name|String
argument_list|(
operator|new
name|byte
index|[
literal|20
operator|*
literal|1024
index|]
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
name|INPUTSIZE
condition|;
name|i
operator|++
control|)
block|{
name|String
name|str
init|=
literal|""
operator|+
name|i
decl_stmt|;
name|int
name|zerosToPrepend
init|=
literal|3
operator|-
name|str
operator|.
name|length
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|zerosToPrepend
condition|;
name|j
operator|++
control|)
block|{
name|str
operator|=
literal|"0"
operator|+
name|str
expr_stmt|;
block|}
name|wr
operator|.
name|write
argument_list|(
name|prefix
operator|+
literal|"hey"
operator|+
name|str
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|wr
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
DECL|method|validateOutput (RunningJob runningJob, boolean validateCount)
specifier|private
name|void
name|validateOutput
parameter_list|(
name|RunningJob
name|runningJob
parameter_list|,
name|boolean
name|validateCount
parameter_list|)
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
name|runningJob
operator|.
name|getCounters
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|runningJob
operator|.
name|isSuccessful
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|validateCount
condition|)
block|{
comment|//validate counters
name|String
name|counterGrp
init|=
literal|"org.apache.hadoop.mapred.Task$Counter"
decl_stmt|;
name|Counters
name|counters
init|=
name|runningJob
operator|.
name|getCounters
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"MAP_SKIPPED_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|MAPPER_BAD_RECORDS
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|mapRecs
init|=
name|INPUTSIZE
operator|-
name|MAPPER_BAD_RECORDS
operator|.
name|size
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"MAP_INPUT_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|mapRecs
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"MAP_OUTPUT_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|mapRecs
argument_list|)
expr_stmt|;
name|int
name|redRecs
init|=
name|mapRecs
operator|-
name|REDUCER_BAD_RECORDS
operator|.
name|size
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"REDUCE_SKIPPED_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|REDUCER_BAD_RECORDS
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"REDUCE_SKIPPED_GROUPS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|REDUCER_BAD_RECORDS
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"REDUCE_INPUT_GROUPS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|redRecs
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"REDUCE_INPUT_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|redRecs
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|counters
operator|.
name|findCounter
argument_list|(
name|counterGrp
argument_list|,
literal|"REDUCE_OUTPUT_RECORDS"
argument_list|)
operator|.
name|getCounter
argument_list|()
argument_list|,
name|redRecs
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|badRecs
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|badRecs
operator|.
name|addAll
argument_list|(
name|MAPPER_BAD_RECORDS
argument_list|)
expr_stmt|;
name|badRecs
operator|.
name|addAll
argument_list|(
name|REDUCER_BAD_RECORDS
argument_list|)
expr_stmt|;
name|Path
index|[]
name|outputFiles
init|=
name|FileUtil
operator|.
name|stat2Paths
argument_list|(
name|getFileSystem
argument_list|()
operator|.
name|listStatus
argument_list|(
name|getOutputDir
argument_list|()
argument_list|,
operator|new
name|Utils
operator|.
name|OutputFileUtils
operator|.
name|OutputFilesFilter
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|outputFiles
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|InputStream
name|is
init|=
name|getFileSystem
argument_list|()
operator|.
name|open
argument_list|(
name|outputFiles
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|BufferedReader
name|reader
init|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|is
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|line
init|=
name|reader
operator|.
name|readLine
argument_list|()
decl_stmt|;
name|int
name|counter
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|line
operator|!=
literal|null
condition|)
block|{
name|counter
operator|++
expr_stmt|;
name|StringTokenizer
name|tokeniz
init|=
operator|new
name|StringTokenizer
argument_list|(
name|line
argument_list|,
literal|"\t"
argument_list|)
decl_stmt|;
name|String
name|value
init|=
name|tokeniz
operator|.
name|nextToken
argument_list|()
decl_stmt|;
name|int
name|index
init|=
name|value
operator|.
name|indexOf
argument_list|(
literal|"hey"
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|index
operator|>
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|index
operator|>
operator|-
literal|1
condition|)
block|{
name|String
name|heyStr
init|=
name|value
operator|.
name|substring
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
operator|!
name|badRecs
operator|.
name|contains
argument_list|(
name|heyStr
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|line
operator|=
name|reader
operator|.
name|readLine
argument_list|()
expr_stmt|;
block|}
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|validateCount
condition|)
block|{
name|assertEquals
argument_list|(
name|INPUTSIZE
operator|-
name|badRecs
operator|.
name|size
argument_list|()
argument_list|,
name|counter
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/*    * Disable test as skipping bad records not supported in 0.23    */
comment|/*   public void testSkip() throws Exception {     JobConf clusterConf = createJobConf();     createInput();     int attSkip =0;     SkipBadRecords.setAttemptsToStartSkipping(clusterConf,attSkip);     //the no of attempts to successfully complete the task depends      //on the no of bad records.     int mapperAttempts = attSkip+1+MAPPER_BAD_RECORDS.size();     int reducerAttempts = attSkip+1+REDUCER_BAD_RECORDS.size();          String[] args =  new String[] {       "-input", (new Path(getInputDir(), "text.txt")).toString(),       "-output", getOutputDir().toString(),       "-mapper", badMapper,       "-reducer", badReducer,       "-verbose",       "-inputformat", "org.apache.hadoop.mapred.KeyValueTextInputFormat",       "-jobconf", "mapreduce.task.skip.start.attempts="+attSkip,       "-jobconf", "mapreduce.job.skip.outdir=none",       "-jobconf", "mapreduce.map.maxattempts="+mapperAttempts,       "-jobconf", "mapreduce.reduce.maxattempts="+reducerAttempts,       "-jobconf", "mapreduce.map.skip.maxrecords="+Long.MAX_VALUE,       "-jobconf", "mapreduce.reduce.skip.maxgroups="+Long.MAX_VALUE,       "-jobconf", "mapreduce.job.maps=1",       "-jobconf", "mapreduce.job.reduces=1",       "-jobconf", "fs.default.name="+clusterConf.get("fs.default.name"),       "-jobconf", "mapreduce.jobtracker.address=" +                     clusterConf.get(JTConfig.JT_IPC_ADDRESS),       "-jobconf", "mapreduce.jobtracker.http.address="                     +clusterConf.get(JTConfig.JT_HTTP_ADDRESS),       "-jobconf", "mapreduce.task.files.preserve.failedtasks=true",       "-jobconf", "stream.tmpdir="+System.getProperty("test.build.data","/tmp"),       "-jobconf", "mapred.jar=" + TestStreaming.STREAMING_JAR,       "-jobconf", "mapreduce.framework.name=yarn"     };     StreamJob job = new StreamJob(args, false);           job.go();     validateOutput(job.running_, false);     //validate that there is no skip directory as it has been set to "none"     assertTrue(SkipBadRecords.getSkipOutputPath(job.jobConf_)==null);   }   */
comment|/*    * Disable test as skipping bad records not supported in 0.23    */
comment|/*   public void testNarrowDown() throws Exception {     createInput();     JobConf clusterConf = createJobConf();     String[] args =  new String[] {       "-input", (new Path(getInputDir(), "text.txt")).toString(),       "-output", getOutputDir().toString(),       "-mapper", badMapper,       "-reducer", badReducer,       "-verbose",       "-inputformat", "org.apache.hadoop.mapred.KeyValueTextInputFormat",       "-jobconf", "mapreduce.task.skip.start.attempts=1",       //actually fewer attempts are required than specified       //but to cater to the case of slow processed counter update, need to        //have more attempts       "-jobconf", "mapreduce.map.maxattempts=20",       "-jobconf", "mapreduce.reduce.maxattempts=15",       "-jobconf", "mapreduce.map.skip.maxrecords=1",       "-jobconf", "mapreduce.reduce.skip.maxgroups=1",       "-jobconf", "mapreduce.job.maps=1",       "-jobconf", "mapreduce.job.reduces=1",       "-jobconf", "fs.default.name="+clusterConf.get("fs.default.name"),       "-jobconf", "mapreduce.jobtracker.address="+clusterConf.get(JTConfig.JT_IPC_ADDRESS),       "-jobconf", "mapreduce.jobtracker.http.address="                     +clusterConf.get(JTConfig.JT_HTTP_ADDRESS),       "-jobconf", "mapreduce.task.files.preserve.failedtasks=true",       "-jobconf", "stream.tmpdir="+System.getProperty("test.build.data","/tmp"),       "-jobconf", "mapred.jar=" + TestStreaming.STREAMING_JAR,       "-jobconf", "mapreduce.framework.name=yarn"     };     StreamJob job = new StreamJob(args, false);           job.go();          validateOutput(job.running_, true);     assertTrue(SkipBadRecords.getSkipOutputPath(job.jobConf_)!=null);   }   */
annotation|@
name|Test
DECL|method|testNoOp ()
specifier|public
name|void
name|testNoOp
parameter_list|()
block|{
comment|// Added to avoid warnings when running this disabled test
block|}
DECL|class|App
specifier|static
class|class
name|App
block|{
DECL|field|isReducer
name|boolean
name|isReducer
decl_stmt|;
DECL|method|App (String[] args)
specifier|public
name|App
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|isReducer
operator|=
name|Boolean
operator|.
name|parseBoolean
argument_list|(
name|args
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
block|}
name|String
name|counter
init|=
name|SkipBadRecords
operator|.
name|COUNTER_MAP_PROCESSED_RECORDS
decl_stmt|;
if|if
condition|(
name|isReducer
condition|)
block|{
name|counter
operator|=
name|SkipBadRecords
operator|.
name|COUNTER_REDUCE_PROCESSED_GROUPS
expr_stmt|;
block|}
name|BufferedReader
name|in
init|=
operator|new
name|BufferedReader
argument_list|(
operator|new
name|InputStreamReader
argument_list|(
name|System
operator|.
name|in
argument_list|)
argument_list|)
decl_stmt|;
name|String
name|line
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
while|while
condition|(
operator|(
name|line
operator|=
name|in
operator|.
name|readLine
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|processLine
argument_list|(
name|line
argument_list|)
expr_stmt|;
name|count
operator|++
expr_stmt|;
if|if
condition|(
name|count
operator|>=
literal|10
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"reporter:counter:"
operator|+
name|SkipBadRecords
operator|.
name|COUNTER_GROUP
operator|+
literal|","
operator|+
name|counter
operator|+
literal|","
operator|+
name|count
argument_list|)
expr_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
DECL|method|processLine (String line)
specifier|protected
name|void
name|processLine
parameter_list|(
name|String
name|line
parameter_list|)
throws|throws
name|Exception
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|line
argument_list|)
expr_stmt|;
block|}
DECL|method|main (String[] args)
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
operator|new
name|App
argument_list|(
name|args
argument_list|)
expr_stmt|;
block|}
block|}
DECL|class|BadApp
specifier|static
class|class
name|BadApp
extends|extends
name|App
block|{
DECL|method|BadApp (String[] args)
specifier|public
name|BadApp
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|super
argument_list|(
name|args
argument_list|)
expr_stmt|;
block|}
DECL|method|processLine (String line)
specifier|protected
name|void
name|processLine
parameter_list|(
name|String
name|line
parameter_list|)
throws|throws
name|Exception
block|{
name|List
argument_list|<
name|String
argument_list|>
name|badRecords
init|=
name|MAPPER_BAD_RECORDS
decl_stmt|;
if|if
condition|(
name|isReducer
condition|)
block|{
name|badRecords
operator|=
name|REDUCER_BAD_RECORDS
expr_stmt|;
block|}
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|line
operator|.
name|contains
argument_list|(
name|badRecords
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Encountered BAD record"
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|1
operator|&&
name|line
operator|.
name|contains
argument_list|(
name|badRecords
operator|.
name|get
argument_list|(
literal|1
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Encountered BAD record"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|Exception
argument_list|(
literal|"Got bad record..crashing"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|badRecords
operator|.
name|size
argument_list|()
operator|>
literal|2
operator|&&
name|line
operator|.
name|contains
argument_list|(
name|badRecords
operator|.
name|get
argument_list|(
literal|2
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Encountered BAD record"
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|processLine
argument_list|(
name|line
argument_list|)
expr_stmt|;
block|}
DECL|method|main (String[] args)
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
operator|new
name|BadApp
argument_list|(
name|args
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

