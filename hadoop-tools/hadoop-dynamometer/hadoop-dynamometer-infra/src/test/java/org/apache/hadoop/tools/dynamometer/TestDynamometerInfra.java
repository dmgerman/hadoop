begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
DECL|package|org.apache.hadoop.tools.dynamometer
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|dynamometer
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Supplier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|PlatformAssumptions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|dynamometer
operator|.
name|workloadgenerator
operator|.
name|audit
operator|.
name|AuditLogDirectParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|dynamometer
operator|.
name|workloadgenerator
operator|.
name|audit
operator|.
name|AuditReplayMapper
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URISyntaxException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URL
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Properties
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|ZipEntry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|zip
operator|.
name|ZipOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|DistributedFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|test
operator|.
name|GenericTestUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Counters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|JarFinder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Shell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|ApplicationId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|ApplicationReport
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|ContainerId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|NodeId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|api
operator|.
name|records
operator|.
name|YarnApplicationState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|client
operator|.
name|api
operator|.
name|YarnClient
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|conf
operator|.
name|YarnConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|exceptions
operator|.
name|YarnException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|MiniYARNCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|nodemanager
operator|.
name|containermanager
operator|.
name|container
operator|.
name|Container
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|resourcemanager
operator|.
name|nodelabels
operator|.
name|RMNodeLabelsManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|server
operator|.
name|resourcemanager
operator|.
name|scheduler
operator|.
name|capacity
operator|.
name|CapacitySchedulerConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|resource
operator|.
name|DominantResourceCalculator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|yarn
operator|.
name|util
operator|.
name|resource
operator|.
name|ResourceCalculator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|AfterClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assume
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|tools
operator|.
name|dynamometer
operator|.
name|DynoInfraUtils
operator|.
name|fetchHadoopTarball
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
operator|.
name|PROP_TEST_BUILD_DATA
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|hamcrest
operator|.
name|CoreMatchers
operator|.
name|notNullValue
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|fail
import|;
end_import

begin_comment
comment|/**  * Start a Dynamometer cluster in a MiniYARNCluster. Ensure that the NameNode is  * able to start correctly, exit safemode, and run some commands. Subsequently  * the workload job is launched and it is verified that it completes  * successfully and is able to replay commands as expected.  *  * To run this test JAVA_HOME must be set correctly, and the {@code tar} utility  * must be available.  *  * You can optionally specify which version of HDFS should be started within the  * Dynamometer cluster; the default is {@value HADOOP_BIN_VERSION_DEFAULT}. This  * can be adjusted by setting the {@value HADOOP_BIN_VERSION_KEY} property. This  * will automatically download the correct Hadoop tarball for the specified  * version. It downloads from an Apache mirror (by default  * {@value DynoInfraUtils#APACHE_DOWNLOAD_MIRROR_DEFAULT}); which mirror is used  * can be controlled with the {@value DynoInfraUtils#APACHE_DOWNLOAD_MIRROR_KEY}  * property. Note that mirrors normally contain only the latest releases on any  * given release line; you may need to use  * {@code http://archive.apache.org/dist/} for older releases. The downloaded  * tarball will be stored in the test directory and can be reused between test  * executions. Alternatively, you can specify the {@value HADOOP_BIN_PATH_KEY}  * property to point directly to a Hadoop tarball which is present locally and  * no download will occur.  */
end_comment

begin_class
DECL|class|TestDynamometerInfra
specifier|public
class|class
name|TestDynamometerInfra
block|{
DECL|field|LOG
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|TestDynamometerInfra
operator|.
name|class
argument_list|)
decl_stmt|;
DECL|field|MINICLUSTER_NUM_NMS
specifier|private
specifier|static
specifier|final
name|int
name|MINICLUSTER_NUM_NMS
init|=
literal|3
decl_stmt|;
DECL|field|MINICLUSTER_NUM_DNS
specifier|private
specifier|static
specifier|final
name|int
name|MINICLUSTER_NUM_DNS
init|=
literal|1
decl_stmt|;
DECL|field|HADOOP_BIN_PATH_KEY
specifier|private
specifier|static
specifier|final
name|String
name|HADOOP_BIN_PATH_KEY
init|=
literal|"dyno.hadoop.bin.path"
decl_stmt|;
DECL|field|HADOOP_BIN_VERSION_KEY
specifier|private
specifier|static
specifier|final
name|String
name|HADOOP_BIN_VERSION_KEY
init|=
literal|"dyno.hadoop.bin.version"
decl_stmt|;
DECL|field|HADOOP_BIN_VERSION_DEFAULT
specifier|private
specifier|static
specifier|final
name|String
name|HADOOP_BIN_VERSION_DEFAULT
init|=
literal|"3.1.3"
decl_stmt|;
DECL|field|FSIMAGE_FILENAME
specifier|private
specifier|static
specifier|final
name|String
name|FSIMAGE_FILENAME
init|=
literal|"fsimage_0000000000000061740"
decl_stmt|;
DECL|field|VERSION_FILENAME
specifier|private
specifier|static
specifier|final
name|String
name|VERSION_FILENAME
init|=
literal|"VERSION"
decl_stmt|;
DECL|field|HADOOP_BIN_UNPACKED_DIR_PREFIX
specifier|private
specifier|static
specifier|final
name|String
name|HADOOP_BIN_UNPACKED_DIR_PREFIX
init|=
literal|"hadoop_unpacked_"
decl_stmt|;
DECL|field|NAMENODE_NODELABEL
specifier|private
specifier|static
specifier|final
name|String
name|NAMENODE_NODELABEL
init|=
literal|"dyno_namenode"
decl_stmt|;
DECL|field|DATANODE_NODELABEL
specifier|private
specifier|static
specifier|final
name|String
name|DATANODE_NODELABEL
init|=
literal|"dyno_datanode"
decl_stmt|;
DECL|field|OUTPUT_PATH
specifier|private
specifier|static
specifier|final
name|String
name|OUTPUT_PATH
init|=
literal|"/tmp/trace_output_direct"
decl_stmt|;
DECL|field|miniDFSCluster
specifier|private
specifier|static
name|MiniDFSCluster
name|miniDFSCluster
decl_stmt|;
DECL|field|miniYARNCluster
specifier|private
specifier|static
name|MiniYARNCluster
name|miniYARNCluster
decl_stmt|;
DECL|field|yarnClient
specifier|private
specifier|static
name|YarnClient
name|yarnClient
decl_stmt|;
DECL|field|fs
specifier|private
specifier|static
name|FileSystem
name|fs
decl_stmt|;
DECL|field|conf
specifier|private
specifier|static
name|Configuration
name|conf
decl_stmt|;
DECL|field|yarnConf
specifier|private
specifier|static
name|Configuration
name|yarnConf
decl_stmt|;
DECL|field|fsImageTmpPath
specifier|private
specifier|static
name|Path
name|fsImageTmpPath
decl_stmt|;
DECL|field|fsVersionTmpPath
specifier|private
specifier|static
name|Path
name|fsVersionTmpPath
decl_stmt|;
DECL|field|blockImageOutputDir
specifier|private
specifier|static
name|Path
name|blockImageOutputDir
decl_stmt|;
DECL|field|auditTraceDir
specifier|private
specifier|static
name|Path
name|auditTraceDir
decl_stmt|;
DECL|field|confZip
specifier|private
specifier|static
name|Path
name|confZip
decl_stmt|;
DECL|field|testBaseDir
specifier|private
specifier|static
name|File
name|testBaseDir
decl_stmt|;
DECL|field|hadoopTarballPath
specifier|private
specifier|static
name|File
name|hadoopTarballPath
decl_stmt|;
DECL|field|hadoopUnpackedDir
specifier|private
specifier|static
name|File
name|hadoopUnpackedDir
decl_stmt|;
DECL|field|infraAppId
specifier|private
name|ApplicationId
name|infraAppId
decl_stmt|;
annotation|@
name|BeforeClass
DECL|method|setupClass ()
specifier|public
specifier|static
name|void
name|setupClass
parameter_list|()
throws|throws
name|Exception
block|{
name|PlatformAssumptions
operator|.
name|assumeNotWindows
argument_list|(
literal|"Dynamometer will not run on Windows"
argument_list|)
expr_stmt|;
name|Assume
operator|.
name|assumeThat
argument_list|(
literal|"JAVA_HOME must be set properly"
argument_list|,
name|System
operator|.
name|getenv
argument_list|(
literal|"JAVA_HOME"
argument_list|)
argument_list|,
name|notNullValue
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|Shell
operator|.
name|ShellCommandExecutor
name|tarCheck
init|=
operator|new
name|Shell
operator|.
name|ShellCommandExecutor
argument_list|(
operator|new
name|String
index|[]
block|{
literal|"bash"
block|,
literal|"-c"
block|,
literal|"command -v tar"
block|}
argument_list|)
decl_stmt|;
name|tarCheck
operator|.
name|execute
argument_list|()
expr_stmt|;
name|Assume
operator|.
name|assumeTrue
argument_list|(
literal|"tar command is not available"
argument_list|,
name|tarCheck
operator|.
name|getExitCode
argument_list|()
operator|==
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|Assume
operator|.
name|assumeNoException
argument_list|(
literal|"Unable to execute a shell command"
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
name|conf
operator|=
operator|new
name|Configuration
argument_list|()
expr_stmt|;
comment|// Follow the conventions of MiniDFSCluster
name|testBaseDir
operator|=
operator|new
name|File
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
name|PROP_TEST_BUILD_DATA
argument_list|,
literal|"build/test/data"
argument_list|)
argument_list|)
expr_stmt|;
name|String
name|hadoopBinVersion
init|=
name|System
operator|.
name|getProperty
argument_list|(
name|HADOOP_BIN_VERSION_KEY
argument_list|,
name|HADOOP_BIN_VERSION_DEFAULT
argument_list|)
decl_stmt|;
if|if
condition|(
name|System
operator|.
name|getProperty
argument_list|(
name|HADOOP_BIN_PATH_KEY
argument_list|)
operator|==
literal|null
condition|)
block|{
name|hadoopTarballPath
operator|=
name|fetchHadoopTarball
argument_list|(
name|testBaseDir
argument_list|,
name|hadoopBinVersion
argument_list|,
name|conf
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hadoopTarballPath
operator|=
operator|new
name|File
argument_list|(
name|System
operator|.
name|getProperty
argument_list|(
name|HADOOP_BIN_PATH_KEY
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|testBaseDir
operator|.
name|exists
argument_list|()
condition|)
block|{
comment|// Delete any old unpacked bin dirs that weren't previously cleaned up
name|File
index|[]
name|oldUnpackedDirs
init|=
name|testBaseDir
operator|.
name|listFiles
argument_list|(
parameter_list|(
name|dir
parameter_list|,
name|name
parameter_list|)
lambda|->
name|name
operator|.
name|startsWith
argument_list|(
name|HADOOP_BIN_UNPACKED_DIR_PREFIX
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldUnpackedDirs
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|File
name|oldDir
range|:
name|oldUnpackedDirs
control|)
block|{
name|FileUtils
operator|.
name|deleteQuietly
argument_list|(
name|oldDir
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Set up the Hadoop binary to be used as the system-level Hadoop install
name|hadoopUnpackedDir
operator|=
operator|new
name|File
argument_list|(
name|testBaseDir
argument_list|,
name|HADOOP_BIN_UNPACKED_DIR_PREFIX
operator|+
name|UUID
operator|.
name|randomUUID
argument_list|()
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Failed to make temporary directory"
argument_list|,
name|hadoopUnpackedDir
operator|.
name|mkdirs
argument_list|()
argument_list|)
expr_stmt|;
name|Shell
operator|.
name|ShellCommandExecutor
name|shexec
init|=
operator|new
name|Shell
operator|.
name|ShellCommandExecutor
argument_list|(
operator|new
name|String
index|[]
block|{
literal|"tar"
block|,
literal|"xzf"
block|,
name|hadoopTarballPath
operator|.
name|getAbsolutePath
argument_list|()
block|,
literal|"-C"
block|,
name|hadoopUnpackedDir
operator|.
name|getAbsolutePath
argument_list|()
block|}
argument_list|)
decl_stmt|;
name|shexec
operator|.
name|execute
argument_list|()
expr_stmt|;
if|if
condition|(
name|shexec
operator|.
name|getExitCode
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|fail
argument_list|(
literal|"Unable to execute tar to expand Hadoop binary"
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|setInt
argument_list|(
name|YarnConfiguration
operator|.
name|RM_SCHEDULER_MINIMUM_ALLOCATION_MB
argument_list|,
literal|128
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|YarnConfiguration
operator|.
name|NODE_LABELS_ENABLED
argument_list|,
literal|true
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|q
range|:
operator|new
name|String
index|[]
block|{
literal|"root"
block|,
literal|"root.default"
block|}
control|)
block|{
name|conf
operator|.
name|setInt
argument_list|(
name|CapacitySchedulerConfiguration
operator|.
name|PREFIX
operator|+
name|q
operator|+
literal|"."
operator|+
name|CapacitySchedulerConfiguration
operator|.
name|CAPACITY
argument_list|,
literal|100
argument_list|)
expr_stmt|;
name|String
name|accessibleNodeLabelPrefix
init|=
name|CapacitySchedulerConfiguration
operator|.
name|PREFIX
operator|+
name|q
operator|+
literal|"."
operator|+
name|CapacitySchedulerConfiguration
operator|.
name|ACCESSIBLE_NODE_LABELS
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|accessibleNodeLabelPrefix
argument_list|,
name|CapacitySchedulerConfiguration
operator|.
name|ALL_ACL
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|accessibleNodeLabelPrefix
operator|+
literal|"."
operator|+
name|DATANODE_NODELABEL
operator|+
literal|"."
operator|+
name|CapacitySchedulerConfiguration
operator|.
name|CAPACITY
argument_list|,
literal|100
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setInt
argument_list|(
name|accessibleNodeLabelPrefix
operator|+
literal|"."
operator|+
name|NAMENODE_NODELABEL
operator|+
literal|"."
operator|+
name|CapacitySchedulerConfiguration
operator|.
name|CAPACITY
argument_list|,
literal|100
argument_list|)
expr_stmt|;
block|}
comment|// This is necessary to have the RM respect our vcore allocation request
name|conf
operator|.
name|setClass
argument_list|(
name|CapacitySchedulerConfiguration
operator|.
name|RESOURCE_CALCULATOR_CLASS
argument_list|,
name|DominantResourceCalculator
operator|.
name|class
argument_list|,
name|ResourceCalculator
operator|.
name|class
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|YarnConfiguration
operator|.
name|NM_DISK_HEALTH_CHECK_ENABLE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|=
operator|new
name|MiniYARNCluster
argument_list|(
name|TestDynamometerInfra
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
literal|1
argument_list|,
name|MINICLUSTER_NUM_NMS
argument_list|,
literal|1
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|.
name|init
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|.
name|start
argument_list|()
expr_stmt|;
name|yarnConf
operator|=
name|miniYARNCluster
operator|.
name|getConfig
argument_list|()
expr_stmt|;
name|miniDFSCluster
operator|=
operator|new
name|MiniDFSCluster
operator|.
name|Builder
argument_list|(
name|conf
argument_list|)
operator|.
name|format
argument_list|(
literal|true
argument_list|)
operator|.
name|numDataNodes
argument_list|(
name|MINICLUSTER_NUM_DNS
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|miniDFSCluster
operator|.
name|waitClusterUp
argument_list|()
expr_stmt|;
name|FileSystem
operator|.
name|setDefaultUri
argument_list|(
name|conf
argument_list|,
name|miniDFSCluster
operator|.
name|getURI
argument_list|()
argument_list|)
expr_stmt|;
name|FileSystem
operator|.
name|setDefaultUri
argument_list|(
name|yarnConf
argument_list|,
name|miniDFSCluster
operator|.
name|getURI
argument_list|()
argument_list|)
expr_stmt|;
name|fs
operator|=
name|miniDFSCluster
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
name|URL
name|url
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getContextClassLoader
argument_list|()
operator|.
name|getResource
argument_list|(
literal|"yarn-site.xml"
argument_list|)
decl_stmt|;
if|if
condition|(
name|url
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Could not find 'yarn-site.xml' dummy file in classpath"
argument_list|)
throw|;
block|}
name|yarnConf
operator|.
name|set
argument_list|(
name|YarnConfiguration
operator|.
name|YARN_APPLICATION_CLASSPATH
argument_list|,
operator|new
name|File
argument_list|(
name|url
operator|.
name|getPath
argument_list|()
argument_list|)
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
comment|// Write the XML to a buffer before writing to the file. writeXml() can
comment|// trigger a read of the existing yarn-site.xml, so writing directly could
comment|// trigger a read of the file while it is in an inconsistent state
comment|// (partially written)
try|try
init|(
name|ByteArrayOutputStream
name|bytesOut
init|=
operator|new
name|ByteArrayOutputStream
argument_list|()
init|)
block|{
name|yarnConf
operator|.
name|writeXml
argument_list|(
name|bytesOut
argument_list|)
expr_stmt|;
try|try
init|(
name|OutputStream
name|fileOut
init|=
operator|new
name|FileOutputStream
argument_list|(
operator|new
name|File
argument_list|(
name|url
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|)
init|)
block|{
name|fileOut
operator|.
name|write
argument_list|(
name|bytesOut
operator|.
name|toByteArray
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|yarnClient
operator|=
name|YarnClient
operator|.
name|createYarnClient
argument_list|()
expr_stmt|;
name|yarnClient
operator|.
name|init
argument_list|(
operator|new
name|Configuration
argument_list|(
name|yarnConf
argument_list|)
argument_list|)
expr_stmt|;
name|yarnClient
operator|.
name|start
argument_list|()
expr_stmt|;
name|fsImageTmpPath
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/"
operator|+
name|FSIMAGE_FILENAME
argument_list|)
argument_list|)
expr_stmt|;
name|fsVersionTmpPath
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/"
operator|+
name|VERSION_FILENAME
argument_list|)
argument_list|)
expr_stmt|;
name|blockImageOutputDir
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/blocks"
argument_list|)
argument_list|)
expr_stmt|;
name|auditTraceDir
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/audit_trace_direct"
argument_list|)
argument_list|)
expr_stmt|;
name|confZip
operator|=
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/conf.zip"
argument_list|)
argument_list|)
expr_stmt|;
name|uploadFsimageResourcesToHDFS
argument_list|(
name|hadoopBinVersion
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|.
name|waitForNodeManagersToConnect
argument_list|(
literal|30000
argument_list|)
expr_stmt|;
name|RMNodeLabelsManager
name|nodeLabelManager
init|=
name|miniYARNCluster
operator|.
name|getResourceManager
argument_list|()
operator|.
name|getRMContext
argument_list|()
operator|.
name|getNodeLabelManager
argument_list|()
decl_stmt|;
name|nodeLabelManager
operator|.
name|addToCluserNodeLabelsWithDefaultExclusivity
argument_list|(
name|Sets
operator|.
name|newHashSet
argument_list|(
name|NAMENODE_NODELABEL
argument_list|,
name|DATANODE_NODELABEL
argument_list|)
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|NodeId
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|nodeLabels
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|nodeLabels
operator|.
name|put
argument_list|(
name|miniYARNCluster
operator|.
name|getNodeManager
argument_list|(
literal|0
argument_list|)
operator|.
name|getNMContext
argument_list|()
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|Sets
operator|.
name|newHashSet
argument_list|(
name|NAMENODE_NODELABEL
argument_list|)
argument_list|)
expr_stmt|;
name|nodeLabels
operator|.
name|put
argument_list|(
name|miniYARNCluster
operator|.
name|getNodeManager
argument_list|(
literal|1
argument_list|)
operator|.
name|getNMContext
argument_list|()
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|Sets
operator|.
name|newHashSet
argument_list|(
name|DATANODE_NODELABEL
argument_list|)
argument_list|)
expr_stmt|;
name|nodeLabelManager
operator|.
name|addLabelsToNode
argument_list|(
name|nodeLabels
argument_list|)
expr_stmt|;
block|}
annotation|@
name|AfterClass
DECL|method|teardownClass ()
specifier|public
specifier|static
name|void
name|teardownClass
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|miniDFSCluster
operator|!=
literal|null
condition|)
block|{
name|miniDFSCluster
operator|.
name|shutdown
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|miniDFSCluster
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|yarnClient
operator|!=
literal|null
condition|)
block|{
name|yarnClient
operator|.
name|stop
argument_list|()
expr_stmt|;
name|yarnClient
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|miniYARNCluster
operator|!=
literal|null
condition|)
block|{
name|miniYARNCluster
operator|.
name|getResourceManager
argument_list|()
operator|.
name|stop
argument_list|()
expr_stmt|;
name|miniYARNCluster
operator|.
name|getResourceManager
argument_list|()
operator|.
name|waitForServiceToStop
argument_list|(
literal|30000
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|.
name|stop
argument_list|()
expr_stmt|;
name|miniYARNCluster
operator|.
name|waitForServiceToStop
argument_list|(
literal|30000
argument_list|)
expr_stmt|;
name|FileUtils
operator|.
name|deleteDirectory
argument_list|(
name|miniYARNCluster
operator|.
name|getTestWorkDir
argument_list|()
argument_list|)
expr_stmt|;
name|miniYARNCluster
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|hadoopUnpackedDir
operator|!=
literal|null
condition|)
block|{
name|FileUtils
operator|.
name|deleteDirectory
argument_list|(
name|hadoopUnpackedDir
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|After
DECL|method|tearDown ()
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
if|if
condition|(
name|infraAppId
operator|!=
literal|null
operator|&&
name|yarnClient
operator|!=
literal|null
condition|)
block|{
name|yarnClient
operator|.
name|killApplication
argument_list|(
name|infraAppId
argument_list|)
expr_stmt|;
block|}
name|infraAppId
operator|=
literal|null
expr_stmt|;
block|}
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|15
operator|*
literal|60
operator|*
literal|1000
argument_list|)
DECL|method|testNameNodeInYARN ()
specifier|public
name|void
name|testNameNodeInYARN
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|localConf
init|=
operator|new
name|Configuration
argument_list|(
name|yarnConf
argument_list|)
decl_stmt|;
name|localConf
operator|.
name|setLong
argument_list|(
name|AuditLogDirectParser
operator|.
name|AUDIT_START_TIMESTAMP_KEY
argument_list|,
literal|60000
argument_list|)
expr_stmt|;
specifier|final
name|Client
name|client
init|=
name|createAndStartClient
argument_list|(
name|localConf
argument_list|)
decl_stmt|;
name|awaitApplicationStartup
argument_list|()
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|maxWaitTimeMs
init|=
name|TimeUnit
operator|.
name|MINUTES
operator|.
name|toMillis
argument_list|(
literal|10
argument_list|)
decl_stmt|;
name|Supplier
argument_list|<
name|Boolean
argument_list|>
name|exitCheckSupplier
init|=
parameter_list|()
lambda|->
block|{
if|if
condition|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|>
name|maxWaitTimeMs
condition|)
block|{
comment|// Wait at most 10 minutes for the NameNode to start and be ready
return|return
literal|true
return|;
block|}
try|try
block|{
comment|// Exit immediately if the YARN app fails
return|return
name|yarnClient
operator|.
name|getApplicationReport
argument_list|(
name|infraAppId
argument_list|)
operator|.
name|getYarnApplicationState
argument_list|()
operator|==
name|YarnApplicationState
operator|.
name|FAILED
return|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|YarnException
name|e
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
block|}
decl_stmt|;
name|Optional
argument_list|<
name|Properties
argument_list|>
name|namenodeProperties
init|=
name|DynoInfraUtils
operator|.
name|waitForAndGetNameNodeProperties
argument_list|(
name|exitCheckSupplier
argument_list|,
name|localConf
argument_list|,
name|client
operator|.
name|getNameNodeInfoPath
argument_list|()
argument_list|,
name|LOG
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|namenodeProperties
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|fail
argument_list|(
literal|"Unable to fetch NameNode properties"
argument_list|)
expr_stmt|;
block|}
name|DynoInfraUtils
operator|.
name|waitForNameNodeReadiness
argument_list|(
name|namenodeProperties
operator|.
name|get
argument_list|()
argument_list|,
literal|3
argument_list|,
literal|false
argument_list|,
name|exitCheckSupplier
argument_list|,
name|localConf
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
name|assertClusterIsFunctional
argument_list|(
name|localConf
argument_list|,
name|namenodeProperties
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|ContainerId
argument_list|,
name|Container
argument_list|>
name|namenodeContainers
init|=
name|miniYARNCluster
operator|.
name|getNodeManager
argument_list|(
literal|0
argument_list|)
operator|.
name|getNMContext
argument_list|()
operator|.
name|getContainers
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|ContainerId
argument_list|,
name|Container
argument_list|>
name|datanodeContainers
init|=
name|miniYARNCluster
operator|.
name|getNodeManager
argument_list|(
literal|1
argument_list|)
operator|.
name|getNMContext
argument_list|()
operator|.
name|getContainers
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|ContainerId
argument_list|,
name|Container
argument_list|>
name|amContainers
init|=
name|miniYARNCluster
operator|.
name|getNodeManager
argument_list|(
literal|2
argument_list|)
operator|.
name|getNMContext
argument_list|()
operator|.
name|getContainers
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|namenodeContainers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|2
argument_list|,
name|namenodeContainers
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
operator|.
name|getContainerId
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|2
argument_list|,
name|datanodeContainers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|amContainers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|amContainers
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
operator|.
name|getContainerId
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for workload job to start and complete"
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
parameter_list|()
lambda|->
block|{
try|try
block|{
return|return
name|client
operator|.
name|getWorkloadJob
argument_list|()
operator|!=
literal|null
operator|&&
name|client
operator|.
name|getWorkloadJob
argument_list|()
operator|.
name|isComplete
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|IllegalStateException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
argument_list|,
literal|3000
argument_list|,
literal|60000
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Workload job completed"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|client
operator|.
name|getWorkloadJob
argument_list|()
operator|.
name|isSuccessful
argument_list|()
condition|)
block|{
name|fail
argument_list|(
literal|"Workload job failed"
argument_list|)
expr_stmt|;
block|}
name|Counters
name|counters
init|=
name|client
operator|.
name|getWorkloadJob
argument_list|()
operator|.
name|getCounters
argument_list|()
decl_stmt|;
name|assertEquals
argument_list|(
literal|6
argument_list|,
name|counters
operator|.
name|findCounter
argument_list|(
name|AuditReplayMapper
operator|.
name|REPLAYCOUNTERS
operator|.
name|TOTALCOMMANDS
argument_list|)
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|counters
operator|.
name|findCounter
argument_list|(
name|AuditReplayMapper
operator|.
name|REPLAYCOUNTERS
operator|.
name|TOTALINVALIDCOMMANDS
argument_list|)
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for infra application to exit"
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
parameter_list|()
lambda|->
block|{
try|try
block|{
name|ApplicationReport
name|report
init|=
name|yarnClient
operator|.
name|getApplicationReport
argument_list|(
name|infraAppId
argument_list|)
decl_stmt|;
return|return
name|report
operator|.
name|getYarnApplicationState
argument_list|()
operator|==
name|YarnApplicationState
operator|.
name|KILLED
return|;
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|YarnException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
argument_list|,
literal|3000
argument_list|,
literal|300000
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for metrics file to be ready"
argument_list|)
expr_stmt|;
comment|// Try to read the metrics file
name|Path
name|hdfsStoragePath
init|=
operator|new
name|Path
argument_list|(
name|fs
operator|.
name|getHomeDirectory
argument_list|()
argument_list|,
name|DynoConstants
operator|.
name|DYNAMOMETER_STORAGE_DIR
operator|+
literal|"/"
operator|+
name|infraAppId
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|metricsPath
init|=
operator|new
name|Path
argument_list|(
name|hdfsStoragePath
argument_list|,
literal|"namenode_metrics"
argument_list|)
decl_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
parameter_list|()
lambda|->
block|{
try|try
block|{
name|FSDataInputStream
name|in
init|=
name|fs
operator|.
name|open
argument_list|(
name|metricsPath
argument_list|)
decl_stmt|;
name|String
name|metricsOutput
init|=
name|in
operator|.
name|readUTF
argument_list|()
decl_stmt|;
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Just assert that there is some metrics content in there
name|assertTrue
argument_list|(
name|metricsOutput
operator|.
name|contains
argument_list|(
literal|"JvmMetrics"
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
argument_list|,
literal|3000
argument_list|,
literal|60000
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|fs
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|OUTPUT_PATH
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
DECL|method|assertClusterIsFunctional (Configuration localConf, Properties namenodeProperties)
specifier|private
name|void
name|assertClusterIsFunctional
parameter_list|(
name|Configuration
name|localConf
parameter_list|,
name|Properties
name|namenodeProperties
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Test that we can successfully write to / read from the cluster
try|try
block|{
name|URI
name|nameNodeUri
init|=
name|DynoInfraUtils
operator|.
name|getNameNodeHdfsUri
argument_list|(
name|namenodeProperties
argument_list|)
decl_stmt|;
name|DistributedFileSystem
name|dynoFS
init|=
operator|(
name|DistributedFileSystem
operator|)
name|FileSystem
operator|.
name|get
argument_list|(
name|nameNodeUri
argument_list|,
name|localConf
argument_list|)
decl_stmt|;
name|Path
name|testFile
init|=
operator|new
name|Path
argument_list|(
literal|"/tmp/test/foo"
argument_list|)
decl_stmt|;
name|dynoFS
operator|.
name|mkdir
argument_list|(
name|testFile
operator|.
name|getParent
argument_list|()
argument_list|,
name|FsPermission
operator|.
name|getDefault
argument_list|()
argument_list|)
expr_stmt|;
name|FSDataOutputStream
name|out
init|=
name|dynoFS
operator|.
name|create
argument_list|(
name|testFile
argument_list|,
operator|(
name|short
operator|)
literal|1
argument_list|)
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|42
argument_list|)
expr_stmt|;
name|out
operator|.
name|hsync
argument_list|()
expr_stmt|;
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
name|FileStatus
index|[]
name|stats
init|=
name|dynoFS
operator|.
name|listStatus
argument_list|(
name|testFile
operator|.
name|getParent
argument_list|()
argument_list|)
decl_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|stats
operator|.
name|length
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"foo"
argument_list|,
name|stats
index|[
literal|0
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to write or read"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
DECL|method|awaitApplicationStartup ()
specifier|private
name|void
name|awaitApplicationStartup
parameter_list|()
throws|throws
name|TimeoutException
throws|,
name|InterruptedException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Waiting for application ID to become available"
argument_list|)
expr_stmt|;
name|GenericTestUtils
operator|.
name|waitFor
argument_list|(
parameter_list|()
lambda|->
block|{
try|try
block|{
name|List
argument_list|<
name|ApplicationReport
argument_list|>
name|apps
init|=
name|yarnClient
operator|.
name|getApplications
argument_list|()
decl_stmt|;
if|if
condition|(
name|apps
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|infraAppId
operator|=
name|apps
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getApplicationId
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|apps
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
name|fail
argument_list|(
literal|"Unexpected: more than one application"
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
decl||
name|YarnException
name|e
parameter_list|)
block|{
name|fail
argument_list|(
literal|"Unexpected exception: "
operator|+
name|e
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
argument_list|,
literal|1000
argument_list|,
literal|60000
argument_list|)
expr_stmt|;
block|}
DECL|method|createAndStartClient (Configuration localConf)
specifier|private
name|Client
name|createAndStartClient
parameter_list|(
name|Configuration
name|localConf
parameter_list|)
block|{
specifier|final
name|Client
name|client
init|=
operator|new
name|Client
argument_list|(
name|JarFinder
operator|.
name|getJar
argument_list|(
name|ApplicationMaster
operator|.
name|class
argument_list|)
argument_list|,
name|JarFinder
operator|.
name|getJar
argument_list|(
name|Assert
operator|.
name|class
argument_list|)
argument_list|)
decl_stmt|;
name|client
operator|.
name|setConf
argument_list|(
name|localConf
argument_list|)
expr_stmt|;
name|Thread
name|appThread
init|=
operator|new
name|Thread
argument_list|(
parameter_list|()
lambda|->
block|{
try|try
block|{
name|client
operator|.
name|run
argument_list|(
operator|new
name|String
index|[]
block|{
literal|"-"
operator|+
name|Client
operator|.
name|MASTER_MEMORY_MB_ARG
operator|,
literal|"128"
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|CONF_PATH_ARG
operator|,
name|confZip
operator|.
name|toString
argument_list|()
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|BLOCK_LIST_PATH_ARG
operator|,
name|blockImageOutputDir
operator|.
name|toString
argument_list|()
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|FS_IMAGE_DIR_ARG
operator|,
name|fsImageTmpPath
operator|.
name|getParent
argument_list|()
operator|.
name|toString
argument_list|()
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|HADOOP_BINARY_PATH_ARG
operator|,
name|hadoopTarballPath
operator|.
name|getAbsolutePath
argument_list|()
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|DATANODES_PER_CLUSTER_ARG
operator|,
literal|"2"
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|DATANODE_MEMORY_MB_ARG
operator|,
literal|"128"
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|DATANODE_NODELABEL_ARG
operator|,
name|DATANODE_NODELABEL
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|NAMENODE_MEMORY_MB_ARG
operator|,
literal|"256"
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|NAMENODE_METRICS_PERIOD_ARG
operator|,
literal|"1"
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|NAMENODE_NODELABEL_ARG
operator|,
name|NAMENODE_NODELABEL
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|SHELL_ENV_ARG
operator|,
literal|"HADOOP_HOME="
operator|+
name|getHadoopHomeLocation
argument_list|()
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|SHELL_ENV_ARG
operator|,
literal|"HADOOP_CONF_DIR="
operator|+
name|getHadoopHomeLocation
argument_list|()
operator|+
literal|"/etc/hadoop"
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|WORKLOAD_REPLAY_ENABLE_ARG
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|WORKLOAD_INPUT_PATH_ARG
operator|,
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
literal|"/tmp/audit_trace_direct"
argument_list|)
argument_list|)
operator|.
name|toString
argument_list|()
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|WORKLOAD_OUTPUT_PATH_ARG
operator|,
name|fs
operator|.
name|makeQualified
argument_list|(
operator|new
name|Path
argument_list|(
name|OUTPUT_PATH
argument_list|)
argument_list|)
operator|.
name|toString
argument_list|()
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|WORKLOAD_THREADS_PER_MAPPER_ARG
operator|,
literal|"1"
operator|,
literal|"-"
operator|+
name|Client
operator|.
name|WORKLOAD_START_DELAY_ARG
operator|,
literal|"10s"
operator|,
literal|"-"
operator|+
name|AMOptions
operator|.
name|NAMENODE_ARGS_ARG
operator|,
literal|"-Ddfs.namenode.safemode.extension=0"
block|}
argument_list|)
decl_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error running client"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_empty_stmt
unit|)
empty_stmt|;
end_empty_stmt

begin_expr_stmt
name|appThread
operator|.
name|start
argument_list|()
expr_stmt|;
end_expr_stmt

begin_return
return|return
name|client
return|;
end_return

begin_function
unit|}    private
DECL|method|getResourcePath (String resourceName)
specifier|static
name|URI
name|getResourcePath
parameter_list|(
name|String
name|resourceName
parameter_list|)
block|{
try|try
block|{
return|return
name|TestDynamometerInfra
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
operator|.
name|getResource
argument_list|(
name|resourceName
argument_list|)
operator|.
name|toURI
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|URISyntaxException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
block|}
end_function

begin_comment
comment|/**    * Get the Hadoop home location (i.e. for {@code HADOOP_HOME}) as the only    * directory within the unpacked location of the Hadoop tarball.    *    * @return The absolute path to the Hadoop home directory.    */
end_comment

begin_function
DECL|method|getHadoopHomeLocation ()
specifier|private
name|String
name|getHadoopHomeLocation
parameter_list|()
block|{
name|File
index|[]
name|files
init|=
name|hadoopUnpackedDir
operator|.
name|listFiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|files
operator|==
literal|null
operator|||
name|files
operator|.
name|length
operator|!=
literal|1
condition|)
block|{
name|fail
argument_list|(
literal|"Should be 1 directory within the Hadoop unpacked dir"
argument_list|)
expr_stmt|;
block|}
return|return
name|files
index|[
literal|0
index|]
operator|.
name|getAbsolutePath
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Look for the resource files relevant to {@code hadoopBinVersion} and upload    * them onto the MiniDFSCluster's HDFS for use by the subsequent jobs.    *    * @param hadoopBinVersion    *          The version string (e.g. "3.1.1") for which to look for resources.    */
end_comment

begin_function
DECL|method|uploadFsimageResourcesToHDFS (String hadoopBinVersion)
specifier|private
specifier|static
name|void
name|uploadFsimageResourcesToHDFS
parameter_list|(
name|String
name|hadoopBinVersion
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Keep only the major/minor version for the resources path
name|String
index|[]
name|versionComponents
init|=
name|hadoopBinVersion
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
if|if
condition|(
name|versionComponents
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|fail
argument_list|(
literal|"At least major and minor version are required to be specified; got: "
operator|+
name|hadoopBinVersion
argument_list|)
expr_stmt|;
block|}
name|String
name|hadoopResourcesPath
init|=
literal|"hadoop_"
operator|+
name|versionComponents
index|[
literal|0
index|]
operator|+
literal|"_"
operator|+
name|versionComponents
index|[
literal|1
index|]
decl_stmt|;
name|String
name|fsImageResourcePath
init|=
name|hadoopResourcesPath
operator|+
literal|"/"
operator|+
name|FSIMAGE_FILENAME
decl_stmt|;
name|fs
operator|.
name|copyFromLocalFile
argument_list|(
operator|new
name|Path
argument_list|(
name|getResourcePath
argument_list|(
name|fsImageResourcePath
argument_list|)
argument_list|)
argument_list|,
name|fsImageTmpPath
argument_list|)
expr_stmt|;
name|fs
operator|.
name|copyFromLocalFile
argument_list|(
operator|new
name|Path
argument_list|(
name|getResourcePath
argument_list|(
name|fsImageResourcePath
operator|+
literal|".md5"
argument_list|)
argument_list|)
argument_list|,
name|fsImageTmpPath
operator|.
name|suffix
argument_list|(
literal|".md5"
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|.
name|copyFromLocalFile
argument_list|(
operator|new
name|Path
argument_list|(
name|getResourcePath
argument_list|(
name|hadoopResourcesPath
operator|+
literal|"/"
operator|+
name|VERSION_FILENAME
argument_list|)
argument_list|)
argument_list|,
name|fsVersionTmpPath
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|auditTraceDir
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|copyBytes
argument_list|(
name|TestDynamometerInfra
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
operator|.
name|getResourceAsStream
argument_list|(
literal|"audit_trace_direct/audit0"
argument_list|)
argument_list|,
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
name|auditTraceDir
argument_list|,
literal|"audit0"
argument_list|)
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|blockImageOutputDir
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|blockFile
range|:
operator|new
name|String
index|[]
block|{
literal|"dn0-a-0-r-00000"
block|,
literal|"dn1-a-0-r-00001"
block|,
literal|"dn2-a-0-r-00002"
block|}
control|)
block|{
name|IOUtils
operator|.
name|copyBytes
argument_list|(
name|TestDynamometerInfra
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
operator|.
name|getResourceAsStream
argument_list|(
literal|"blocks/"
operator|+
name|blockFile
argument_list|)
argument_list|,
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
name|blockImageOutputDir
argument_list|,
name|blockFile
argument_list|)
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|File
name|tempConfZip
init|=
operator|new
name|File
argument_list|(
name|testBaseDir
argument_list|,
literal|"conf.zip"
argument_list|)
decl_stmt|;
name|ZipOutputStream
name|zos
init|=
operator|new
name|ZipOutputStream
argument_list|(
operator|new
name|FileOutputStream
argument_list|(
name|tempConfZip
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|file
range|:
operator|new
name|String
index|[]
block|{
literal|"core-site.xml"
block|,
literal|"hdfs-site.xml"
block|,
literal|"log4j.properties"
block|}
control|)
block|{
name|zos
operator|.
name|putNextEntry
argument_list|(
operator|new
name|ZipEntry
argument_list|(
literal|"etc/hadoop/"
operator|+
name|file
argument_list|)
argument_list|)
expr_stmt|;
name|InputStream
name|is
init|=
name|TestDynamometerInfra
operator|.
name|class
operator|.
name|getClassLoader
argument_list|()
operator|.
name|getResourceAsStream
argument_list|(
literal|"conf/etc/hadoop/"
operator|+
name|file
argument_list|)
decl_stmt|;
name|IOUtils
operator|.
name|copyBytes
argument_list|(
name|is
argument_list|,
name|zos
argument_list|,
name|conf
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|is
operator|.
name|close
argument_list|()
expr_stmt|;
name|zos
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
name|zos
operator|.
name|close
argument_list|()
expr_stmt|;
name|fs
operator|.
name|copyFromLocalFile
argument_list|(
operator|new
name|Path
argument_list|(
name|tempConfZip
operator|.
name|toURI
argument_list|()
argument_list|)
argument_list|,
name|confZip
argument_list|)
expr_stmt|;
name|tempConfZip
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
end_function

unit|}
end_unit

